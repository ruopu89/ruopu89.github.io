<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python基础练习-递归与生成器]]></title>
    <url>%2F2019%2F11%2F20%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E9%80%92%E5%BD%92%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[把一个字典扁平化 12345678910111213141516171819202122232425262728293031# 源字典&#123;'a':&#123;'b':1,'c':2&#125;,'d':&#123;'e':3,'f':&#123;'g':4&#125;&#125;&#125;# 目标字典 &#123;'a.c':2,'d.e':3,'d.f'g':4,'a.b':1&#125;source = &#123;'a':&#123;'b':1,'c':2&#125;,'d':&#123;'e':3,'f':&#123;'g':4&#125;&#125;&#125;target = &#123;&#125;# recursiondef flatmap(src,prefix=''): for k,v in src.items(): if isinstance(v,(list,tuple,set,dict)): flatmap(v,prefix=prefix+k+'.') # 递归调用 else: target[prefix+k] = v flatmap(source)print(target)- 一般这种函数都会生成一个新的字典，因此改造一下dest字典可以由内部创建，也可以由外部提供 source = &#123;'a':&#123;'b':1,'c':2&#125;,'d':&#123;'e':3,'f':&#123;'g':4&#125;&#125;&#125;# recursiondef flatmap(src,dest=None,prefix=''): if dest == None: dest = &#123;&#125; for k,v in src.items(): if isinstance(v,(list,tuple,set,dict)): flatmap(v,dest,prefix=prefix+k+'.') # 递归调用 else: dest[prefix+k] = v return destprint(flatmap(source)) 实现Base64编码 1# 要求自己实现算法 求2个字符串的最长公共子串12]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>递归与生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-装饰器]]></title>
    <url>%2F2019%2F11%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[装饰器 需求 一个加法函数，想增强它的功能，能够输出被调用过以及调用的参数信息 12345678910def add(x,y): return x + y增加信息输出功能def add(x,y): print("call add,x+y") # 日志输出到控制台 return x + y# 上面的加法函数是完成了需求，但是有以下的缺点：# 打印语句的耦合太高# 加法函数属于业务功能，而输出信息的功能，属于非业务功能代码，不该放在业务函数加法中 做到了业务功能分离，但是fn函数调用传参是个问题 12345678910def add(x,y): returndef logger(fn): print('begin') # 增强的输出 x = fn(4,5) print('end') # 增加的功能 return xprint(logger(add)) 解决了传参的问题，进一步改变 12345678910def add(x,y): return x + ydef logger(fn,*args,**kwargs): print('begin') x = fn(*args,**kwargs) print('end') return xprint(logger(add,5,y=60)) 柯里化 1234567891011121314def add(x,y): return x + ydef logger(fn): def wrapper(*args,**kwargs): print('begin') x = fn(*args,**kwargs) print('end') return x return wrapperprint(logger(add)(5,y=50))# 换一种写法add = logger(add)print(add(x=5,y=10)) 装饰器语法糖 1234567891011121314def logger(fn): def wrapper(*args,**kwargs): print('begin') x = fn(*args,**kwargs) print('end') return x return wrapper@logger # 等价于add = logger(add)def add(x,y): return x + yprint(add(45,40))# @logger是什么？这就是装饰器语法 装饰器（无参） 它是一个函数 函数作为它的形参 返回值也是一个函数 可以使用@functionname方式，简化调用 装饰器和高阶函数 装饰器是高阶函数，但装饰器是对传入函数的功能的装饰（功能增强） 12345678910111213141516171819202122import datetimeimport timedef logger(fn): def wrap(*args,**kwargs): # before功能增强 print("args=&#123;&#125;,kwargs=&#123;&#125;".format(args,kwargs)) start = datetime.datetime.now() ret = fn(*args,**kwargs) # after功能增强 duration = datetime.datetime.now() - start print("function &#123;&#125; to ok &#123;&#125;s".format(fn.__name__,duration.total_seconds())) return ret return wrap@logger # 相当于 add = logger(add)def add(x,y): print("=====call add=====") time.sleep(2) return x + yprint(add(4,y=7)) 怎么理解装饰器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687def add(x,y,file): print("call &#123;&#125;,&#123;&#125;+&#123;&#125;".format(add.__name__,x,y),file=file) # 双下划线是函数的特殊属性，__name__可以获取函数的名称，file是print()的选项，可以输出到外面，如果要灵# 活设置参数，应该把参数写到上面定义add函数的地方，print中前一个file是形参，后一个file是传进来的参数 return x+yadd(4,5)# 通过嵌套函数可以实现用外部函数将里面的函数包起来输出：call add,4+59=======================================================================================def add1(x,y): return x + ydef add2(x,y,z): return x+y+zdef add3(x,y,*args,z): return x+y+zdef logger(fn,*args,**kwargs): # 这里用了两个可变参数 print('before') ret = fn(*args,**kwargs) # 这里用的是解参数 print('after') return retprint(logger(add2,4,x=5,y=6)) # 这里调用的时候，logger中fn对应的是add2，*args对应的是4,**kwargs对应的是x=5，y=6。当调用fn()函数# 时，会将*args等于4，**kwargs等于x=5,y=6代入到add2()函数中，这时，x为4，y为5，z为6，但顺序不一定# 是这样排列的。最后返回x+y+z的值，并赋值给ret并结束print(logger(add3,4,z=5,y=6))输出：beforeafter15beforeafter15def logger(fn): def _logger(*args,**kwargs): # 这里定义的参数是根据外层要调用的函数来设计的，如外层的add1到add3函数，这里这样定义都可以满足外层函数# 的要求。# 柯里化就是把第一个参数拿到外面来，之后的参数放到内层函数中去，因为是嵌套函数，里边的函数要能被用到，总# 要返回一个值，上面返回的是内层函数的一个引用，这里就返回了_logger print('before') ret = fn(*args,**kwargs) # 这里用的是解参数。这里一定要写成这样，不能在这里用return，不然下面就不执行了 print('after') return ret # 被包装函数也应该返回，不然会破坏原函数，原函数本来有返回的。 return _logger # 这个_logger函数叫包装函数，里面的fn函数叫被包装函数，这一句非常重要，一定要有返回值，一定返回内层函数# 的引用。我们这里对原函数没有任何侵入式# foo = logger(add1)# print(foo(4,5))# logger(add1)(40,30)# add1 = logger(add1) # fn是自由变量，里面引用是成为闭包，这个变量被留下来了。python提供了一种简单的方式，@logger，如下@logger # 装饰器函数，add1 = logger(add1)，这里add1被覆盖掉了，之后再调用add1就相当于调用内层函数_logger，_logger中的fn函数才是真正进行运算的。_logger函数就相当于add1函数的增加版，即实现了add1# 函数的功能，还增加了其他功能。把函数加上@后，就会把其下面的函数当作参数传入加@的函数中，再次调用add1# 时，执行的实际是logger函数def add1(x,y): return x + yadd1(4,100)输出：beforeafter104# 如果换成下面的写法，它的本质是，返回了内层函数_logger，_logger中的fn并没有丢，通过闭包把这个外部变# 量保存下来了，当真正调用add1时，实际上调用的是内层函数_logger，调用内层函数_logger时，这个fn还在，# 它保存在自由变量里，这个fn才是真正被包装的函数，也就是最原始的那个函数，现在的add1已经被覆盖掉了，所# 以print()中的add1已经是内层函数了，传参被_logger函数的参数接收了，接收后放在fn函数中，这就是保存下# 来的自由变量，指向的是外部的add1函数add1 = logger(add1) print(add1(x=5,y=10))# 装饰器是一种语法糖，对上面两行代码的代替。用@logger代替add1 = logger(add1)，而且logger函数应该写# 在@logger前面，不然@logger会提示不认识logger函数。这里必须先定义logger函数，之后定义装饰器函数# @logger，最后定义add1函数@ logger # 装饰器只接收到add1函数的标识符，并不包括参数，参数由内层函数_logger管def add1(x,y): # 这里是原始的add1函数标识符 return x + yprint(add1(45,40)) # 这里调用的是被装饰器函数修改过的add1函数，指的是内层函数的一个引用# 装饰器函数主机是为了装饰，但函数功能增强，必免侵入式 副作用 12345678910111213141516def logger(fn): def wrapper(*args,**kwargs): 'I am wrapper' print('begin') x = fn(*args,**kwargs) print('end') return x return wrapper@logger # add = logger(add)def add(x,y): '''This is a function for add''' return x + yprint("name=&#123;&#125;,doc=&#123;&#125;".format(add.__name__,add.__doc__))# 原函数对象的属性都被替换了，而使用装饰器，我们的需求是查看被封装函数的属性，如何解决？ 提供一个函数，被封装函数属性 ==copy==&gt;包装函数属性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# def copy_properties(src,dst):# dst.__name__ = src.__name__# dst.__doc__ = src.__doc__# dst.__qualname__ = src.__qualname__# 把上面的代码改为装饰器，如下：def copy_properties(src): def _copy(dst): dst.__name__ = src.__name__ dst.__doc__ = src.__doc__ dst.__qualname__ = src.__qualname__ return dst return _copy def logger(fn): @copy_properties(fn) # wrapper = copy_properties(fn)(wrapper)# 这里先不看@符号，copy_properties(fn)这个函数调用中的fn参数会被传到copy_properties函数中当作# src参数，下面的add会被当作fn从logger传进来，这时add就变成copy_properties的src参数了，这里返回# 的就是_copy这个内层函数了。当copy_properties(fn)加了@后，就相当于@_copy，即使是同一个函数对象，# 不同次调用，里面的结果都不一样，因为_copy是嵌入在内层的函数，在外部是不可见的，所以要用函数调用返回# 回来，相当于@copy_properties.wrapper = @_copy，@_copy要将其下面的函数的名字当作参数传入，这样就# 成了_copy(logger.wrapper)，也就是说logger中的wrapper函数要作为参数传到_copy中去，它会把@下面的# wrapper覆盖一次，_copy(wrapper)返回什么，在_copy中就应该返回什么，也就是说_copy一定要有返回值，# 而不能是None，如果是None，那么下面的wrapper函数也就无法执行了，_copy(wrapper)的返回值还要赋值给# wrapper，_copy(wrapper)的值就是它自己，也就是dst。使用装饰器时，有几层就要return几层。 def wrapper(*args,**kwargs):# 柯里化就是把第一个参数拿到外面来，之后的参数放到内层函数中去，因为是嵌套函数，里边的函数要能被用到，总# 要返回一个值，这里返回的是内层函数的一个引用，这里就返回了wrapper '''This is a wrapper''' print('before') ret = fn(*args,**kwargs) # 这里用的是解参数。这里一定要写成这样，不能在这里用return，不然下面就不执行了 print('after') return ret # 被包装函数也应该返回，不然会破坏原函数，原函数本来有返回的。# copy_properties(fn,_logger) # 这是一个普通函数调用，与wrapper函数没关系。这一句放在这里时，已经有了wrapper和fn函数另外，这一句一# 定要放在return _logger前。这个return就是装饰器@logger干的事情，这个装饰器相当于有一个函数调用，调# 用时给logger传一个实参，fn就是add，def _logger是定义，什么都不用动，因为还没有调用它，这里指外部还# 没有调用过logger函数，如print(logger(add1(39,23)))这样。这时执行copy_properties函数，将fn的属# 性复制给_logger，那么当使用help或用__name__或__doc__时，就会显示add函数的属性了 return _logger@logger # 加入装饰器后，看一下add.__name和add.__doc__是不是还是add。结果显示是_logger，但我们想看的是add的帮助文档# 这里本身也不应该改变原函数的帮助文档。所以要添加一个copy_properties函数，并在logger函数中调用def add(x,y): 'This is a function' # 文档字符串，必须放在函数后的第一行，如果有多行，要用三引号 ret = x + y return ret# add(4,100)print(add.__name__,add.__doc__,add.__qualname__,sep='\n')# print(help(add))# help本身就是在调用__name__和__doc__这些东西# __qualname__与add没有关系，这个打印的叫限定名print("name=&#123;&#125;,doc=&#123;&#125;".format(add.__name__,add.__doc__)) 通过copy_properties函数将被包装函数的属性覆盖掉包装函数 凡是被装饰的函数都需要复制这些属性，这个函数很通用 可以将复制属性的函数构建成装饰器函数，带参装饰器 带参装饰器1234567891011121314151617181920# 获取函数的执行时长，对超过阈值的函数记录一下def logger(duration): def _logger(fn): @copy_properties(fn) # wrapper = wrapper(fn)(wrapper) # 这里使用上面定义的copy_properties函数 def wrapper(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() print('so slow') if delta &gt; duration else print('so fast') return ret return wrapper return _logger@logger(5) # add = logger(5)(add)def add(x,y): time.sleep(3) return x + yprint(add(5,6)) 带参装饰器 它是一个函数 函数作为它的形参 返回值是一个不带参的装饰器函数 使用@functionname(参数列表)方式调用 可以看做在装饰器外层又加了一层函数 12345678910111213# 将记录的功能提取出来，这样就可以通过外部提供的函数来灵活的控制输出def logger(duration,func=lambda name,duration:print('&#123;&#125; took &#123;&#125;s'.format(name,duration))): def _logger(fn): @copy_properties(fn) # wrapper = wrapper(fn)(wrapper) def wrapper(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() if delta &gt; duration: func(fn.__name__,duration) return ret return wrapper return _logger 练习12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 获取函数的执行时长，对超过阈值的函数记录一下import datetimeimport timedef logger(t): def _logger(fn): def wrap(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) duration = (datetime.datetime.now() - start).total_seconds() if duration &gt; t: print("function &#123;&#125; took &#123;&#125;s.".format(fn.__name__,duration)) return ret return wrap return _logger@logger(3) # add = logger(50)(add)def add(x,y): print("=====call add=====") time.sleep(5) return x + yprint(add(5,6))# 带参装饰器最多三层def logger(t1,t2): def _logger(fn): def wrap(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) duration = (datetime.datetime.now() - start).total_seconds() if duration &gt; t1 and duration &lt; t2: print("function &#123;&#125; took &#123;&#125;s.".format(fn.__name__,duration)) return ret return wrap return _logger@logger(3,5) # add = logger(50)(add)def add(x,y): print("=====call add=====") time.sleep(5) return x + yprint(add(5,6)) =======================================================================================def logger(fn): return 10@logger # 这里等价于add1 = logger(add1)，加了@实际就是把其下面的函数拿来做参数转入这个加了@函数def add1(x,y): # 这样做完，add1就变成了上面的logger函数中的return 10了 return x + yprint(add1)# 这里借用了装饰器的语法，但并没有对函数进行装饰 文档字符串 python的文档 python是文档字符串Documentation Strings 在函数语句块的第一行，且习惯是多行的文本，所以多使用三引号 惯例是首字母大写，第一行写概述，空一行，第三行写详细描述 可以使用特殊属性__doc__访问这个文档 1234567def add(x,y): """This is a function of addition""" a = x + y return x + yprint("name=&#123;&#125;\ndoc=&#123;&#125;".format(add.__name__,add.__doc__))print(help(add)) functools模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960- functools.update_wrapper(wrapper,wrapped,assigned=WRAPPER_ASSIGNMENTS,updated=WRAPPER_UPDATES)- 类似copy_properties功能- wrapper：包装函数、被更新者，wrapped：被包装函数、数据源- 元组WRAPPER_ASSIGNMENTS中是要被覆盖的属性- '__module__'，'__name__'，'__qualname__'，'__doc__'，'__annotations__'- 表示模块名、名称、限定名、文档、参数详解- 元组WRAPPER_UPDATES中是要被更新的属性，__dict__属性字典- 增加一个__wrapped__属性，保留着wrapped函数import datetime,time,functoolsdef logger(duration,func=lambda name,duration:print('&#123;&#125; took &#123;&#125;s'.format(name,duration))): def _logger(fn): def wrapper(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() if delta &gt; duration: func(fn.__name__,duration) return ret return functools.update_wrapper(wrapper,fn) return _logger@logger(5) # add = logger(5)(add)def add(x,y): time.sleep(1) return x + yprint(add(5,6),add.__name__,add.__wrapped__,add.__dict__,sep='\n')- @functools.wraps(wrapped,assigned=WRAPPER_ASSIGNMENTS,updated=WRAPPER_UPDATES)- 类似copy_properties功能- wrapped被包装函数- 元组WRAPPER_ASSIGNMENTS中是要被覆盖的属性- '__module__'，'__name__'，'__qualname__'，'__doc__'，'__annotations__'- 表示模块名、名称、限定名、文档、参数详解- 元组WRAPPER_UPDATES中是要被更新的属性，__dict__属性字典- 增加一个__wrapped__属性，保留着wrapped函数import datetime,time,functoolsdef logger(duration,func=lambda name,duration:print('&#123;&#125; took &#123;&#125;s'.format(name,duration))): def _logger(fn): @functools.wraps(fn) def wrapper(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() if delta &gt; duration: func(fn.__name__,duration) return ret return wrapper return _logger@logger(5) # add = logger(5)(add)def add(x,y): time.sleep(1) return x + yprint(add(5,6),add.__name__,add.__wrapped__,add.__dict__,sep='\n') 个人总结 装饰器是对现有函数的增强 看到装饰器的图时，就会想到钢铁侠的反浩克装甲—维罗妮卡 装饰之后调用的还是原函数的名字，但功能已经是装饰后听效果了 装饰器函数的内层函数就是原函数的增强代码，即实现原函数功能，又增加了功能 函数加了@符号后，就会将其下面的函数当作参数传入到加了@符号的函数中 带参装饰器可以有多个参数，并且也会把其下面的函数当作参数传入这个带参的函数中的内层函数里 带参装饰器一般最多使用三层，每一层都返回其内层函数的函数名，这样就可以使用内层函数被上一层函数调用。只有最内一层的函数返回的是原函数的值 装饰器函数演化过程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581. 普通函数def add(x,y): return x + y2. 加强功能def add(x,y): print("call add,x+y") # 日志输出到控制台 return x + y3. 业务分离def add(x,y): return ...def logger(fn,*args,**kwargs): ... x = fn(*args,**kwargs) ... return x4. 柯里化def add(x,y): return ...def logger(fn): # 柯里化就是把第一个参数提出去，之后的参数当内层函数的参数 def wrapper(*args,**kwargs): ... x = fn(*args,**kwargs) ... return x return wrapper# 下面是调用方法print(logger(add)(5,y=50))# 换一种写法add = logger(add)print(add(x=5,y=10))5. 装饰器语法糖def logger(fn): def wrapper(*args,**kwargs): ... x = fn(*args,**kwargs) ... return x return wrapper@logger # 等价于add = logger(add)，add在logger中就是fn了def add(x,y): return ...6. 带参装饰器# 因为无法使用原函数的属性信息，所以讲到了带参装饰器def copy_properties(src): def _copy(dst): ... return dst return _copy# 因为_copy就是wrapper，这里只是把原函数的属性信息复制到目标函数中，目录函数就是下面的wrapper，因为上# 面讲到过，装饰器就是用wrapper函数覆盖了原函数，所以要把原函数的属性保留在wrapper中def logger(fn): @copy_properties(fn) # wrapper = copy_properties(fn)(wrapper) def wrapper(*args,**kwargs): ...# 这实际就是把原函数内做fn，wrapper当作dst传入到了带参装饰器中7. 多参数装饰器def logger(t1,t2): def _logger(fn): def wrap(*args,**kwargs): start = datetime.datetime.now() ret = fn(*args,**kwargs) duration = (datetime.datetime.now() - start).total_seconds() if duration &gt; t1 and duration &lt; t2: print("function &#123;&#125; took &#123;&#125;s.".format(fn.__name__,duration)) return ret return wrap return _logger@logger(3,5) # add = logger(50)(add)。这里的参数数量与上面定义的logger的参数数量是一样的def add(x,y): 8. functools模块# 这个模块中的update_wrapper函数和wraps装饰器函数可以实现上面的copy_properties函数的功能，并且比我# 们自己写的函数的功能强。update_wrapper(wrapper,wrapped,assigned=,updated=)中的wrapper指包# 装，wrapped指被包装。被包装的是外面的add函数，是原函数，包装的是里面的wrapper函数。assigned表示# wrapper中的属性信息要被wrapped中的属性信息覆盖掉，也就是保留原函数的属性信息；updated指把wrapped# 中字典属性加到wrapper的字典属性中，如果key相同就覆盖了，如果不同就追加。- update_wrapper函数import functoolsdef logger(fn): # 这里用了两个可变参数 @copy_properties(fn) def _logger(*args,**kwargs): '''This is a wrapper''' print('before') ret = fn(*args,**kwargs) print('after') return ret functools.update_wrapper(_logger,fn) # # wrapped得是fn，不能是add，因为这里要用一个参数 print("&#123;&#125; &#123;&#125;".format(id(_logger),id(fn))) # 看一下下面打印的add1.__wrapped__是wrapper的还是fn的 return _logger@logger def add1(x,y): 'This is a function' ret = x + y return ret# add1(4,100)print(add1.__name__,add1.__doc__,add1.__qualname__,sep='\n')print('*'*40)print(id(add1.__wrapped__)) # 这是fn的id，所以这个新增的__wrapped__就是把fn给放进去了，这样就能找到原来的函数是谁了输出：139975566907728 139975566908408add1This is a functionadd1****************************************139975566908408- wraps函数# 这个装饰器函数只需要wrapped，而不需要wrapper，因为是装饰器函数，所以用@来将其下面的函数当做参数传入# 了，所以无需指定wrapperimport functoolsdef logger(fn): # 这里用了两个可变参数 @functools.wraps(fn) # wraps函数只需要写wrapped即可，至于wrapper，因为这里用了@符号，所以会把其下面的函数当作wrapper传入，这相当于 # functools.wraps(fn)(_logger) def _logger(*args,**kwargs): '''This is a wrapper''' print('before') ret = fn(*args,**kwargs) print('after') return ret # functools.update_wrapper(_logger,fn) # wrapped得是fn，不能是add，因为这里要用一个参数 print("&#123;&#125; &#123;&#125;".format(id(_logger),id(fn))) # 看一下下面打印的add1.__wrapped__是wrapper的还是fn的 return _logger@logger def add1(x,y): 'This is a function' ret = x + y return ret# add1(4,100)print(add1.__name__,add1.__doc__,add1.__qualname__,sep='\n')print('*'*40)print(id(add1.__wrapped__)) print('@'*40)print(add1.__wrapped__(4,90)) # 打印出了94,这说明__wrapped__保存了原函数的功能，这只是证明，而不是真正使用的方法输出：139975561244184 139975561244048add1This is a functionadd1****************************************139975561244048@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@94]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-高阶函数]]></title>
    <url>%2F2019%2F11%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[高阶函数 First Class Object 函数在Python中是一等公民 函数也是对象，可调用的对象 函数可以作为普通变量、参数、返回值等等 高阶函数 数学概念y=g(f(x)) 在数学和计算机科学中，高阶函数应当是至少满足下面一个条件的函数 接受一个或多个函数作为参数 输出一个函数 计数器 12345678910111213141516171819202122232425def counter(base): def inc(step=1): nonlocal base# 这里因为base是自由变量，在inc函数中 base += step是在重新赋值，所以要加上nonlocal，让inc函数向上一级且不是global环境找base函数 base += step return base return incfoo = counter(10)foo1 = counter(10)foo == foo1输出：False# 内存分为堆和栈，在堆内存中做对象的创建，栈是相对有限的空间，堆比栈大一些，但堆里是乱的(实际没这么乱，# 只是这样理解)，所以虚拟机才要回收走。我们在堆上创建两个对象foo和foo1，这两个对象都是inc创建出来的，# 这都是因为调用 counter()之后，inc又赋值给了foo和foo1，foo和foo1变量实际不在这，所以看到foo和foo1# 的地址不一样。当第一次调用counter()时，counter会压栈，counter的参数也压栈，压栈后要创建一段栈帧，# 创建栈帧后，里面要创建临时对象。这个对象就是inc，inc要把它的函数体执行完才能把inc赋值给foo，因为执行# 完inc最后要return，那么return后，从return base以上就全部消失了，因为栈里要清空，之后就要以把函数# 的return值赋给foo了。foo1的过程是一样的，但foo1是inc在堆里重新创建的对象，所以foo和foo1是两个完全# 不一样的对象。因为两个对象foo和foo1在堆中没有消亡，所以两个指向对象的函数inc在堆中也没有消亡。id(foo)输出：140341302380608id(foo1)输出：140341302381832 分析 函数counter是不是一个高阶函数 上面代码有没有什么问题？怎么改进 如何调用完成计数功能 foo = counter(10)和foo1 = counter(10)，请问foo和foo1相等吗？ 自定义sort函数 排序问题 依照内建函数sorted，请自行实现一个sort函数（不使用内建函数），能够为列表元素排序 思路 内建函数sorted函数是返回一个新的列表，可以设置升序或降序，可以设置一个排序的函数。自定义的sort函数也要实现这个功能 新建一个列表，遍历原列表，和新列表的值依次比较决定如何插入到新列表中 思考 sorted函数的实现原理，扩展到map、filter函数的实现原理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# sort函数实现。下面实现的什么排序？还能怎么改变def sort(iterable): ret = [] for x in iterable: for i,y in enumerate(ret): # 使用enumerate是为了给列表中的元素添加上索引，以方便下面比较。比较会将iterable中的数字与所 # 有ret列表中的数字比较，比较一次就进行一次下面的操作，当每轮全部比较完时，iterable中的数字也 # 就找到了在ret列表中应该放的确切位置 if x &gt; y: # 找到大的就地插入。如果换成x &lt; y呢，函数什么意思呢？ ret.insert(i,x) # 降序 break else: # 不大于，说明是最小的，尾部追加 ret.append(x) return ret# 开始这里是没有函数的，但我们认为if x &gt; y: 可以利用函数把它变成更加灵活的表现形式，要把它抽象出来，可# 以先写成一个if三元的形式，然后把它抽象成一个内部的函数，之后再把它变成一个外部函数，变成外部函数后要把# 它的形参和本地变量去掉，变成一个通用的函数。函数的封装要通用，它尽量不要直接引用外部的变量，除了在嵌套# 函数中使用闭包的时候。写函数的原则是，外部变量都应该不是通过可见性来访问的，而是通过传参的方式传递给你# 的。核心的逻辑，如果是可变的，把它提取出去，作为参数传递进来，因为函数是一等公民print(sort([1,2,5,4,2,3,5,6]))# sort函数实现。用一个参数控制顺序def sort(iterable,reverse=False): ret = [] for x in iterable: for i,y in enumerate(ret): flag = x &gt; y if reverse else x &lt; y if flag: # 是否能进一步改进 ret.insert(i,x) break else: ret.append(x) return retprint(sort([1,2,5,4,2,3,5,6]))# sort函数实现。下面实现的什么排序？还能怎么改变def sort(iterable,key=kambda a,b:a&gt;b): ret = [] for x in iterable: for i,y in enumerate(ret): if key(x,y): # 函数的返回值是bool ret.insert(i,x) break else: ret.append(x) return retprint(sort([1,2,5,4,2,3,5,6]))# sort函数实现def sort(iterable,reverse=False,key=lambda x,y:x&lt;y): ret = [] for x in iterable: for i,y in enumerate(ret): flag = key(x,y) if not reverse else not key(x,y) if flag: ret.insert(i,x) break else: ret.append(x) return retprint(sort([1,2,5,4,2,3,5,6])) 内建函数-高阶函数 sorted(iterable[,key][,reverse]) 排序 返回一个新的列表，对一个可迭代对象的所有元素排序，排序规则为key定义的函数，reverse表示是否排序翻转 sorted(lst,key=lambda x:6-x) 返回新列表 list.sort(key=lambda x:6-x) 就地修改 filter(function,iterable)-&gt;filter object 过滤数据 过滤可迭代对象的元素，返回一个迭代器 function一个具有一个参数的函数，返回bool 例如，过滤出数列中能被3整除的数字 list(filter(lambda x:x%3 == 0,[1,9,55,150,-3,78,28,123])) 因为x%3 == 0是一个逻辑表达式，那一定会返回True或False，这个表达式的值就是return值，所以这里返回的是一个bool类型。把x%3 == 0可以改为0或True，效果是怎样的？ map(func,*iterables) -&gt; map object 映射 对多个可迭代对象的元素按照指定的函数进行映射，返回一个迭代器 list(map(lambda x:2*x+1,range(5))) dict(map(lambda x:(x%5,x),range(500))) 只会显示下面5个信息是因为通过key过滤掉重复数据了? 柯里化 Currying 柯里化 指的是将原来接受两个参数的函数变成新的接受一个参数的函数的过程。新的函数返回一个以原有第二个参数为参数的函数 z = f(x,y)转换成z = f(x)(y)的形式 123456789101112131415# 举例：将加法函数柯里化def add(x,y): return x + y# 转换如下：def add(x): def _add(y): return x + y return _add # 这里应该返回一个函数add(5)(6)# 通过嵌套数就可以把函数转换成柯里化函数# 我们需要将add(4,5) ==&gt; add(4)(5) ==&gt; func(5) ==&gt; func=add(4)foo = add(4)print(foo(5))# 等价于下面的写法pinrt(add(4)(5))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ngrok简单配置与使用]]></title>
    <url>%2F2019%2F11%2F15%2Fngrok%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍​ ngrok是一个内网穿透的解决方案，它可以使你通过公网服务器连接到你本地的服务器 下载安装1234567-------------- 公网服务器--------------yum install -y gcc git mercurial bzr subversion golang golang-pkg-windows-amd64 golang-pkg-windows-386# 安装所需包git clone https://github.com/inconshreveable/ngrok.git# 克隆到本地 生成证书1234567891011121314151617181920212223242526272829cd ngrokmkdir certcd certexport NGROK_DOMAIN="abc.com"# 这里的域名就是你要访问的域名，需要在互联网可以解析到openssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj "/CN=$NGROK_DOMAIN" -days 5000 -out rootCA.pemopenssl genrsa -out device.key 2048openssl req -new -key device.key -subj "/CN=$NGROK_DOMAIN" -out device.csropenssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000# 生成密钥cp rootCA.pem ../assets/client/tls/ngrokroot.crt cp device.crt ../assets/server/tls/snakeoil.crt cp device.key ../assets/server/tls/snakeoil.key # 将密钥复制到指定位置cd ..GOOS=linux GOARCH=amd64 make release-server# 生成服务端包GOOS=linux GOARCH=amd64 make release-client# 生成linux客户端名# windows客户端# GOOS=windows GOARCH=amd64 make release-client# GOOS=windows GOARCH=386 make release-client# MacOS客户端# GOOS=darwin GOARCH=amd64 make release-client# GOOS=darwin GOARCH=386 make release-client./bin/ngrokd -domain="$NGROK_DOMAIN" -httpAddr=":28080" -httpsAddr=":28443" -tunnelAddr=":24443"# 指定端口并启动ngrok服务，如果不指定端口，http默认端口80，https默认端口443，tunnel默认端口4443，# tunnel端口是服务端与客户端联系的端口 客户端配置1234567891011121314151617181920212223登录服务器下载上面生成的客户端包，因为使用的是ubuntu客户端，所以下载ngrok包就可以了vim ngrok.cfg server_addr: "abc.com:24443"trust_host_root_certs: false# 添加一个ngrok的配置文件，注意这个文件是yaml文件，所以对格式要求很严格。冒号与后面引号之间是有空格的。# 配置的配置文件可以放在家目录，叫.ngrok./ngrok -config ngrok.cfg -proto=tcp 22# 这样可以启动客户端，这里用-config指定了配置文件，本地与服务器都使用tcp协议，本地监听22端口，服务器会# 监听一个随机端口，本地要监听哪个端口，要取决于要连接的服务监听的端口，如这里要使用ssh服务，输出如下：ngrok Tunnel Status online # 这里要变成online才是正常，开始是connectingVersion 1.7/1.7Forwarding tcp://abc.com:38139 -&gt; 127.0.0.1:22Web Interface 127.0.0.1:4040# Conn 1Avg Conn Time 24193.12ms # 这里有一个问题，当连接成功后，域名是没有前缀的。所有添加域名解析时，就直接解析域名即可。使用这种方法可# 以添加不同的端口映射到本地，如3389端口。但这里的问题是，服务器一端打开的随机端口，所以每次都需要手动修# 改安全组的配置，放开指定端口./ngrok -subdomain ngrok -config=./ngrok.cfg# -subdomain指定域名的前缀，如域名是abc.com，那么连接后就是ngrok.abc.com，这样启动客户端后要监听80# 端口。这里如果加了域名前缀，那么在添加域名解析时，就要在添加A记录时，添加一个泛域名解析，如*.ngrok]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>ngrok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-生成器]]></title>
    <url>%2F2019%2F11%2F14%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概念 生成器 generator *** 生成器指的是生成器对象，可以由生成器表达式得到，也可以使用yield关键字得到一个生成器函数，调用这个函数得到一个生成器对象 生成器函数 函数体中包含yield语句的函数就是生成器函数，返回生成器对象 生成器对象，是一个可迭代对象，是一个迭代器。迭代器一定是一个可迭代对象，但可迭代对象不一定是迭代器 生成器对象，是延迟计算、惰性求值的 包含yield语句的生成器函数生成生成器对象的时候，生成器函数的函数体不会立即执行 next(generator)会从函数的当前位置向后执行到之后碰到的第一个yield语句，会弹出值，并暂停函数执行 再次调用next函数，和上一条一样的处理过程 没有多余的yield语句能被执行，继续调用next函数，会抛出StopIteration异常 通过生成器表达式或生成器函数就可以得到一个生成器对象或简称生成器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273def inc(): for i in range(5): yield iprint(type(inc)) # 返回函数类型，因为inc是标识符print(type(inc())) # 返回值是generator类型，是生成器对象x = inc()print(type(x))print(next(x))for m in x: print(m,'*')for m in x: # 不会进入这里执行 print(m,'**')输出：&lt;class 'function'&gt;&lt;class 'generator'&gt;&lt;class 'generator'&gt;01 *2 *3 *4 *# 普通的函数调用fn()，函数会立即执行完毕，因为用的是return语句，但是生成器函数可以使用next函数多次执行# 生成器函数等价于生成器表达式，只不过生成器函数可以更加的复杂。y = (i for i in range(5))print(type(y))print(type(y))print(type(y))=======================================================================================def gen(): print('line 1') yield 1 print('line 2') yield 2 print('line 3') return 3 # 生成器内一般不会加return语句next(gen()) # line 1 遇到yield暂停，之后跳到下一句next(gen())执行# 有yiele语句就会是一个生成器，这里调用一次这个gen()函数，就会返回一个生成器对象，生成器对象要拨一下转# 一下，转到第一次遇到yield的时候，会返回1给next()，但我们不关心，print函数第一次返回line 1。# 遇到yield语句就要暂停一下，yield语句就是拨一下转一下，是next函数在拨它，执行到第一次碰到yield为止。# 所以第一次返回line 1，这个返回值我们是可以拿到的。(***return会终止当前函数执行，yield不会终止当前# 函数执行，而是暂停到yield，这个暂停很特别，一般地如果一个函数没有执行完是不能执行下一句的。但这里没有# 执行完gen()函数，而直接跳到了下一个gen()函数去执行了。***)yield有让出的意思，这里yield就让出了函# 数，让出了当前的控制，给下一个语句，这里就是让给下一个next(gen())执行，让出给谁并不重要。所以执行第# 二次gen()又生成了一个生成器，之后又重新开始执行，这是一个新的gen()函数调用，所以还是返回line 1。函# 数随着调用的结束而消亡了，所以第二次调用会重新开始。next(gen()) # line 1 g = gen() # 这里是第三次生成一个生成器对象并赋给了变量gprint(next(g)) # line 1 # 执行到这里先打印一个line 1，然后 yield返回一个1，这回next(g)是拨同一个生成器对象了，# 因为用print包裹起来了，所以还会打印一个1，# print print(next(g)) # line 2 # 这里是又拨了g函数一下，所以找下一个yield，先打印line 2，再打印2print(next(g)) # StopIteration 这里先打印一个line 3，之后没有yield了，而且我们使用了next# 函数调用，next函数是找下一个yield的，也就是找下一个生成器对象的值的，而不是找return的，因为找不到# yield，所以返回StopIteration。最后一句也不会执行了。如果注释这一行就不会报错了，因为next是找下一个# yield的，但没有了，这里会抛异常，但我们给了一个缺省值'End'，所以打印‘End'，而不会抛异常print(next(g, 'End'))# 一个生成器函数中，可以有多个yield表达式或return语句，碰到return，这个函数就结束了，但生成器对象还# 在，因为引用还在，但每一次next都是要找到下一个yield# 这里为什么用next()调用就会重新调用函数，一直返回line 1，而用print(next())就会在函数中继续向下执# 行？这与g = gen()有关系，这一句是将gen()函数调用的值都赋给了g，而且是一个generator类型，用next()# 一直取g的下一个值，所以会显示line 1 1 line 2 2。如果用print(next(gen()))，这一样会一直显示line 1- 在生成器函数中，使用多个yield语句，执行一次后会暂停执行，把yield表达式的值返回- 再次执行会执行到下一个yield语句- return语句依然可以终止函数运行，但return语句的返回值不能被获取到- return会导致无法继续获取下一个值，抛出StopIteration异常- 如果函数没有显示的return语句，如果生成器函数执行到结尾，一样会抛出StopIteration异常 生成器应用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# 无限循环def counter(): i = 0 while True: i += 1 yield idef inc(c): return next(c)c = counter()print(inc(c))print(inc(c))输出：12def counter(): i = 0 while True: i += 1 yield idef inc(): c = counter() return next(c)print(inc())print(inc())print(inc())输出：111# 执行了三次print(inc())，因为每次都创建一个生成器对象inc()，所以并不是同一个生成器对象，所以打印三次1# 计数器def inc(): def counter(): i = 0 while True: i += 1 yield i c = counter() return lambda:next(c) # c对于lambda来讲是自由变量，这里是一个闭包foo = inc()print(foo())print(foo())# inc()函数调用的返回值是lambda:next(c)，lambda:next(c)不是生成器而只是拨了一下c，# lambda:next(c)是一个新的函数，新的函数中并没有yield语句。counter()才是生成器函数。c是生成器对象，# 我们在lambda函数中拨它，所以foo只是lambda函数的引用值，之后再调用 foo()函数，这相当于在拨c，所以这里输出1和2# lambda表达式是匿名函数# return返回的是一个匿名函数# 等价于下面的代码def inc(): def counter(): i = 0 while True: i += 1 yield i c = counter() def _inc(): return next(c) return _inc# 上面三行相当于之前的lambda:next(c)foo = inc()print(foo())print(foo())print(foo())# 处理递归问题def fib(): x = 0 y = 1 while True: yield y x,y = y,x+y foo = fib()for _ in range(5): print(next(foo)) for _ in range(100): next(foo)print(next(foo)) # 等价于下面的代码pre = 0cur = 1 # No1print(pre,cur,end=' ')# recursiondef fib1(n,pre=0,cur=1): pre,cur = cur,pre+cur print(cur,end=' ') if n == 2: return fib1(n-1,pre,cur) 协程 coroutine 生成器的高级用法 比进程、线程轻量级 是在用户空间调度函数的一种实现 Python3 asyncio就是协程实现，已经加入到标准库 Python3.5 使用 async、await关键字直接原生支持协程 协程调度器实现思路 有2个生成器A、B next(A)后，A执行到了yield语句暂停，然后去执行next(B)，B执行到yield语句也暂停，然后再次调用 next(A)，再调用next(B)，周而复始，就实现了调度的效果 可以引入调度的策略来实现切换的方式 协程是一种非抢占式调度 yield from1234567891011121314151617def inc(): for x in range(1000): yield x foo = inc()print(next(foo))print(next(foo))print(next(foo))# 等价于下面的代码def inc(): yield from range(1000) # 这一种代码相当于上面的for循环的两句代码foo = inc()print(next(foo))print(next(foo))print(next(foo)) yield from是Python3出现的新的语法 yield from iterable 是 for item in iterable: yield item 形式的讲法糖 从可迭代对象中一个个拿元素 12345678910def counter(n): # 生成器、迭代器 for x in range(n): yield x def inc(n): yield from counter(n) foo = inc(10)print(next(foo))print(next(foo))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-匿名函数]]></title>
    <url>%2F2019%2F11%2F13%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[匿名函数 匿名，即没有名字 匿名函数，即没有名字的函数 没有名字如何定义 没有名字如何调用 如果能调用，如何使用 python借助Lambda表达式构建匿名函数 123456789语法：lambda 参数列表: 表达式lambda x:x**2(lambda x:x**2)(4) # 调用输出：16foo = lambda x,y:(x+y)**2 # 不推荐这么用foo(2,1)def foo(x,y): # 建议使用普通函数 return(x+y)**2foo(2,1) 使用lambda关键字来定义匿名函数 参数列表不需要小括号 冒号是用来分割参数列表和表达式的 不需要使用return，表达式的值，就是匿名函数返回值 lambda表达式(匿名函数)只能写在一行上，被称为单行函数 用途 在高阶函数传参时，使用lambda表达式，往往能简化代码 1234567891011121314151617181920212223242526272829303132333435363738lst = [1]# lst.sort?# key=None,reverse=Falselst.sort(key=str)lst.append('a')# lst.sort()# 没办法比较，因为类型不一样，需要统一类型lst.sort(key=str) # 送进去一个函数，和lambda函数一样，都是送进去函数lst.append(2)lst.sort(key=str) # 这里key就是向进传函数的lst print((lambda :0)())# 上面一句相当于# def fn():# return 0print((lambda x,y=3:x+y)(5))print((lambda x,y=3:x+y)(5,6))输出：11print((lambda x,*,y=30:x+y)(5))输出：35print((lambda x,*,y=30:x+y)(5,y=10))输出：15print((lambda *args:(x for x in args))(*range(5)))输出：&lt;generator object &lt;lambda&gt;.&lt;locals&gt;.&lt;genexpr&gt; at 0x7f056cf7c138&gt;print((lambda *args:[x+1 for x in args])(*range(5)))输出：[1, 2, 3, 4, 5]print((lambda *args:&#123;x+2 for x in args&#125;)(*range(5)))输出：&#123;2, 3, 4, 5, 6&#125;[x for x in (lambda *args:map(lambda x:x+1,args))(*range(5))] # 高阶函数标准输出：Out:[1, 2, 3, 4, 5][x for x in (lambda *args:map(lambda x:(x+1,args),args))(*range(5))]标准输出：Out:[(1, (0, 1, 2, 3, 4)), (2, (0, 1, 2, 3, 4)), (3, (0, 1, 2, 3, 4)), (4, (0, 1, 2, 3, 4)), (5, (0, 1, 2, 3, 4))]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python匿名函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-递归函数]]></title>
    <url>%2F2019%2F11%2F13%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[求n的阶乘 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071def func(num): if num == 1: return 1 else: return num * func(num-1) # 这是阶乘的关键，也是公式，就是总是自已乘以比自己小1的数func(5)# 执行过程是，进入函数后，直接到num * func(num-1)这一行。代入数字就是5*func(4)，func(4)再进入函# 数，返回4*fun(3)，之后是3*func(2)，2*func(1)，再进入函数时，num等于1了，所以返回1。把1代入# 2*func(1)，也就是2*1=2，再向上返回到3×func(2)，因为之前func(2)已经返回了2，所以这里是3*2=6，再# 向上返回，代入后是4*6=24，再向上，5*24=120，这样阶乘的结果就出来了。返回条件是当条件满足时返回一个# 值，之后依次向前返回并计算=======================================================================================def factorial(n,mu1 = 1): mu1 *= n # 当前乘以当前值就完了，如果调用时n给了2，那么这里就是1*2。这里又重新给mu1赋了值，那么这时mu1就是2了 if n == 1: # 这是边界条件 return mu1 return factorial(n-1,mu1) # 调用自己，这时n-1=1，mu1=2，这样再进入函数时，mul=2*1=2，n等于1,满足了条件，就会返回mu1的2factorial(5)=======================================================================================def fac(n): if n == 1: return 1 return n * fac(n-1)fac(5)=======================================================================================def fac1(n,p = 1): if n == 1: return p p *= n print(p) fac1(n-1,p) return pfac1(5)输出：52060120=======================================================================================def fac2(n, p = None): if p is None: p = [1] if n == 1: return p[0] p[0] *= n print(p[0]) fac2(n-1,p) return pn =5print(fac2(n))输出：52060120[120]# fac函数性能最好，因为时间复杂度是相同的，fac最简单 将一个数逆序放入列表中，例如1234 -&gt; [4,3,2,1] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 把1234改为4321data = str(1234)def reversal(x): if x == -1: return '' else: return data[x] + reversal(x-1) # 这是一个字符串连接，最后一次return出去。这个return才是我们可以拿到的值，上面的return是拿不到的 print(reversal(len(data)-1))=======================================================================================def reverse(n,lst=None): # lst=None应该改为一个[] if lst is None: lst = [] lst.append(n%10) # 这里可以用divmod函数，可以拿到商和模两个数 if n//10 == 0: return lst return reverse(n//10,lst)reverse(12345)=======================================================================================data = str(1234)def revert(x): if x == -1: return '' return data[x] + revert(x-1)print(revert(len(data)-1))输出：4321=======================================================================================def revert(n,lst=None): if lst is None: lst = [] x,y = divmod(n,10) lst.append(y) if x == 0: return lst return revert(x,lst)revert(12345)输出：[5, 4, 3, 2, 1]=======================================================================================num = 1234def revert(num,target=[]): # 这里的target不是关键字参数，而是位置参数 if num: # 表示当num为空时，是false，就不满足条件了 target.append(num[len(num)-1]) # target.append(num[-1:]) 因为使用了切片，所以有一个copy的过程 revert(num[:len(num)-1]) return target # 里面return多少次都没有关系。我们只关心最外层的return出的内容print(revert(str(num)))输出：['4', '3', '2', '1'] 解决猴子吃桃问题。猴子第一天摘下若干个桃子，当即吃了一半，还不过瘾，又多吃了一个。第二天早上又将剩下的桃子吃掉一半，又多吃了一个。以后每天早上都吃了前一天剩下的一半零一个。到第10天早上想吃时，只剩下一个桃子了。求第一天共摘多少个桃子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 发现公式：(后一天的桃子数量+1) * 2 = 前一天的桃子数量def peach(day=9,sum=1): sum=2*(sum+1) day-=1 if day==0: # 要循环10次，所以这里要到0 return sum return peach(day,sum)print(peach())输出：1534=======================================================================================def monkey(n): if n == 1: return 1 return 2 * monkey(n - 1) + 2peach = monkey(10)print(peach)输出：1534for _ in range(10,0,-1): # 这里的range()一定要写成这种形式，不然会超出递归最大深度，主要因为这里如果是0就会成为列循环 print(_,"-&gt;",monkey(_))输出：10 -&gt; 15349 -&gt; 7668 -&gt; 3827 -&gt; 1906 -&gt; 945 -&gt; 464 -&gt; 223 -&gt; 102 -&gt; 41 -&gt; 1=======================================================================================def peach(days=10): if days == 1: return 1 return (peach(days-1)+1)*2print(peach())# 注意这里必须是10，因为return(peach(days-1)+1)*2立即拿不到结果，必须通过再一次进入函数时判断是不是# 到了最后一天。也就是当前使用的值是由下一次函数调用得到，所以要执行10次函数调用=======================================================================================def peach(days=1): if days == 10: return 1 return (peach(days+1)+1)*2print(peach()) 递归调用对比 123456789101112131415161718192021222324252627282930313233343536373839404142import datetime# Fib Seqstart = datetime.datetime.now()pre = 0cur = 1 # No1print(pre, cur, end=' ')n = 35# loopfor i in range(n-1): pre, cur = cur, pre + cur print(cur, end=' ')delta = (datetime.datetime.now() - start).total_seconds()print(delta)# Fib Seqstart = datetime.datetime.now()pre = 0cur = 1 # No1print(pre, cur, end=' ')# recursiondef fib1(n, pre=0,cur=1): pre, cur = cur, pre + cur print(cur, end=' ') if n == 2: return fib1(n-1, pre, cur)fib1(n)delta = (datetime.datetime.now() - start ).total_seconds()print(delta)start = datetime.datetime.now()def fib2(n): if n &lt; 2: return 1 return fib2(n-1) + fib2(n-2)for i in range(n): print(fib2(i), end=' ')delta = (datetime.datetime.now() - start).total_seconds()print(delta)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python递归函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-递归函数]]></title>
    <url>%2F2019%2F11%2F12%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数执行流程12345678910111213141516171819# http://pythontutor.com/visualize.html#mode=edit# 建议自己想像函数执行流程，先不要去上面的网站上看def foo1(b,b1=3): print("foo1 called",b,b1) def foo2(c): foo3(c) print("foo2 called",c) def foo3(d): print("foo3 called",d) def main(): print("main called") foo1(100,101) foo2(200) print("main ending") main() 全局帧中生成foo1、foo2、foo3、main函数对象 main函数调用 main中查找内建函数print压栈，将常量字符串压栈，调用函数，弹出栈顶 main中全局查找函数foo1压栈，将常量100、101压栈，调用函数foo1，创建栈帧。print函数压栈，字符串和变量b、b1压栈，调用函数，弹出栈顶，返回值 main中全局查找foo2函数压栈，将常量200压栈，调用foo2，创建栈帧。foo3函数压栈，变量c引用压栈，调用foo3，创建栈帧。foo3完成print函数调用后返回。foo2恢复调用，执行print后，返回值。main中foo2调用结束弹出栈顶。main继续执行print函数调用，弹出栈顶。main函数返回。 内存中分栈和堆，对函数来讲，它有一个栈，栈就是落盘子，只能从上面拿。栈是一个内存区域，它一直不停在被使用。它是一个先进后出，后进先出的。谁在压栈，谁就在使用内存，内存中的其他数据会先保存起来，保存起来以后给它压下去，之后再把print()压在它上面。这里指PPT中的代码def main(): print(“main called”)一段。这样当前就是print环境了，然后将字符常量也压到栈里。调用函数就是print()真的要执行了，它会把print()栈内的所有数据依次拿出来执行，执行完以后，栈上的数据就依次拿完了，它刚压进去的数据就消耗完了，这时print就可以弹出了，print一弹出，之前有为main保存的数据，依次再加载起来。main函数就可以继续执行了。之后在main中查找foo1并压栈，将常量100、101压栈。要依次用掉函数内的数据。在栈内要创建一段，这一段叫帧，因为在栈上，所以叫栈帧。函数的执行过程就是压栈与弹出的过程 123456789101112131415161718192021222324# 字节码不是重点，当对语言掌握的很好了，写程序没问题了，再来了解字节码def foo1(b, b1=3): print("foo1 called", b, b1) foo2(2) def foo2(A): pass # foo1字节码4 0 LOAD_GLOBAL 0 (print) 3 LOAD_CONST 1 ('foo1 called) 6 LOAD_FAST 0 (b) 9 LOAD_FAST 1 (b1) 12 CALL_FUNCTION 3 (1 positional, 0 keyword pair) 函数调用，调用完成后，弹出所有函数参数，函数本身关闭堆栈，并推送返回值 15 POP_TOP # 删除顶部(TOS)项目 5 16 LOAD_GLOBAL 1 (foo2) 19 LOAD_CONST 2 (2) 22 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 25 POP_TOP 26 LOAD_CONST 0 (None) # 这两行是foo1的返回值，None这个空值是一个常量，所以是LOAD_CONST 29 RETURN_VALUE# python中所有函数都有返回值 递归Recursion 函数直接或者间接调用自身就是递归 递归需要有边界条件、递归前进段、递归返回段 递归一定要有边界条件 当边界条件不满足的时候，递归前进 当边界条件满足的时候，递归返回 斐波那契数列 Fibonacci number: 1,1,2,3,5,8,13,21,34,55,89,144, … 如果设F(n) 为该数列的第n项，那么这句话可以写成如下形式：F(n)=F(n-1)+F(n-2) F(0)=0，F(1)=1，F(n)=F(n-1)+F(n-2) 123456789101112131415161718192021pre = 0cur = 1 print(pre, cur, end=' ')n = 4# loopfor i in range(n-1): pre,cur = cur,pre + cur print(cur,end=' ') # 递归解决斐波那契数列# F(0)=0, F(1)=1, F(n)=F(n-1)+F(n-2)def fib(n): return 1 if n &lt; 2 else fib(n-1)+fib(n-2)for i in range(5): print(fib(i),end='') # 把4代入，就是fib(3)+fib(2)，fib(3)要再次压栈，这时就又进fib这个函数了，这时要调用fib(2)+fib(1)# fib(2)不小于2,所以还要调用一次fib(1)。fib(1)就是边界，因为小于2，这时就会执行return了，之前都不会# return。这里的fib(3)+fib(2)会分别执行fib(3)和fib(2)，也就是执行2次# 而且这个递归的效率非常低，因为压栈太多 递归要求 递归一定要有退出条件，递归调用一定要执行到这个退出条件。没有退出条件的递归调用 ，就是无限调用 递归调用 的深度不宜过深 Python对递归调用的深度做了限制，以保护解释器 超过递归深度限制，抛出RecursionError: maxinum recursion depth exceeded 超出最大深度 sys.getrecursionlimit() 12345678910# 用pycharm测试def foo1(b,b1=3): foo1(b) # foo1(3)import sysprint(sys.getrecursionlimit())# 视频中是1000,超过这个值就会报错，这是一种保护机制sys.setrecursionlimit(1000)# 修改递归的层数，太消耗内存了 递归的性能123456789101112131415161718192021222324# for 循环import datetimestart = datetime.datetime.now()pre = 0cur = 1 # No1print(pre, cur, end=' ')n = 35for i in range(n-1):pre, cur = cur, pre + cur print(cur, end=' ') delta = (datetime.datetime.now() - start).total_seconds()print(delta)# 递归import datetimen = 35start = datetime.datetime.now()def fib(n): return 1 if n &lt; 2 else fib(n-1) + fib(n-2)for i in range(n): print(fib(i), end=' ')delta = (datetime.datetime.now() - start).total_seconds()print(delta) 循环稍微复杂一些，但是只要不是死循环，可以多次迭代直至算出结果 fib函数代码极简易懂，但是只能获取到最外层的函数调用，内部递归结果都是中间结果。而且给定一个n都要进行近2n次递归，深度越深，效率越低。为了获取斐波那契数列需要外面再套一个n次的循环，效率就更低了 递归还有深度限制，如果递归复杂，函数反复压栈，栈内存很快就溢出了 思考：这个极简的递归代码能否提高性能？ 123456789101112131415161718192021# 斐波寻契数列的改进pre = 0cur = 1print(pre, cur, end=' ') # 这里打印的是最前面的0和1def fib(n, pre=0, cur =1): pre, cur = cur, pre + cur print(cur, end=' ') if n == 2: # 这是最外层的条件，当满足条件时执行一次return。n是计数的， return fib(n-1, pre, cur) # 这一句后隐含有return，每次都会执行return。我们不关心这个，因为我们要的是上面print的值 # 上一次的结果，作为下一次的参数传进来fib(5)- 改进 - 左边的fib函数和循环的思想类似 - 参数n是边界条件，用n来计数 - 上一次的计算结果直接作为函数的实参 - 效率很高 - 和循环比较，性能相近。所以并不是说递归一定效率代下。但是递归有深度限制- 对比一下三个fib函数的性能 间接递归 123456789def foo1(): foo2() def foo2(): foo1() foo1()- 间接递归，是通过别的函数调用了函数自身。但是如果构成了循环递归调用是非常危险的，但是往往这种情况在代码复杂的情况下，还是可能发生这种调用。要用代码的规范来避免这种递归调用的发生 递归总结 递归是一种很自然的表达，符合逻辑思维 递归相对运行效率低，每一次调用函数都要开辟栈帧 递归有深度限制，如果递归层次太深，函数反复压栈，栈内存很快就溢出了 如果是有限次数的递归，可以使用递归调用，或者使用循环代替，循环代码稍微复杂一些，但是只要不是死循环，可以多次迭代直至算出结果 绝大多数递归，都可以使用循环实现 即使递归代码很简洁，但是能不用则不用递归 个人感觉，递归最重要的有三点。一是定义时，函数的参数就是变量，它一直在变化，所以可以向下执行。二是找到公式，也就是函数要完成的功能，如何不断的用一个公式递归自己，这可以通过要实现的功能来发现其中的规律。三是返回，实际就是告诉函数到什么地方就可以一级一级地向上返回值了，这个也可以从要实现的功能中找到，看功能到什么时候就可以结束。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python递归函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-树]]></title>
    <url>%2F2019%2F11%2F12%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[树的概念 非线性结构，每个元素可以有多个前驱和后继 树是n(n&gt;0)个元素的集合 n = 0时，称为空树 树只有一个特殊的没有前驱的元素，称为树的根root 树中除了根结点外，其余元素只能有一个前驱，可以有零个或多个后继 递归定义 树T是n(n&gt;=0)个元素的集合。n=0时，称为空树 有且只有一个特殊元素根，剩余元素都可以被划分为m个互不相交的集合T1、T2、T3、…、Tm，而每一个集合都是树，称为T的子树Subtree 子树也有自己的根 结点：树中的数据元素 结点的度degree：结点拥有的子树的数目称为度，记作d(v)。 叶子结点：结点的度不为0，称为非终端结点或分支结点 分支：结点之间的关系 内部结点：除根结点外的分支结点，当然也不包括叶子结点 树的度是树内各结点的度的最大值。D结点度最大为3，树的度数就是3 孩子(儿子Child)结点：结点的子树的根结点称为该结点的孩子 双亲(父Parent)结点：一个结点是它各子树的根结点的双亲 兄弟(Sibling)结点：具有相同双亲结点的结点 祖先结点：从根结点到该结点所经分支上所有的结点。A、B、D都是G的祖先结点 子孙结点：结点的所有子树上的结点都称为该结点的子孙。B的子孙是D、G、H、I 结点的层次(Level)：根节点为第一层，根的孩子为第二层，以此类推，记作L(v) 树的深度(高度Depth)：树的层次的最大值。上图的树深度为4 堂兄弟：双亲在同一层的结点 有序树：结点的子树是有顺序的(兄弟有大小，有先后次序)，不能交换。 无序树：结点的子树是有无序的，可以交换 路径：树中的k个结点n1、n2、…、nk，满足ni是n(i+1)的双亲，称为n1到nk的一条路径。就是一条线串下来的，前一个都是后一个的父(前驱)结点。 路径长度=路径上结点数-1，也是分支数 森林：m(m&gt;=0)棵不相交的树的集合 对于结点而言，其子树的集合就是森林。A结点的2棵子树的集合就是森林 树的特点 唯一的根 子树不相交 除了根以外，每个元素只能有一个前驱，可以有零个或多个后继 根结点没有双亲结点(前驱)，叶子结点没有孩子结点(后继) vi是vj的双亲，则L(vi) = L(vj) - 1，也就是说双亲比孩子结点的层次小1 堂兄弟的双亲是兄弟关系吗？ 二叉树 每个结点最多两棵子树 二叉树不存在度数大于2的结点 它是有序树，左子树、右子树是顺序的，不能交换次序 即使某个结点只有一棵子树，也要确定它是左子树还是右子树 二叉树的五种基本形态 空二叉树 只有一个根结点 根结点只有左子树 根结点只有右子树 根结点有左子树和右子树 斜树 左斜树，所有结点都只有左子树 右斜树，所有结点都只有右子树 满二叉树 一棵二叉树的所有分支结点都存在左子树和右子树，并且所有叶子结点只存在在最下面一层。 同样深度二叉树中，满二叉树结点最多。 k为深度(1&lt;=k&lt;=n)，则结点总数为2^k-1 如下图，一个深度为4的15个结点的满二叉树 完全二叉树 Complete Binary Tree 若二叉树的深度为k，二叉树的层数从1到k-1层的结点数都达到了最大个数，在第k层的所有结点都集中在最左边，这就是完全二叉树 完全二叉树由满二叉树引出 满二叉树一定是完全二叉树，但完全二叉树不是满二叉树 k为深度(1&lt;=k&lt;=n)，则结点总数最大值为2^k-1，当达到最大值的时候就是满二叉树 举例，完全二叉树，最下一层的叶子结点都连续的集中在左边 举例，完全二叉树，最下一层的叶子结点都连续的集中在左边 举例，完全二叉树，最下一层的叶子结点都连续的集中在左边 举例，不是完全二叉树 二叉树性质 性质1 在二叉树的第i层上至多有2^(i-1)个结点(i&gt;=1) 性质2 深度为k的二叉树，至多有2^k-1个结点(k&gt;=1) 一层 2-1=1 二层4-1=1+2=3 三层 8-1=1+2+4=7 性质3 对任何一棵二叉树T，如果其终端结点数为n0，度数为2的结点为n2，则有n0=n2+1 换句话说，就是叶子结点数-1就等于度数为2的结点数 证明： 总结点数为n=n0+n1+n2，n1为度数为1的结点总数。 一棵树的分支数为n-1，因为除了根结点外，其余结点都有一个分支，即n0+n1+n2-1 分支数还等于n00+n11+n22，n2是2分支结点所以乘以2,2n2+n1 可行2*n2+n1=n0+n1+n2-1 =&gt; n2 = n0-1 其他性质 高度为k的二叉树，至少有k个结点 含有n(n&gt;=1)的结点的二叉树高度至多为n。和上句一个意思 含有n(n&gt;=1)的结点的二叉树的高度至多为n，最小为math.ceil(log2(n+1))，不小于对数值的最小整数，向上取整 假设高度为h，2^h-1=n=&gt;h=log2(n+1)，层次数是取整。如果是8个结点，3.1699就要向上取整为4,为4层。 性质4 具有n个结点的完全二叉树的深度为int(log2n)+1或者math.ceil(log2(n+1)) 性质5 如果有一棵n个结点的完全二叉树(深度为性质4)，结点按照层序编号，如下图 如果i=1，则结点i是二叉树的根，无双新；如果i&gt;1，则其双亲是int(i/2)，向下取整。就是子结点的编号整除2得到的就是父结点的编号。父结点如果是i，那么左孩子结点就是2i，右孩子结点就是2i+1 如果2i&gt;n，则结点i无左孩子，即结点i为叶子结点；否则其左孩子结点存在编号为2i 如果2i+1&gt;n，则结点i无右孩子，注意这里并不能说明结点i没有左孩子；否则右孩子结点存在编号为2i+1]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python算法-插入排序]]></title>
    <url>%2F2019%2F11%2F11%2Fpython%E7%AE%97%E6%B3%95-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[直接插入排序 Direct Insertion Sort 直接插入排序原理 在未排序序列中，构建一个子排序序列,直至全部数据排序完成 将待排序的数，插入到已经排序的序列中合适的位置 增加一个哨兵，放入待比较值，让它和后面已经排好序的序列比较，找到合适的插入点 初始的0及下面开头的红色数字为哨兵，即待插入值 从第二个数字开始排序，即9 第一趟，哨兵是9，用1和哨兵比较，1小，哨兵插入，本轮比较结束 第二趟，哨兵是8，用9和哨兵比较大于哨兵，9向右移，1和哨兵比较，1小，哨兵插入本轮比较结束 以此类推，直至把最后一个数字放到哨兵并比较，插入完成 123456789101112131415161718192021222324252627m_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[9,8,7,6,5,4,3,2,1],[1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,2]]nums = [0] + m_list[0] # nums为[0,1,9,8,5,6,7,4,3,2]# print(nums)sentinel,*origin = nums # 哨兵位，待比较数字。sentinel为0，origin为[1,9,8,5,6,7,4,3,2]# print(sentinel)# print(origin)count_swap = 0 # 计算每轮循环中，与哨兵位比较后要交换的次数count_iter = 0 # 计算从第二个数字到最后一个数字，一共要循环的资源length = len(nums)for i in range(2,length): # 从第二个数字开始 nums[0] = nums[i] # 放置哨兵，把比较的数字赋值给第一个数字，第一个数字就是哨兵位。如第一次就是把9放到哨兵位。这里的哨兵是在按列表中的数字不停顺序变化的，# ，第一次是9，之后是8,5,6，一直到最后，如果要比较的数字比哨兵位的数字小，就不动，如果比哨兵位的数字大，就向右移 j = i - 1 # 得出要比较数字的索引位置，下面就要用1和9比较 count_iter += 1 if nums[j] &gt; nums[0]: # 大数右移，找到插入位置。如果要比较的数字比哨兵位的数字大 while nums[j] &gt; nums[0]: nums[j+1] = nums[j] # 依次右移 j -= 1# 如果索引j比哨兵位的数字大，就把索引j向后移一个位置，之后把索引j减1，再进行同样的比较。当8是哨兵位时，9与8比较，因为比8大，就会把9# 的索引向后移动，之后再用1和哨兵位的8比较，1小于8,那么执行下面的哨兵插入，这时正好插入到了之前9的位置 count_swap += 1 nums[j+1] = nums[0] # 将哨兵插入，注意插入在右侧要+1print(nums, count_swap, count_iter)输出：[2, 1, 2, 3, 4, 5, 6, 7, 8, 9] 25 8# 可以看到最后一个数字2在哨兵位上。 增加一个哨兵位，每轮比较将待比较数放入 哨兵依次和待比较数的前一个数据比较，大数向右移动，找到哨兵中值的插入位置 每一轮结束后，得到一个从开始到待比较数位置的一个有序序列 最好情况，正好是升序排列，比较迭代n-1次 最差情况，正好是降序排列，比较迭代1,2,…,n-1即n(n-1)/2 使用两层嵌套循环，时间复杂度O(n^2) 稳定排序算法 使用在小规模数据比较 优化 如果比较操作耗时大的话，可以采用二分查找来提高效率，即二分查找插入排序]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-函数]]></title>
    <url>%2F2019%2F11%2F08%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[编写一个函数，能够接受至少2个参数，返回最小值和最大值 1234567891011121314import randomdef double_values(*nums): print(nums) return max(nums), min(nums)print(*double_values(*[random.randint(10,20) for _ in range(10)]))# 这里调用double_values()时给的参数使用了参数解构，并且使用了列表解析式，# random.randint(10,20)表示返回10到20之间的随机整数，后面的for循环表示执行10次，这将组成一个列表，# 然后用参数解构挨个给double_balues函数。double_values前面的星号也是参数解构，打印时会将# double_values中得到的最大最小值分开打印，不然会按元组形式打印在一起# 这里的print()还有一个隐含的强制类型转换，并数字转换为字符串再打印输出：(11, 10, 16, 13, 13, 15, 13, 11, 16, 13)16 10 编写一个函数，接受一个参数n，n为正整数，左右两种打印方式。要求数字必须对齐 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 上三角def show(n): tail = " ".join([str(i) for i in range(n,0,-1)])# 这一行算的是最下面一行的值，不管有几位数，知道最后一行就可以知道上面的行的字符串长度了join用于字符串连# 接，以" "为分隔符，列表解析式将n到0倒序传给i，再将i依次转换为字符串，最后就是要以倒序排列一个字符串，如12 11 ... 1 width = len(tail)# 计算tail的长度 for i in range(1,n): # 因为这里到第n行，所以最后还要再打印一次tail行的值 print("&#123;:&gt;&#123;&#125;&#125;".format(" ".join([str(j) for j in range(i,0,-1)]),width))# &#123;:&gt;&#123;&#125;&#125;中&gt;表示右对齐，里面的&#123;&#125;表示这一行的宽度，format()里，逗号前面的部分就是要打印的部分，width表# 示这一行的宽度，宽度是不会变的。只是打印都向右对齐就可以了 print(tail)show(12)输出： 1 2 1 3 2 1 4 3 2 1 5 4 3 2 1 6 5 4 3 2 1 7 6 5 4 3 2 1 8 7 6 5 4 3 2 1 9 8 7 6 5 4 3 2 1 10 9 8 7 6 5 4 3 2 1 11 10 9 8 7 6 5 4 3 2 112 11 10 9 8 7 6 5 4 3 2 1# 下三角def showtail(n): tail = " ".join([str(i) for i in range(n,0,-1)]) # 计算出第一行的值 print(tail) # 把第一行的值打印出来 # 无需再次生成列表# print(len(tail)) # 查看tail一共有多少个元素 for i in range(len(tail)): # 这里计算出第一行的长度，之后以此为基础。第一行的长度是23，这表示空格也算为一个元素。另外，双数的算两个元素# print(i) # 加入此行可以更明显地看出i的值执行到哪就满足了下面的条件 if tail[i] == ' ': # 从11开始算，第一个1的索引是0，第二个1的索引是1,第三个空格的索引是2,这时满足条件 print(' '*i,tail[i+1:])# 当上面满足时，这里用空格乘在上面的i，这样就形成了从第二行开始，每行前面要打印的空格，再加上tail中i+1索引处到最后的值。这样就凑出了# 一行的值。另外，tail[i+1:]是一个列表切片操作，这是一个copy方法，所以对性能有一些影响，如果打印10000的话可能会引起垃圾回收showtail(11)输出：11 10 9 8 7 6 5 4 3 2 1012 10 9 8 7 6 5 4 3 2 1345 9 8 7 6 5 4 3 2 167 8 7 6 5 4 3 2 189 7 6 5 4 3 2 11011 6 5 4 3 2 11213 5 4 3 2 11415 4 3 2 11617 3 2 11819 2 12021 122]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-函数]]></title>
    <url>%2F2019%2F11%2F07%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数 数学定义：y=f(x)，y是x的函数，x是自变量。y=f(x0,x1,…,xn) Python函数 由若干语句组成的语句块、函数名称、参数列表构成，它是组织代码的最小单元 完成一定的功能 函数的作用 函数是为了完成某几种功能 函数的作用就是简单封装，不会做非常复杂的封装 结构化编程对代码的最基本的封装，一般按照功能组织一段代码 封装的目的是为了复用，减少冗余代码 函数本身也是方法，叫函数或方法都可以。 代码更加简洁美观、可读易懂 函数的分类 内建函数，如max()、reversed()等 库函数，如math.ceil()等 函数定义、调用 def语句定义函数 1234567def 函数名(参数列表): 函数体(代码块) [return 返回值]# 函数名就是标识符，命名要求一样# 语句块必须缩进，约定4个空格# Python的函数如果没有return语句，隐式会返回一个None值# 定义中的参数列表称为形式参数，只是一种符号表达，简称形参 调用 函数定义，只是声明了一个函数，它不会被执行，需要调用 调用的方式，就是函数名加上小括号，括号内写上参数 调用时写的参数是实际参数，是实实在在传入的值，简称实参 函数举例 12345678910def add(x,y): result = x + y return resultout = add(4,5)print(out)# 上面只是一个函数的定义，有一个函数叫做add，接收2个参数# 计算的结果，通过return返回值返回# 调用通过函数名add加2个参数，返回值可使用变量接收# 定义需要在调用前，也就是说调用时，已经被定义过了，否则抛NameError异常# 函数是可调用的对象，callable() 函数参数 参数调用时传入的参数要和定义的个数相匹配（可变参数例外） 位置参数 def f(x,y,z)调用使用f(1,3,5) 按照参数定义顺序传入实参 关键字参数 def f(x,y,z)调用使用f(x=1,y=3,z=5) 使用形参的名字来输入实参的方式，如果使用了形参名字，那么传参顺序就可和定义顺序不同 传参 f(z=None,y=10,x=[1]) f((1,),z=6,y=4.1) f(y=5,z=6,2) # 这会报错 要求位置参数在关键字参数之前传入，位置参数是按位置对应的 位置参数与关键字参数只是传参的方法不一样而已，定义函数时的方法是一样的 函数参数默认值 参数默认值(缺省值) 定义时，在后跟上一个值 1234def add(x=4,y=5): return x + y# 测试调用 add(6,10)、add(6,y=7)、add(x=5)、add()、add(y=7)、add(x=5,6)、add(y=8,4)、add(x=5,y=6)、add(y=5,x=6)# 测试定义后面这样的函数 def add(x=4,y) 作用 参数的默认值可以在未传入足够的实参的时候，对没有给定的参数赋值为默认值 参数非常多的时候，并不需要用户每次都输入所有的参数，简化函数调用 举例 12345678910111213# 定义一个函数login，参数名称为host、port、username、passworddef login(host='127.0.0.1',port='8080',username='wayne',password='magedu'): print('&#123;&#125;:&#123;&#125;@&#123;&#125;/&#123;&#125;'.format(host,port,username,password))login() # 可以这样调用，使用默认值。在测试时很有用，但在实际使用中作用不大输出：127.0.0.1:8080@wayne/magedulogin('127.0.0.1',80,'tom','tom')输出：127.0.0.1:80@tom/tomlogin('127.0.0.1',username='root')输出：127.0.0.1:8080@root/magedulogin('localhost',port=80,password='com')输出：localhost:80@wayne/comlogin(port=90,password='magedu',host='www')输出：www:90@wayne/magedu 可变参数 问题 1234567891011# 有多个数，需要累加求和def add(nums): sum = 0 for x in nums: sum += x return sumadd([1,3,5])标准输出：Out: 9add((2,4,6))标准输出：Out: 12# 可以只传入一个参数，这个参数是一个可迭代对象。定义时只有一个形参，调用时的实参是一个可迭代对象 可变参数 一个形参可以匹配任意个参数 位置参数的可变参数 123456789101112131415161718192021222324252627282930313233# 有多个数，需要累加求和def add(*nums): sum = 0 print(type(nums)) for x in nums: sum += x print(sum)add(3,6,9)# 在形参前使用*表示该形参是可变参数，可以接收多个实参# 收集多个实参为一个tuple例：def add(*nums): # 加星号表示可以接收任意多个实参，包括0个。不加星号时只能接收一个实参。但这样定义后，不能接收关键字参数，如nums=3。 sum = 0 print(type(nums)) for x in nums: # 上面用*nums来接收，这里要用nums，不能加星号 sum += x print(sum) # 这个打印是给控制台的，不是给我们使用的# return sum# return返回值是给我们自己使用的，我们可以把这个返回值赋值给一个标识符，之前在说列表解析时特别用了一下print()，返回的都是Noneval = add(3,5,7)# 结果显示nums是一个tuple类型，用这个类型来接收。在传完实参，真正要调用这个函数体时，解释器已经知道有几# 个参数了，把这几个参数直接给tuple，相当于构建一个tuple。我们是一次全送进来的。它已经知道了当前参数有# 几个，就可以构建出一个不可变对象来，因为在内部是不能再改变这个nums的，我们只能迭代读取nums。所以用这# 种方式传进去的参数是不可变类型的。15是通过print打印出来的，这是给控制台的，我们是拿不到的。我们要通过# return来拿。如果我们注释掉return一行，那么下面打印的会是None。print(val)输出：&lt;class 'tuple'&gt;15None 关键字参数的可变参数 12345678910111213# 配置信息打印def showconfig(**kwargs): for k,v in kwargs.items(): print('&#123;&#125; = &#123;&#125;'.format(k,v)) showconfig(host='127.0.0.1',port='8080',username='wayne',password='magedu')输出：host = 127.0.0.1port = 8080username = waynepassword = magedu# 形参前使用**符号，表示可以接收多个关键字参数# 收集的实参名称和值组成一个字典 可变参数混合使用 1234567891011121314151617181920212223242526272829# 配置信息打印def showconfig(username,password,**kwargs)def showconfig(username,*args,**kwargs)def showconfig(username,password,**kwargs,*args)例：- 可变参数。用两个星号，构建的是字典item形式。因为要用到关键字参数，如nums=2，这和字典的nums:2是一样的。所以构建的是字典。- 混合使用，一个星号就是接收任意多个实参的，两个星号就是接收关键字参数的。- 注意，在定义时，一个星号要放在两个星号前，如def showconfig(username,passwd,**kwargs,*args)，这样就不行。- 给实参时，会尽量先满足不可变参数，再满足可变参数def add(*args,x): # 这样定义的话，x就变成了关键字参数，调用时必须给出x的值，或者在定义时就要定义默认值，不然会报错 print(x) print(args)add(4,3,x=0)输出：0(4, 3)def(**kwargs,x): print(x) print(kwargs)# 这里报错的原因是**kwargs和x都是关键字参数，都是keyword。所以会报错输出： File "&lt;ipython-input-14-7e57b033edae&gt;", line 1 def(**kwargs,x): ^SyntaxError: invalid syntax 总结 有位置可变参数和关键字可变参数 位置可变参数在形参前使用一个星号* 关键字可变参数在形参前使用两个星号** 位置可变参数和关键字可变参数都可以收集若干个实参，位置可变参数收集形成一个tuple，关键字可变参数收集形成一个dict 混合使用参数的时候，可变参数要放到参数列表的最后，普通参数需要放到参数列表前面，位置可变参数需要在关键字可变参数之前 举例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273def fn(x,y,*args,**kwargs): print(x) print(y) print(args) print(kwargs) fn(3,5,7,9,10,a=1,b='python')输出：35(7, 9, 10)&#123;'a': 1, 'b': 'python'&#125;fn(3,5)输出：35()&#123;&#125;fn(3,5,7)输出：35(7,)&#123;&#125;fn(3,5,a=1,b='python')输出：35()&#123;'a': 1, 'b': 'python'&#125;fn(7,9,y=5,x=3,a=1,b='python')输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-51-ff279493d0b6&gt; in &lt;module&gt; 9 # fn(3,5,7) 10 # fn(3,5,a=1,b='python')---&gt; 11 fn(7,9,y=5,x=3,a=1,b='python')TypeError: fn() got multiple values for argument 'y'# 错误，7和9分别赋给了x，y，之后又给了y=5，x=3，重复了def fn(*args,x,y,**kwargs): print(x) print(y) print(args) print(kwargs) fn(3,5)fn(3,5,7)fn(3,5,a=1,b='python')输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-56-2097f13d817a&gt; in &lt;module&gt; 5 print(kwargs) 6 ----&gt; 7 fn(7,9)TypeError: fn() missing 2 required keyword-only arguments: 'x' and 'y'# 按上面定义的方法，这三种调用的方法都会报错，要求将x和y这两个关键字参数的值明确给出fn(7,9,y=5,x=3,a=1,b='python')输出：35(7, 9)&#123;'a': 1, 'b': 'python'&#125;# 按上面方法定义时，只要这样调用才可以。 keyword-only参数 keyword-only参数(Python3加入) 1234567891011121314151617181920212223242526272829303132333435363738394041# 如果在一个星号参数后，或者一个位置可变参数后，出现的普通参数，实际上已经不是普通的参数了，而是keyword-only参数def fn(*args,x): print(x) print(args) fn(3,5) fn(3,5,7)输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-58-a561a8c35f3d&gt; in &lt;module&gt; 3 print(args) 4 ----&gt; 5 fn(3,5)TypeError: fn() missing 1 required keyword-only argument: 'x' fn(3,5,x=7)输出：7(3, 5)# args可以看做已经截获了所有的位置参数，x不使用关键字参数就不可能拿到实参# 思考:def fn(**kwargs, x) 可以吗？def fn(**kwargs,x): print(x) print(kwargs)输出： File "&lt;ipython-input-62-33c9a294d8b7&gt;", line 1 def fn(**kwargs,x): ^SyntaxError: invalid syntax# 直接报语法错误# 可以理解为kwargs会截获所有的关键字参数，就算你写了x=5，x也永远得不到这个值，所以语法错误# keyword-only参数另一种形式def fn(*,x,y): # 星号或*args后如果有x,y，那么x，y都会变成关键字参数 print(x,y)fn(x=5,y=6)# *号之后，普通形参都变成了必须给出的keyword-only参数。星号表示只接受两个参数x和y，且两个参数都要是关键字参数 - 定义时，一个星号后一般都用args，表示多个参数，如果是两个星号，用*kwargs，表示keywordargs 可变参数和参数默认值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108def fn(*args,x=5): print(x) print(args)fn()输出：5()# 等价于fn(x=5)fn(5)输出：5(5,)fn(x=6)输出：6()fn(1,2,3,x=10)输出：10(1, 2, 3)def fn(y,*args,x=5): print('x=&#123;&#125;,y=&#123;&#125;'.format(x,y)) print(args)fn()输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-67-d1577c4645e1&gt; in &lt;module&gt; 3 print(args) 4 ----&gt; 5 fn()TypeError: fn() missing 1 required positional argument: 'y' fn(5)输出：x=5,y=5()fn(x=6)输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-69-0a11163cdc28&gt; in &lt;module&gt; 3 print(args) 4 ----&gt; 5 fn(x=6)TypeError: fn() missing 1 required positional argument: 'y' fn(1,2,3,x=10)输出：x=10,y=1(2, 3)fn(y=17,2,3,x=10)输出： File "&lt;ipython-input-71-f33d57e490fb&gt;", line 5 fn(y=17,2,3,x=10) ^SyntaxError: positional argument follows keyword argument fn(1,2,y=3,x=10)输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-72-526c5ac03606&gt; in &lt;module&gt; 3 print(args) 4 ----&gt; 5 fn(1,2,y=3,x=10)TypeError: fn() got multiple values for argument 'y'# x是keyword-only参数 def fn(x=5,**kwargs): print('x=&#123;&#125;'.format(x)) print(kwargs) fn()输出：x=5&#123;&#125;fn(5)输出：x=5&#123;&#125;fn(x=6)输出：x=6&#123;&#125;fn(y=3,x=10)输出：x=10&#123;'y': 3&#125;fn(3,y=10)输出：x=3&#123;'y': 10&#125; 函数参数规则 参数列表参数一般顺序是，普通参数、缺省参数、可变位置参数、keyword-only参数(可带缺省值)、可变关键字参数 1234def fn(x,y,z=3,*arg,m=4,n,**kwargs): print(x,y,z,m,n) print(args) print(kwargs) 注意 代码应该易读易懂，而不是为难别人 请按照书写习惯定义函数参数 参数规则举例 12345678910111213141516171819202122def connect(host='localhost', port='3306', user='admin', password='admin', **kwargs): print(host, port) print(user, password) print(kwargs) connect(db='cmdb')输出：localhost 3306admin admin&#123;'db': 'cmdb'&#125;connect(host='192.168.1.123', db='cmdb')输出：192.168.1.123 3306admin admin&#123;'db': 'cmdb'&#125;connect(host='192.168.1.123', db='cmdb', password='mysql')输出：192.168.1.123 3306admin mysql&#123;'db': 'cmdb'&#125; 参数解构 举例 12345678910111213141516171819202122232425262728293031323334353637# 加法函数def add(x, y): return x+yadd(4, 5)输出： Out:9 add((4,5))输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-82-aca89f37f922&gt; in &lt;module&gt; 2 return x+y 3 ----&gt; 4 add((4, 5))TypeError: add() missing 1 required positional argument: 'y' t = (4, 5)add(t[0], t[1])输出：Out:9 add(*t)输出：Out:9 add(*(4,5))输出：Out:9 add(*range(1,3))输出：Out:3# range(1,3)的结果是1和2，所以相加是3add(*[4,5])输出：Out:9 add(*&#123;4,6&#125;)输出：Out:10 参数解构 给函数提供实参的时候，可以在集合类型前使用*或者**，把集合类型的结构解开，提取出所有元素作为函数的实参 非字典类型使用*解构成位置参数 字典类型使用**解构成关键字参数 提取出来的元素数目要和参数的要求匹配，也要和参数的类型匹配 参数解构，有时候有，有时候没有。如果有，就把参数一个个解构出来，如果没有，就解构成一个整体，如列表或元组 1234567891011121314151617181920212223242526272829def add(x, y): return x+yadd(*(4,5))输出：Out:9add(*[4,5])输出：Out:9add(*&#123;4,6&#125;)输出：Out:10d = &#123;'x': 5, 'y': 6&#125;add(**d)输出：Out:11add(**&#123;'a': 5, 'b': 6&#125;)输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-95-407fdeb69ace&gt; in &lt;module&gt; 2 return x+y 3 ----&gt; 4 add(**&#123;'a':5,'b':6&#125;)TypeError: add() got an unexpected keyword argument 'a' add(*&#123;'a': 5, 'b': 6&#125;)输出：Out:'ab' 参数解构和可变参数 12345678910111213141516171819# 给函数提供实参的时候，可以在集合类型前使用*或者**，把集合类型的结构解开，提取出所有元素作为函数的实参def add(*iterable): result = 0 for x in iterable: result += x return resultadd(1,2,3)输出：Out:6 add(*[1,2,3])输出：Out:6add(*range(10))输出：Out:45- 可见范围，函数内定义的变量，在函数外是不可见的，不能调用。- 但在函数外定义一个变量，在函数内可以调用- 函数内的变量叫本地变量 函数的返回值12345678def showplus(x): print(x) return x + 1showplus(5)输出：5Out:6 多条return语句 123456789def guess(x): if x &gt; 3: return "&gt;3" else: return "&lt;=3"print(guess(10))输出：&gt;3# return可以执行多次吗？ 举例 12345678910111213141516171819def fn(x): for i in range(x): if i &gt; 3: return i else: print("&#123;&#125; is not greater than 3".format(i)) # print(fn(5)) 打印什么？0 is not greater than 31 is not greater than 32 is not greater than 33 is not greater than 34# print(fn(3)) 打印什么？0 is not greater than 31 is not greater than 32 is not greater than 3None 总结 Python函数使用return语句返回“返回值” 所有函数都有返回值，如果没有使用return语句，隐式调用return None return语句并不一定是函数的语句块的最后一条语句 一个函数可以存在多个return语句，但是只有一条可以被执行。如果没有一条return语句被执行到，隐式调用return None 如果有必要，可以显示调用return None，可以简写为return 如果函数执行了return语句，函数就会返回，当前被执行的return语句之后的其它语句就不会被执行了 作用：结束函数调用、返回值 返回多个值 12345678910111213141516171819def showlist(): return [1,3,5]# showlist函数是返回了多个值吗？输出： Out:[1, 3, 5] def showlist(): return 1,3,5# 这次showlist函数是否返回了多个值？输出：Out:(1, 3, 5) - 函数不能同时返回多个值- return [1,3,5]是指明返回一个列表，是一个列表对象- return 1,3,5 看似返回多个值，隐式的被python封装成了一个元组def showlist(): return 1,3,5x,y,z = showlist()# 使用解构提取更为方便 函数嵌套 在一个函数中定义了另外一个函数 12345678910def outer(): def inner(): print("inner") print("outer") inner()outer()inner()- 函数有可见范围，这就是作用域的概念- 内部函数不能在外部直接使用，会抛NameError异常，因为它不可见 作用域*** 一个标识符的可见范围，这就是标识符的作用域。一般常说的是变量的作用域 12345678910111213- 举例，对比下面两个函数，x到底是否可见？x = 5def foo(): print(x) foo()x = 5def foo(): x += 1 print(x) foo() 全局作用域 在整个程序运行环境中都可见 局部作用域 在函数、类等内部可见 局部变量使用范围不能超过其所在的局部作用域 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def fn1(): x = 1# 局部作用域，在fn1内def fn2(): print(x)# x 可见吗print(x)# x 可见吗* 嵌套结构def outer1(): o = 65 def inner(): print("inner &#123;&#125;".format(o)) print(chr(o)) print("outer &#123;&#125;".format(o)) inner() outer1()def outer2(): o = 65 def inner(): o = 97 print("inner &#123;&#125;".format(o)) print(chr(o)) print("outer &#123;&#125;".format(o)) outer2()# 上面两个函数中变量o的差别- 从嵌套结构例子看出 - 外层变量作用域在内层作用域可见 - 内层作用域inner中，如果定义了o=97，相当于当前作用域中重新定义了一个新的变量o，但是这个o并没有覆 盖外层作用域outer2中的o x = 5def foo(): y = x + 1 # 会报错吗？ x += 1 # 报错，报什么错？为什么？换成x=1还有错吗？# 这里报错的原因是，左边的x就相当于要定义一个x，那么系统会认为要在本地重新定义这个x。而右边的x+1表示要# 调用本地x的值，但x在本地还没有定义所以会报错。而上面的y = x + 1表示调用外部的x的值，所以不会报错。调# 用函数时系统会先扫描语句块内部是否有x =，如果有，表示定义了一个本地x，所以不能再引用x print(x) # 为什么它不报错 foo()输出：---------------------------------------------------------------------------UnboundLocalError Traceback (most recent call last)&lt;ipython-input-1-8bced725b7fd&gt; in &lt;module&gt; 7 # 引用x 8 print(x)----&gt; 9 foo()&lt;ipython-input-1-8bced725b7fd&gt; in foo() 1 x = 5 2 def foo():----&gt; 3 y = x + 1 4 x = x + 1UnboundLocalError: local variable 'x' referenced before assignment- x += 1 其实是x = x + 1- 相当于在foo内部定义一个局部变量x，那么foo内部所有x都是这个局部变量x了- 但是这个x还没有完成赋值，就被右边拿来做加1操作了- 如何解决这个问题？ 全局变量global 1234567891011121314151617181920212223def foo(): global x x = 10 x += 1 # 报错吗？ print(x) # 打印什么？print(x) # 打印什么？# 做这些实验建议不要使用ipython、jupyter，因为它会使用上下文中x的定义，也就是之前的x的定义，可能测试# 不出来效果。如果要用这些工具，要在函数前用del x先删除变量- 使用global关键字的变量，将foo内的x声明为使用外部的全局作用域中定义的x- 但是，x = 10赋值即定义，这是在内部作用域为一个外部作用域的变量x赋值，而不是在内部作用域定义一个新变 量，所以x += 1不会报错。注意，这里x的作用域还是全局的。 def foo(): global z z = 20 z += 2 print(z)foo()print(z)# 这个z是一个全局的变量，而不是本地的变量。因为在最后的print()函数打印的z是不能调用函数内的变量的，只能# 由函数内调用函数外的变量因为在函数中使用了global，所以已经定义了作用域在外部，即使在内部又定义了一个# 本地变量也没用。在内部的z = 20等于是在外部定义了一个变量 global总结 x+=1这种是特殊形式产生的错误的原因？先引用后赋值，而python动态语言是赋值才算定义，才能被引用。解决办法是在这条语句前增加x=0之类的赋值语句，或者使用global告诉内部作用域，去全局作用域查找变量定义 内部作用域使用x=5之类的赋值语句会重新定义局部作用域使用的变量x，但是，一旦这个作用域中使用global声明x为全局的，那么x=5相当于在为全局作用域的变量x赋值 global使用原则 外部作用域变量会在内部作用域可见，但也不要在这个内部的局部作用域中直接使用，因为函数的目的就是为了封装，尽量与外界隔离 如果函数需要使用外部全局变量，请使用函数的形参传参解决 一句话：不用global。学习它就是为了深入理解变量作用域 闭包* 自由变量：未在本地作用域中定义的变量。例如定义在内存函数外的外层函数的作用域中的变量 闭包：就是一个概念，出现在嵌套函数中，指的是内层函数引用到了外层函数的自由变量，就形成了闭包。这实际是一个函数嵌套，内层的函数引用到了上一层函数的问题。如果引用的是全局作用域中的函数就不是闭包。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121- c[0] += 1这行会报错吗？- print(foo(),foo())会打印什么结果？- print(foo())def counter(): c = [0] # 定义变量并赋值 def inner(): c[0] += 1 # 这里是修改c变量，而不是赋值，修改不是重新定义。而且这是对c变量的内部元素在修改，对变量本身没有修改。这# 里没有用global，而用一个引用类型来实现，这样就避开了c += 1会报错的情况。所以这行不会报错 return c[0] # 这里返回c[0]的值，也就是返回了c第一个元素的值 return inner# 这里不是函数调用，因为没有括号。这里返回的是一个标识符/函数名，这个标识符对应一个对象。标识符用来定义# 一个对象，这个对象叫函数，所以返回的是函数对象。它返回的不是函数调用的返回值。加括号表示调用函数。这行# 返回的不是函数调用的结果，这里的返回值就是inner，inner是一个可调用对象callable，也是一个function对象foo = counter() # 这里的counter()函数调用返回的是return inner，也就是函数对象的引用。这里的foo的类型也变成了一个# callable，可调用对象。这时foo就等于inner了，foo()与inner()是一样的，像是一个别名。但在外面不能使# 用inner() 这种方法，因为它是函数中的函数，所以在外面是不可见的。从里面可以使用外面的变量，用global。# 但从外面不能引用函数中的定义print(type(foo)) # 这就可以看出foo是一个function了print(callable(foo)) # 这里返回Trueprint(type(foo()))print(foo(),foo())# 这里要调用两次foo函数，调用第一个foo()的时候就会进到函数中的def inner():里面，执行c[0] += 1和# return c[0]，因为c的索引0的值在def counter():中定义了是0，再加1后，c就是1了，之后用return返回。# 第二次调用foo()时，c已经是1了，这时c再加1就变成2了，之后返回。这说明c的值被保留下来了。一般按道理执# 行过foo()之后，它的局部变量就没了，也就是c = [0]这个值就应该随counter函数消亡了，每次调用foo()时，# c = [0]这个值应该不存在或重新赋值。但这里foo = counter()一步拿到了一个内部函数的引用，然后赋值给了# 一个变量，之后加1，这时c[0]的值一定不是0。对象计数引用加1。被引用后inner()这个对象不应该被消亡，所以# 打印时，foo是function对象，而且一定是callable的，也可以把一个callable对象用callable()检查，如果# 是可调用对象，会返回True。counter()中定义的c = [0]没有消亡，而且可以被inner()函数引用，那么# inner()函数就使用了一个外层函数的变量，这个c就叫自由变量。内部使用了外层函数的变量，外层函数的变量就# 叫自由变量，使用了自由变量就产生了闭包，因为有闭包，所以c变量就一直存在，所以第一次调用后，c[0]就变# 成了1，第二次调用时，以c[0]的值是1为基础，调用后就变成了2c = 200 # 覆盖c，这里定义的是一个全局变量，但与上面的函数定义中的c没有关系print(foo()) # 再调用foo函数，因为上面调用过两次了，所以这时c[0]的值已经是2了，所以这里再调用时，c[0]的值就变成了3# 如果要改变外部变量的元素的值，在python2中只能用这种方法，在python3中可以使用nonlocal输出：&lt;class 'function'&gt;True&lt;class 'int'&gt;1 23=======================================================================================def counter1(): c = 5 def inner1():# c += 1 return c # 这也是一个闭包，因为这也是对外部变量的引用。引用时只要改变外部变量就不是闭包了。如在这里加上c = 4，这# 里的c与外部的c就是两个变量了。闭包就是为了使用外层函数的变量，如果加入c += 1，就会出问题了。因为这时# 没有定义c，就要改变c的值。上面只是改变c的元素的值。所以在定义时c就不能被定义成一个数字，应该定义为列# 表，set等。如果要用c += 1这种方式，要用glocal return inner1foo1 = counter1()print(callable(foo1))print(foo1(),foo1())c = 200print(foo1())输出：True---------------------------------------------------------------------------UnboundLocalError Traceback (most recent call last)&lt;ipython-input-11-d6047de65f5a&gt; in &lt;module&gt; 11 foo1 = counter1() 12 print(callable(foo1))---&gt; 13 print(foo1(),foo1()) 14 c = 200 15 print(foo1())&lt;ipython-input-11-d6047de65f5a&gt; in inner1() 2 c = 5 3 def inner1():----&gt; 4 c += 1 5 # return c 6 # 这也是一个闭包，因为这也是对外部变量的引用。引用时只要改变外部变量就不是闭包了。如在这里加上c = 4，这里的c与外部的c就是两个变量了UnboundLocalError: local variable 'c' referenced before assignment# 使用global可以解决上面的报错，但这样使用的是全局变量，而不是闭包# 如果要用对普通变量的闭包，python3中可以使用nonlocal=======================================================================================def counter1(): c = [4] def inner1(): c.append(1) return c return inner1foo1 = counter1()print(callable(foo1))print(foo1(),foo1())c = 200print(foo1())输出：True[4, 1, 1] [4, 1, 1][4, 1, 1, 1]=======================================================================================# del cc = 9 # 加上这句就不会报错了def count(): c = 1 a = 10 def inner(): global c # 报错的原因是在函数的外部没有定义过c，函数中定义的都算本地环境。解析器才是global环境# global的作用域在全局和使用global声明的函数中有效。以这个函数来说，只在全局和inner()函数中有效。 c += 1 return c return innerfoo = count()print(foo()) # 执行错误，提示c没有定义print(foo())输出：1011 nonlocal关键字 使用了nonlocal关键字，将变量标记为不在本地作用域定义，而在上级的某一级局部作用域中定义，但不能是全局作用域中定义 1234567891011121314151617181920212223242526272829303132333435def counter(): count = 0 def inc(): nonlocal count# 表示不是本地作用域定义的，是上一级的局部作用域而且不是全局作用域的作用域定义的。这样count += 1就不会报错了 count += 1 return count return incfoo = counter()foo()foo()输出：12- count是外层函数的局部变量，被内部函数引用- 内部函数使用nonlocal关键字声明count变量在上级作用域而非本地作用域中定义- 上面代码可以正常使用，且形成闭包=======================================================================================a = 50def counter(): nonlocal a a += 1 print(a) count = 0 def inc(): nonlocal count count += 1 return count return incfoo = counter()foo()foo()- 这段代码不能正常运行，变量a不能在全局作用域中 默认值作用域12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394def foo(xyz=2): print(xyz)foo()# 无论调用几次都会打印2，返回Noneprint(xyz)# xyz虽然是形参，但也是一个局部变量，所以会报错。因为它只能在函数内使用输出：2---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-2-9faea3c8b99f&gt; in &lt;module&gt; 5 # 这会打印2，返回None 6 ----&gt; 7 print(xyz) 8 # xyz虽然是形参，但也是一个局部变量，所以会报错。因为它只能在函数内使用NameError: name 'xyz' is not defined =======================================================================================def foo(xyz=[]): xyz.append(100) print(xyz)foo()输出：[100]foo()输出：[100, 100]# 引用类型要小心。这不是xyz导致的，而是缺省值/默认值导致的。xyz用完或调用完就消亡了# 第二次打印[100,100]是因为在当前作用域，也就是全局作用域内，ipython这个运行环境在当前作用域内还没有# 结束。foo是一个函数对象，这个对象没有消亡，它还存在，它把xyz的默认值放在了一个函数对象的特殊属# 性上了，这个属性叫foo.__defaults__。这个对象没有消亡，所以这个属性一直存在，这个属性是一个值，就是# 把xyz = []放到了这个属性中，xyz的值是一个列表，列表元素可以改变。这就是每次调用foo函数都会变化的原# 因。并不是因为xyz还存在，xyz会随函数调用而消亡。__defaults__是为函数对象提供的特殊属性- 为什么第二次调用foo函数打印的是[100,100]- 因为函数也是对象，python把函数的默认值放在了属性中，这个属性就伴随着这个函数对象的整个生命周期- 查看foo.__defaults__属性=======================================================================================def foo(xyz=[],m=5,n=6): xyz.append(100) print(xyz) print(1,foo.__defaults__)# 在调用前打印一次，所以是默认值：([], 5, 6)print(foo(),id(foo))# 查看一个foo函数对象的内存地址。执行时会先执行foo()调用，所以会执行函数内的print(xzy)，打印出[100]print(2, foo.__defaults__)# __defaults__是一个属性，属性就不用加括号了。加括号就成调用了print(foo(),id(foo))# 第二次调用，并查看foo的地址是否改变。如果没变，说明在当前作用域内，就是那一个对象，是同一个对象# 地址可以用is来判断，内容是否相同可以用==来判断print(3,foo.__defaults__)# 查看函数默认值是否改变# 可以看到执行结果是一个元组：([100], 5, 6)，但元组中还有列表，所以可以变化# 在当前的这个运行环境中，内存地址都不会改变。因为它指向的是同一个函数对象。对cPython来说，id()取的是# 这个对象的地址，第二次相当于对默认值做了改变，所以第二次，第三次的值都不一样。但如果设置了默认值，如# m=5，那么这是不可替换的，并且在元组中，更是不能改变的输出：1 ([], 5, 6)[100]None 1404607382542322 ([100], 5, 6)[100, 100]None 1404607382542323 ([100, 100], 5, 6)- 函数地址并没有变，调用它，它的属性__defaults__中使用元组保存默认值- xyz默认值是引用类型，引用类型的元素变动，并不是元组的变化=======================================================================================def foo(w,u='abc',*,z=123,zz=[456]): u = 'xyz' z = 789 zz.append(1) print(w,u,z,zz)print(foo.__defaults__)foo('magedu')print(foo.__kwdefaults__)输出：('abc',)magedu xyz 789 [456, 1]&#123;'z': 123, 'zz': [456, 1]&#125;- 属性__defaults__中使用元组保存所有位置参数默认值，这里说的位置参数包括关键字参数或默认参数- 属性__kwdefaults__中使用字典保存所有keyword-only参数的默认值- 这里涉及之前的概念不可混淆。位置参数与关键字参数是传参的方法不一样，但定义函数时是一样的，都是- def f(a,b,c)，位置参数传参时可以直接使用f(1,2,3)，只要参数个数与定义时一样就可以，它会按定义时的顺- 序给参数赋值。而关键字参数传参时用，f(b=2,c=0,a=3)，这样传参更灵活，不用计较定义时的顺序。默认参数是- 在定义时就给了参数一个默认值，f(a=8)，调用时如果不给参数，就用默认值；keyword-only是在定义时在星号- 或可变参数后定义的普通参数，如f(a,*,r)、f(*args,e)，这里的r和e都是keyword-only，调用函数时必须给- keyword-only类型的参数指定明确的值，如f(1,r=8)；可变参数可以用一个参数匹配多个参数，如- f(*args,a)，调用时可以用f(1,2,3,a=0)；可变关键字参数在定义时要放在最后，它可以截取所有关键字参数，- 以字典方式保存，定义如f(**kwargs)，调用时用f(a=8,b=9) 使用可变类型作为默认值，就可能修改这个默认值 有时候这个特性是好的，有的时候这种特性是不好的，有副作用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 如何做到按需改变？如下面两例：def foo(xyz=[],u='abc',z=123): xyz = xyz[:] # 浅拷贝，这里的xyz与默认值的xyz没有关系 xyz.append(1) print(xyz) foo()print(1,foo.__defaults__)foo()print(2,foo.__defaults__)foo([10])# 这里给了foo()函数一个值，那就不使用默认值了，之后再向xyz中追加1，所以下面浅拷贝后再打印出来的是[10,1]print(3,foo.__defaults__)foo([10,5])# 因为上面没有修改默认值，所以打印出来的是[10,5,1]print(4,foo.__defaults__)# 如果不在函数内部改变默认值的值，使用浅拷贝是不会改变默认值的 输出：[1]1 ([], 'abc', 123)[1]2 ([], 'abc', 123)[10, 1]3 ([], 'abc', 123)[10, 5, 1]4 ([], 'abc', 123)- 函数体内，不改变默认值- xyz都是传入参数或者默认参数的副本，如果就想修改原参数，无能为力=======================================================================================# 比较常用的方法def foo(xyz=None,u='abc',z=123): if xyz is None: xyz = [] xyz.append(1) return xyzlst = foo() # 因为没有给foo()函数值，所以使用默认值，当xyz是None时，把xyz改为空列表并追加一个[1]。lst的值就是[1]a = foo(lst)# 用a来接收foo(lst)函数返回的值，一般都会这样使用。print(a)# 再打印a时，因为foo()已经是[1]了，并赋值给了lst，所以再次调用foo(lst)时，会直接向[1]中追加[1]，所# 以结果是[1,1]。这是使用不可变类型作为默认值，一般都用None，不会用123这样的值的。这种方式比较常用 输出：[1, 1]- 使用不可变类型默认值- 如果使用缺省值None就创建一个列表- 如果传入一个列表，就修改这个列表 方法一： 使用影子拷贝创建一个新的对象，永远不能改变传入的参数 方法二： 通过值的判断就可以灵活的选择创建或者修改传入对象 这种方式灵活，应用广泛 很多函数的定义，都可以看到使用None这个不可变的值作为默认参数，可以说这是一种惯用方法 变量名解析原则LEGB Local，本地作用域、局部作用域的local命名空间。函数调用时创建，调用结束消亡 Enclosing，Python2.2时引入了嵌套函数，实现了闭包，这个就是嵌套函数的外部函数的命名空间 Global，全局作用域，即一个模块的命名空间。模块被import时创建，解释器退出时消亡 Build-in，内置模块的命名空间，生命周期从python解释器启动时创建到解释器退出时消亡。例如print(open)，print和open都是内置的变量 所以一个名词的查找顺序就是LEGB 函数的销毁 全局函数 1234567891011121314151617181920212223def foo(xyz=[],u='abc',z=123): xyz.append(1) return xyzprint(foo(),id(foo),foo.__defaults__)输出：[1] 139660910996064 ([1], 'abc', 123)def foo(xyz=[],u='abc',z=123): xyz.append(1) return xyzprint(foo(),id(foo),foo.__defaults__)del fooprint(foo(),id(foo),foo.__defaults__)输出：[1] 139660910996608 ([1], 'abc', 123)---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-152-21d255639bdf&gt; in &lt;module&gt; 4 print(foo(),id(foo),foo.__defaults__) 5 del foo----&gt; 6 print(foo(),id(foo),foo.__defaults__)NameError: name 'foo' is not defined 全局函数销毁 重新定义同名函数 del语句删除函数对象 程序结束时 局部函数 1234567891011121314151617181920212223242526def foo(xyz=[],u='abc',z=123): xyz.append(1) def inner(a=10): pass print(inner) def inner(a=100): print(xyz) print(inner) return innerbar = foo()print(id(foo),id(bar),foo.__defaults__,bar.__defaults__)输出：&lt;function foo.&lt;locals&gt;.inner at 0x7f0556fd2730&gt;&lt;function foo.&lt;locals&gt;.inner at 0x7f0556fd2b70&gt;139660910996200 139660910996336 ([1], 'abc', 123) (100,)del barprint(id(foo),id(bar),foo.__defaults__,bar.__defaults__)输出：---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-154-da23e1c7a787&gt; in &lt;module&gt; 1 del bar----&gt; 2 print(id(foo),id(bar),foo.__defaults__,bar.__defaults__)NameError: name 'bar' is not defined 局部函数销毁 重新在上级作用域定义同名函数 del语句删除函数名称，函数对象的引用计数减1 上级作用域销毁时]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用ssh密钥对的私钥访问服务器]]></title>
    <url>%2F2019%2F11%2F01%2F%E5%88%A9%E7%94%A8ssh%E5%AF%86%E9%92%A5%E5%AF%B9%E7%9A%84%E7%A7%81%E9%92%A5%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829------------ Server------------ 1. 创建密钥对ssh-keygen -t rsa -P &apos;&apos;2. 将私钥改为.pem格式openssl rsa -in .ssh/id_rsa -outform pem &gt; dsjali.pem3. 修改权限，不然连接时会报错chmod 400 dsjali.pem4. 从私钥中产生公钥ssh-keygen -y -f dsjali.pem ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC+5xBrPVEJ3mRo/yVFtSQSv1/J09oYHkbTD+l/4or04YqUCHJ7iR+A/LMeff0c9xKCbT9hsb/MvJGmCZGxuE375Fwu8XZGS8SfjYSxeh0uASOcZazOiBu4Ooegj9A3Ov4C9odPqISWbTdUx286WJqdzW7RZ0ZwkFOiproFrszAPnvg5xmlnMSa0afYgWhRXimmn2oyLt7PFfZIXX8PJnMs7x9B0+lwLLIVJRKrpU8if+gD80viC9wUJu3/jC1VF8Jg4Bq2aS7KiMX++LY1SKoOUUc0sHa/SFZEzuouaRGgrmU9XkM3DvzlfcrGN+/14WczAZG4st5. 将上面的公钥写入认证文件vim .ssh/authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC+5xBrPVEJ3mRo/yVFtSQSv1/J09oYHkbTD+l/4or04YqUCHJ7iR+A/LMeff0c9xKCbT9hsb/MvJGmCZGxuE375Fwu8XZGS8SfjYSxeh0uASOcZazOiBu4Ooegj9A3Ov4C9odPqISWbTdUx286WJqdzW7RZ0ZwkFOiproFrszAPnvg5xmlnMSa0afYgWhRXimmn2oyLt7PFfZIXX8PJnMs7x9B0+lwLLIVJRKrpU8if+gD80viC9wUJu3/jC1VF8Jg4Bq2aS7KiMX++LY1SKoOUUc0sHa/SFZEzuouaRGgrmU9XkM3DvzlfcrGN+/14WczAZG4st------------ Client------------1. 下载服务器上的.pem文件2. 连接ssh -i &quot;dsjali.pem&quot; root@39.106.93.138# .pem文件的权限为400，如果不是，可能报错。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-random模块]]></title>
    <url>%2F2019%2F10%2F31%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-random%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[random.choice(seq) 从非空序列 seq 返回一个随机元素。 如果 seq 为空，则引发 IndexError。 random.shuffle(x[, random]) 将序列 x 随机打乱位置。可选参数 random 是一个0参数函数，在 [0.0, 1.0) 中返回随机浮点数；默认情况下，这是函数 random() 。要改变一个不可变的序列并返回一个新的打乱列表，请使用sample(x, k=len(x))。请注意，即使对于小的 len(x)，x 的排列总数也可以快速增长，大于大多数随机数生成器的周期。 这意味着长序列的大多数排列永远不会产生。 例如，长度为2080的序列是可以在 Mersenne Twister 随机数生成器的周期内拟合的最大序列。 random.random() 返回 [0.0, 1.0) 范围内的下一个随机浮点数。 random.sample(population, k) 返回从总体序列或集合中选择的唯一元素的 k 长度列表。 用于无重复的随机抽样。返回包含来自总体的元素的新列表，同时保持原始总体不变。 结果列表按选择顺序排列，因此所有子切片也将是有效的随机样本。 这允许抽奖获奖者（样本）被划分为大奖和第二名获胜者（子切片）。总体成员不必是 hashable 或 unique 。 如果总体包含重复，则每次出现都是样本中可能的选择。要从一系列整数中选择样本，请使用 range() 对象作为参数。 对于从大量人群中采样，这种方法特别快速且节省空间：sample(range(10000000), k=60) 。如果样本大小大于总体大小，则引发 ValueError 。 random.uniform(a, b) 返回一个随机浮点数 N ，当 a &lt;= b 时 a &lt;= N &lt;= b ，当 b &lt; a 时 b &lt;= N &lt;= a 。取决于等式 a + (b-a) * random() 中的浮点舍入，终点 b 可以包括或不包括在该范围内。 random.randrange(stop) random.randrange(start, stop[, step]) 从 range(start, stop, step) 返回一个随机选择的元素。 这相当于 choice(range(start, stop, step)) ，但实际上并没有构建一个 range 对象。位置参数模式匹配 range() 。不应使用关键字参数，因为该函数可能以意外的方式使用它们。在 3.2 版更改: randrange() 在生成均匀分布的值方面更为复杂。 以前它使用了像int(random()*n)这样的形式，它可以产生稍微不均匀的分布。 random.randint(a, b) 返回随机整数 N 满足 a &lt;= N &lt;= b。相当于 randrange(a, b+1)。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python-random</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-字典]]></title>
    <url>%2F2019%2F10%2F30%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[字典练习 用户输入一个数字 打印每一位数字及其重复的次数 1234567891011121314151617num = input('&gt;&gt;&gt;')d = &#123;&#125;for c in num: if not d.get(c): d[c] = 1 continue d[c] += 1 print(d)d = &#123;&#125;for c in num: if c not in d.keys(): d[c] = 1 else: d[c] += 1print(d) 数字重复统计 随机产生100个整数 数字的范围[-1000,1000] 升序输出所有不同的数字及其重复的次数 1234567891011121314151617181920import randomn = 100nums = [0] * nfor i in range(n): nums[i] = random.randint(-1000,1000)print(nums)t = nums.copy()t.sort()print(t)d = &#123;&#125;for x in nums: if x not in d.keys(): d[x] = 1 else: d[x] += 1print(d)d1 = sorted(d.items())print(d1) 字符串重复统计 字符表’abcdefghijklmnopqrstuvwxyz’ 随机挑选2个字母组成字符串，共挑选100个 降序输出所有不同的字符串及重复的次数 1234567891011121314151617import randomalphabet = 'abcdefghijklmnopqrstuvwxyz'words = []for _ in range(100): # words.append(random.choice(alphabet)+random.choice(alphabet)) # words.append(''.join(random.sample(alphabet,2))) 随机采样 words.append(''.join(random.choice(alphabet) for _ in range(2))) # 生成器 d = &#123;&#125;for x in words: d[x] = d.get(x,0) + 1print(d)d1 = sorted(d.items(),reverse=True)print(d1) 将字符串格式设置功能用于字典123456789101112131415161718192021222324&gt;&gt; phonebook&#123;'Beth': '9102', 'Alice': '2341', 'Cecil': '3258'&#125;&gt;&gt;&gt; "Cecil's phone number is &#123;Cecil&#125;.".format_map(phonebook)"Cecil's phone number is 3258."# 可在字典中包含各种信息，这样只需在格式字符串中提取所需的信息即可。使用format_map来指出你# 将通过一个映射来提供所需的信息。可使用字符串格式设置功能来设置值的格式，这些值是作为命名或# 非命名参数提供给方法format的。&gt;&gt;&gt; template = '''&lt;html&gt;... &lt;head&gt;&lt;title&gt;&#123;title&#125;&lt;/title&gt;&lt;/head&gt;... &lt;body&gt;... &lt;h1&gt;&#123;title&#125;&lt;/h1&gt;... &lt;p&gt;&#123;text&#125;&lt;/p&gt;... &lt;/body&gt;'''&gt;&gt;&gt; data = &#123;'title': 'My Home Page', 'text': 'Welcome to my home page!'&#125;&gt;&gt;&gt; print(template.format_map(data))&lt;html&gt;&lt;head&gt;&lt;title&gt;My Home Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;My Home Page&lt;/h1&gt;&lt;p&gt;Welcome to my home page!&lt;/p&gt;&lt;/body&gt;# 将data字典的值代入template中。像这样使用字典时，可指定任意数量的转换说明符，条件是所有# 的字段名都是包含在字典中的键。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python字典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建无线热点]]></title>
    <url>%2F2019%2F10%2F29%2F%E5%88%9B%E5%BB%BA%E6%97%A0%E7%BA%BF%E7%83%AD%E7%82%B9%2F</url>
    <content type="text"><![CDATA[12345671. nm-connection-editor2. 点击左下角的加号，选择Wi-Fi，点击Create...3. 在Wi-Fi栏中，SSID是自定义的热点名称，Mode选择Hotspot，Device选择无线网卡。4. 在Wi-Fi Security栏中，选择WPA &amp; WPA2 Personal，输入密码5. 在ubuntu19.10中，打开设置中的Wi-Fi，选择最上方打开关闭wifi按键右侧的三个竖点，选择Connect to Hidden Network ...，这是连接到隐藏网络中，在Connection中选择上面创建的热点名称，选择后，下面的信息会自动填入，如密码等，直接点击Connect即可打开热点6. 首先，有线网络需要连接，这时已经打开了热点，但测试发现无法看到热点名称，也要选择连接隐藏网络，输入热点名称和密码才能连接。]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>无线热点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-内建函数迭代器]]></title>
    <url>%2F2019%2F10%2F11%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%BB%BA%E5%87%BD%E6%95%B0%E8%BF%AD%E4%BB%A3%E5%99%A8%2F</url>
    <content type="text"><![CDATA[内建函数 标识 id(object) 返回对象的“标识值”。该值是一个整数，在此对象的生命周期中保证是唯一且恒定的。两个生命期不重叠的对象可能具有相同的id()值。CPython返回内存地址(CPython implementation detail: This is the address of the object in memory.)。 哈希 hash(object) 返回该对象的哈希值（如果它有的话）。哈希值是整数。它们在字典查找元素时用来快速比较字典的键。相同大小的数字变量有相同的哈希值 类型 type(object)\type(name, bases, dict) 返回对象的类型。传入一个参数时，返回 object 的类型。 返回值是一个 type 对象，通常与 object.__class__所返回的对象相同。 推荐使用isinstance()内置函数来检测对象的类型，因为它会考虑子类的情况。 传入三个参数时，返回一个新的 type 对象。 这在本质上是class语句的一种动态形式。 name 字符串即类名并且会成为__name__属性；bases 元组列出基类并且会成为__bases__属性；而 dict 字典为包含类主体定义的命名空间并且会被复制到一个标准字典成为 __dict__属性。 例如，下面两条语句会创建相同的type对象： 1234&gt;&gt;&gt; class X:... a = 1...&gt;&gt;&gt; X = type('X', (object,), dict(a=1)) 在 3.6 版更改:type的子类如果未重载 type.__new__，将不再能使用一个参数的形式来获取对象的类型。 类型转换 float()、int()、bin()、hex()、oct()、bool()、list()、tuple()、dict()、set()、complex()、bytes()、bytearray() 输入 input([prompt]) 如果存在 prompt 实参，则将其写入标准输出，末尾不带换行符。接下来，该函数从输入中读取一行，将其转换为字符串（除了末尾的换行符）并返回。当读取到 EOF 时，则触发 EOFError。例如: 1234&gt;&gt;&gt; s = input('--&gt; ') --&gt; Monty Python's Flying Circus&gt;&gt;&gt; s "Monty Python's Flying Circus" 如果加载了readline模块，input()将使用它来提供复杂的行编辑和历史记录功能。 打印 print(*objects,sep=’’,end=’\n’,file=sys.stdout,flush=False) 打印输出，默认使用空格分割、换行结尾，输出到控制台。将 objects 打印到 file 指定的文本流，以 sep 分隔并在末尾加上 end。 sep, end, file 和 flush 如果存在，它们必须以关键字参数的形式给出。 所有非关键字参数都会被转换为字符串，就像是执行了str()一样，并会被写入到流，以 sep 且在末尾加上 end。 sep 和 end 都必须为字符串；它们也可以为 None，这意味着使用默认值。 如果没有给出 objects，则print()将只写入 end。 file 参数必须是一个具有 write(string) 方法的对象；如果参数不存在或为 None，则将使用sys.stdout。 由于要打印的参数会被转换为文本字符串，因此 print()不能用于二进制模式的文件对象。 对于这些对象，应改用 file.write(...)。 输出是否被缓存通常决定于 file，但如果 flush 关键字参数为真值，流会被强制刷新。 对象长度 len(s) 返回对象的长度（元素个数）。实参可以是序列（如 string、bytes、tuple、list 或 range 等）或集合（如 dictionary、set 或 frozen set 等）。 isinstance(obj,class_or_tuple) 判断对象obj是否属于某种类型或者元组中列出的某个类型。如果 object 实参是 classinfo 实参的实例，或者是（直接、间接或虚拟）子类的实例，则返回 true。如果 object 不是给定类型的对象，函数始终返回 false。如果 classinfo 是对象类型（或多个递归元组）的元组，如果 object 是其中的任何一个的实例则返回 true。 如果 classinfo 既不是类型，也不是类型元组或类型的递归元组，那么会触发TypeError异常。 isinstance(True,int) issubclass(class,class_or_tuple) 判断类型cls是否是某种类型的子类或元组中列出的某个类型的子类。如果 class 是 classinfo 的子类（直接、间接或虚拟的），则返回 true。classinfo 可以是类对象的元组，此时 classinfo 中的每个元素都会被检查。其他情况，会触发TypeError异常。 issubclass(bool,int) 绝对值abs(x)，x为数值 最大值max()，最小值min() 返回可迭代对象中最大或最小值 返回多个参数中最大或最小值 round(x) 四舍六入五取偶，round(-0.5) pow(x,y) 等价于 x ** y range(stop) 从0开始到stop-1的可迭代对象；range(start, stop[,step]) 从start开始到stop-1结束步长为step的可迭代对象 divmod(x,y) 等价于 tuple(x//y,x%y) sum(iterable[,start]) 对可迭代对象的所有数值元素求和 sum(range(1,100,2)) chr(i) 给一个一定范围的整数返回对应的字符 chr(97) chr(20012) ord(c) 返回字符对应的整数 ord(‘a’) ord(‘中’) str()、repr()、ascii() sorted(iterable[,key][,reverse]) 排序 返回一个新的列表，默认升序 reverse是反转123sorted([1,3,5])sorted([1,3,5],reverse=True)sorted(&#123;'c':1,'b':2,'a':1&#125;) 翻转 reversed(seq) 返回一个翻转元素的迭代器 12345list(reversed("13579"))&#123; reversed((2,4))&#125; # 有几个元素？for x in reversed(['c','b','a']): print(x)reversed(sorted(&#123;1,5,9&#125;)) 枚举 enumerate(seq,start=0) 迭代一个序列，返回索引数字和元素构成的二元组 start表示索引开始的数字，默认是0 123456789101112131415for x in enumerate([2,4,6,8]): print(x) for x in enumerate("abcde"): print(x,end=" ") for k,v in enumerate(range(5)): # k,v是在解构 print(k,v,end="\t")输出：0 0 1 1 2 2 3 3 4 4for k,v in enumerate("mnopq",start=10): # k,v是在解构 print(k,v,end="\t")输出：10 m 11 n 12 o 13 p 14 q 迭代器和取元素 iter(iterable)、next(iterator[,default]) iter将一个可迭代对象封装成一个迭代器 next对一个迭代器取下一个元素。如果全部元素都取过了，再次next会抛StopIteration异常 12345it = iter(range(5))next(it)it = reversed([1,3,5])next(it) 拉链函数zip(*iterables) 像拉链一样,把多个可迭代对象合并在一起,返回一个迭代器 将每次从不同对象中取到的元素合并成一个元组1234list(zip(range(10),range(10)))list(zip(range(10),range(10),range(5),range(10)))dict(zip(range(10),range(10)))&#123;str(x):y for x,y in zip(range(10),range(10))&#125; 可迭代对象 可迭代对象 能够通过迭代一次次返回不同的元素的对象。 所谓相同，不是指值是否相同，而是元素在容器中是否是同一个，例如列表中值可以重复的，[‘a’,’a’]，虽然这个列表有2个元素，值一样，但是两个’a’是不同的元素 可以迭代，但是未必有序，未必可索引 可迭代对象有：list、tuple、string、bytes、bytearray、range、set、dict、生成器等 可以使用成员操作符in、not in、in本质上就是在遍历对象 1233 in range(10)3 in (x for x in range(10))3 in &#123;x:y for x,y in zip(range(4),range(4,10))&#125; 迭代器 迭代器 特殊的对象,一定是可迭代对象,具备可迭代对象的特征 通过iter方法把一个可迭代对象封装成迭代器 通过next方法,迭代 迭代器对象 生成器对象,就是迭代器对象 123456for x in iter(range(10)): print(x)g = (x for x in range(10))print(type(g))print(next(g))print(next(g)) 可迭代对象、迭代器与生成器可迭代对象 实现了inter方法的对象就叫做可迭代对象。inter方法的作用就是返回一个迭代器对象。直观理解就是能用for循环进行迭代的对象就是可迭代对象。比如：字符串，列表，元祖，字典，集合等等，都是可迭代对象。 for循环与inter()方法的关系 12345678910x = [1,2,3]for i in x: print(i)# for循环对一个列表进行迭代# 调用可迭代对象的__inter__方法返回一个迭代器对象（iterator）# 不断调用迭代器的__next__方法返回元素# 知道迭代完成后，处理StopIteration异常# 可迭代对象：使用iter内置函数可以获取迭代器的对象。即要么对象实现了能返回迭代器的iter方# 法，要么对象实现了getitem方法，而且其参数是从零开始的索引。# 可迭代对象要看它是否可以for ... in或能不能in 迭代器 迭代器是一个带状态的对象，它能在你调用next()方法的时候返回容器中的下一个值，任何实现了__iter__和__next__()方法的对象都是迭代器，__iter__返回迭代器自身，__next__返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常。 你可以使用next()内置函数来调用__next__()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 代码实现迭代器，并通过next()方法来调用class Fib(): def __init__(self,max): self.n = 0 self.prev = 0 self.curr = 1 self.max = max def __iter__(self): return self def __next__(self): if self.n &lt; self.max: value = self.curr self.curr += self.prev self.prev = value self.n += 1 return value else: raise StopIteration# 调用f = Fib(5)print(next(f))print(next(f))print(next(f))print(next(f))print(next(f))print(next(f))输出："C:\Program Files\Python36\python.exe" D:/Git/Test_Framework/utils/1.py13Traceback (most recent call last): File "D:/Git/Test_Framework/utils/1.py", line 37, in &lt;module&gt; print(next(f)) File "D:/Git/Test_Framework/utils/1.py", line 29, in __next__ raise StopIterationStopIterationProcess finished with exit code 1# 迭代器就像一个懒加载的工厂，等到有人需要的时候才给它生成值返回，没调用的时候就处于休眠状态# 等待下一次调用。直到无元素可调用，返回StopIteration异常。# 迭代器是这样的对象：实现了无参数的next方法，返回下一个元素，如果没有元素了，那么抛出 # StopIteration异常；并且实现iter方法，返回迭代器本身。 生成器 生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面的类一样写__iter__()和__next__()方法了，只需要一个yiled关键字。每次对生成器调用 next()时，它会从上次离开位置恢复执行（它会记住上次执行语句时的所有数据值）。 生成器一定是迭代器（反之不成立），因此任何生成器也是以一种懒加载的模式生成值。 可以用生成器来完成的操作同样可以用基于类的迭代器来完成。 但生成器的写法更为紧凑，因为它会自动创建__iter__()和__next__()方法。 另一个关键特性在于局部变量和执行状态会在每次调用之间自动保存。 这使得该函数相比使用 self.index 和 self.data 这种实例变量的方式更易编写且更为清晰。 除了会自动创建方法和保存程序状态，当生成器终结时，它们还会自动引发 StopIteration。 这些特性结合在一起，使得创建迭代器能与编写常规函数一样容易。 用生成器来实现斐波那契数列的例子是： 12345678910111213141516171819202122232425def fib(max): n, prev, curr = 0, 0, 1 while n&lt;max: yield curr prev, curr = curr, curr + prev n += 1# 生成器特殊的地方在于函数体中没有return关键字，函数的返回值是一个生成器对象。当执行# f=fib()返回的是一个生成器对象，此时函数体中的代码并不会执行，只有显示或隐示地调用next的# 时候才会真正执行里面的代码。# 生成器还有一个send方法，可以往生成器里的变量传值，如下代码：def foo(): print("first") count=yield print(count) yieldf = foo()f.send(None)f.send(2)# 调用过程：# f = foo()返回一个生成器# f.send(None)进入函数执行代码，遇到count=yield，冻结并跳出函数体# f.send(2)再次进入函数体，接着冻结的代码继续执行，把2传给变量count，打印count,遇到# yield冻结并跳出函数# 生成器是带有yield关键字的函数。调用生成器函数时，会返回一个生成器对象。 生成器表达式 生成器表达式是列表解析式的生成器版本，看起来像列表解析式，但是它返回的是一个生成器对象而不是列表对象。 123456789101112131415161718192021222324252627282930a = (x for x in range(10))print(a)输出："C:\Program Files\Python36\python.exe" D:/Git/Test_Framework/utils/1.py&lt;generator object &lt;genexpr&gt; at 0x000000000289D8E0&gt;Process finished with exit code 0&gt;&gt;&gt; sum(i*i for i in range(10)) # sum of squares285&gt;&gt;&gt; xvec = [10, 20, 30]&gt;&gt;&gt; yvec = [7, 5, 3]&gt;&gt;&gt; sum(x*y for x,y in zip(xvec, yvec)) # dot product260&gt;&gt;&gt; from math import pi, sin&gt;&gt;&gt; sine_table = &#123;x: sin(x*pi/180) for x in range(0, 91)&#125;&gt;&gt;&gt; unique_words = set(word for line in page for word in line.split())&gt;&gt;&gt; valedictorian = max((student.gpa, student.name) for student in graduates)&gt;&gt;&gt; data = 'golf'&gt;&gt;&gt; list(data[i] for i in range(len(data)-1, -1, -1))['f', 'l', 'o', 'g']# 某些简单的生成器可以写成简洁的表达式代码，所用语法类似列表解析式，将外层改为圆括号而非方括# 号。 这种表达式被设计用于生成器将立即被外层函数所使用的情况。 生成器表达式相比完整的生成# 器更紧凑但较不灵活，相比等效的列表解析式则更为节省内存。# 生成器表达式是创建生成器的简洁句法，这样无需先定义函数再调用。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>内建函数迭代器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-列表解析式与生成器表达式]]></title>
    <url>%2F2019%2F10%2F10%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[标准库 datetime datetime模块 对日期、时间、时间戳的处理 datetime类 类方法 today() 返回本地时区当前时间的datetime对象 now(tz=None) 返回当前时间的datetime对象，时间到微秒，tz表示时区，如果tz为None，返回和today()一样。 utcnow()没有时区的当前时间 fromtimestamp(timestamp,tz=None) 从一个时间戳返回一个datetime对象 datetime对象 timestamp() 返回一个到微秒的时间戳 时间戳：格林威治时间1970年1月1日0点到现在的秒数 datetime对象 构造方法 datetime.datetime(2016,12,6,16,29,43,79043) year、month、day、hour、minute、second、microsecond，取datetime对象的年月日时分秒及微秒 weekday() 返回星期的天，周一为0，周日为6 isoweekday() 返回星期的天，周一为1，周日为7 date() 返回日期date对象 time() 返回时间time对象 replace() 修改并返回新的时间 isocalendar() 返回一个三元组（年，周数，周的天） 日期格式化 类方法 strptime(date_string, format)，返回datetime对象 对象方法 strftime(format)，返回字符串 字符串format函数格式化 import datetime dt = datetime.datetime.strptime(“21/11/06 16:30”,”%d %m %y %H:%M”) print(dt.strftime(“%Y-%m-%d %H:%M:%S”)) print(“{0:%Y}/{0:%m}/{0:%d} {0:%H}::{0:%M}::{0:%S}”.format(dt)) timedelta对象 datetime2 = datetime1 + timedelta datetime2 = datetime1 - timedelta timedelta = datetime1 - datetime2 构造方法 datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0,minutes=0, hours=0, weeks=0) year = datetime.timedelta(days=365) total_seconds() 返回时间差的总秒数 标准库time time time.sleep(secs) 将调用线程挂起指定的秒数 练习1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import datetime# 导入一个名词空间或叫模块或叫包或叫库。这表示这是一个名词空间，它管理关一个区域，这个区域内所有的类与另一个区域内的名词空间管理的类不一样datetime.datetime.now()# 第一个datetime是名词空间，第二个datetime是类，now是这个类的方法# 这里是导入名称空间，再使用这个空间管理的类# now(tz=None)，这里的tz指的是时区，一般不设置时区datetime.datetime.today()datetime.datetime.utcnow()# datetime对象是对象的实例化后得到的a = datetime.datetime.now().timestamp()# 返回微秒时间戳，这里返回的是一个数值print(type(a))print(a)b = datetime.datetime.fromtimestamp(a)# fromtimestamp是datetime类的方法，给这个方法一个时间戳a，构造出一个对象，因为还没有对象，所以要让类构造出来。# 对象不存在时，要把方法给类，让类使用这个方法构造出一个对象print(type(b))print(b)b = datetime.datetime.fromtimestamp(int(a))# 这里用int创建一个整数，丢弃微秒部分print(b)a = datetime.datetime(2019,10,8)print(a)a.year# 这里没用括号，所以year是属性，不是调用a.seconda.daya.weekday# 取datetime对象的年月日时分秒及微秒a = datetime.datetime.now()print(a.weekday)a.weekday()a.isoweekday()a.date()a.time()a.replace(2018)# 把a里的时间改为2018年a.isocalendar()# 生成一个日历，是一个三元组（年，周数，周的天）a.strftime('%Y~%m~%d %H-%M-%S')'&#123;0:%y&#125; &#123;0:%m&#125; &#123;0:%d&#125;'.format(a)'&#123;&#125; &#123;&#125; &#123;&#125;'.format(a.year,a.month,a.day) # 这种方法比上面的方法少打很多符号，比较常用h = datetime.timedelta(hours=24)print(h)datetime.datetime.now()n = datetime.datetime.now() - h# 当前时间送去一天。(datetime.datetime.now() - n).total_seconds()# 两个时间对象相减后，是一个timedelta，再调用timedelta的total_seconds方法，就可以算出相差的总秒数了import timetime.sleep(5)# 挂起5秒，哪个线程调用sleep，谁就被挂起，在ipthon中输入此命令后，当前线程被挂起了。# 常用的两个模块，time和datetime 列表解析 举例 生成一个列表,元素0~9,对每一个元素自增1后求平方返回新列表 12345678910111213141516171819202122# 生成一个0-9的列表，之后将每个元素加1,再求平方返回一个新列表# target = range(10)newlist = []# 生成一个0-9的列表，之后将每个元素加1,再求平方返回一个新列表for i in range(10): newlist.append((i + 1) ** 2)print(newlist)输出：[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]# 文档中的解决办法l1 = list(range(10))l2 = []for i in l1: l2.append((i+1)**2)print(l2)# 列表解析式l1 = list(range(10))l2 = [(i+1)**2 for i in l1]print(l2)print(type(l2)) 列表解析List Comprehension 语法 [返回值 for 元素 in 可迭代对象 if 条件] 使用中括号[]，内部是for循环，if条件语句可选 返回一个新的列表 列表解析式是一种语法糖 编译器会优化，不会因为简写而影响效率，反而因优化提高了效率 减少程序员工作量，减少出错 简化了代码，但可读性增强 语法糖（Syntactic sugar）是由英国计算机科学家彼得·兰丁发明的一个术语，指计算机语言中添加的某种语法，这种语法对语言的功能没有影响，但是更方便程序员使用。语法糖让程序更加简洁，有更高的可读性。糖在不改变其所在位置的语法结构的前提下，实现了运行时等价。 举例 获取10以内的偶数，比较执行效率 123456even = []even = [x for x in range(10) if x%2==0]for x in range(10): if x % 2 == 0: even.append(x) 思考 有这样的赋值语句newlist = [print(i) for i in range(10)]，请问newlist的元素打印出来是什么？ 123456789101112131415newlist = [print(i) for i in range(10)]print(newlist)输出：0123456789[None, None, None, None, None, None, None, None, None, None]# 可以看到，标准输出的是None的列表。这是因为必须要把函数执行完了用print(i)的返回值来填充列表，而print(i)的返回值是None。所以这里应该用newlist = [i for i in range(10)] 获取20以内的偶数，如果数是3的倍数也打印[i for i in range(20) if i%2==0 elif i%3==0] 行吗？ 12345678910[i for i in range(20) if i%2==0 elif i%3==0]输出： File "&lt;ipython-input-20-8aea5f5e5abc&gt;", line 1 [i for i in range(20) if i%2==0 elif i%3==0] ^SyntaxError: invalid syntax# 不能使用elif。[i for i in range(20) if i%2==0 or i%3 == 0]输出：[0, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 18] 列表解析进阶12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[expr for item in iterable if cond1 if cond2]等价于ret = []for item in iterable: if cond1: if cond2: ret.append(expr) 例：20以内，既能被2整除又能被3整除的数[i for i in range(20) if i%2==0 and i%3==0]输出：[0, 6, 12, 18][i for i in range(20) if i%2==0 if i%3==0]输出：[0, 6, 12, 18]# 这两种方法的结果都是一个标准输出，如果最后用print()打印，会显示9。所以这里一定要将列表解析的结果赋值给一个变量才行。=======================================================================================[expr for i in iterable1 for j in iterable2 ]等价于ret = []for i in iterable1: for j in iterable2: ret.append(expr)例：[(x, y) for x in 'abcde' for y in range(3)]输出：[('a', 0), ('a', 1), ('a', 2), ('b', 0), ('b', 1), ('b', 2), ('c', 0), ('c', 1), ('c', 2), ('d', 0), ('d', 1), ('d', 2), ('e', 0), ('e', 1), ('e', 2)][[x, y] for x in 'abcde' for y in range(3)]输出：[['a', 0], ['a', 1], ['a', 2], ['b', 0], ['b', 1], ['b', 2], ['c', 0], ['c', 1], ['c', 2], ['d', 0], ['d', 1], ['d', 2], ['e', 0], ['e', 1], ['e', 2]][&#123;x: y&#125; for x in 'abcde' for y in range(3)]输出：[&#123;'a': 0&#125;, &#123;'a': 1&#125;, &#123;'a': 2&#125;, &#123;'b': 0&#125;, &#123;'b': 1&#125;, &#123;'b': 2&#125;, &#123;'c': 0&#125;, &#123;'c': 1&#125;, &#123;'c': 2&#125;, &#123;'d': 0&#125;, &#123;'d': 1&#125;, &#123;'d': 2&#125;, &#123;'e': 0&#125;, &#123;'e': 1&#125;, &#123;'e': 2&#125;]请问下面3种输出各是什么？为什么[(i,j) for i in range(7) if i&gt;4 for j in range(20,25) if j&gt;23]输出：[(5, 24), (6, 24)][(i,j) for i in range(7) for j in range(20,25) if i&gt;4 if j&gt;23]输出：[(5, 24), (6, 24)][(i,j) for i in range(7) for j in range(20,25) if i&gt;4 and j&gt;23]输出：[(5, 24), (6, 24)] 列表解析练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263练习(要求使用列表解析式完成)1. 返回1-10平方的列表[x ** 2 for x in range(1,11)]2. 有一个列表lst = [1,4,9,16,2,5,10,15],生成一个新列表,要求新列表元素是lst相邻2项的和lst = [1,4,9,16,2,5,10,15][lst[i]+lst[i+1] for i in range(len(lst)-1)]3. 打印九九乘法表[print('&#123;&#125;*&#123;&#125;=&#123;:&lt;3&#125;&#123;&#125;'.format(j,i,i*j,'\n' if i==j else ''),end="") for i in range(1,10) for j in range(1,i+1)]# j,i,i*j,'\n' if i==j else ''是一个三目运算输出：1*1=1 1*2=2 2*2=4 1*3=3 2*3=6 3*3=9 1*4=4 2*4=8 3*4=12 4*4=16 1*5=5 2*5=10 3*5=15 4*5=20 5*5=25 1*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=36 1*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=49 1*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=64 1*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81 [None,... None]# 可以看到，标准输出的是None的列表。这是因为必须要把函数执行完了用print(i)的返回值来填充列表，而print(i)的返回值是None。4. "0001.abadicddws" 是ID格式,要求ID格式是以点号分割,左边是4位从1开始的整数,右边是10位随机小写英文字母。请依次生成前100个ID的列表import random['&#123;:04&#125;.&#123;&#125;'.format(n,''.join([random.choice(bytes(range(97,123)).decode()) for _ in range(10)])) for n in range(1,101)]输出：['0001.fbyzrdzoif', '0002.loirmqauym', ... '0098.cjbghrvfmh', '0099.xljsgucscx', '0100.nieckficgn']# 可以看到这是标准输出的# random.choice 此模块的意思指在()内随机生成一个值。bytes(range(97,123)).decode 指生成97至123，前包后不包['&#123;:04&#125;.&#123;&#125;'.format(i,"".join([chr(random.randint(97,122)) for j in range(10)])) for i in range(1,101)]输出：['0001.peiqgmjxix', '0002.nspwscivaz', ... '0099.gavzudepld', '0100.fmpdsztsie']# 这同样是标准输出。# &#123;:04&#125;指宽度为4，默认右对齐，其余空白部分用0填充。random.randint(97,122)指生成指定区间的整数，前包# 后不包。chr()给定一个范围的整数返回对应的字符，即ASCII编码值。# 如chr(48)为0；chr(57)为9；chr(65)为A；chr(90)为Z；chr(97)为a；chr(122)为z。import string['&#123;:&gt;04&#125;.&#123;&#125;'.format(i,''.join(random.choice(string.ascii_lowercase) for _ in range(0,10))) for i in range(1,101)]输出：['0001.anbhqpafcz', '0002.dkbzbypera', ... '0099.otxpmioqpp', '0100.jazkayuqfu']# 这还是标准输出# string.ascii_lowercase 指默认生成所有小写字母。random.choice 此模块的意思指在()内随机生成一个值# join：指将可迭代对象连接起来,使用’’’'作为分隔符，默认在""内不填写为空白符；可迭代对象本身元素都是字符串；返回一个新字符串 生成器表达式 Generator expression 语法 (返回值 for 元素 in 可迭代对象 if 条件) 列表解析式的中括号换成小括号就行了 返回一个生成器 和列表解析式的区别 生成器表达式是按需计算(或称惰性求值、延迟计算),需要的时候才计算值 列表解析式是立即返回值 生成器 可迭代对象 迭代器 生成器表达式**123456789101112131415161718192021222324举例:g = ("&#123;:04&#125;".format(i) for i in range(1,11))next(g)for x in g: print(x)print('~~~~~~~~~~~~')for x in g: print(x)# 总结# 延迟计算# 返回迭代器,可以迭代# 从前到后走完一遍后,不能回头对比列表g = ["&#123;:04&#125;".format(i) for i in range(1,11)]for x in g: print(x)print('~~~~~~~~~~~~')for x in g: print(x)# 总结# 立即计算# 返回的不是迭代器,返回可迭代对象列表# 从前到后走完一遍后,可以重新回头迭代 生成器表达式12345678910111213141516171819202122232425262728293031习题1it = (print("&#123;&#125;".format(i+1)) for i in range(2))first = next(it)second = next(it)val = first + second# val的值是什么?# val = first + second 语句之后能否再次next(it)?输出：12---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-20-9bc925c5dd92&gt; in &lt;module&gt; 2 first = next(it) 3 second = next(it)----&gt; 4 val = first + secondTypeError: unsupported operand type(s) for +: 'NoneType' and 'NoneType'# 不要在列表解析式或生成器表达式中使用print()函数 习题2it = (x for x in range(10) if x % 2)# Python程序语言指定任何非0和非空（null）值为true，0 或者 null为false。所以这里的if后的条件x%2的结果如果是1就满足条件。first = next(it)second = next(it)val = first + secondprint(val)# val的值是什么?# val = first + second 语句之后能否再次next(it)?输出：4 和列表解析式的对比 计算方式 生成器表达式延迟计算,列表解析式立即计算 内存占用 单从返回值本身来说,生成器表达式省内存,列表解析式返回新的列表 生成器没有数据,内存占用极少,但是使用的时候,虽然一个个返回数据,但是合起来占用的内存也差不多 列表解析式构造新的列表需要占用内存 计算速度 单看计算时间看,生成器表达式耗时非常短,列表解析式耗时长 但是生成器本身并没有返回任何值,只返回了一个生成器对象 列表解析式构造并返回了一个新的列表 集合解析式 语法 {返回值 for 元素 in 可迭代对象 if 条件} 列表解析式的中括号换成大括号{}就行了 立即返回一个集合 用法 {(x,x+1) for x in range(10)} {[x] for x in range(10)} 字典解析式 语法 {返回值 for 元素 in 可迭代对象 if 条件} 列表解析式的中括号换成大括号{}就行了 使用key:value形式 立即返回一个字典 用法 {x:(x,x+1) for x in range(10)} {x:[x,x+1] for x in range(10)} {(x,):[x,x+1] for x in range(10)} {[x]:[x,x+1] for x in range(10)} # {chr(0x41+x):x**2 for x in range(10)} {str(x):y for x in range(3) for y in range(4)} # 输出多少个元素? 用法 123456789用法&#123;str(x):y for x in range(3) for y in range(4)&#125; # 输出多少个元素?等价于ret = &#123;&#125;for x in range(3): for y in range(4): ret[str(x)] = y输出：Out: &#123;'0': 3, '1': 3, '2': 3&#125; 总结 Python2 引入列表解析式 Python2.4 引入生成器表达式 Python3 引入集合、字典解析式，并迁移到了2.7 一般来说，应该多应用解析式，简短、高效 如果一个解析式非常复杂，难以读懂，要考虑拆解成for循环 生成器和迭代器是不同的对象，但都是可迭代对象]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>列表解析式与生成器表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode使用git上传代码至github]]></title>
    <url>%2F2019%2F10%2F08%2Fvscode%E4%BD%BF%E7%94%A8git%E4%B8%8A%E4%BC%A0%E4%BB%A3%E7%A0%81%E8%87%B3github%2F</url>
    <content type="text"><![CDATA[安装 安装vscode与git，这里选择在ubuntu系统中安装这两个程序 git设置123456git config --global user.name "r******9" git config --global user.email "r******9@hotmail.com"# 使用git config命令对Git进行全局设置shouyu@shouyu-pc~/文档 git clone https://github.com/r****9/Python.git# 先到github上创建一个项目，之后将github上的代码克隆到本地 vscode设置 查看克隆的项目 使用vscode的open Folder打开克隆下来的目录 创建一个新文件，以.py结尾 输入一些代码 可以看到在CHANGES中标明了此次的变化，可以点击加号添加到暂存区，再点击对勾提交，这时会要求输入一个名称 提交后，将代码push到远程的github上，点击红框部分，再点击OK，这时会要求输入github的用户名和密码 登录github查看，代码已经上传 push到github不再需要输入用户名与密码的方法 123456789101112131415161718git config --global credential.helper store# 输入此命令后，会在用户家目录的.gitconfig中加入下面信息# [credential]# helper = store在vscode中将代码push到github，这时会要求输入用户名和密码，输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码了。这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。# git config --global user.email "alice@aol.com" 操作的就是上面的email# git config --global push.default matching 操作的就是上面的push段中的default字段# git config --global credential.helper store 操作的就是上面最后一行的值# git config --global 命令实际上在操作用户目录下的.gitconfig文件，文件内容如下：# [user]# name = alice# email = alice@aol.com# [push]# default = simple# [credential]# helper = store]]></content>
      <categories>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>git插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通俗的解释排列公式和组合公式的含义]]></title>
    <url>%2F2019%2F09%2F30%2F%E5%A6%82%E4%BD%95%E9%80%9A%E4%BF%97%E7%9A%84%E8%A7%A3%E9%87%8A%E6%8E%92%E5%88%97%E5%85%AC%E5%BC%8F%E5%92%8C%E7%BB%84%E5%90%88%E5%85%AC%E5%BC%8F%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[转：如何通俗的解释排列公式和组合公式的含义？作者：浣熊老师 链接：https://www.zhihu.com/question/26094736/answer/610713978 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 本文试图用具体例子和小的数字来解释各个排列组合公式的意义，用图表的形式列举出来，由浅显到深，让大家彻底地直观地理解各个公式的含义。 写在前面：如何数清楚一个事有多少种可能性，在生活中用的并不多，但在数学里是一个很有趣、也很常考的板块，叫做计数或者排列组合。 排列组合问题简单起来可以非常简单，比如：一个“田”字里有多少个正方形？难起来也可以非常难，中国的高考、高中数学联赛和美国的 AMC、AIME 都会重点考察这个板块。 很多同学一遇到排列组合公式 P 呀 C 呀什么的就不清楚，这很正常，因为初学者在不一一列举的情况下，很难直观地想清楚哪些算重了，哪些算漏了。我自己作为学生刚接触这个的时候也是这样，每次一遇到排列组合题就很慌，后来发现，学习的关键是：你先得非常明确一些基本模型，这些基本模型往往只用很小的数字就能说明，想清楚后再做一些数字大的问题就轻松了。 本文内容包括： 一：P 的由来 二：C 的由来 三：5 个组合数的公式直观解释 四：10 个常见题型和方法 现在开始！ 一：P 的由来所谓排列组合，排列在组合之前，咱们要聊的第一个概念是“排列”，排列的英文是 Permutation 或者 Arrangement，因此在数学符号中，用 P 或者 A 表示都可以，二者意思完全一样。 我们常见的 P 右边会跟两个数字（或字母），右下角的数字 n 表示总数，右上角的数字 m 表示抽出的个数。整个符号的意思是“从 n 个人中，有顺序地抽出 m 个人的抽法数”，可以读作“P n 抽 m”。那么，到底什么叫做有顺序的？我们来举个数字很小的例子： 比如：班里有三名同学，成绩前两名有几种可能性？ 咱们可以用乘法原理：选第一名有 3 种可能性，选第二名有 2 中可能性，因为第一名那个人不可能同时又是第二名了，将这两步相乘起来。（如果你不太理解乘法原理，可以看看下图直观列举的表示。） 这个公式需要注意的是：虽然书上每次讲到这个公式时一般以阶乘（factorial）的形式给出，但实际计算中，往往不用阶乘。我的记法是：从大的数字开始往小乘，乘“小的数字那么多”个。 二：C 的由来咱们聊的第二个概念是“组合”，它比排列更常用，组合的英文是 Combination，因此在数学符号中用 C 表示，美国和英国教材中，也常用“长括号”表示组合数。 我们常见的 C 右边会跟两个数字（或字母），右下角的数字 n 表示总数，右上角的数字 m 表示抽出的个数。整个符号的意思是“从 n 个人中，不计顺序地抽出 m 个人的抽法数”，可以读作“C n 抽 m”。那么，到底什么叫做不计顺序的？我们也来举个例子： 比如：班里有三名同学，选出两名代表参加年级会议有几种选法？ 哈哈，这就可以用到之前排列数的结论了！就让刚才的第一名和第二名去参加会议。但是，对于参加会议来说，谁是第一谁是第二不重要呀！因此我把原图的红色和蓝色都涂成了黑色，以示无区别。（如下图） 至此，第二步中，第一种和第三种都是 A、B 的组合，完全一样，就会有一些算重的，至于有多少个算重，取决于抽出个数 m 的全排列种数，即 m 的阶乘。（如果你不太理解哪些算重了，可以仔细看看下图中箭头所指的对应关系） 于是，组合数公式就是在排列数公式上除以一个 m！。但实际计算中，往往不用阶乘。我的记法是：从大的数字开始往小乘，乘“小的数字那么多”个，再除以“小的数字开始往小乘，乘小的数字那么多个”。 三：组合数的公式直观解释组合公式Ⅰ： 这个公式课内和竞赛都会常常用到。我在刚学的时候把它联想成“做值日”问题，四个同学中，选三名同学做值日就相当于选一名同学放学直接回家。 比如，班里有 A、B、C、D 四个同学，每天要选出三个同学做值日，有几种选法？这个问题对于学过排列组合的同学自然非常简单了，就是 C 4 抽 3，但是，假如问一个没学过排列组合的人，他会怎么想呢？如果想 ABC，ACD……这种就会比较难想，不如去想它的反面：选Ａ、B、C 或 D 放学直接回家，总共就四种。这就能直观的理解这个公式了。 这个公式对于运算 C 10 抽 8 这样的组合数时非常有用，直接转化成 C 10 抽 2 来计算。 组合公式Ⅱ： 这个公式课内会提到，但不要求熟练掌握，竞赛会常用。可以把它联想成“约妹子看电影”问题，看看在四个妹子中，想约两个妹子有几种约法。 如果四个人都是普通朋友，看作是相同的 A、B、C、D，那自然有 C 4 抽 2 =6 种约法。下面我们来点刺激的：假如这四个人中有一个是你女朋友，她最特殊，你会先问她来不来： ①如果她来，但你还想一共约两个妹子（手动滑稽），那么就需要在其他三个妹子中再约一个，有 C 3 抽 1 种方法； ②如果她不来，那你就需要在其他三个妹子中再约两个，有 C 3 抽 2 种方法。 两类相加，表示的意义就是从 4 个妹子中约两个妹子的情况总数，即公式成立。 这个公式对于处理两个组合数相加问题非常有用，落实在计算上，我把它总结成口诀：上面的数字取大的，底下的数字加一。 组合公式Ⅲ 这个公式课内和竞赛都会常常用到。我把它叫做“抓兔子”问题，想象一个笼子里有两只兔子，抓出来的话有几种抓法？ 第一种方法是我去笼子里抓，我在抓的时候就想好是抓 1 只还是抓 2 只，或是抓 0 只（即不抓）。由于先想好了这一点，就会有 C 2 抽 1 和 C 2 抽 2 这些组合数，分别表示按“抓一只”、“抓两只” 分类，每类的情况数； 第二种情况是我把笼子打开，让每只兔子自己选择跳出来或是不跳出来（2 种可能性），每只兔子都是独立的个体，所以可以用乘法原理，总共的情况数是 n 个 2 相乘，即 2 的 n 次方。 两种方法都表示“兔子出来的情况数”，因此一样，即公式得以解释。 这个公式对于处理一系列“底下相同的”组合数相加的问题非常好用，大大节省计算量。而且它与集合、二项式定理等中学数学知识紧密相连，需深入理解。 组合公式Ⅳ 这个公式一般在竞赛中会出现。我把它叫做“火车头”问题：抽出的一些元素，总有一个打头的，称为火车头，它也是火车的一节，只不过是特殊的一节。 具体来讲，比如说你要在 A、B、C、D、E 这 5 个小球中抽取 3 个小球，咱们可以按“哪个小球是第一个”分类 第一类：A 为火车头，那么还需在后面四个小球中抽取两个小球； 第二类：B 为火车头，那么还需在后面三个小球中抽取两个小球； 第三类：C 为火车头，那么还需在后面两个小球中抽取两个小球。 至于 D 或 E 开头的，就不足“三节车厢”了，故不计算。我们把之前说的三类加起来，就直观地理解了这个公式。 这个公式对于处理一系列“上面相同的”组合数相加的问题非常好用，大大节省计算量。记忆方法是：和为上面下面都加一。 组合公式Ⅴ 这个公式是一个相加和相乘结合的公式，看似复杂，但并不难理解。我对它的理解是：可以想象成班里选几名学生，分男女选和不分男女选情况数一样。 比如说，咱们假设班里有 7 名学生，4 男 3 女。如果选出三个人参加竞赛有几种选法？首先容易想到的是 C 7 抽 3 =35。没错，不过咱们还有一个思路，就是按“男女各多少人”分类讨论。 第一类：0 男 3 女，分别抽取，再乘起来。 第二类：1 男 2 女，分别抽取，再乘起来。 第三类：2 男 1 女，分别抽取，再乘起来。 第四类：3 男 0 女，分别抽取，再乘起来。 这四类是互不重叠的，可用加法原理将其相加。原公式就得以直观理解。 上面 5 个公式都可以代数证明，也可按照我举得例子通俗理解，如果这二者你都很清楚，那排列组合就能融会贯通啦。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python算法-简单选择排序]]></title>
    <url>%2F2019%2F09%2F30%2Fpython%E7%AE%97%E6%B3%95-%E7%AE%80%E5%8D%95%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[简单选择排序 简单选择排序 属于选择排序 两两比较大小，找出极值（极大值或极小值）被放置在固定的位置，这个固定位置一般指的是某一端 结果分为升序和降序排列 降序 n个数从左至右，索引从0开始到n-1，两两依次比较，记录大值索引，此轮所有数比较完毕，将大数和索引为0的数交换，如果大数就是索引0，不交换。第二轮，从索引1开始比较，找到最大值，将它和索引1位置交换，如果它就在索引1位置则不交换。依次类推，每次左边都会固定下一个大数。 升序 和降序相反 简单选择排序代码实现一12345678910111213141516171819202122232425262728293031323334# 简单排序实现m_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[9,8,7,6,5,4,3,2,1]]nums = m_list[1]length = len(nums)print(nums)count_swap = 0count_iter = 0for i in range(length):# 按列表元素长度来迭代，第二次进入此循环，第一个索引，也就是索引0就不再进行比较了 maxindex = i# 假定最大值索引为i for j in range(i + 1, length): # j从列表元素的第二个数开始，所以加1。到长度减1结束，因为是索引，所以会少1。 count_iter += 1 if nums[maxindex] &lt; nums[j]: maxindex = j# 用maxindex索引与j索引比软，谁大，maxindex就替换为谁，实际是如果maxindex索引大，就不变，如果j索引# 大，就将maxindex替换为j。之后再用j索引与maxindex索引比较，当第一次比较过后，会得到此轮比较的最大值# 的索引。 if i != maxindex:# 每轮比较过后，用maxindex与i索引比较，如果不一样，说明i索引不是最大值，就要进行下面的替换。如果i索引# 与maxindex索引相等，就不用动了。 tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp count_swap += 1print(nums, count_swap, count_iter)输出：[1, 2, 3, 4, 5, 6, 7, 8, 9][9, 8, 7, 6, 5, 4, 3, 2, 1] 4 36 简单选择排序代码实现二优化实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 二元选择排序# 同时固定左边最大值和右边最小值# 优点：# 减少迭代元素的次数# 1. length//2整除，通过几次运算就可以发现规律# 2. 由于使用了负索引，所以条件中要增加# i == length + minindex# 还有没有优化的可能？m_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[9,8,7,6,5,4,3,2,1]]nums = m_list[1]length = len(nums)print(nums)count_swap = 0 # 交换次数count_iter = 0 # 迭代次数for i in range(length // 2): # [1,9,8,5,6,7,4,3,2]，因为每轮找到两个极值，所以要整除2 maxindex = i# 假定最大值的索引是最左边的i minindex = -i - 1# 假定最小值的索引是最右边的数，因为是前包后不包，所以还要减1 minorigin = minindex# minorigin是记录每轮最小值开头的索引，每轮最大值开头的索引就是i，但没有记录最小值开头的索引，所以这里# 要定义一个minorigin。 for j in range(i + 1, length - i): # 每次左右都要少比较一个，所以range()内的数字都要减少 count_iter += 1 if nums[maxindex] &lt; nums[j]: maxindex = j if nums[minindex] &gt; nums[-j - 1]: minindex = -j - 1# 每轮进行两次比较，得到最大值与最小值索引 # print(maxindex,minindex) 打印每轮比较后得到的两个极值 if i != maxindex: # 如果最大值索引与i不同，就进行下面的交换。下面交换的是值，也就是把最大索引指向的值与i指向听值交换 tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp # 上面三行改为nums[i],nums[maxindex] = nums[maxindex],nums[i]也可以。 count_swap += 1 if i == minindex or i == length + minindex: minindex = maxindex# 这里需要判断一下最小值索引与i是不是一样的，如果一样，经过上面最大值的交换后，i索引的值也发生了变化。所# 以这里要判断一下，如果i与最小值索引一样，那么就说明i受到了影响，因为上面i与maxindex指向的值对调了，# 所以，索引也应该对调，所以这里把maxindex赋值给minindex。这样做是为了修正最小值的索引，因为如果最小# 值索引就是i，那就上面交换后发生了变化，最小值索引变成了maxindex，所以这里要将maxindex赋值给# minindex。上面的判断中使用了or来判断两种情况是因为minindex可能是负数，i是不会等于负数的，如果是负# 数，就要用长度加上这个负索引值，这是就修正为了正数的索引。保存了最小值索引，才能保证下面的判断是有意义的。 if minorigin != minindex: tmp = nums[minorigin] nums[minorigin] = nums[minindex] nums[minindex] = tmp count_swap += 1# 这里与上面一样，判断最小值索引与minorigin是否一致，如果不一致就要交换这两个索引指向的值。print(nums, count_swap, count_iter)输出：[1, 2, 3, 4, 5, 6, 7, 8, 9][9, 8, 7, 6, 5, 4, 3, 2, 1] 8 20# 通过取两个极值，可以看到迭代的次数从36变成了20 改进实现一123456789101112131415161718192021222324252627282930313233343536373839# 如果一轮比较后，极大值、极小值的值相等，说明比较的序列元素全部相等m_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[9,8,7,6,5,4,3,2,1],[1,1,1,1,1,1,1,1,1,1]]nums = m_list[3]length = len(nums)print(nums)count_swap = 0count_iter = 0for i in range(length // 2): maxindex = i minindex = -i - 1 minorigin = minindex for j in range(i + 1, length - i): count_iter += 1 if nums[maxindex] &lt; nums[j]: maxindex = j if nums[minindex] &gt; nums[-j - 1]: minindex = -j -1 if nums[maxindex] == nums[minindex]: break if i != maxindex: tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp count_swap += 1 if i == minindex or i == length + minindex: minindex = maxindex if minorigin != minindex: tmp = nums[minorigin] nums[minorigin] = nums[minindex] nums[minindex] = tmp count_swap += 1print(nums, count_swap, count_iter)输出：[1, 1, 1, 1, 1, 1, 1, 1, 1, 1][1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 0 9 改进实现二123456789101112131415161718192021222324252627282930313233343536373839404142434445# [1,1,1,1,1,1,1,1,2]这种情况，找到的最小值索引是-2，最大值索引是8，上面的代码会交换2# 次，最小值两个1交换是无用功，所以，增加一个判断m_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[9,8,7,6,5,4,3,2,1],[1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,2]]nums = m_list[4]length = len(nums)print(nums)count_swap = 0count_iter = 0for i in range(length // 2): maxindex = i minindex = -i - 1 minorigin = minindex for j in range(i + 1, length - i): count_iter += 1 if nums[maxindex] &lt; nums[j]: maxindex = j if nums[minindex] &gt; nums[-j - 1]: minindex = -j -1 print(maxindex,minindex) if nums[maxindex] == nums[minindex]: # 元素相同 break if i != maxindex: tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp count_swap += 1 # 如果最小值被交换过，要更新索引 if i == minindex or i == length + minindex: minindex = maxindex if minorigin != minindex and nums[minorigin] != nums[minindex]:# 这里的判断指最小值索引不同，但值相同就没有必要交换了 tmp = nums[minorigin] nums[minorigin] = nums[minindex] nums[minindex] = tmp count_swap += 1print(nums, count_swap, count_iter)输出：[1, 1, 1, 1, 1, 1, 1, 1, 1, 2]9 -21 -2[2, 1, 1, 1, 1, 1, 1, 1, 1, 1] 1 16 简单选择排序总结 简单选择排序需要数据一轮轮比较，并在每一轮中发现极值 没有办法知道当前轮是否已经达到排序要求，但是可以知道极值是否在目标索引位置上 遍历次数1,…,n-1之和n(n-1)/2 时间复杂度O(n**2)，因为用了两个循环，所以是n的平方 减少了交换次数，提高了效率，性能略好于冒泡法]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode安装使用python插件]]></title>
    <url>%2F2019%2F09%2F30%2Fvscode%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8python%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[安装插件，搜索安装Python和python for VSCode插件 选择解释器，使用ctrl + shift + p调出顶部的方框，输入Python:Select Interpreter，之后选择一个解释器，这里选择了系统的python3.6.8 安装pip，因为在创建test.py后，打开文件时会提示需要安装，具体作用未明apt install python3-pip 执行代码，先重启一下vscode，执行代码时可以用右键或点右上角的箭头]]></content>
      <categories>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>python插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[axel使用方法]]></title>
    <url>%2F2019%2F09%2F25%2Faxel%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021语法：axel [options] url1 [url2] [url…]选项：--max-speed=x , -s x # 最高速度x--num-connections=x , -n x # 连接数x--output=f , -o f # 下载为本地文件f--search[=x] , -S [x] # 搜索镜像--header=x , -H x # 添加头文件字符串x（指定 HTTP header）--user-agent=x , -U x # 设置用户代理（指定 HTTP user agent）--no-proxy ， -N # 不使用代理服务器--quiet ， -q # 静默模式--verbose ，-v # 更多状态信息--alternate ， -a # Alternate progress indicator--help ，-h # 帮助--version ，-V # 版本信息举例：axel -n 10 -o /tmp/ http://www.jsdig.com/lnmp.tar.gz# 下载安装包指定10个线程，存到/tmp/。如果下载过程中下载中断可以再执行下载命令即可恢复上次# 的下载进度。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>conky</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl使用]]></title>
    <url>%2F2019%2F09%2F25%2Fcurl%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[常用选项1234567891011-A/--user-agent &lt;string&gt; # 设置用户代理发送给服务器，即告诉服务器浏览器为什么-basic # 使用HTTP基本验证--tcp-nodelay # 使用TCP_NODELAY选项-e/--referer &lt;URL&gt; # 来源网址，跳转过来的网址--cacert &lt;file&gt; # 指定CA证书 (SSL)--compressed # 要求返回是压缩的形势，如果文件本身为一个压缩文件，则可以下载至本地-H/--header &lt;line&gt; # 自定义头信息传递给服务器-I/--head # 只显示响应报文首部信息--limit-rate &lt;rate&gt; # 设置传输速度-u/--user &lt;user[:password]&gt; # 设置服务器的用户和密码-0/--http1.0 # 使用HTTP 1.0 使用12345678910111213141516171819202122232425262728curl -I http://www.ruopu.io# -I:只获得对方的响应首部信息# 如果在服务器上手动自定义了一些首部的话，使用curl这个工具的“-I”选项可以很容易的探测出服务# 器是否正确添加了自定义的首部。curl -A testagent http://www.ruopu.io# -A：设置用户代理发送给服务器，即可以伪装客户端身份curl -e http://www.google.com/index.html http://www.ruopu.io# -e：伪装&lt;URL&gt;来源网址，跳转过来的网址curl --cacert /etc/pki/CA/cacert.pem https://www.ruopu.io# --cacert，指定CA证书 (SSL)curl www.baidu.com# 访问网页curl -i www.baidu.com# 显示http response的头信息curl -v www.baidu.com# 显示一次的http请求的通信过程curl -X PUT www.baidu.com curl -X DELETE www.baidu.comcurl -X POST www.baidu.com curl -X GET www.baidu.com# curl执行GET/POST/PUT/DELETE操作]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wget使用]]></title>
    <url>%2F2019%2F09%2F25%2Fwget%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用12345678910111213141516171819202122wget -qO- get.docker.com | bash# -q：--quiet，静默模式，无信息输出。# -O：把后面网址下载后，改成一个指定的名称，如果后面没有跟着一个名字，而是“-”，则表示将下载# 后的内容输出到标准输出，也就是输出到屏幕上。# -qO-：把下载的内容输出到标准输出，但并不在屏幕显示，目的是直接传递给bash进行解析执行。\wget -O - https://install.perlbrew.pl | bash# 前面加一个"\"是取消别名调用，执行原命令。如perlbrew网站wget -P /opt/wordpress https://wordpress.org/latest.zip# 下载后保存到指定目录。wget -c https://wordpress.org/latest.zip# 断点续传，有时候下载某文件，网络中断后，可以用“-c”来继续之前的下载，如果不使用“-c“则表示# 重新开始整个下载，且在下载的文件后面加".1"，因为之前没有下载完的文件还存在。wget -b http://example.com/big-file.zip# 对于大文件，你可以用“-b”参数在后台下载，输出信息会保存在同目录的“wget-log”中，你可以# 用“tail -f wget-log”来查看。wget --no-check-certificate https://github.com/teejee2008/conky-manager/releases/download/v2.4/conky-manager-v2.4-amd64.run# --no-check-certificate：不检查证书]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-set及操作]]></title>
    <url>%2F2019%2F09%2F23%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-set%E5%8F%8A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[集合set 约定 set翻译为集合 collection翻译为集合类型，是一个大概念 set 可变的、无序的、不重复的元素的集合 set定义与初始化 set() -&gt; new empty set object set(iterable) -&gt; new set object，set()中可以是一个可迭代对象，也可以是list或tuple 官网解释：返回一个新的 set 或 frozenset 对象，其元素来自于 iterable。 集合的元素必须为 hashable。 要表示由集合对象构成的集合，所有的内层集合必须为 frozenset 对象。 如果未指定 iterable，则将返回一个新的空集合。 hashable – 可哈希 一个对象的哈希值如果在其生命周期内绝不改变，就被称为 可哈希 （它需要具有 __hash__() 方法），并可以同其他对象进行比较（它需要具有 __eq__() 方法）。可哈希对象必须具有相同的哈希值比较结果才会相同。 可哈希性使得对象能够作为字典键或集合成员使用，因为这些数据结构要在内部使用哈希值。 大多数 Python 中的不可变内置对象都是可哈希的；可变容器（例如列表或字典）都不可哈希；不可变容器（例如元组和 frozenset）仅当它们的元素均为可哈希时才是可哈希的。 用户定义类的实例对象默认是可哈希的。 它们在比较时一定不相同（除非是与自己比较），它们的哈希值的生成是基于它们的 id()。 123456789101112131415161718192021222324252627s1 = set()s2 = set(range(5))s3 = set(list(range(10))) # 使用list时，一定要用set()，不能用&#123;&#125;s4 = &#123;&#125; # 这样定义的是dict，而不是set。使用大括号来定义时，不能在大括号中用列表类型s5 = &#123;9,10,11&#125; # 使用&#123;&#125;定义set，大括号中必须有内容s6 = &#123;(1,2),3,'a'&#125;s7 = &#123;[1],(1,),1&#125;# 查看这三个元素是否都可以hash，大括号中需要使用可hash的元素，可以使用hash()函数测试，列表是不能hash的s8 = set(&#123;'a':2,'b':3,'c':4&#125;)# 字典转set集合，需要注意的是，只取了字典的key，相当于将字典中的dict.keys()列表转成set集合。# 大括号或 set() 函数可以用来创建集合。 # set集合类需要的参数必须是迭代器类型的，如：序列、字典等，然后转换成无序不重复的元素集。由于集合是不重复的，所以可以对字符串、列表、元组进行去重操作。s1 = set([1,2,3,4])# 个人感觉，&#123;&#125;是在定义一个集合，而set()是在将类型转换，所以大括号中不能使用列表类型，而set()中可以。&gt;&gt;&gt; s=set()&gt;&gt;&gt; sset()&gt;&gt;&gt; s1=set([]) ＃列表&gt;&gt;&gt; s1set()&gt;&gt;&gt; s2=set(()) ＃元组&gt;&gt;&gt; s2set()&gt;&gt;&gt; s3=set(&#123;&#125;) ＃字典&gt;&gt;&gt; s3set() set的元素 set的元素要求必须可以hash 目前学过的不可hash的类型有list、set 元素不可以索引，因为没有顺序所以无法索引 set可以迭代，如果不可以迭代，就不能用in了 set增加 add(elem) 把要传入的元素作为一个整体添加到set集合中 如果元素存在，什么都不做 123456&gt;&gt;&gt; s=set('one')&gt;&gt;&gt; s&#123;'e', 'o', 'n'&#125;&gt;&gt;&gt; s.add('two')&gt;&gt;&gt; s&#123;'e', 'two', 'o', 'n'&#125; update(*others) 合并其他元素到set集合中来。是把要传入的元素拆分成单个字符，存于集合中，并去掉重复的字符。可以一次添加多个值 参数others必须是可迭代对象 就地修改 123456&gt;&gt;&gt; s=set('one')&gt;&gt;&gt; s&#123;'e', 'o', 'n'&#125;&gt;&gt;&gt; s.update('two')&gt;&gt;&gt; s&#123;'e', 'n', 't', 'w', 'o'&#125; set删除 remove(elem) 从set中移除一个元素 元素不存在，抛出KeyError异常。为什么是KeyError？因为是key比较，所以抛出KeyError。这个方法用hash()做了比较 123456&gt;&gt;&gt; s=set('one')&gt;&gt;&gt; s&#123;'e', 'o', 'n'&#125;&gt;&gt;&gt; s.remove('e')&gt;&gt;&gt; s&#123;'n', 'o'&#125; discard(elem) 从set中移除一个元素 元素不存在，什么都不做 12345&gt;&gt;&gt; sListset([1, 2, 3, 4, 5])&gt;&gt;&gt; sList.discard(1)&gt;&gt;&gt; sListset([2, 3, 4, 5]) pop() -&gt; item 移除并返回任意的元素。为什么是任意元素? 空集返回KeyError异常，因为没有key可以拿了 1234&gt;&gt;&gt; sListset([2, 3, 4, 5])&gt;&gt;&gt; sList.pop()2 clear() 移除所有元素 12345&gt;&gt;&gt; sListset([3, 4, 5])&gt;&gt;&gt; sList.clear()&gt;&gt;&gt; sListset([]) set修改、查询 修改 要么删除，要么加入新的元素 为什么没有修改？因为是非线性结构，无法索引？ 查询 非线性结构，无法索引 遍历 可以迭代所有元素 123456789101112131415161718192021&gt;&gt;&gt; s=set('one')&gt;&gt;&gt; s&#123;'e', 'o', 'n'&#125;&gt;&gt;&gt; for i in s: print(i)... ... eon&gt;&gt;&gt; &gt;&gt;&gt; s=set('one')&gt;&gt;&gt; s&#123;'e', 'o', 'n'&#125;&gt;&gt;&gt; for idex,i in enumerate(s): print (idex,i)... ... 0 e1 o2 n&gt;&gt;&gt; 成员运算符 in 和 not in 判断元素是否在set中 效率呢? 1234567891011121314151617181920212223# set成员运算符的比较# list和set的比较lst1 = list(range(100))lst2 = list(range(1000000))-1 in lst1、-1 in lst2 # 看看效率set1 = set(range(100))set2 = set(range(1000000))-1 in set1、-1 in set2 # 看看效率# 例%%timeit lst1=list(range(100))a = -1 in lst1# 用-1是为了遍历一次，也可以写99，也是为了遍历一次%%timeit lst1=list(range(1000000))a = -1 in lst1%%timeit set1=set(range(100))a = -1 in set1%%timeit set1=set(range(1000000))a = -1 in set1# set保存的是key，用hash值对比。如果hash值一样，就会去重 set和线性结构 线性结构的查询时间复杂度是O(n)，即随着数据规模的增大而增加耗时 set、dict等结构，内部使用hash值作为key，时间复杂度可以做到O(1)，查询时间和数据规模无关，把列表，集合与字典一定要弄清楚 可hash 数值型int、float、complex 布尔型True、False 字符串string、bytes tuple None 以上都是不可变类型，成为可哈希类型，hashable set的元素必须是可hash的 集合其他方法 函数 说明 len(s) set 的长度 x in s 测试 x 是否是 s 的成员 x not in s 测试 x 是否不是 s 的成员 s.issubset(t) 测试是否 s 中的每一个元素都在 t 中 s.issuperset(t) 测试是否 t 中的每一个元素都在 s 中 s.union(t) 返回一个新的 set 包含 s 和 t 中的每一个元素 s.intersection(t) 返回一个新的 set 包含 s 和 t 中的公共元素 s.difference(t) 返回一个新的 set 包含 s 中有但是 t 中没有的元素 s.symmetric_difference(t) 返回一个新的 set 包含 s 和 t 中不重复的元素 s.copy() 返回 set “s”的一个浅复制 集合 基本概念 全集 所有元素的集合。例如实数集，所有实数组成的集合就是全集 子集subset和超集superset 一个集合A所有元素都在另一个集合B内，A是B的子集，B是A的超集 真子集和真超集 A是B的子集，且A不等于B，A就是B的真子集，B是A的真超集 并集：多个集合合并的结果 交集：多个集合的公共部分 差集：集合中除去和其他集合公共部分 集合运算 并集 将两个集合A和B的所有的元素合并到一起，组成的集合称作集合A与集合B的并集 union(*others) 返回和多个集合合并后的新的集合 | 运算符重载 等同union update(*others) 和多个集合合并，就地修改 |= 等同update 1234567&gt;&gt;&gt; st1set(['h', 'o', 'n', 'p', 't', 'y'])&gt;&gt;&gt; st3 = set('two')&gt;&gt;&gt; st3set(['o', 't', 'w'])&gt;&gt;&gt; st1 | st3set(['p', 't', 'w', 'y', 'h', 'o', 'n']) 交集 集合A和B，由所有属于A且属于B的元素组成的集合 intersection(*others) 返回和多个集合的交集 &amp; 等同intersection intersection_update(*others) 获取和多个集合的交集，并就地修改 &amp;= 等同intersection_update 12345678&gt;&gt;&gt; st1 = set('python')&gt;&gt;&gt; st1set(['h', 'o', 'n', 'p', 't', 'y'])&gt;&gt;&gt; st2 = set('htc')&gt;&gt;&gt; st2set(['h', 'c', 't'])&gt;&gt;&gt; st1 &amp; st2set(['h', 't']) 差集 集合A和B，由所有属于A且不属于B的元素组成的集合 difference(*others) 返回和多个集合的差集 12345678910&gt;&gt;&gt; s1set([1, 2, 3, 4, 5])&gt;&gt;&gt; s2set([1, 2, 3, 4])&gt;&gt;&gt; s1.difference(s2)set([5])&gt;&gt;&gt; s3set(['1', '8', '9', '5'])&gt;&gt;&gt; s1.difference(s3)set([1, 2, 3, 4, 5]) - 等同difference difference_update(*others) 获取和多个集合的差集并就地修改 -= 等同difference_update 1234567&gt;&gt;&gt; st1set(['1', '3', '2', '5', '4', '7', '6'])&gt;&gt;&gt; st2 = set('4589')&gt;&gt;&gt; st2set(['9', '8', '5', '4'])&gt;&gt;&gt; st1 - st2set(['1', '3', '2', '7', '6']) 对称差集 集合A和B，由所有不属于A和B的交集元素组成的集合，记作(A-B)∪(B-A) symmetric_differece(other) 返回和另一个集合的差集 ^ 等同symmetric_differece symmetric_differece_update(other) 获取和另一个集合的差集并就地修改 ^= 等同symmetric_differece_update issubset(other)、&lt;= 判断当前集合是否是另一个集合的子集 set1 &lt; set2 判断set1是否是set2的真子集 issuperset(other)、&gt;= 判断当前集合是否是other的超集 set1 &gt; set2 判断set1是否是set的真超集 isdisjoint(other) 当前集合和另一个集合没有交集 没有交集，返回True 123456789101112131415161718192021&gt;&gt;&gt; s1＝set([1, 2, 3, 4, 5])&gt;&gt;&gt; s2＝set([1, 2, 3, 4])&gt;&gt;&gt; s3＝set(['1', '8', '9', '5'])&gt;&gt;&gt; s1 &gt; s2True&gt;&gt;&gt; s1 &gt; s3False&gt;&gt;&gt; s1 &gt;= s2True&gt;&gt;&gt; s2 &lt; s1True&gt;&gt;&gt; s1 &lt; s3False&gt;&gt;&gt; s3 &lt; s1False&gt;&gt;&gt; s1 == s2False&gt;&gt;&gt; s2 == s3False&gt;&gt;&gt; s1 != s2True 集合应用 共同好友 你的好友A、B、C，他的好友C、B、D，求共同好友 交集问题：{‘A’, ‘B’, ‘C’}.intersection({‘B’, ‘C’, ‘D’}) 微信群提醒 XXX与群里其他人都不是微信朋友关系 并集：userid in (A | B | C | …) == False，A、B、C等是微信好友的并集，用户ID不在这个并集中，说明他和任何人都不是朋友 权限判断 有一个API，要求权限同时具备A、B、C才能访问，用户权限是B、C、D，判断用户是否能够访问该API API集合A，权限集合P A - P = {} ，A-P为空集，说明P包含A A.issubset(P) 也行，A是P的子集也行 A &amp; P = A 也行 有一个API，要求权限具备A、B、C任意一项就可访问，用户权限是B、C、D，判断用户是否能够访问该API API集合A，权限集合P A &amp; P != {} 就可以 A.isdisjoint(P) == False 表示有交集 一个总任务列表，存储所有任务。一个完成的任务列表。找出未完成的任务 业务中，任务ID一般不可以重复 所有任务ID放到一个set中，假设为ALL 所有已完成的任务ID放到一个set中，假设为COMPLETED，它是ALL的子集 ALL - COMPLETED = UNCOMPLETED 集合推导式(Set comprehension)123&gt;&gt;&gt;a = &#123;x for x in 'abracadabra' if x not in 'abc'&#125;&gt;&gt;&gt; a&#123;'r', 'd'&#125; 练习1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768a = &#123;1,2,3,4&#125;b = &#123;2,3,4&#125;print(a.union(b))c = b.union(a)print(a)print(c)print(a | b)print(b|a)b.update(a)print(b)a |= &#123;5,6&#125; | &#123;7,8&#125;# 先计算&#123;5,6&#125; | &#123;7,8&#125;，再将值给a。print(a)a = 1a += 1+2print(a)输出：&#123;1, 2, 3, 4&#125;&#123;1, 2, 3, 4&#125;&#123;1, 2, 3, 4&#125;&#123;1, 2, 3, 4&#125;&#123;1, 2, 3, 4&#125;&#123;1, 2, 3, 4, 5, 6, 7, 8&#125;4a = &#123;1,2,3&#125;b = &#123;3,4,5&#125;a = a &amp; ba.intersection_update(b)print(a)b.intersection_update(a)print(b)a.update(&#123;1,2,3,4,5,6&#125;)print(a)print(a - b)print(b - a)print(a,b)a -= b输出：&#123;3&#125;&#123;3&#125;&#123;1, 2, 3, 4, 5, 6&#125;&#123;1, 2, 4, 5, 6&#125;set()&#123;1, 2, 3, 4, 5, 6&#125; &#123;3&#125;# 随机产生2组各10个数字的列表,如下要求:# 每个数字取值范围[10,20]# 统计20个数字中,一共有多少个不同的数字?# 2组比较,不重复的数字有几个?分别是什么?# 2组比较,重复的数字有几个?分别是什么?a = [1, 9, 7, 5, 6, 7, 8, 8, 2, 6]b = [1, 9, 0, 5, 6, 4, 8, 3, 2, 3]s1 = set(a)s2 = set(b)print(s1)print(s2)print(s1.union(s2))print(s1.symmetric_difference(s2))print(s1.intersection(s2)) 不可变集合frozensetPython中还有一种不可改变的集合，那就是frozenset，不像set集合，可以增加删除集合中的元素，该集合中的内容是不可改变的，类似于字符串、元组。 1234567891011121314151617&gt;&gt;&gt; f = frozenset()&gt;&gt;&gt; ffrozenset([])&gt;&gt;&gt; f = frozenset('asdf')&gt;&gt;&gt; ffrozenset(['a', 's', 'd', 'f'])&gt;&gt;&gt; f = frozenset([1,2,3,4])&gt;&gt;&gt; ffrozenset([1, 2, 3, 4])&gt;&gt;&gt; f = frozenset((1,2,3,4))&gt;&gt;&gt; ffrozenset([1, 2, 3, 4])&gt;&gt;&gt; f = frozenset(&#123;1:2, 'a':2, 'c':3&#125;)&gt;&gt;&gt; ffrozenset(['a', 1, 'c'])# 如果试图改变不可变集合中的元素，就会报AttributeError错误。# 不可变集合，除了内容不能更改外，其他功能及操作跟可变集合set一样。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python学习-set及操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-内置数据结构]]></title>
    <url>%2F2019%2F09%2F23%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%86%85%E7%BD%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[练习1：杨辉三角，求杨辉三角第n行第k列的值算法11234567891011121314151617181920212223# 算法1# 计算到m行，打印出k项# 求m行k个元素# m行元素有m个，所以k不能大于m# 这个需求需要保存m行的数据，那么可以使用一个嵌套机构[[],[],[]]m = 5k = 4triangle = []for i in range(m): # 所有行都需要1开头 row = [1] triangle.append(row) if i == 0: continue for j in range(1,i): row.append(triangle[i-1][j-1] + triangle[i-1][j]) row.append(1)print(triangle)print("---------")print(triangle[m-1][k-1])print("---------")# 这里算出的是第五行第四列的值 算法21234567891011121314151617181920212223242526272829303132# 算法2# 根据杨辉三角的定理：第n行的m个数(m&gt;0且n&gt;0)可表示为C(n-1,m-1)，即为从n-1个不同元素中取m-1个元素的组合数# 组合数公式：有m个不同元素，任意取n(n&lt;=m)个元素，记作c(m,n)，组合数公式为：# C(m,n) = m!/(n!(m-n)!)# m行k列的值，c(m-1,k-1)组合数m = 9k = 5# c(n,r) = c(m-1,k-1) = (m-1)!/((k-1)!(m-r)!)# m最大n = m - 1r = k - 1d = n - r# 上面三行可以写成一行，使用封装解构的方法targets = [] # r, n-r, nfactorial = 1# factorial是初始值，求阶乘起始为1，求和起始为0# 可以加入k为1或者m的判断，返回1for i in range(1,n+1):# range中的范围就是要求的阶乘的范围 factorial *= i# 这里是求阶乘 if i == r: targets.append(factorial) if i == d: targets.append(factorial) if i == n: targets.append(factorial)print(targets)print(targets[2]//(targets[0]*targets[1]))# i == r 、i == n 、i == d，这三个条件不要写在一起，因为它们有可能两两相等# 算法说明：一趟到n的阶乘算出所有阶乘值。 练习2：转置矩阵方法112345678910111213141516171819202122232425262728293031323334353637383940# 转置矩阵# 1 2 3 1 4 7# 4 5 6 ==&gt; 2 5 8# 7 8 9 3 6 9# 规律：对角线不动，a[i][j] &lt;=&gt; a[j][i]，而且到了对角线，就停止，去做下一行，对角线上的元素不动。# 定义一个方阵# 1 2 3 1 4 7# 4 5 6 ==&gt; 2 5 8# 7 8 9 3 6 9# 方法1matrix=[[1,2,3],[4,5,6],[7,8,9]]print(matrix)count = 0for i,row in enumerate(matrix): # 这里的结果是# 0 [1,2,3] i是索引0，row是值[1,2,3]# 1 [4,5,6] # 2 [7,8,9] for j,col in enumerate(row):# 当这里是0 [1,2,3]时，这里的结果是# 0 1# 1 2# 2 3 if i &lt; j:# 在这里进行索引的比较，交i小于j时才交换，第一次时，i一直是0，j是0,1,2，当i和j都是0时，不会有变动。当i是0,j是1时，# 就将matrix[0][1]和matrix[1][0]对调，也就成了[[1,4,3],[2,5,6],[7,8,9]]，当i是0，j是2时，# 就将matrix[0][2]和matrix[2][0]对调，也就成了[[1,4,7],[2,5,6],[3,8,9]]。之后以此类推。 temp = matrix[i][j] matrix[i][j] = matrix[j][i] matrix[j][i] = temp count += 1print(matrix)print(count)# 统计一共交换的次数输出：[[1, 2, 3], [4, 5, 6], [7, 8, 9]][[1, 4, 7], [2, 5, 8], [3, 6, 9]]3 方法21234567891011matrix = [[1,2,3,10],[4,5,6,11],[7,8,9,12],[1,2,3,4]]length = len(matrix)count = 0for i in range(length): for j in range(i): # 这个设计更加巧妙，按此方法，如果matrix中有五个元素，每个元素中有五个小的元素，使用此方法# 也可以转置。只要matrix中的元素与元素中的子元素个数是相等的就可以转置。 matrix[i][j],matrix[j][i] = matrix[j][i],matrix[i][j] count += 1print(matrix)print(count) 练习3：任意矩阵转置算法11234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 1 2 3 1 4# 4 5 6 &lt;=&gt; 2 5# 3 6# 这是一个矩阵，但不是方阵# enumerate(iterable[, start]) -&gt; iterator for index, value of iterable# 返回一个可迭代对象，将原有可迭代对象的元素和从start开始的数字配对# 算法1# 过程就是，扫描matrix第一行，在tm的第一列从上至下附加，然后再第二列附加。# 举例，扫描第一行1,2,3，加入到tm的第一列，然后扫描第二行4,5,6，追加到tm的第二列# 定义一个矩阵，不考虑稀疏矩阵# 1 2 3 1 4# 4 5 6 &lt;=&gt; 2 5# 3 6import datetimematrix = [[1,2,3],[4,5,6]]# matrix = [[1,4],[2,5],[3,6]]tm = []count = 0for row in matrix: for i,col in enumerate(row):# 这里是为了计算matrix中有几列，有几列就要为tm创建几行，结果是：# 0 1# 1 2# 2 3# 0 4# 1 5# 2 6 if len(tm) &lt; i + 1: # matrix的列数与tm的行数应该相等，len(tm)就是计算tm有几行的，i+1是列数，加1是因为i是# 从0开始的。这里的条件会一直满足，len(tm)会一直小于i+1。因为第一次len(tm)的结果是0。只# 有这个条件满足时，才会向tm的元素中追加值。把tm转化为matrix也一样可以使用这个方法 tm.append([]) tm[i].append(col) count += 1 print(matrix)print(tm)print(count)输出：[[1, 4], [2, 5], [3, 6]][[1, 2, 3], [4, 5, 6]]6 算法2123456789101112131415161718192021222324252627# 思考：# 能否一次性开辟目标矩阵的内存空间？# 如果一次性开辟好目标矩阵内存空间，那么原矩阵的元素直接移动到转置矩阵的对称坐标就行了# 1 2 3 1 4# 4 5 6 &lt;=&gt; 2 5# 3 6# 在原有矩阵上改动，牵扯到增加元素和减少元素，麻烦，所以，定义一个新的矩阵输出matrix = [[1,2,3],[4,5,6]]# matrix = [[1,4],[2,5],[3,6]]tm = [[0 for col in range(len(matrix))] for row in range(len(matrix[0]))]count = 0for i,row in enumerate(tm): for j,col in enumerate(row): tm[i][j] = matrix[j][i] # 将matrix的所有元素搬到tm中 count += 1print(matrix)print(tm)print(count)输出：[[1, 4], [2, 5], [3, 6]][[1, 2, 3], [4, 5, 6]]6 效率测试12345678910111213141516171819202122232425262728293031323334353637383940414243import datetimematrix = [[1,2,3],[4,5,6],[7,8,9]]matrix = [[1,4],[2,5],[3,6]]print('\nMethod 1')start = datetime.datetime.now()for c in range(100000): tm = [] # 目标矩阵 for row in matrix: for i,item in enumerate(row): if len(tm) &lt; i + 1: tm.append([]) tm[i].append(item) delta = (datetime.datetime.now()-start).total_seconds()print(delta)print(matrix)print(tm)print('\nMethod 2')start = datetime.datetime.now()for c in range(100000): tm = [0] * len(matrix[0]) for i in range(len(tm)): tm[i] = [0] * len(matrix) for i,row in enumerate(tm): for j,col in enumerate(row): tm[i][j] = matrix[j][i] delta = (datetime.datetime.now()-start).total_seconds()print(delta)print(matrix)print(tm)# 说明：# 上面两个方法在ipython中，使用%%timeit测试下来方法一效率更高。# 但是方法一效率真的高吗？# 给一个大矩阵，测试一下# matrix = [[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6],[1,2,3],[4,5,6]]# 测试发现，其实只要增加到4*4开始，方法二优势就开始了。# 矩阵规模越大，先开辟空间比后append效率高 练习4：数字统计12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 随机产生10个数字# 要求：# 每个数字取值范围[1,20]# 统计重复的数字有几个？分别是什么？# 统计不重复的数字有几个？分别是什么？# 举例：11,7,5,11,6,7,4，其中2个数字7和11重复了，3个数字4,5,6没有重复过# 思路：# 对于一个排序的序列，相等的数字会挨在一起。但是如果先排序，还是要花时间，能否不排序解决？# 例如11,7,5,11,6,7,4，先拿出11，依次从第二个数字开始比较，发现11就把对应索引标记，这样一趟比较就知道11是否重复，哪些地方重复。# 第二趟使用7和其后数字依次比较，发现7就标记，当遇到以前比较过的11的位置的时候，其索引已经被标记为1,直接跳过。import randomnums = []for _ in range(10): nums.append(random.randrange(21)) print("Origin numbers = &#123;&#125;".format(nums))print()length = len(nums)samenums = [] # 记录相同的数字diffnums = [] # 记录不同的数字states = [0] * length # 记录不同的索引异同状态for i in range(length): flag = False # 假定没有重复 if states[i] == 1: continue for j in range(i+1,length): if states[j] == 1: continue if nums[i] == nums[j]: flag = True states[j] = 1 if flag: # 有重复 samenums.append(nums[i]) states[i] = 1 else: diffnums.append(nums[i]) print("Same numbers = &#123;1&#125;,Counter = &#123;0&#125;".format(len(samenums),samenums))print("Different numbers = &#123;1&#125;,Counter = &#123;0&#125;".format(len(diffnums),diffnums))print(list(zip(states,nums)))输出：Origin numbers = [7, 15, 12, 8, 10, 0, 5, 19, 15, 2]Same numbers = [15],Counter = 1Different numbers = [12, 8, 10, 0, 5, 19, 15, 2],Counter = 8[(0, 7), (1, 15), (0, 12), (0, 8), (0, 10), (0, 0), (0, 5), (0, 19), (1, 15), (0, 2)]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python练习-内置数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-封装与解构]]></title>
    <url>%2F2019%2F09%2F19%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%B0%81%E8%A3%85%E4%B8%8E%E8%A7%A3%E6%9E%84%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657练习1：lst = list(range(10)) # 这样一个列表,取出第二个、第四个、倒数第二个lst = list(range(10))one,two,three,four,*_,Mtwo,Mone = lstprint(two,four,Mtwo)输出：1 3 8练习2：从lst = [1,(2,3,4),5]中提取4出来lst = [1,(2,3,4),5]_,(*_,a),_ = lstprint(a)输出：4练习3：环境变量JAVA_HOME=/usr/bin，返回环境变量名和路径s = 'JAVA_HOME=/usr/bin'name,_,path = s.partition('=')print(name,path)输出：JAVA_HOME /usr/bins = 'JAVA_HOME=/usr/bin'name,*_,path = s.split('=')print(name,path)输出：JAVA_HOME /usr/bins = 'JAVA_HOME=/usr/bin'name,path = s.split('=')print(name,path)输出：JAVA_HOME /usr/bin练习4：对列表[1,9,8,5,6,7,4,3,2]使用冒泡法排序，要求使用封装和解构来交互数据lst=[1,9,8,6,3,4,5,2,7]for i in range(9):# 一共要循环比较的次数，从第一个数字与第二个数字比较，一直比较到最后一个数字。# 这算一次。因为一共有9个数字，所以要比较九轮 for j in range(8-i):# range中是每次要比较的次数，因为i是从0开始的，所以这里用8来减i，就是每次数字要比较# 的次数，也就是从第一个比较到最后一个，第一次第1个数字要和后面8个数字比较，之后每次# 比较都会少一个数字 if lst[j] &gt; lst[j+1]:# 如果在比较中，前面的数字大于后面的数字，就按下面方法把前后两个数字对调。这样一直比较，# 就会将最大的数字放到最后。 lst[j],lst[j+1] = lst[j+1],lst[j] # 这是封装解构的过程，但交换还是很耗时的print(lst)输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]lst = [1,9,8,6,3,4,5,2,7]for i in range(len(lst)): for j in range(8,0,-1): if lst[j] &gt; lst[j-1]: # 因为上面range定义的范围是从大到小排列，所以这里是从后面前比较，大的数字会排到最前面。 lst[j],lst[j-1] = lst[j-1],lst[j]print(lst)输出：[9, 8, 7, 6, 5, 4, 3, 2, 1]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python练习-封装和解构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-bytes和bytearray]]></title>
    <url>%2F2019%2F09%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-bytes%E5%92%8Cbytearray%2F</url>
    <content type="text"><![CDATA[bytes、bytearray Python3引入两个新类型 bytes 不可变字节序列 bytearray 字节数组 可变 字符串与bytes 字符串是字符组成的有序序列，字符可以使用编码来理解 bytes是字节组成的有序的不可变序列 bytearray是字节组成的有序的可变序列 编码与解码 字符串按照不同的字符集编码encode返回字节序列bytes encode(encoding=”utf-8”,errors=”strict”) -&gt; str 字节序列按照不同的字符集解码decode返回字符串 bytes.decode(encoding=”utf-8”,errors=”strict”) -&gt; str bytearray.decode(encoding=”utf-8”,errors=”strict”) -&gt; str ASCII ASCII(American Standard Code for Infomation 美国信息交换标准代码)是基于拉丁字母的一套单字节编码系统 bytes定义 定义 bytes() 空bytes bytes(int) 指定字节的bytes，被0填充 bytes(iterable_of_ints) -&gt; bytes[0,255]的int组成的可迭代对象 bytes(string,encoding[,errors]) -&gt; bytes等价于string.encode() bytes(bytes_of_buffer) -&gt; immutable copy of bytes_of_buffer 从一个字节序列或者buffer复制出一个新的不可变的bytes对象 使用b前缀定义 只允许基本ASCII使用字符形式b’abc9’ 使用16进制表示b”\x41\x61” bytes操作 和str类型类似，都是不可变类型，所以方法很多都一样。只不过bytes的方法，输入是bytes，输出是bytes 12b'abcdef'.replace(b'f',b'k')b'abc'.find(b'b') 类方法 bytes.fromhex(string) string必须是2个字符的16进制的形式，’6162 6a 6b’，空格将被忽略 类方法就是类型的方法，另外还有对象方法 1bytes.fromhex('6162 09 6a 6b00') hex() 返回16进制表示的字符串 1'abc'.encode().hex() 索引 12b'abcdef'[2]# 返回该字节对应的数，int类型 bytearray定义 定义 bytearray() 空bytearray bytearray(int) 指定字节的bytearray，被0填充 bytearray(iterable_of_ints) -&gt; bytearray [0,255]的int组成的可迭代对象 bytearray(string, encoding[, errors]) -&gt; bytearray 近似string.encode()，不过返回可变对象 bytearray(bytes_or_buffer) 从一个字节序列或者buffer复制出一个新的可变的bytearray对象 注意：b前缀定义的类型是bytes类型 bytearray操作 和bytes类型的方法相同 12bytearray(b'abcdef').replace(b'f',b'k')bytearray(b'abc').find(b'b') 类方法 bytearray.fromhex(string) string必须是2个字符的16进制的形式,’6162 6a 6b’,空格将被忽略 1bytearray.fromhex('6162 09 6a 6b00') hex() 返回16进制表示的字符串 1bytearray('abc'.encode()).hex() 索引 12bytearray(b'abcdef')[2] # 返回该字节对应的数，int类型 bytearray操作 append(int) 尾部追加一个元素 insert(index, int) 在指定索引位置插入元素 extend(iterable_of_ints) 将一个可迭代的整数集合追加到当前bytearray pop(index=-1) 从指定索引上移除元素,默认从尾部移除 remove(value) 找到第一个value移除,找不到抛ValueError异常 注意:上述方法若需要使用int类型,值在[0, 255] clear() 清空bytearray reverse() 翻转bytearray,就地修改 123456789b = bytearray()b.append(97)b.append(99)b.insert(1,98)b.extend([65,66,67])b.remove(66)b.pop()b.reverse()b.clear()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python字符串bytes和bytearray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-封装和解构]]></title>
    <url>%2F2019%2F09%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%B0%81%E8%A3%85%E5%92%8C%E8%A7%A3%E6%9E%84%2F</url>
    <content type="text"><![CDATA[封装和解构 封装 将多个值使用逗号分割，组合在一起 本质上，返回一个元组，只是省掉了小括号 python特有语法，被很多语言学习和借鉴 1234t1 = (1,2) # 定义为元组t2 = 1,2 # 将1和2封装成元组type(t1)type(t2) 举例 12345678a = 4b = 5temp = aa = bb = temp # 这不是冒泡法吗？等价于a, b = b, a上句中，等号右边使用了封装，而左边就使用了解构 解构 把线性结构的元素解开，并顺序的赋给其它变量 左边接纳的变量数要和右边解开的元素个数一致 举例 123456789101112131415lst = [3, 5]first, second = lstprint(first, second)a,b = 1,2a,b = (1,2)a,b = [1,2]a,b = [10,20]a,b = &#123;10,20&#125;a,b = &#123;'a':10,'b':20&#125; # 非线性结构也可以解构a,b = &#123;10,20,30&#125;a,*b = &#123;10,20,30&#125;[a,b] = (1,2)[a,b] = 10,20(a,b) = &#123;30,40&#125; Python3的解构 使用 *变量名 接收，但不能单独使用 被 *变量名 收集后组成一个列表 举例 123456789101112131415161718192021lst = list(range(1, 101, 2))head, *mid, tail = lst*lst2 = lst*body, tail = lsthead, *tail = lsthead, *m1, *m2, tail = lsthead, *mid, tail = "abcdefghijklmn"type(mid)# a,*b星号在这里是解构用的，可以匹配任意多个其后面的元素。如：a,*b = &#123;10,20,30&#125;。也就是# 让b尽可能多的接收元素，此例中，a只能接收一个元素，那么剩下的都由b接收。不能有两个星号，只# 能有一个。# 封装解构的过程就是冒泡法。封装解构过程如下# a = 4# b = 5# c = a,b# b,a = c# print(b)# print(a)# 这时a和b的值就反过来了# (b,a) = a,b# 这时又恢复了a和b的值 丢弃变量 这是一个惯例，是一个不成文的约定，不是标准 如果不关心一个变量，就可以定义改变量的名字为_ _是一个合法的标识符，也可以作为一个有效的变量使用，但是定义成下划线就是希望不要被使用，除非你明确的知道这个数据需要使用 举例 123456789101112131415lst = [9,8,7,20]first, *second = lsthead, *_, tail = lstprint(head)print(tail)# _是合法的标识符,看到下划线就知道这个变量就是不想被使用print(_)lst = [9,8,7,20]first, *second = lst_, *_, tail = lstprint(_)print(tail)print(_)# *_可以表示要丢弃的变量。_,*_,tail中_和*_是两个变量。但*_会覆盖前面_的值。 总结 _ 这个变量本身无任何语义，没有任何可读性,所以不是用来给人使用的 Python中很多库,都使用这个变量,使用十分广泛。请不要在不明确变量作用域的情况下,使用 _ 导致和库中_ 冲突 解构，是Python提供的很好的功能，可以方便的提取复杂数据结构的值 配置 _ 的使用，会更加便利]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python封装和解构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-IPython使用]]></title>
    <url>%2F2019%2F09%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-IPython%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[帮助 ? IPython的概述和简介 help(name) 查询指定名称的帮助 obj? 列出obj对象的详细信息 obj?? 列出更加详细的信息 特殊变量 _表示前一次输出 __ 表示倒数第二次输出 ___ 表示倒数第三次输出 _dh 目录历史 _oh 输出历史 shell命令 !command 执行shell命令 !ls -l !touch test.txt files = !ls -l | grep py 魔术方法 使用%百分号开头的,IPython内置的特殊方法 %magic 格式 % 开头是line magic %% 开头是 cell magic,notebook的cell %alias 定义一个系统命令的别名 alias ll ls -l %timeit statement -n 一个循环loop执行语句多少次 -r 循环执行多少次loop,取最好的结果 %%timeit setup_codecode….. %cd 改变当前工作目录,cd可以认为是%cd的链接。路径历史在_dh中查看 %pwd、pwd 显示当前工作目录 %ls 、ls 返回文件列表 注意:%pwd这种是魔术方法,是IPython的内部实现,和操作系统无关。而!pwd 就要依赖当前操作系统的shell提供的命令执行,默认windows不支持pwd命令 %%js、%%javascript 在cell中运行js脚本%%jsalert(‘a’ + 1) 举例123456789101112131415161718192021222324252627方法1def fac1(limit): lst = [2, 3] for i in range(5, limit, 2): for j in range(3, int(i**0.5)+1, 2): if i % j == 0: break else: lst.append(i) return lst方法2def fac2(limit): lst = [2, 3] for i in range(5, limit, 2): flag = False up = int(i**0.5) # 这一句是关键 for j in lst: if i % j == 0: #flag = False break if j &gt; up: flag = True break if flag: lst.append(i) return lst]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python-IPython使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-切片操作]]></title>
    <url>%2F2019%2F09%2F18%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%88%87%E7%89%87%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[线性结构 线性结构 可迭代 for … in len()可以获取长度 通过下标可以访问 可以切片 学过的线性结构 列表、元组、字符串、bytes、bytearray 切片 切片 通过索引区间访问线性结构的一段数据 sequence[start:stop] 表示返回[start,stop]区间的子序列 支持负索引 start为0，可以省略 stop为末尾，可以省略 超过上界（右边界），就取到末尾；超过下界（左边界），取到开头 start一定要在stop的左边 [:]表示从头至尾，全部元素被取出，等效于copy()方法 举例 1234567891011121314151617181920212223242526272829303132'www.magedu.com'[4:10]输出：'magedu''www.magedu.com'[:10]输出：'www.magedu''www.magedu.com'[4:]输出：'magedu.com''www.magedu.com'[:]输出：'www.magedu.com''www.magedu.com'[:-1]输出：'www.magedu.co''www.magedu.com'[4:-4]输出：'magedu''www.magedu.com'[4:50]输出：'magedu.com'b'www.magedu.com'[-40:10]输出：b'www.magedu'bytearray(b'www.magedu.com')[-4:10]输出：bytearray(b'')tuple('www.magedu.com')[-10:10]输出：('m', 'a', 'g', 'e', 'd', 'u')list('www.magedu.com')[-10:-4]输出：['m', 'a', 'g', 'e', 'd', 'u'] 步长切片 [start:stop:step] step为步长，可以是正、负整数，默认是1 step要和start:stop同向，否则返回空序列 举例 1234567891011121314'www.magedu.com'[4:10:2]输出：'mgd'list('www.magedu.com')[4:10:-2]输出：[]tuple('www.magedu.com')[-10:-4:2]输出：('m', 'g', 'd')b'www.magedu.com'[-4:-10:2]输出：b''bytearray(b'www.magedu.com')[-4:-10:-2]输出：bytearray(b'.dg')]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python切片操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习-字符串]]></title>
    <url>%2F2019%2F09%2F09%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串习题1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121================================================= 用户输入一个数字 1. 判断是几位数 2. 打印每一位数字及其重复的次数 3. 依次打印每一位数字，顺序个、十、百、千、万...位=================================================答案1：m = input("&gt;&gt;&gt;").strip().lstrip('0')# 去除数字前面的空格和0print("这是&#123;&#125;位数".format(len(m)))# len计算变量有几位数字for i in range(len(m)): print("&#123;&#125;'s count = &#123;&#125;".format(m[i],m.count(m[i])))# 循环len次，每次打印m的数字和m[i]在m中出现的次数。这个方法不好的原因是需要遍历整个数字，如果输入的是相# 同的数字，如11111，那么就要遍历len次for j in range(len(m)): n = m[-j-1] print(n)# 从后向前打印。m[-j-1]表示从最后一个索引开始，因为索引是从0开始的，所以要-1。print(m)答案2：num = ''# 不一定要定义，但最好定义，告诉别人num的作用域在外面while True: num = input('Input a positive number &gt;&gt;&gt;').strip().lstrip('0') # 去除空白和前面的0，为了得到有效的数字。用int()也可以去掉数字前的0，但下面执行时会报错，提示int()没有 # count方法。另外，input()也会输出自己的内容。 if num.isdigit(): break# 判断是否全部数字(0~9)，如果是，就向下执行，如果不是，就重新输入。print("The length of &#123;&#125; is &#123;&#125;.".format(num,len(num)))# 计算打印num和num的长度# 倒序打印1for i in range(len(num),0,-1): print(num[i-1],end=' ')print()# print()是换行的# 倒序打印2for i in reversed(num): print(i,end=' ')print()# reversed()是一个内置的方法，可以返回一个新的可迭代对象# 负索引方式打印for i in range(len(num)): print(num[-i-1],end=' ')print()# 判断0-9的数字在字符串中出现的次数，每一次抚今追昔都是用count，都是O(n)问题counter = [0]*10 # 开辟一个0～9的空间，下面迭代后将数字出现的次数放入这个空间中对应的位置for i in range(10): # 10*n counter[i] = num.count(str(i)) if counter[i]: # 如果counter[i]不等于0就打印出来。如果是0表示这个数字没有统计到。 print("The count of &#123;&#125; is &#123;&#125;".format(i,counter[i])) print('~'*20)# 迭代字符串本身的字符counter = [0]*10for x in num: # unique(n) * n，unique(n)取值[1,10]，当数字一样时，就是1*n。# 这里会将数字的每一位传给x i = int(x)# 这里先将x转为数字，之后赋值给i。 if counter[i] == 0: #如果不加判断，就是n*n的效率# counter是一个有十个位置的空间，因为不论是几位数，数字都是在0～9之间，这里判断counter# 中索引为[i]的地方是否为0，因为如果是第一次判断索引[i]，那么一定是0，因为没有统计过，如# 果统计过，这个索引[i]一定不为0。因为x和i的值是一样的，所以这里将索引与数字相对应，使数字# 与索引的值一致，达到counter的值为0～9顺序排列的效果，这从下面一行代码可以更好的表现出# 来。这里将num变为索引[i]来对应counter中的位置，只是不会超出counter的范围 counter[i] = num.count(x)# 当判断为0时，这时就要计算x在num中出现过几次，再将这个值放入counter中索引为[i]的位置# 比如用户输入的数字是12113，初始应该像是[0,0,0,0,0,0,0,0,0,0]，统计过次数后，变为# [0,3,1,1,0,0,0,0,0,0]。下面打印时，会将x先打印出来，之后是x的出现次数。# 也就是counter中的值。但因为输入的是12113，也就是x是12113，应该依次打印这五个数字出现的# 次数。但因为上面加入了判断：if counter[i] == 0时才会进入这里统计打印，所以当有重复数字# 出现时，是不会进入这里的。 print("The count of &#123;&#125; is &#123;&#125;".format(x,counter[i])) print('~'*20)# 迭代字符串本身的字符counter = [0]*10for x in num: i = int(x) counter[i] += 1for i in range(len(counter)): if counter[i]: print("The count of &#123;&#125; is &#123;&#125;".format(i, counter[i]))# 这个方法同样是开辟一个空间，之后在第一个for循环时遍历所有数字，每遇到一个数字就在其对应# 的索引位置加1。如11231，第一次是1，在counter[1]的位置加1，第二次还是1，在counter[1]# 的位置再加1。第三次是2，在counter[2]的位置加1。都统计过之后，counter的值应该像是# [0,3,1,1,0,0,0,0,0,0]，这个值对应的就是0～9顺序排列的位置，这是在第二个for循环开始# 定义好的，也就是for i in range(len(counter)):就定义好了，这个counter的值是顺序排列# 的。在第二个for循环中，以counter的长度为范围，这个范围是10，用if counter[i]:判断这个# 索引位置的值是否为0，如果为0，就进入下一次循环，如果不为0，就打印i的值和对应的索引位置的# 值。 # 输出结果：# Input a positive number &gt;&gt;&gt;123# The length of 123 is 3.# 3 2 1 # 3 2 1 # 3 2 1 # The count of 1 is 1# The count of 2 is 1# The count of 3 is 1# ~~~~~~~~~~~~~~~~~~~~# The count of 1 is 1# The count of 2 is 1# The count of 3 is 1# ~~~~~~~~~~~~~~~~~~~~# The count of 1 is 1# The count of 2 is 1# The count of 3 is 1 字符串习题212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667============================================================ 输入5个数字,打印每个数字的位数,将这些数字排序打印,要求升序打印============================================================答案1：sort方法排序nums = []while len(nums) &lt; 5: # 只要nums中少于5个元素就循环，也就是让用户输入五次数字 num = input("Please input a number:".strip().lstrip('0')) if not num.isdigit(): # 如果输入的不是数字就会跳出此次循环，重新输入五次 continue print('The length of &#123;&#125; is &#123;&#125;'.format(num,len(num))) nums.append(int(num))print(nums)lst = nums.copy()lst.sort()print(lst)输出：Please input a number:123124124The length of 123124124 is 9Please input a number:12312312The length of 12312312 is 8Please input a number:123123123The length of 123123123 is 9Please input a number:123123123The length of 123123123 is 9Please input a number:12312312The length of 12312312 is 8[123124124, 12312312, 123123123, 123123123, 12312312][12312312, 12312312, 123123123, 123123123, 123124124]答案2：冒泡法nums = []while len(nums) &lt; 5: num = input("Please input a number:".strip().lstrip('0')) if not num.isdigit(): continue print('The length of &#123;&#125; is &#123;&#125;'.format(num,len(num))) nums.append(int(num))print(nums)for i in range(len(nums)): # 输入五次数字后这里要循环5次，也就是5个数字分别与每个数字比较 flag = False for j in range(len(nums)-i-1): # 这里定义的是每次比较的次数，因为不需要与本身比较，所以会减i，因为索引是从0开始的，# 所以i第一次是0,所以还要减1。每次比较后最大的数字就会排在最后，下一次循环就不用比较了 if nums[j] &gt; nums[j+1]: # 如果靠前的索引大于后面的索引，如索引0大于索引1 tmp = nums[j] # 将靠前的索引值给一个临时变量 nums[j] = nums[j+1] # 将后面的索引值赋值给靠前的索引 nums[j+1] = tmp # 将临时变量的值赋值给靠后的索引，这样前后索引的值就对调了 flag = True # 对调过一次就将标记改为True if not flag: breakprint(nums)输出：Please input a number:123456The length of 123456 is 6Please input a number:74532The length of 74532 is 5Please input a number:875643The length of 875643 is 6Please input a number:673452The length of 673452 is 6Please input a number:09876543The length of 09876543 is 8[123456, 74532, 875643, 673452, 9876543][74532, 123456, 673452, 875643, 9876543]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>字符串习题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python基础练习-列表元组与冒泡法]]></title>
    <url>%2F2019%2F09%2F04%2FPython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0-%E5%88%97%E8%A1%A8%E5%85%83%E7%BB%84%E4%B8%8E%E5%86%92%E6%B3%A1%E6%B3%95%2F</url>
    <content type="text"><![CDATA[列表-依次接收用户输入的3个数，排序后打印123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118=============================================== 示例，最笨拙的方法。从小到大排列，i1最小，i3最大===============================================nums = []# 需要先定义出nums这个变量，不然会提示"nums not deni"for i in range(3): nums.append(int(input('&#123;&#125;:'.format(i))))# '&#123;&#125;:'是取其后面format()中变量的值，这时format中是i，'&#123;&#125;:'是显示的提示信息，# 输入的值会被int处理后追加到nums列表中。结果如下：# 0:1 第0次，输入的是1# 0 这里打印了一次i# [1] 这里打印一次nums# 1:3 第1次输入的是3# 1# [1, 3] nums现在就是两个数字了# 2:4# 2# [1, 3, 4]if nums[0] &gt; nums[1]: if nums[0] &gt; nums[2]: i3 = nums[0] # 上面先比较索引0是否大于索引1和2，如果大于，就把索引0的数字给i3。 if nums[1] &gt; nums[2]: i2 = nums[1] i1 = nums[2] # 继续判断，这时已判断完索引0了，再判断索引1是否大于索引2，如果大于，就把索引1给i2，索引2给i1。否则，就把# 索引2给i2，索引1给i1。 else: i2 = nums[2] i1 = nums[1] else: i2 = nums[0] i3 = nums[2] i1 = nums[1]# 如果上面判断索引0不大于索引2，就表示索引2最大，给i3，索引1最小，给i1。else: # 0&lt;1 if nums[0] &gt; nums[2]: i3 = nums[1] i2 = nums[0] i1 = nums[2]# 如果最开始判断的索引0小于索引1，再判断索引 0是否大于索引2，如果大于，就表示索引2最小，索引1最大。# 下面的判断道理是一样的 else: # 0&lt;2 if nums[1] &lt; nums[2]: # 1&lt;2 i1 = nums[0] i2 = nums[1] i3 = nums[2] else: # 1 &gt; 2 i1 = nums[0] i2 = nums[2] i3 = nums[1]print(i1,i2,i3)# 这里主要看六种变化，1. 索引0大于索引1和索引2，索引1大于索引2；2. 索引0大于索引1和索引2，索引2大于索引1；# 3. 索引2大于索引0和索引1，索引0大于索引1；4. 索引2大于索引0和索引1，索引1大于索引0；5. 索引1大于索引0和索引2，索引0大于索引2；6. 索引1大于索引0和索引2，索引2大于索引0=================== 改进，从大到小排列===================nums = []out = None # 定义空列表，将None改为[]也可以。for i in range(3): nums.append(int(input('&#123;&#125;:'.format(i)))) if nums[0] &gt; nums[1]: if nums[0] &gt; nums[2]: if nums[1] &gt; nums[2]: out = [2,1,0] # 这里的[2,1,0]指的是索引，保存在out变量中# out是为了保存索引的顺序 else: out = [1,2,0] else: out = [1,0,2]else: # 0&lt;1 if nums[0] &gt; nums[2]: out = [2,0,1] else: # 0&lt;2 if nums[1] &lt; nums[2]: # 1&lt;2 out = [0,1,2] else: # 1&gt;2 out = [0,2,1]out.reverse()# reverse()是为了将out列表中的元素整个反过来，原本是从小到大排列，变成从大到小排列。for i in out: print(nums[i],end=', ')# 最后将out中的三个数字依次传给i，i中保存的实际就是索引编号，再把i带入到nums列表，# 这样就从小到大打印出结果了================ max min的实现================nums = []out = Nonefor i in range(3): nums.append(int(input('&#123;&#125;:'.format(i)))) while True: cur = min(nums)# 死循环，用min把列表中最小的数字选出 print(cur)# 打印最小的数字 nums.remove(cur)# 将最小的数字删除，因为上面for循环定义了循环3次，所以这里while循环可以循环两次，最后一次用下面的代码执行 if len(nums) == 1:# 判断nums列表中是否只有1个元素，如果不是，就继续上面的循环 print(nums[0]) break# 打印出最后一个元素后就退出循环============== 列表sort实现==============nums = []for i in range(3): nums.append(int(input('&#123;&#125;:'.format(i)))) nums.sort()# sort() 函数用于对原列表进行排序print(nums) 元组习题冒泡法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465numlist = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9]]# 定义一个列表，列表中有两个元素nums = numlist[0]# 设置nums等于列表中的第一个元素print(nums)# 打印一次numslength = len(nums)# 计算nums的长度，这是为了计算出要比较交换的次数，长度就是比较交换的次数count_swap = 0# 统计交换的次数，也就是两个数相比，如果两个数对调过一次，这里就会加1。count = 0# 统计一共进入比较多少次，进入比较后不一定会交换，因为前面的数比后面的数小是不用交换的。for i in range(length): # 这是整个要比较的次数。如第1个数与第2个数比较，一直比较到最后一个数。这就是一次比较 for j in range(length-i-1):# 这是每次要比较几个数，总是从0到n。因为第1次比较完，最大的数就排列在最后了，下一次比较就不用再和最后一个数比较了。-1是因为range()是从0开始的。 count += 1# 统计进入比较的次数，每进入一次就加1。进入比较后不一定会交换，因为前面的数比后面的数小是不用交换的。 if nums[j] &gt; nums[j+1]:# 第1次比较索引0和索引1两个数字，如果索引0比索引1大，就向下执行 tmp = nums[j]# 将索引0的数赋值给tmp，临时存放 nums[j] = nums[j+1]# 把索引1的数赋值给索引0,这时小的数字就向前移了 nums[j+1] = tmp# 再把临时存放的大的数字给索引1，这样大的数字就向后移了 count_swap += 1# 记录1次交换print(nums,count_swap,count)# 最后打印排列好的结果，进入比较的次数，实际交换的次数。# 输出结果：# [1, 9, 8, 5, 6, 7, 4, 3, 2]# [1, 2, 3, 4, 5, 6, 7, 8, 9] 25 36======= 优化=======# 冒泡法代码实现二，优化实现num_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[1,2,3,4,5,6,7,9,8]]nums = num_list[2]print(nums)length = len(nums)count_swap = 0count = 0for i in range(length): flag = False# 每次每个数比较之前都加一个标记 for j in range(length-i-1): count += 1 if nums[j] &gt; nums[j+1]: tmp = nums[j] nums[j] = nums[j+1] nums[j+1] = tmp flag = True # 如果前面的数字比后面的大，进行了交换，就将flag改为True count_swap += 1 if not flag: # 如果not flag为真，就break。这里也可以写成if flag，如果写成这样，那么上面两处对flag的定义就要转过来，把# False变成True，True变成False。 break# 当flag为False时，证明没有交换，也就证明没必要再进行之后的动作，顺序已经排好了。print(nums, count_swap, count)# 输出结果：[1, 2, 3, 4, 5, 6, 7, 9, 8][1, 2, 3, 4, 5, 6, 7, 8, 9] 1 15 命名元组123456789101112131415161718# 帮助文档中,查阅namedtuple,有使用例程# namedtuple(typename, field_names, verbose=False, rename=False) # 命名元组,返回一个元组的子类,并定义了字段 # field_names可以是空白符或逗号分割的字段的字符串,可以是字段的列表from collections import namedtuplePoint = namedtuple('_Point',['x','y']) # Point为返回的类p = Point(11, 22)print(p)输出：_Point(x=11, y=22)Student = namedtuple('Student', 'name age')tom = Student('tom', 20)jerry = Student('jerry', 18)tom.name输出：'tom'jerry.age输出：18]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>冒泡法与练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash基础知识]]></title>
    <url>%2F2019%2F06%2F26%2Flogstash%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[配置语法Logstash 设计了自己的 DSL，包括有区域，注释，数据类型(布尔值，字符串，数值，数组，哈希)，条件判断，字段引用等。 区段(section)Logstash 用 {} 来定义区域。区域内可以包括插件区域定义，你可以在一个区域内定义多个插件。插件区域内则可以定义键值对设置。示例如下： 1234input &#123; stdin &#123;&#125; syslog &#123;&#125;&#125; 数据类型Logstash 支持少量的数据值类型： bool 1debug =&gt; true string 1host =&gt; "hostname" number 1port =&gt; 514 array 1match =&gt; ["datetime", "UNIX", "ISO8601"] hash 1234options =&gt; &#123; key1 =&gt; "value1", key2 =&gt; "value2"&#125; 注意：如果你用的版本低于 1.2.0，哈希的语法跟数组是一样的，像下面这样写： 1match =&gt; [ "field1", "pattern1", "field2", "pattern2" ] 字段引用(field reference)字段是 Logstash::Event 对象的属性。我们之前提过事件就像一个哈希一样，所以你可以想象字段就像一个键值对。 小贴士：我们叫它字段，因为 Elasticsearch 里是这么叫的。 如果你想在 Logstash 配置中使用字段的值，只需要把字段的名字写在中括号 [] 里就行了，这就叫字段引用。 对于 嵌套字段(也就是多维哈希表，或者叫哈希的哈希)，每层的字段名都写在 [] 里就可以了。比如，你可以从 geoip 里这样获取 longitude 值(是的，这是个笨办法，实际上有单独的字段专门存这个数据的)： 1[geoip][location][0] 小贴士：logstash 的数组也支持倒序下标，即 [geoip][location][-1] 可以获取数组最后一个元素的值。 Logstash 还支持变量内插，在字符串里使用字段引用的方法是这样： 1"the longitude is %&#123;[geoip][location][0]&#125;" 条件判断(condition)Logstash从 1.3.0 版开始支持条件判断和表达式。 表达式支持下面这些操作符： equality, etc: ==, !=, &lt;, &gt;, &lt;=, &gt;= regexp: =~, !~ inclusion: in, not in boolean: and, or, nand, xor unary: !() 通常来说，你都会在表达式里用到字段引用。比如： 1234if "_grokparsefailure" not in [tags] &#123;&#125; else if [status] !~ /^2\d\d/ and [url] == "/noc.gif" &#123;&#125; else &#123;&#125; 命令行参数Logstash 提供了一个 shell 脚本叫 logstash 方便快速运行。它支持以下参数： -e 意即执行。我们在 “Hello World” 的时候已经用过这个参数了。事实上你可以不写任何具体配置，直接运行 bin/logstash -e &#39;&#39; 达到相同效果。这个参数的默认值是下面这样： 123456input &#123; stdin &#123; &#125;&#125;output &#123; stdout &#123; &#125;&#125; –config 或 -f 意即文件。真实运用中，我们会写很长的配置，甚至可能超过 shell 所能支持的 1024 个字符长度。所以我们必把配置固化到文件里，然后通过 bin/logstash -f agent.conf 这样的形式来运行。 此外，logstash 还提供一个方便我们规划和书写配置的小功能。你可以直接用 bin/logstash -f /etc/logstash.d/ 来运行。logstash 会自动读取 /etc/logstash.d/ 目录下所有的文本文件，然后在自己内存里拼接成一个完整的大配置文件，再去执行。 –configtest 或 -t 意即测试。用来测试 Logstash 读取到的配置文件语法是否能正常解析。Logstash 配置语法是用 grammar.treetop 定义的。尤其是使用了上一条提到的读取目录方式的读者，尤其要提前测试。 –log 或 -l 意即日志。Logstash 默认输出日志到标准错误。生产环境下你可以通过 bin/logstash -l logs/logstash.log 命令来统一存储日志。 –filterworkers 或 -w 意即工作线程。Logstash 会运行多个线程。你可以用 bin/logstash -w 5 这样的方式强制 Logstash 为过滤插件运行 5 个线程。 注意：Logstash目前还不支持输入插件的多线程。而输出插件的多线程需要在配置内部设置，这个命令行参数只是用来设置过滤插件的！ 提示：Logstash 目前不支持对过滤器线程的监测管理。如果 filterworker 挂掉，Logstash 会处于一个无 filter 的僵死状态。这种情况在使用 filter/ruby 自己写代码时非常需要注意，很容易碰上 NoMethodError: undefined method ‘*‘ for nil:NilClass 错误。需要妥善处理，提前判断。 –pluginpath 或 -P 可以写自己的插件，然后用 bin/logstash --pluginpath /path/to/own/plugins 加载它们。 –verbose 输出一定的调试日志。 小贴士：如果你使用的 Logstash 版本低于 1.3.0，你只能用 bin/logstash -v 来代替。 –debug 输出更多的调试日志。 小贴士：如果你使用的 Logstash 版本低于 1.3.0，你只能用 bin/logstash -vv 来代替。 输入插件(Input)Logstash 配置一定要有一个 input 和一个 output。 标准输入(Stdin)配置示例1234567891011121314vim /etc/logstash/conf.d/system.confinput &#123; stdin &#123; add_field =&gt; &#123;"key" =&gt; "value"&#125; codec =&gt; "plain" tags =&gt; ["add"] type =&gt; "std" &#125;output &#123; stdout &#123; # 这样写会输出到屏幕 &#125;&#125; 运行结果1234567891011121314151617181920212223[root@A5_SW_3552P ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system.conf WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console[WARN ] 2019-06-26 16:05:08.173 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified[INFO ] 2019-06-26 16:05:08.213 [LogStash::Runner] runner - Starting Logstash &#123;"logstash.version"=&gt;"6.5.4"&#125;[INFO ] 2019-06-26 16:05:14.564 [Converge PipelineAction::Create&lt;main&gt;] pipeline - Starting pipeline &#123;:pipeline_id=&gt;"main", "pipeline.workers"=&gt;2, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;50&#125;[INFO ] 2019-06-26 16:05:14.930 [[main]&gt;worker1] stdin - Automatically switching from plain to line codec &#123;:plugin=&gt;"stdin"&#125;[INFO ] 2019-06-26 16:05:15.043 [Converge PipelineAction::Create&lt;main&gt;] pipeline - Pipeline started successfully &#123;:pipeline_id=&gt;"main", :thread=&gt;"#&lt;Thread:0x55fda7a3 run&gt;"&#125;The stdin plugin is now waiting for input:[INFO ] 2019-06-26 16:05:15.171 [Ruby-0-Thread-1: /usr/share/logstash/lib/bootstrap/environment.rb:6] agent - Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;[INFO ] 2019-06-26 16:05:15.646 [Api Webserver] agent - Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;hello world&#123; "message" =&gt; "hello world", "@timestamp" =&gt; 2019-06-26T08:05:23.027Z, "@version" =&gt; "1", "host" =&gt; "A5_SW_3552P", "key" =&gt; "value", "tags" =&gt; [ [0] "add" ], "type" =&gt; "std"&#125; 解释type 和 tags 是 logstash 事件中两个特殊的字段。通常来说我们会在输入区段中通过 type 来标记事件类型 —— 我们肯定是提前能知道这个事件属于什么类型的。而 tags 则是在数据处理过程中，由具体的插件来添加或者删除的。 最常见的用法是像下面这样： 12345678910111213141516171819202122input &#123; stdin &#123; type =&gt; "web" &#125;&#125;filter &#123; if [type] == "web" &#123; grok &#123; match =&gt; ["message", %&#123;COMBINEDAPACHELOG&#125;] &#125; &#125;&#125;output &#123; if "_grokparsefailure" in [tags] &#123; nagios_nsca &#123; nagios_status =&gt; "1" &#125; &#125; else &#123; elasticsearch &#123; &#125; &#125;&#125; 读取文件(File)​ Logstash 使用一个名叫 FileWatch 的 Ruby Gem 库来监听文件变化。这个库支持 glob 展开文件路径，而且会记录一个叫 .sincedb 的数据库文件来跟踪被监听的日志文件的当前读取位置。所以，不要担心 logstash 会漏过你的数据。 ​ sincedb 文件中记录了每个被监听的文件的 inode, major number, minor number 和 pos。 配置示例1234567input file &#123; path =&gt; ["/var/log/*.log", "/var/log/message"] type =&gt; "system" start_position =&gt; "beginning" &#125;&#125; 解释有一些比较有用的配置项，可以用来指定 FileWatch 库的行为： discover_interval logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒。 exclude 不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开。 sincedb_path 如果你不想用默认的 $HOME/.sincedb(Windows 平台上在 C:\Windows\System32\config\systemprofile\.sincedb)，可以通过这个配置定义 sincedb 文件到其他位置。 sincedb_write_interval logstash 每隔多久写一次 sincedb 文件，默认是 15 秒。 stat_interval logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒。 start_position logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 “beginning”，logstash 进程就从头开始读取，有点类似 cat，但是读到最后一行不会终止，而是继续变成 tail -F。 注意 通常你要导入原有数据进 Elasticsearch 的话，你还需要 filter/date 插件来修改默认的”@timestamp” 字段值。 FileWatch 只支持文件的绝对路径，而且会不自动递归目录。所以有需要的话，请用数组方式写明具体哪些文件。 LogStash::Inputs::File 只是在进程运行的注册阶段初始化一个 FileWatch 对象。所以它不能支持类似 fluentd 那样的 path =&gt; &quot;/path/to/%{+yyyy/MM/dd/hh}.log&quot; 写法。达到相同目的，你只能写成 path =&gt; &quot;/path/to/*/*/*/*.log&quot;。 start_position 仅在该文件从未被监听过的时候起作用。如果 sincedb 文件中已经有这个文件的 inode 记录了，那么 logstash 依然会从记录过的 pos 开始读取数据。所以重复测试的时候每回需要删除 sincedb 文件。使用locate查询，文件路径在/var/lib/logstash/plugins/inputs/file/目录下，也有一说在用户家目录中，但没有找到。 因为 windows 平台上没有 inode 的概念，Logstash 某些版本在 windows 平台上监听文件不是很靠谱。windows 平台上，推荐考虑使用 nxlog 作为收集端。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch概念]]></title>
    <url>%2F2019%2F06%2F26%2FElasticSearch%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[基本概念索引(Index)​ ElasticSearch把数据存放到一个或者多个索引(indices)中。如果用关系型数据库模型对比，索引(index)的地位与数据库实例(database)相当。索引存放和读取的基本单元是文档(Document)。我们也一再强调，ElasticSearch内部用Apache Lucene实现索引中数据的读写。读者应该清楚的是：在ElasticSearch中被视为单独的一个索引(index)，在Lucene中可能不止一个。这是因为在分布式体系中，ElasticSearch会用到分片(shards)和备份(replicas)机制将一个索引(index)存储多份。 文档(Document)​ 在ElasticSearch的世界中，文档(Document)是主要的存在实体(在Lucene中也是如此)。所有的ElasticSearch应用需求到最后都可以统一建模成一个检索模型：检索相关文档。文档(Document)由一个或者多个域(Field)组成，每个域(Field)由一个域名(此域名非彼域名)和一个或者多个值组成(有多个值的值称为多值域(multi-valued))。在ElasticSeach中，每个文档(Document)都可能会有不同的域(Field)集合；也就是说文档(Document)是没有固定的模式和统一的结构。文档(Document)之间保持结构的相似性即可(Lucene中的文档(Document)也秉持着相同的规定)。实际上，ElasticSearch中的文档(Document)就是Lucene中的文档(Document)。从客户端的角度来看，文档(Document)就是一个JSON对象。 参数映射(Mapping)​ 所有的文档(Document)在存储之前都必须经过分析(analyze)流程。用户可以配置输入文本分解成Token的方式；哪些Token应该被过滤掉；或者其它的处理流程，比如去除HTML标签。此外，ElasticSearch提供的各种特性，比如排序的相关信息。保存上述的配置信息，这就是参数映射(Mapping)在ElasticSearch中扮演的角色。尽管ElasticSearch可以根据域的值自动识别域的类型(field type)，在生产应用中，都是需要自己配置这些信息以避免一些问题发生。要保证应用的可控性。 文档类型(Type)​ 每个文档在ElasticSearch中都必须设定它的类型。文档类型使得同一个索引中在存储结构不同的文档时，只需要依据文档类型就可以找到对应的参数映射(Mapping)信息，方便文档的存取。 节点(Node)​ 单独一个ElasticSearch服务器实例称为一个节点。对于许多应用场景来说，部署一个单节点的ElasticSearch服务器就足够了。但是考虑到容错性和数据过载，配置多节点的ElasticSearch集群是明智的选择。 集群(Cluster)​ 集群是多个ElasticSearch节点的集合。这些节点齐心协力应对单个节点无法处理的搜索需求和数据存储需求。集群同时也是应对由于部分机器(节点)运行中断或者升级导致无法提供服务这一问题的利器。ElasticSearch提供的集群各个节点几乎是无缝连接（所谓无缝连接，即集群对外而言是一个整体，增加一个节点或者去掉一个节点对用户而言是透明的）。在ElasticSearch中配置一个集群非常简单，在我们看来，这是在与同类产品中竞争所体现出的最大优势。 分片索引(Shard)​ 前面已经提到，集群能够存储超出单机容量的信息。为了实现这种需求，ElasticSearch把数据分发到多个存储Lucene索引的物理机上。这些Lucene索引称为分片索引，这个分发的过程称为索引分片(Sharding)。在ElasticSearch集群中，索引分片(Sharding)是自动完成的，而且所有分片索引(Shard)是作为一个整体呈现给用户的。需要注意的是，尽管索引分片这个过程是自动的，但是在应用中需要事先调整好参数。因为集群中分片的数量需要在索引创建前配置好，而且服务器启动后是无法修改的，至少目前无法修改。 索引副本(Replica)​ 通过索引分片机制(Sharding)可以向ElasticSearch集群中导入超过单机容量的数据，客户端操作任意一个节点即可实现对集群数据的读写操作。当集群负载增长，用户搜索请求阻塞在单个节点上时，通过索引副本(Replica)机制就可以解决这个问题。索引副本(Replica)机制的的思路很简单：为索引分片创建一份新的拷贝，它可以像原来的主分片一样处理用户搜索请求。同时也顺便保证了数据的安全性。即如果主分片数据丢失，ElasticSearch通过索引副本使得数据不丢失。索引副本可以随时添加或者删除，所以用户可以在需要的时候动态调整其数量。 时间之门(Gateway)​ 在运行的过程中，ElasticSearch会收集集群的状态、索引的参数等信息。这些数据被存储在Gateway中。 ElasticSearch背后的核心理念​ ElasticSearch是构建在极少数的几个概念之上的。ElasticSearch的开发团队希望它能够快速上手，可扩展性强。而且这些核心特性体现在ElasticSearch的各个方面。从架构的角度来看，这些主要特性是： 开箱即用。安装好ElasticSearch后，所有参数的默认值都自动进行了比较合理的设置，基本不需要额外的调整。包括内置的发现机制(比如Field类型的自动匹配)和自动化参数配置。 天生集群。ElasticSearch默认工作在集群模式下。节点都将视为集群的一部分，而且在启动的过程中自动连接到集群中。 自动容错。ElasticSearch通过P2P网络进行通信，这种工作方式消除了单点故障。节点自动连接到集群中的其它机器，自动进行数据交换及以节点之间相互监控。索引分片 扩展性强。无论是处理能力和数据容量上都可以通过一种简单的方式实现扩展，即增添新的节点。 近实时搜索和版本控制。由于ElasticSearch天生支持分布式，所以延迟和不同节点上数据的短暂性不一致无可避免。ElasticSearch通过版本控制(versioning)的机制尽量减少问题的出现。 ElasticSearch的工作原理启动过程​ 当ElasticSearch的节点启动后，它会利用多播（multicast）（或者单播，如果用户更改了配置）寻找集群中的其它节点，并与之建立连接。这个过程如下图所示 ​ 在集群中，一个节点被选举成主节点(master node)。这个节点负责管理集群的状态，当群集的拓扑结构改变时把索引分片分派到相应的节点上。 ​ 需要注意的是，从用户的角度来看，主节点在ElasticSearch中并没有占据着重要的地位，这与其它的系统（比如数据库系统）是不同的。实际上用户并不需要知道哪个节点是主节点；所有的操作需求可以分发到任意的节点，ElasticSearch内部会完成这些让用户感到不明白的工作。在必要的情况下，任何节点都可以并发地把查询子句分发到其它的节点，然后合并各个节点返回的查询结果。最后返回给用户一个完整的数据集。所有的这些工作都不需要经过主节点转发(节点之间通过P2P的方式通信)。 ​ 主节点会去读取集群状态信息；在必要的时候，会进行恢复工作。在这个阶段，主节点会去检查哪些分片可用，决定哪些分片作为主分片。处理完成后，集群就会转入到黄色状态。 ​ 这意味着集群已经可以处理搜索请求了，但是还没有火力全开（这主要是由于所有的主索引分片（primary shard）都已经分配好了，但是索引副本还没有）。接下来需要做的事情就是找到复制好的分片，并设置成索引副本。当一个分片的副本数量太少时，主节点会决定将缺少的分片放置到哪个节点中，并且依照主分片创建副本。所有工作完成后，集群就会变成绿色的状态（表示所有的主分片的索引副本都已经分配完成）。 探测失效节点​ 在正常工作时，主节点会监控所有的节点，查看各个节点是否工作正常。如果在指定的时间里面，节点无法访问，该节点就被视为出故障了，接下来错误处理程序就会启动。集群需要重新均衡——由于该节点出现故障，分配到该节点的索引分片丢失。其它节点上相应的分片就会把工作接管过来。换句话说，对于每个丢失的主分片，新的主分片将从剩余的分片副本(Replica)中选举出来。重新安置新的分片和副本的这个过程可以通过配置来满足用户需求。 ​ 由于只是展示ElasticSearch的工作原理，我们就以下图三个节点的集群为例。集群中有一个主节点和两个数据节点。主节点向其它的节点发送Ping命令然后等待回应。如果没有得到回应（实际上可能得不到回复的Ping命令个数取决于用户配置），该节点就会被移出集群。 与ElasticSearch进行通信​ 我们已经探讨了ElasticSearch是如何构建起来的，但是归根到底，最重要的是如何往ElasticSearch中添加数据以及如何查询数据。为了实现上述的需求，ElasticSearch提供了精心设计的API。这些主要的API都是基于REST风格(参看http://en.wikipedia.org/wiki/Pepresentational_state_transfer )。而且这些API非常容易与其它能够处理HTTP请求的系统进行集成。 ​ ElasticSearch认为数据应该伴随在URL中，或者作为请求的主体(request body)，以一种JSON格式的文档发送给服务器。如果读者用Java或者其它运行在JVM虚拟机上的语言，应该关注一下Java API，它除了是群集中内置的REST风格API外，功能与URL请求是一样的。 ​ 值得一提的是在ElasticSearch内部，节点之间的通信也是用相关的Java API。 索引数据​ ElasticSearch提供了4种索引数据的办法。最简单的是使用索引API。通过它可以将文档添加到指定的索引中去。比如，通过curl工具(访问http://curl.haxx.se/ )，我们可以通过如下的命令创建一个新的文档： 123curl -XPUT http://localhost:9200/blog/article/1 '&#123;"title": "Newversion of Elastic Search released!", "content": "...","tags":["announce", "elasticsearch", "release"] &#125;' ​ 第2种和第3种办法可以通过bulk API和UDP bulk API批量添加文档。通常的bulk API采用HTTP协议，UDP bulk API采用非连接的数据包协议。UDP协议传输速度会更快，但是可靠性要差一点。最后一种办法就是通过river插件。river运行在ElasticSearch集群的节点上，能够从外部系统中获取数据。 ​ 有一点需要注意，索引数据的操作只会发生在主分片(primary shard)上，而不会发生在分片副本(Replica) 上。如果索引数据的请求发送到的节点没有合适的分片或者分片是副本，那么请求会被转发到含有主分片的节点。 数据查询​ 查询API在ElasticSearch中有着很大的比重。通过使用Query DSL（基于JSON，用来构建复杂查询的语言），我们能够： 使用各种类型的查询方式，包括：简单的关键词查询(termquery) 、短语(phrase)、区间(range)、布尔(boolean)、模糊(fuzzy)、跨度(span)、通配符(wildcard)、地理位置(spatial)等其它类型的查询方式。 通过组合简单查询构建出复杂的查询。 过滤文档，去除不符合标准的文档而且不影响打分排序。 查找给定文档的相似文档。 查找给定短语的搜索建议和查询短语修正。 通过faceting构建动态的导航和数据统计 使用prospective search而且找到匹配写定文档的查询语句。(关于prospective search，似乎是一种推送方式。即把用户的查询语句存储到索引中，如果新的文档添加到索引中，就把文档关联到匹配的查询语句中。这种查询适合于新闻、博客等会定时更新的应用场景) ​ 关于数据查询，其核心点在于查询过程不是一个简单、单一的流程。通常这个过程分为两个阶段：查询分发阶段和结果汇总阶段。在查询分发阶段，会从各个分片中查询数据；在结果汇总阶段，会把从各个分片上查询到的结果进行合并、排序等其它处理过程，然后返回给用户。 ​ 用户可以通过指定搜索类型来控制查询的分发和汇总过程，目前搜索类型只有6种可选值。在Packt出版的《ElasticSearch Server》一书中，已经讲述了查询范围(query scope)这一知识点. 索引参数设置​ 前面已经提到ElasticSearch索引参数的自动化配置和文档结构及域类型的自动识别。当然，ElasticSearch也允许用户自行修改默认配置。用户可以自行配置很多参数，比如通过mapping配置索引中的文档结构，设置分片(shard)和副本(replica)的的个数，设置文本分析组件…… 集群管理和监控​ 通过管理和监控部分的API，用户可以更改集群的设置。比如调整节点发现机制(discovery mechanism) 或者更改索引的分片策略。用户可以查看集群状态信息，或者每个节点和索引和统计信息。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene介绍]]></title>
    <url>%2F2019%2F06%2F26%2FLucene%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[简介​ 为了更深入地理解ElasticSearch的工作原理，特别是索引和查询这两个过程，理解Lucene的工作原理至关重要。本质上，ElasticSearch是用Lucene来实现索引的查询功能的。 ​ Lucene是一个成熟的、高性能的、可扩展的、轻量级的，而且功能强大的搜索引擎包。Lucene的核心jar包只有一个文件，而且不依赖任何第三方jar包。更重要的是，它提供的索引数据和检索数据的功能开箱即用。当然，Lucene也提供了多语言支持，具有拼写检查、高亮等功能；但是如果你不需要这些功能，你只需要下载Lucene的核心jar包，应用到你的项目中就可以了。 概念 analyzer：Analyzer是分析器，它的作用是把一个字符串按某种规则划分成一个个词语，并去除其中的无效词语，这里说的无效词语是指英文中的“of”、“the”，中文中的“的”、“地”等词语，这些词语在文章中大量出现，但是本身不包含什么关键信息，去掉有利于缩小索引文件、提高效率与命中率。分词的规则千变万化，但目的只有一个：按语义划分。这点在英文中比较容易实现，因为英文本身就是以单词为单位的，已经用空格分开；而中文则必须以某种方法将连成一片的句子划分成一个个词语 Document：一个Document代表索引库中的一条记录（书目录中的其中一个条目），也叫做文档。要搜索的信息封装成Document后通过IndexWriter写入索引库。调用Searcher接口按关键词搜索后，返回的也是一个封装后的Document列表。它是在索引和搜索过程中数据的主要表现形式，或者称“载体”，承载着我们索引和搜索的数据，它由一个或者多个域(Field)组成。用户提供的源是一条条记录，它们可以是文本文件、字符串或者数据库表的一条记录等等。一条记录经过索引之后，就是以一个Document的形式存储在索引文件中的。用户进行搜索，也是以Document列表的形式返回。 Field：它是Document的组成部分，由两部分组成，名称(name)和值(value)。一个Document可以包含多个信息域，一个Document可以包含多个列，叫做Field。例如一篇文章可以包含“标题”、“正文”、“最后修改时间”等信息域，这些信息域就是通过Field在Document中存储的。Field有两个属性可选：存储和索引。通过存储属性你可以控制是否对这个Field进行存储；通过索引属性你可以控制是否对该Field进行索引。这看起来似乎有些废话，事实上对这两个属性的正确组合很重要，下面举例说明：还是以刚才的文章为例子，我们需要对标题和正文进行全文搜索，所以我们要把索引属性设置为真，同时我们希望能直接从搜索结果中提取文章标题，所以我们把标题域的存储属性设置为真，但是由于正文域太大了，我们为了缩小索引文件大小，将正文域的存储属性设置为假，当需要时再直接读取文件；我们只是希望能从搜索结果中提取最后修改时间，不需要对它进行搜索，所以我们把最后修改时间域的存储属性设置为真，索引属性设置为假。上面的三个域涵盖了两个属性的三种组合，还有一种全为假的没有用到，事实上Field不允许你那么设置，因为既不存储又不索引的域是没有意义的。 Term：term是搜索的最小单位，它表示文档的一个词语，term由两部分组成：它表示的词语和这个词语所出现的field。 Token：Analyzer返回的结果就是一串Token。Token包含一个代表词本身含义的字符串（也就是词本身）和该词在文章中相应的起止偏移位置，Token还包含一个用来存储词类型的字符串。token是term的一次出现，它包含term文本和相应的起止偏移，以及一个类型字符串。一句话中可以出现多次相同的词语，它们都用同一个term表示，但是用不同的token，每个token标记该词语出现的地方。 segment：添加索引时并不是每个document都马上添加到同一个索引文件，它们首先被写入到不同的小文件，然后再合并成一个大索引文件，这里每个小文件都是一个segment。 ​ Apache Lucene把所有的信息都写入到一个称为倒排索引的数据结构中。这种数据结构把索引中的每个Term与相应的Document映射起来，这与关系型数据库存储数据的方式有很大的不同。读者可以把倒排索引想象成这样的一种数据结构：数据以Term为导向，而不是以Document为导向。下面看看一个简单的倒排索引是什么样的，假定我们的Document只有title域(Field)被编入索引，Document如下： ElasticSearch Server (document 1) Mastering ElasticSearch (document 2) Apache Solr 4 Cookbook (document 3) 所以索引(以一种直观的形式)展现如下： Term count Docs 4 1 Apache 1 Cookbook 1 ElasticSearch 2 Mastering 1 Server 1 Solr 1 ​ 正如所看到的那样，每个词都指向它所在的文档号(Document Number/Document ID)。这样的存储方式使得高效的信息检索成为可能，比如基于词的检索(term-based query)。此外，每个词映射着一个数值(Count)，它代表着Term在文档集中出现的频繁程度。 ​ 当然，Lucene创建的真实索引远比上文复杂和先进。这是因为在Lucene中，词向量(由单独的一个Field形成的小型倒排索引，通过它能够获取这个特殊Field的所有Token信息)可以存储；所有Field的原始信息可以存储；删除Document的标记信息可以存储……。核心在于了解数据的组织方式，而非存储细节。 ​ 每个索引被分成了多个段(Segment)，段具有一次写入，多次读取的特点。只要形成了，段就无法被修改。例如：被删除文档的信息被存储到一个单独的文件，但是其它的段文件并没有被修改。 ​ 需要注意的是，多个段是可以合并的，这个合并的过程称为segments merge。经过强制合并或者Lucene的合并策略触发的合并操作后，原来的多个段就会被Lucene创建的更大的一个段所代替了。很显然，段合并的过程是一个I/O密集型的任务。这个过程会清理一些信息，比如会删除.del文件。除了精减文件数量，段合并还能够提高搜索的效率，毕竟同样的信息在一个段中读取会比在多个段中读取要快得多。但是，由于段合并是I/O密集型任务，建议不要强制合并，小心地配置好合并策略就可以了。 分析你的文本​ 问题到这里就变得稍微复杂了一些。传入到Document中的数据是如何转变成倒排索引的？查询语句是如何转换成一个个Term使高效率文本搜索变得可行？这种转换数据的过程就称为文本分析(analysis) ​ 文本分析工作由analyzer组件负责。analyzer由一个分词器(tokenizer)和0个或者多个过滤器(filter)组成,也可能会有0个或者多个字符映射器(character mappers)组成。 ​ Lucene中的tokenizer用来把文本拆分成一个个的Token。Token包含了比较多的信息，比如Term在文本的中的位置及Term原始文本，以及Term的长度。文本经过tokenizer处理后的结果称为token stream。token stream其实就是一个个Token的顺序排列。token stream将等待着filter来处理。 ​ 除了tokenizer外，Lucene的另一个重要组成部分就是filter链，filter链将用来处理Token Stream中的每一个token。这些处理方式包括删除Token，改变Token，甚至添加新的Token。Lucene中内置了许多filter，读者也可以轻松地自己实现一个filter。有如下内置的filter： Lowercase filter：把所有token中的字符都变成小写 ASCII folding filter：去除tonken中非ASCII码的部分 Synonyms filter：根据同义词替换规则替换相应的token Multiple language-stemming filters：把Token(实际上是Token的文本内容)转化成词根或者词干的形式。 所以通过Filter可以让analyzer有几乎无限的处理能力：因为新的需求添加新的Filter就可以了。 索引和查询​ 在我们用Lucene实现搜索功能时，也许会有读者不明白：上述的原理是如何对索引过程和搜索过程产生影响？ ​ 索引过程：Lucene用用户指定好的analyzer解析用户添加的Document。当然Document中不同的Field可以指定不同的analyzer。如果用户的Document中有title和description两个Field，那么这两个Field可以指定不同的analyzer。 ​ 搜索过程：用户的输入查询语句将被选定的查询解析器(query parser)所解析，生成多个Query对象。当然用户也可以选择不解析查询语句，使查询语句保留原始的状态。在ElasticSearch中，有的Query对象会被解析(analyzed)，有的不会，比如：前缀查询(prefix query)就不会被解析，精确匹配查询(match query)就会被解析。对用户来说，理解这一点至关重要。 ​ 对于索引过程和搜索过程的数据解析这一环节，我们需要把握的重点在于：倒排索引中词应该和查询语句中的词正确匹配。如果无法匹配，那么Lucene也不会返回我们想要的结果。举个例子：如果在索引阶段对文本进行了转小写(lowercasing)和转变成词根形式(stemming)处理，那么查询语句也必须进行相同的处理，不然搜索结果就会是竹篮打水一场空。 Lucene查询语言基础语法​ 用户使用Lucene进行查询操作时，输入的查询语句会被分解成一个或者多个Term以及逻辑运算符号。一个Term，在Lucene中可以是一个词，也可以是一个短语(用双引号括起来的多个词)。如果事先设定规则：解析查询语句，那么指定的analyzer就会用来处理查询语句的每个term形成Query对象。 ​ 一个Query对象中会存在多个布尔运算符，这些布尔运算符将多个Term关联起来形成查询子句。布尔运算符号有如下类型： AND(与)：给定两个Term(左运算对象和右运算对象)，形成一个查询表达式。只有两个Term都匹配成功，查询子句才匹配成功。比如：查询语句”apache AND lucene”的意思是匹配含apache且含lucene的文档。 OR(或)：给定的多个Term，只要其中一个匹配成功，其形成的查询表达式就匹配成功。比如查询表达式”apache OR lucene”能够匹配包含“apache”的文档，也能匹配包含”lucene”的文档，还能匹配同时包含这两个Term的文档。 NOT(非)：这意味着对于与查询语句匹配的文档，NOT运算符后面的Term就不能在文档中出现。例如：查询表达式“lucene NOT elasticsearch”就只能匹配包含lucene但是不含elasticsearch的文档。 此外，我们也许会用到如下的运算符： +：如果想要查询语句与文档匹配，那么给定的Term必须出现在文档中。例如：希望搜索到包含关键词lucene，最好能包含关键词apache的文档，可以用如下的查询表达式：”+lucene apache”。 -：如果想要查询语句与文档匹配，那么给定的Term不能出现在文档中。例如：希望搜索到包含关键词lucene，但是不含关键词elasticsearch的文档，可以用如下的查询表达式：”+lucene -elasticsearch”。 如果在Term前没有指定运算符，那么默认使用OR运算符。 此外，也是最后一点：查询表达式可以用小括号组合起来，形成复杂的查询表达式。比如： AND (mastering OR book)```12345678#### 多域查询​ 当然，跟ElasticSearch一样，Lucene中的所有数据都是存储在一个个的Field中，多个Field形成一个Document。如果希望查询指定的Field，就需要在查询表达式中指定Field Name(此域名非彼域名)，后面接一个冒号，紧接着一个查询表达式。例如：查询title域中包含关键词elasticsearch的文档，查询表达式如下：```title:elasticsearch ​ 也可以把多个查询表达式用于一个域中。例如：查询title域中含关键词elasticsearch并且含短语“mastering book”的文档，查询表达式如下： +"mastering book")```1234​ 当然，也可以换一种写法，作用是一样的：```+title:elasticsearch +title:&quot;mastering book&quot;) ​ 另外，Lucene支持模糊查询(fuzzy query)和邻近查询(proximity query)。语法规则是查询表达式后面接一个~号，后面紧跟一个整数。如果查询表达式是单独一个Term，这表示我们的搜索关键词可以由Term变形（替换一个字符，添加一个字符，删除一个字符）而来，即与Term是相似的。这种搜索方式称为模糊搜索(fuzzy query)。在~符号后面的整数表示最大编辑距离。例如：执行查询表达式“writer~2”能够搜索到含writer和writers的文档。 ​ 当~符号用于一个短语时，~后面的整数表示短语中可接收的最大的词编辑距离（短语中替换一个词，添加一个词，删除一个词）。举个例子，查询表达式elasticsearch"```只能匹配title域中含"mastering elasticsearch"的文档，而无法匹配含"mastering book elasticsearch"的文档。但是如果查询表达式变成```title:"mastering elasticsearch"~2```，那么两种文档就都能够成功匹配了。123456​ 另外，我们还可以使用加权（boosting）机制来改变关键词的重要程度。加权机制的语法是一个^符号后面接一个浮点数表示权重。如果权重小于1，就会降低关键词的重要程度。同理，如果权重大于1就会增加关键词的重要程度。默认的加权值为1。​ 除了上述的功能外，Lucene还支持区间查询（range scarching），其语法是用中括号或者&#125;表示区间。例如：如果我们查询一个数值域（numeric field），可以用如下查询表达式：```price:[10.00 TO 15.00] ​ 这条查询表达式能查询到price域的值在10.00到15.00之间的所有文档。 ​ 对于string类型的field，区间查询也同样适用。例如： TO Adria]```123456​ 这条查询表达式能查询到name域中含关键词Adam到关键词Adria之间关键词（字符串升序，且闭区间）的文档。​ 如果希望区间的边界值不会被搜索到，那么就需要用大括号替换原来的中括号。例如，查询price域中价格在10.00(10.00要能够被搜索到)到15.00(15.00不能被搜索到)之间的文档，就需要用如下的查询表达式：```price:[10.00 TO 15.00&#125; 处理特殊字符​ 如果在搜索关键词中出现了如下字符集合中的任意一个字符，就需要用反斜杠(\)进行转义。字符集合如下： +, -, &amp;&amp;, || , ! , (,) , { } , [ ] , ^, “ , ~, *, ?, : , \, / 。例如，查询关键词 abc”efg 就需要转义成 abc\”efg。 请注意出于性能考虑，默认的通配符不能是关键词的首字母。 此外，Lucene支持模糊查询(fuzzy query)和邻近查询(proximity query)。语法规则是查询表达式后面接一个~符号，后面紧跟一个整数。如果查询表达式是单独一个Term，这表示我们的搜索关键词可以由Term变形(替换一个字符，添加一个字符，删除一个字符)而来，即与Term是相似的。这种搜索方式称为模糊搜索(fuzzy search)。在~符号后面的整数表示最大编辑距离。例如：执行查询表达式 “writer~2”能够搜索到含writer和writers的文档。 当~符号用于一个短语时，~后面的整数表示短语中可接收的最大的词编辑距离(短语中替换一个词，添加一个词，删除一个词)。举个例子,查询表达式title:”mastering elasticsearch”只能匹配title域中含”mastering elasticsearch”的文档，而无法匹配含”mastering book elasticsearch”的文档。但是如果查询表达式变成title:”mastering elasticsearch”~2,那么两种文档就都能够成功匹配了。 此外，我们还可以使用加权(boosting)机制来改变关键词的重要程度。加权机制的语法是一个^符号后面接一个浮点数表示权重。如果权重小于1，就会降低关键词的重要程度。同理，如果权重大于1就会增加关键词的重要程度。默认的加权值为1。可以参考 第2章 活用用户查询语言 的 Lucene默认打分规则详解 章节部分的内容来了解更多关于加权(boosting)是如何影响打分排序的。 除了上述的功能外，Lucene还支持区间查询(range searching),其语法是用中括号或者}表示区间。例如：如果我们查询一个数值域(numeric field)，可以用如下查询表达式：]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[varnish使用]]></title>
    <url>%2F2019%2F06%2F20%2Fvarnish%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[测试安装123yum install epel-releaseyum install -y varnish yum install -y varnish-docs.x86_64 配置123456789101112131415161718192021222324252627282930vim /etc/sysconfig/varnish:NFILES=131072 # 所能够打开的最大文件数MEMLOCK=82000 # 用多大内存空间保存日志信息NPROCS="unlimited"DAEMON_COREFILE_LIMIT="unlimited" # 进程核心转储所使用的内存空间，unlimited表示无上限RELOAD_VCL=1 # 重新启动服务时是否重新读取VCL并重新编译的VARNISH_VCL_CONF=/etc/varnish/config/default.vcl # 默认读取的VCL文件VARNISH_LISTEN_PORT=6081 # 监听的端口，默认监听6081VARNISH_ADMIN_LISTEN_ADDRESS=127.0.0.1 # 管理接口监听的地址VARNISH_ADMIN_LISTEN_PORT=6082 # 管理接口监听的端口VARNISH_SECRET_FILE=/etc/varnish/secret # 使用的密钥文件VARNISH_MIN_THREADS=50 # 最少线程数VARNISH_MAX_THREADS=1000 # 最大线程数VARNISH_THREAD_TIMEOUT=120 # 线程的超时时间VARNISH_STORAGE_SIZE=2046M # 存储文件的大小VARNISH_STORAGE="malloc,$&#123;VARNISH_STORAGE_SIZE&#125;" # 存储的文件格式# file：单个文件，不支持持久机制# malloc：内存# persistent：基于文件的持久存储VARNISH_TTL=120 # 联系后端服务器的超时时间DAEMON_OPTS="-a $&#123;VARNISH_LISTEN_ADDRESS&#125;:$&#123;VARNISH_LISTEN_PORT&#125; \ -f $&#123;VARNISH_VCL_CONF&#125; \ -T $&#123;VARNISH_ADMIN_LISTEN_ADDRESS&#125;:$&#123;VARNISH_ADMIN_LISTEN_PORT&#125; \ -t $&#123;VARNISH_TTL&#125; \ -p thread_pool_min=$&#123;VARNISH_MIN_THREADS&#125; \ -p thread_pool_max=$&#123;VARNISH_MAX_THREADS&#125; \ -p thread_pool_timeout=$&#123;VARNISH_THREAD_TIMEOUT&#125; \ -u varnish -g varnish \ -S $&#123;VARNISH_SECRET_FILE&#125; \ -s $&#123;VARNISH_STORAGE&#125;" # 使用定义的各高级配置的参数 vcl文件123456789vim /etc/varnish/default.vclvcl 4.0;backend default &#123; .host = "192.168.1.109"; # 后端服务器地址 .port = "80"; # 后端服务器端口&#125;# 目前只测试varnish是否可以正常工作，尚未定义缓存属性信息systemctl start varnish 安装配置web服务1234567yum install -y httpd php php-mysqlvim /var/www/html/index.html&lt;h1&gt;www.abc.com and varnish of backend&lt;/h1&gt;&lt;h2&gt;node1.abc.com&lt;/h2&gt;systemctl start httpd访问IP:80访问IP:6081 设置响应是否命中123456789101112131415161718vim default.vclsub vcl_deliver &#123; if (obj.hits &gt; 0)&#123; set resp.http.X-Cache = "HIT from"; # 判断如果命中了就在http响应首部设置X-Cache为HIT &#125;else&#123; set resp.http.X-Cache = "MISS"; # 否则就在http响应首部设置X-Cache为MISS&#125;# 这里的语法是if(条件)&#123;方法&#125;else&#123;方法&#125;，如果满足if后面小括号中的条件，就执行小括号后面大括号中的方法，否则执行else后面大括号中的方法。varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082# 连接varnish，进入varnish的命令操作vcl.load test1 /etc/varnish/default.vcl# 在命令行中输入上面命令，加载default.vcl文件，test1是自定义的名称，这应该是一个策略的名称，策略的名称每次都不能一样。vcl.listvcl.show test1# 查看test1的策略内容访问IP:6081，之后按F12查看是否有X-Cache一项，如果没有此项，可以重启一下varnish。之后可以看到X-Cache一项为MISS，再次刷新后，此项变为HIT。 指定某些文件不能查缓存12345678910111213141516171819vim default.vclvcl 4.0;# Default backend definition. Set this to point to your content server.backend default &#123; .host = "192.168.1.109"; .port = "80";&#125;sub vcl_recv &#123; if (req.url ~ "test.html")&#123; return(pass); &#125;# return(lookup);&#125;# 这里不可以加return(lookup)，因为varnish4中使用return(hash)代替了return(lookup)。vcl.load test2 /etc/varnish/default.vcl# 加载策略访问IP:6081/test.html，无论如何刷新，F12中的x-cache都是MISS vcl配置文件VCL中内置预设变量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495req：The request object，请求到达时可用的变量(客户端发送的请求对象)bereq：The backend request object，向后端主机请求时可用的变量beresp：The backend response object，从后端主机获取内容时可用的变量(后端响应请求对象)resp：The HTTP response object，对客户端响应时可用的变量(返回给客户端的响应对象)obj：存储在内存中时对象属性相关的可用的变量(高速缓存对象，缓存后端响应请求内容)预设变量是系统固定的，请求进入对应的vcl子程序后便生成，这些变量可以方便子程序提取，当然也可以自定义一些全局变量。当前时间：now :作用：返回当前时间戳。客户端：（客户端基本信息）client.ip：返回客户端IP地址。注：原client.port已经弃用，如果要取客户端请求端口号使用 std.port(client.ip)，需要import std;才可以使用stdclient.identity：用于装载客户端标识码。服务器：（服务器基本信息）注：原server.port已经弃用，如果要取服务器端口号使用 std.port(server.ip)，需要import std;才可以使用stdserver.hostname：服务器主机名。server.identity：服务器身份标识。server.ip：返回服务器端IP地址。req :（客户端发送的请求对象）req：整个HTTP请求数据结构req.backend_hint：指定请求后端节点，设置后 bereq.backend 才能获取后端节点配置数据req.can_gzip：客户端是否接受GZIP传输编码。req.hash_always_miss：是否强制不命中高速缓存，如果设置为true，则高速缓存不会命中，一直会从后端获取新数据。req.hash_ignore_busy：忽略缓存中忙碌的对象，多台缓存时可以避免死锁。req.http：对应请求HTTP的header。req.method：请求类型（如 GET , POST）。req.proto：客户端使用的HTTP协议版本。req.restarts：重新启动次数。默认最大值是4req.ttl：缓存有剩余时间。req.url：请求的URL。req.xid：唯一ID。bereq：（发送到后端的请求对象，基于req对象）bereq：整个后端请求后数据结构。bereq.backend：所请求后端节点配置。bereq.between_bytes_timeout：从后端每接收一个字节之间的等待时间（秒）。bereq.connect_timeout：连接后端等待时间（秒），最大等待时间。bereq.first_byte_timeout：等待后端第一个字节时间（秒），最大等待时间。bereq.http：对应发送到后端HTTP的header信息。bereq.method：发送到后端的请求类型（如：GET , POST）。bereq.proto：发送到后端的请求的HTTP版本。bereq.retries：相同请求重试计数。bereq.uncacheable：无缓存这个请求。bereq.url：发送到后端请求的URL。bereq.xid：请求唯一ID。beresp：（后端响应请求对象）beresp：整个后端响应HTTP数据结构。beresp.backend.ip：后端响应的IP。beresp.backend.name：响应后端配置节点的name。beresp.do_gunzip：默认为 false 。缓存前解压该对象beresp.do_gzip：默认为 false 。缓存前压缩该对象beresp.grace：设置当前对象缓存过期后可额外宽限时间，用于特殊请求加大缓存时间，当并发量巨大时，不易设置过大否则会堵塞缓存，一般可设置 1m 左右，当beresp.ttl=0s时该值无效。beresp.http：对应的HTTP请求headerberesp.keep：对象缓存后带保持时间beresp.proto：响应的HTTP版本beresp.reason：由服务器返回的HTTP状态信息beresp.status：由服务器返回的状态码beresp.storage_hint：指定保存的特定存储器beresp.ttl：该对象缓存的剩余时间，指定统一缓存剩余时间。beresp.uncacheable：继承bereq.uncacheable，是否不缓存OBJ ：（高速缓存对象，缓存后端响应请求内容）obj.grace：该对象额外宽限时间obj.hits：缓存命中次数，计数器从1开始，当对象缓存该值为1，一般可以用于判断是否有缓存，当前该值大于0时则为有缓存。obj.http：对应HTTP的headerobj.proto：HTTP版本obj.reason：服务器返回的HTTP状态信息obj.status：服务器返回的状态码obj.ttl：该对象缓存剩余时间（秒）obj.uncacheable：不缓存对象resp :（返回给客户端的响应对象）resp：整个响应HTTP数据结构。resp.http：对应HTTP的header。resp.proto：编辑响应的HTTP协议版本。resp.reason：将要返回的HTTP状态信息。resq.status：将要返回的HTTP状态码。存储 ：storage.&lt;name&gt;.free_space：存储可用空间（字节数）。storage.&lt;name&gt;.used_space：存储已经使用空间（字节数）。storage.&lt;name&gt;.happy：存储健康状态。 特定功能性语句12345678910111213141516171819202122232425262728293031323334353637ban(expression)：清除指定对象缓存call(subroutine)：调用子程序，如：call(name);hash_data(input)：生成hash键，用于制定hash键值生成结构，只能在vcl_hash子程序中使用。调用hash_data(input) 后，即这个hash为当前页面的缓存hash键值，无需其它获取或操作，如:=======================================================================================sub vcl_hash&#123; hash_data(client.ip); return(lookup);&#125;=======================================================================================注意：return(lookup);是默认返回值，所以可以不写。new()：创建一个vcl对象，只能在vcl_init子程序中使用。return()：结束当前子程序，并指定继续下一步动作，如：return (ok); 每个子程序可指定的动作均有不同。rollback()：恢复HTTP头到原来状态，已经弃用，使用 std.rollback() 代替。synthetic(STRING)：合成器，用于自定义一个响应内容，比如当请求出错时，可以返回自定义 404 内容，而不只是默认头信息，只能在 vcl_synth 与 vcl_backend_error 子程序中使用，如：=======================================================================================sub vcl_synth &#123; //自定义内容 synthetic (&#123;"&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;&lt;html lang="zh-cn"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"/&gt; &lt;title&gt;error&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Error&lt;/h1&gt; &lt;h3&gt;这只是一个测试自定义响应异常内容&lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; "&#125;); //只交付自定义内容 return(deliver);=======================================================================================regsub(str, regex, sub)：使用正则替换第一次出现的字符串，第一个参数为待处理字符串，第二个参数为正则表达式，第三个为替换为字符串。regsuball(str, regex, sub)：使用正则替换所有匹配字符串。参数与regsuball相同。具体变量详见：https://www.varnish-cache.org/docs/4.0/reference/vcl.html#reference-vcl return 语句1234567891011121314151617return 语句是终止子程序并返回动作，所有动作都根据不同的vcl子程序限定来选用。https://www.varnish-cache.org/docs/4.0/users-guide/vcl-built-in-subs.html语法：return(action);常用的动作：abandon 放弃处理，并生成一个错误。deliver 交付处理fetch 从后端取出响应对象hash 哈希缓存处理lookup 查找缓存对象ok 继续执行pass 进入pass非缓存模式pipe 进入pipe非缓存模式purge 清除缓存对象，构建响应restart 重新开始retry 重试后端处理synth(status code,reason) 合成返回客户端状态信息 varnish中内置子程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131注意：varnish内置子程序均有自己限定的返回动作 return （动作）; 不同的动作将调用对应下一个子程序。vcl_recv子程序：开始处理请求，通过 return (动作); 选择varnish处理模式，默认进入hash缓存模式（即return(hash);），缓存时间为配置项default_ttl（默认为 120秒）过期保持时间default_grace（默认为10秒）。该子程序一般用于模式选择，请求对象缓存及信息修改，后端节点修改，终止请求等操作。可操作对象：（部分或全部值）读：client，server，req，storage写：client，req返回值：synth(status code,reason); 定义响应内容。pass 进入pass模式，并进入vcl_pass子程序。pipe 进入pipe模式，并进入vcl_pipe子程序。hash 进入hash缓存模式，并进入vcl_hash子程序，默认返回值。purge 清除缓存等数据，子程序先从vcl_hash再到vcl_purge。vcl_pipe子程序：pipe模式处理，该模式主要用于直接取后端响应内容返回客户端，可定义响应内容返回客户端。该子程序一般用于需要及时且不作处理的后端信息，取出后端响应内容后直接交付到客户端不进入vcl_deliver子程序处理。可操作对象：（部分或全部值）读：client，server，bereq，req，storage写：client，bereq，req返回值：synth(status code,reason); 定义响应内容。pipe 继续pipe模式，进入后端vcl_backend_fetch子程序，默认返回值。vcl_pass子程序：pass模式处理，该模式类似hash缓存模式，仅不做缓存处理。可操作对象：（部分或全部值）读：client，server，req，storage写：client，req返回值：synth(status code,reason); 定义响应内容。fetch 继续pass模式，进入后端vcl_backend_fetch子程序，默认返回值。vcl_hit子程序：hash缓存模式时，存在hash缓存时调用，用于缓存处理，可放弃或修改缓存。可操作对象：（部分或全部值）读：client，server，obj，req，storage写：client，req返回值：restart 重启请求。deliver 交付缓存内容，进入vcl_deliver子程序处理，默认返回值。synth(status code,reason); 定义响应内容。vcl_miss子程序：hash缓存模式时，不存在hash缓存时调用，用于判断性的选择进入后端取响应内容，可以修改为pass模式。可操作对象：（部分或全部值）读：client，server，req，storage写：client，req返回值：restart 重启请求。synth(status code,reason); 定义响应内容。pass 切换到pass模式，进入vcl_pass子程序。fetch 正常取后端内容再缓存，进入vcl_backend_fetch子程序，默认返回值。vcl_hash子程序：hash缓存模式，生成hash值作为缓存查找键名提取缓存内容，主要用于缓存hash键值处理，可使用hash_data(string)指定键值组成结构，可在同一个页面通过IP或cookie生成不同的缓存键值。可操作对象：（部分或全部值）读：client，server，req，storage写：client，req返回值：lookup 查找缓存对象，存在缓存进入vcl_hit子程序，不存在缓存进入vcl_miss子程序，当使用了purge清理模式时会进入vcl_purge子程序，默认返回值。vcl_purge子程序：清理模式，当查找到对应的缓存时清除并调用，用于请求方法清除缓存，并报告.可操作对象：（部分或全部值）读：client，server，req，storage写：client，req返回值：synth(status code,reason); 定义响应内容。restart 重启请求。vcl_deliver子程序：客户端交付子程序，在vcl_backend_response子程序后调用（非pipe模式），或vcl_hit子程序后调用，可用于追加响应头信息，cookie等内容。可操作对象：（部分或全部值）读：client，server，req，resp，obj，storage写：client，req，resp返回值：deliver 正常交付后端或缓存响应内容，默认返回值。restart 重启请求。vcl_backend_fetch子程序：发送后端请求之前调用，可用于改变请求地址或其它信息，或放弃请求。可操作对象：（部分或全部值）读：server，bereq，storage写：bereq返回值：fetch 正常发送请求到到后端取出响应内容，进入vcl_backend_response子程序，默认返回值。abandon 放弃后端请求，并生成一个错误，进入vcl_backend_error子程序。vcl_backend_response子程序：后端响应后调用，可用于修改缓存时间及缓存相关信息。可操作对象：（部分或全部值）读：server，bereq，beresp，storage写：bereq，beresp返回值：deliver 正常交付后端响应内容，进入vcl_deliver子程序，默认返回值。abandon 放弃后端请求，并生成一个错误，进入vcl_backend_error子程序。retry 重试后端请求，重试计数器加1，当超过配置中max_retries值时会报错并进入vcl_backend_error子程序。vcl_backend_error子程序：后端处理失败调用，异常页面展示效果处理，可自定义错误响应内容，或修改beresp.status与beresp.http.Location重定向等。可操作对象：（部分或全部值）读：server，bereq，beresp，storage写：bereq，beresp返回值：deliver 只交付 sysnthetic(string) 自定义内容，默认返回后端异常标准错误内容。retry 重试后端请求，重试计数器加1，当超过配置中max_retries值时会报错并进入vcl_backend_error子程序。vcl_synth子程序：自定义响应内容。可以通过synthetic（）和返回值 synth调用，这里可以自定义异常显示内容，也可以修改resp.status与resp.http.Location重定向。可操作对象：（部分或全部值）读：client，server，req，resp，storage写：req，resp返回值：deliver 只交付 sysnthetic(string) 自定义内容，默认返回 sysnth 异常指定状态码与错误内容。restart 重启请求。vcl_init子程序：加载vcl时最先调用，用于初始化VMODs，该子程序不参与请求处理，仅在vcl加载时调用一次。可操作对象：（部分或全部值）读：server写：无返回值：ok 正常返回，进入vcl_recv子程序，默认返回值。vcl_fini子程序：卸载当前vcl配置时调用，用于清理VMODs，该子程序不参与请求处理，仅在vcl正常丢弃后调用。可操作对象：（部分或全部值）读：server写：无返回值：ok 正常返回，本次vcl将释放，默认返回值。 varnish子程序调用流程图，通过大部分子程序的return返回值进入下一步行动： 优雅模式(Garce mode)Varnish中的请求合并 当几个客户端请求同一个页面的时候，varnish只发送一个请求到后端服务器，然后让其他几个请求挂起并等待返回结果；获得结果后，其它请求再复制后端的结果发送给客户端； 但如果同时有数以千计的请求，那么这个等待队列将变得庞大，这将导致2类潜在问题： 惊群问题(thundering herd problem)，即突然释放大量的线程去复制后端返回的结果，将导致负载急速上升；没有用户喜欢等待； 为了解决这类问题，可以配置varnish在缓存对象因超时失效后再保留一段时间，以给那些等待的请求返回过去的文件内容(stale content)，配置案例如下： 12345678910sub vcl_recv &#123;if (! req.backend.healthy) &#123;set req.grace = 5m;&#125; else &#123;set req.grace = 15s;&#125;&#125;sub vcl_fetch &#123;set beresp.grace = 30m;&#125; 以上配置表示varnish将会将失效的缓存对象再多保留30分钟，此值等于最大的req.grace值即可； 而根据后端主机的健康状况，varnish可向前端请求分别提供5分钟内或15秒内的过期内容 后端服务器地址池配置及后端服务器健康检查后端服务器定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546命令：backend。这个定义为最基本的反向入口定义，用于varnish连接对应的服务器，如果没有定义或定义错误则用户无法访问正常页面。语法格式：backend name&#123; .attribute = "value";&#125;说明：backend 是定义后端关键字，name 是当前后端节点的别名，多个后端节点时，name 名不能重复，否则覆盖。花括号里面定义当前节点相关的属性（键=值）。除默认节点外其它节点定义后必需有调用，否则varnish无法启动。后端是否正常可以通过std.healthy(backend)判断。支持运算符:= （赋值运算）== （相等比较）~ （匹配，可以使用正则表达式，或访问控制列表）!~ （不匹配，可以使用正则表达式，或访问控制列表）！ （非）&amp;&amp; （逻辑与）|| （逻辑或）属性列表：.host="xxx.xxx.xxx.xxx"; //要转向主机（即后端主机）的IP或域名，必填键/值对。.port="8080"; //主机连接端口号或协议名（HTTP等），默认80.host_header=''; //请示主机头追加内容.connect_timeout=1s; //连接后端的超时时间.first_byte_timeout=5s; //等待从后端返回的第一个字节时间.between_bytes_timeout=2s; //每接收一个字节之间等待时间.probe=probe_name; //监控后端主机的状态,指定外部监控name或者内部直接添加.max_connections=200; //设置最大并发连接数，超过这个数后连接就会失败例：（下面两个例子结果是一样的，但第二个例子中更适用于集群，可以方便批量修改）backend web&#123; .host="192.168.197.180"; .port="80"; .probe=&#123; //直接追加监控块.probe是一个的参数 .url="/"; .timeout=2s; &#125;&#125;或probe web_probe&#123; //监控必需定义在前面，否则后端调用找不到监控块。 .url="/"; .timeout=2s;&#125; backend web&#123; .host="192.168.197.180"; .port="80"; .probe=web_probe; //调用外部共用监控块&#125; 监视器定义123456789101112131415161718192021222324252627命令：probe 。监控可以循环访问指定的地址，通过响应时间判定服务器是否空闲或正常。这类命令非常适用于集群中某些节点服务器崩溃或负载过重，而禁止访问这台节点服务器。语法格式：probe name&#123; .attribute = "value";&#125;说明：probe 是定义监控关键字，name 是当前监控点的别名，多个监控节点时，name 名不能重复，否则覆盖。花括号里面定义当前节点相关的属性（键=值）。没有必填属性，因为默认值就可以正常执行操作。属性列表：.url="/"; //指定监控入口URL地址，默认为"/".request=""; //指定监控请求入口地址，比 .url 优先级高。.expected_response="200"; //请求响应代码，默认是 200.timeout=2s; //请求超时时间。.interval=5s; //每次轮询请求间隔时间,默认为 5s 。.initial=-1; //初始启动时以.window轮询次数中几次良好后续才能使用这个后端服务器节点，默认为 -1 ，则轮询完 .window 所有次数良好判定为正常。.window=8; //指定多少轮询次数，用于判定服务器正常，默认是 8。.threshold=3; //必须多少次轮询正常才算该后端节点服务器正常,默认是 3。例：创建健康监测，定义健康检查名称为backend_healthcheckprobe backend_healthcheck &#123; .url = "/"; .timeout = 1s; .interval = 5s; .window = 5; .threshold = 3; &#125;在上面的例子中varnish将每5s检测后端，超时设为1s。每个检测将会发送get /的请求。如果5个检测中大于3个是成功，varnish就认为后端是健康的，反之，后端就有问题了。 集群负载均衡directors1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980varnish可以定义多个后端，也可以将几个后端放在一个后端集群里面已达到负载均衡的目的。你也可以将几个后端组成一组后端。这个组被叫做Directors。可以提高性能和弹性。directors是varnish负载均衡模块，使用前必需引入directors模块，directors模块主要包含：round_robin，random，hash，fallback负载均衡模式。round_robin : 循环依次逐个选择后端服务器。random ： 随机选择后端服务器，可设置每个后端权重增加随机率。hash : 通过散列随机选择对应的后端服务器且保持选择对应关系，下次则直接找对应的后端服务器。Fallback:后备注意：random，hash有权重值设置，用于提高随机率。每个后端最好都配置监控器（后端服务器正常监测）以便directors自动屏蔽不正常后端而不进入均衡列队中。这些操作需要你载入VMOD（varnish module），然后在vcl_init中调用这个VMOD。import directors; # load the directorsbackend web1 &#123;.host = "192.168.197.175";.port = "80";.probe = backend_healthcheck;&#125;backend web2 &#123;.host = "192.168.197.176";.port = "80";.probe = backend_healthcheck;&#125;//初始化处理sub vcl_init &#123; //调用vcl_init初始化子程序创建后端主机组，即directors new web_cluster = directors.round_robin(); //使用new关键字创建drector对象,使用round_robin算法 web_cluster.add_backend(web1); //添加后端服务器节点web_cluster.add_backend(web2);&#125;//开始处理请求sub vcl_recv &#123; //调用vcl_recv子程序，用于接收和处理请求 set req.backend_hint = web_cluster.backend(); //选取后端&#125;说明：set命令是设置变量unset命令是删除变量web_cluster.add_backend( backend , real); 添加后端服务器节点，backend 为后端配置别名，real 为权重值，随机率计算公式：100 * (当前权重 / 总权重)。req.backend_hint是varnish的预定义变量，作用是指定请求后端节点vcl对象需要使用new关键字创建，所有可创建对象都是内定的，使用前必需import，所有new操作只能在vcl_init子程序中。扩展：varnish将不同的url发送到不同的后端serverimport directors; # load the directorsbackend web1 &#123;.host = "192.168.197.175";.port = "80";.probe = backend_healthcheck;&#125;backend web2 &#123;.host = "192.168.197.176";.port = "80";.probe = backend_healthcheck;&#125;backend img1 &#123; .host = "img1.lnmmp.com"; .port = "80"; .probe = backend_healthcheck;&#125;backend img2 &#123; .host = "img2.lnmmp.com"; .port = "80"; .probe = backend_healthcheck;&#125;//初始化处理sub vcl_init &#123; //调用vcl_init初始化子程序创建后端主机组，即directors new web_cluster = directors.round_robin(); //使用new关键字创建drector对象,使用round_robin算法 web_cluster.add_backend(web1); //添加后端服务器节点web_cluster.add_backend(web2);new img_cluster = directors.random();img_cluster.add_backend(img1,2); //添加后端服务器节点，并且设置权重值img_cluster.add_backend(img2,5);&#125;//根据不同的访问域名，分发至不同的后端主机组sub vcl_recv &#123;if (req.http.host ~ "(?i)^(www.)?benet.com$") &#123; set req.http.host = "www.benet.com"; set req.backend_hint = web_cluster.backend(); //选取后端 &#125; elsif (req.http.host ~ "(?i)^images.benet.com$") &#123; set req.backend_hint = img_cluster.backend(); &#125;&#125;说明：中的i就是忽略大小写的意思。(?i)表示开启忽略大小写，而(?-i)表示关闭忽略大小写 访问控制列表（ACL）123456789101112131415161718192021创建一个地址列表，用于后面的判断，可以是域名或IP集合。这个可以用于指定某些地址请求入口，防止恶意请求等。语法格式：acl purgers &#123; "127.0.0.1";"localhost";“192.168.134.0/24” !"192.168.134.1";&#125;说明：acl 是访问列表关键字（必需小写），name 是该列表的别名用于调用，花括号内部是地址集。注意：如果列表中包含了无法解析的主机地址，它会匹配任何地址。如果不想让它匹配可以在前添加一个 ! 符号，如上面 !"192.168.134.1"; 使用ACL只需要用匹配运算符 ~ 或 !~ 如：sub vcl_recv &#123; if (req.method == "PURGE") &#123; //PURGE请求的处理 if (client.ip ~ purgers) &#123; return(purge); &#125; else &#123; return(synth(403, "Access denied.")); &#125; &#125;&#125; 缓存规则配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546sub vcl_recv &#123; // PURGE请求的处理 if (req.method == "PURGE") &#123; if (!client.ip ~ purgers) &#123; return (synth(405, "Not Allowed.")); &#125; return (purge); &#125; set req.backend_hint = web.backend(); //将php、asp等动态内容访问请求直接发给后端服务器，不缓存。 if (req.url ~ "\.(php|asp|aspx|jsp|do|ashx|shtml)($|\?)") &#123; return (pass); &#125; //将非GET和HEAD访问请求直接发给后端服务器，不缓存。例如POST请求。 if (req.method != "GET" &amp;&amp; req.method != "HEAD") &#123; return (pass); &#125; //如果varnish看到header中有'Authorization'头，它将pass请求。 if (req.http.Authorization) &#123; return (pass);&#125; //带cookie首部的GET请求也缓存 if (req.url ~ "\.(css|js|html|htm|bmp|png|gif|jpg|jpeg|ico|gz|tgz|bz2|tbz|zip|rar|mp3|mp4|ogg|swf|flv)($|\?)") &#123; unset req.http.cookie; return (hash); &#125;说明：默认情况，varnish不缓存从后端响应的http头中带有Set-Cookie的对象。如果客户端发送的请求带有Cookie header，varnish将忽略缓存，直接将请求传递到后端。为发往后端主机的请求添加X-Forward-For首部,首次访问增加X-Forwarded-For 头信息,方便后端程序获取客户端ip，而不是varnish地址if (req.restarts == 0) &#123; if (req.http.x-forwarded-for) &#123;//如果设置过此header则要再次附加上用逗号隔开 set req.http.X-Forwarded-For = req.http.X-Forwarded-For + ", " + client.ip; &#125; else &#123;//如果只有一层代理的话,就无需设置了 set req.http.X-Forwarded-For = client.ip; &#125;&#125;说明：X-Forwarded-For是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段子程序：子程序是一种类似C的函数，但是程序没有调用参数，子程序以 sub 关键字定义。在VCL里子程序是用于管理程序。注意：所有VCL内置的程序都是以 vcl_ 开头，并已经预置好，在VCL文件中只要声明对应的内置子程序，都会在对应的流程中调用。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299vcl 4.0; # 使用varnish版本4的格式.import std; # 标准日志需要加载此模块import directors; # 加载后端轮询模块，为了可以使用下面的vcl_init# import表示加载varnish模块(VMODs)backend server1 &#123; # Define one backend。定义后端主机，server1是自定义的后端主机名称 .host = "10.129.14.4"; # Gateway on dl-gw-01 .port = "8090"; # Port Apache or whatever is listening .max_connections = 30000; # That's it .probe = &#123; #.url = "/"; # short easy way (GET /) # We prefer to only do a HEAD / .request = "HEAD / HTTP/1.1" "Host: localhost" "Connection: close" "User-Agent: Varnish Health Probe"; .interval = 5s; # check the health of each backend every 5 seconds .timeout = 1s; # timing out after 1 second. .window = 5; # If 3 out of the last 5 polls succeeded the backend is considered healthy, otherwise it will be marked as sick .threshold = 3; &#125; .first_byte_timeout = 300s; # How long to wait before we receive a first byte from our backend? .connect_timeout = 5s; # How long to wait for a backend connection? .between_bytes_timeout = 2s; # How long to wait between bytes received from our backend?&#125;backend server2 &#123; # Define one backend .host = "10.129.14.5"; # Gateway on dl-gw-01 .port = "8090"; # Port Apache or whatever is listening .max_connections = 30000; # That's it .probe = &#123; #.url = "/"; # short easy way (GET /) # We prefer to only do a HEAD / .request = "HEAD / HTTP/1.1" "Host: localhost" "Connection: close" "User-Agent: Varnish Health Probe"; .interval = 5s; # check the health of each backend every 5 seconds .timeout = 1s; # timing out after 1 second. .window = 5; # If 3 out of the last 5 polls succeeded the backend is considered healthy, otherwise it will be marked as sick .threshold = 3; &#125; .first_byte_timeout = 300s; # How long to wait before we receive a first byte from our backend? .connect_timeout = 5s; # How long to wait for a backend connection? .between_bytes_timeout = 2s; # How long to wait between bytes received from our backend?&#125;acl purge &#123; # 定义允许清理缓存的IP # ACL we'll use later to allow purges "localhost"; "127.0.0.1"; "::1";&#125;sub vcl_init &#123; # 配置后端集群事件 # Called when VCL is loaded, before any requests pass through it. # Typically used to initialize VMODs. # 后端集群有4种模式 random, round-robin, fallback, hash # random 随机 # round-robin 轮询 # fallback 后备 # hash 固定后端 根据url(req.http.url) 或用户cookie(req.http.cookie) 或用户session(req.http.sticky)(这个还有其他要配合) new vdir = directors.round_robin(); vdir.add_backend(server1); vdir.add_backend(server2); # vdir.add_backend(server...); # vdir.add_backend(servern);&#125;sub vcl_recv &#123; # Called at the beginning of a request, after the complete request has been received and parsed. # Its purpose is to decide whether or not to serve the request, how to do it, and, if applicable, # which backend to use. # also used to modify the request # 请求入口，这里一般用作路由处理，判断是否读取缓存和指定该请求使用哪个后端 set req.backend_hint = vdir.backend(); # send all traffic to the vdir director # Normalize the header, remove the port (in case you're testing this on various TCP ports) set req.http.Host = regsub(req.http.Host, ":[0-9]+", ""); # Remove the proxy header (see https://httpoxy.org/#mitigate-varnish) unset req.http.proxy; # Normalize the query arguments set req.url = std.querysort(req.url); # Allow purging if (req.method == "PURGE") &#123; if (!client.ip ~ purge) &#123; # purge is the ACL defined at the begining # Not from an allowed IP? Then die with an error. return (synth(405, "This IP is not allowed to send PURGE requests.")); &#125; # If you got this stage (and didn't error out above), purge the cached result return (purge); &#125;# 如果不是指定IP执行PURGE方法会报错，否则就执行 # Only deal with "normal" types if (req.method != "GET" &amp;&amp; req.method != "HEAD" &amp;&amp; req.method != "PUT" &amp;&amp; req.method != "POST" &amp;&amp; req.method != "TRACE" &amp;&amp; req.method != "OPTIONS" &amp;&amp; req.method != "PATCH" &amp;&amp; req.method != "DELETE") &#123; /* Non-RFC2616 or CONNECT which is weird. */ /*Why send the packet upstream, while the visitor is using a non-valid HTTP method? */ return (synth(404, "Non-valid HTTP method!")); &#125;# 如果使用上面指定的方法就报错。 # Only cache GET or HEAD requests. This makes sure the POST requests are always passed. if (req.method != "GET" &amp;&amp; req.method != "HEAD") &#123; return (pass); &#125; if (req.url ~ "/aquapaas/rest/usertags/") &#123; return (hash); &#125; # 如果请求的地址中包含/aquapaas/rest/usertags/，就缓存。 return (pass);&#125;# The data on which the hashing will take placesub vcl_hash &#123; # Called after vcl_recv to create a hash value for the request. This is used as a key # to look up the object in Varnish. hash_data(req.url); return (lookup);&#125;# Handle the HTTP request coming from our backendsub vcl_backend_response &#123; # Called after the response headers has been successfully retrieved from the backend. # Sometimes, a 301 or 302 redirect formed via Apache's mod_rewrite can mess with the HTTP port that is being passed along. # This often happens with simple rewrite rules in a scenario where Varnish runs on :80 and Apache on :8080 on the same box. # A redirect can then often redirect the end-user to a URL on :8080, where it should be :80. # This may need finetuning on your setup. # # To prevent accidental replace, we only filter the 301/302 redirects for now. if (beresp.status == 301 || beresp.status == 302) &#123; set beresp.http.Location = regsub(beresp.http.Location, ":[0-9]+", ""); &#125; # Don't cache 50x responses if (beresp.status == 500 || beresp.status == 502 || beresp.status == 503 || beresp.status == 504) &#123; return (abandon); # abandon 放弃处理，并生成一个错误。 &#125; # Set 2min cache if unset for static files # if (beresp.ttl &lt;= 0s || beresp.http.Set-Cookie || beresp.http.Vary == "*") &#123; # set beresp.ttl = 120s; # Important, you shouldn't rely on this, SET YOUR HEADERS in the backend # set beresp.uncacheable = true; # return (deliver); # &#125; # Allow stale content, in case the backend goes down. # make Varnish keep all objects for 24000 hours beyond their TTL # set beresp.ttl = 5m; # set beresp.grace = 24000h; if ( beresp.status == 200 ) &#123; #只有返回状态为200 OK的数据才考虑缓存。 if (bereq.url ~ "/aquapaas/rest/usertags/") &#123; #AAA数据缓存30秒，过期后缓存0秒。 set beresp.ttl = 30s; set beresp.grace = 0s; &#125; &#125; else &#123; #其余数据不缓存。 set beresp.ttl = 0s; &#125; return (deliver);&#125;# The routine when we deliver the HTTP request to the user# Last chance to modify headers that are sent to the clientsub vcl_deliver &#123; # Called before a cached object is delivered to the client. if (obj.hits &gt; 0) &#123; # Add debug header to see if it's a HIT/MISS and the number of hits, disable when not needed set resp.http.X-Cache = "HIT"; &#125; else &#123; set resp.http.X-Cache = "MISS"; &#125; # Please note that obj.hits behaviour changed in 4.0, now it counts per objecthead, not per object # and obj.hits may not be reset in some cases where bans are in use. See bug 1492 for details. # So take hits with a grain of salt set resp.http.X-Cache-Hits = obj.hits; # Remove some headers: PHP version unset resp.http.X-Powered-By; # Remove some headers: Apache version &amp; OS unset resp.http.Server; unset resp.http.X-Drupal-Cache; unset resp.http.X-Varnish; unset resp.http.Via; unset resp.http.Link; unset resp.http.X-Generator; return (deliver);&#125;sub vcl_purge &#123; # Only handle actual PURGE HTTP methods, everything else is discarded if (req.method == "PURGE") &#123; # restart request set req.http.X-Purge = "Yes"; return (restart); &#125;&#125;sub vcl_synth &#123; if (resp.status == 720) &#123; # We use this special error status 720 to force redirects with 301 (permanent) redirects # To use this, call the following from anywhere in vcl_recv: return (synth(720, "http://host/new.html")); set resp.http.Location = resp.reason; set resp.status = 301; return (deliver); &#125; elseif (resp.status == 721) &#123; # And we use error status 721 to force redirects with a 302 (temporary) redirect # To use this, call the following from anywhere in vcl_recv: return (synth(720, "http://host/new.html")); set resp.http.Location = resp.reason; set resp.status = 302; return (deliver); &#125; return (deliver);&#125;sub vcl_hit &#123; # Called when a cache lookup is successful. if (obj.ttl &gt;= 0s) &#123; # A pure unadultered hit, deliver it return (deliver); &#125; # https://www.varnish-cache.org/docs/trunk/users-guide/vcl-grace.html # When several clients are requesting the same page Varnish will send one request to the backend and place the others on hold while fetching one copy from the backend. In some products this is called request coalescing and Varnish does this automatically. # If you are serving thousands of hits per second the queue of waiting requests can get huge. There are two potential problems - one is a thundering herd problem - suddenly releasing a thousand threads to serve content might send the load sky high. Secondly - nobody likes to wait. To deal with this we can instruct Varnish to keep the objects in cache beyond their TTL and to serve the waiting requests somewhat stale content.# if (!std.healthy(req.backend_hint) &amp;&amp; (obj.ttl + obj.grace &gt; 0s)) &#123;# return (deliver);# &#125; else &#123;# return (miss);# &#125; # We have no fresh fish. Lets look at the stale ones. if (std.healthy(req.backend_hint)) &#123; # Backend is healthy. Limit age to 10s. if (obj.ttl + 10s &gt; 0s) &#123; #set req.http.grace = "normal(limited)"; return (deliver); &#125; else &#123; # No candidate for grace. Fetch a fresh object. return (fetch); &#125; &#125; else &#123; # backend is sick - use full grace if (obj.ttl + obj.grace &gt; 0s) &#123; #set req.http.grace = "full"; return (deliver); &#125; else &#123; # no graced object. return (fetch); &#125; &#125; # fetch &amp; deliver once we get the result return (fetch); # Dead code, keep as a safeguard&#125;sub vcl_miss &#123; # Called after a cache lookup if the requested document was not found in the cache. Its purpose # is to decide whether or not to attempt to retrieve the document from the backend, and which # backend to use. return (fetch);&#125;sub vcl_fini &#123; # Called when VCL is discarded only after all requests have exited the VCL. # Typically used to clean up VMODs. return (ok);&#125;]]></content>
      <categories>
        <category>缓存服务</category>
      </categories>
      <tags>
        <tag>varnish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础练习]]></title>
    <url>%2F2019%2F06%2F20%2Fpython%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[打印一个边长为n的正方形12345678910111213141516171819202122n = 5 # 设置打印边长的星号数print('*'*n) # 打印第一行for i in ('*'*(n-2)): # 设置循环为减去上下两条边的数量 print('*'+' '*(n-2)+'*') # 先打印前面一个星号，再打印减去了前后两个星号的空格，最后打印最后一个星号print('*'*n) # 打印最下面一行的*n = 6e = -n//2for i in range(e,n+e): if i == e or i == n+e-1: print('*'*n) # 上面判断的是要打印上下两条边 else: print('*' + ' '*(n-2) + '*') # 上面的代码等价于下面的代码n = 5for i in range(n): if i == 0 or i == n-1: print('*'*n) else: print('*'+' '*(n-2)+'*') 求100以内所有奇数的和1234sum = 0for i in range(1,100,2): sum += iprint(sum) 求1到5的阶乘之和12345678910111213141516171819# 方法1n = 5 # 控制阶乘的边界sum = 0for i in range(1,n+1): tmp = 1 # 第一次1的阶乘还是1 for j in range(1,i+1): tmp *= j # 第一次1的阶乘是1×1 sum += tmp # 第一次sum=0+1print(sum)# 1+1*2+1*2*3+1*2*3*4+1*2*3*4*5# 方法2nums = 1sum = 0for n in range(1,6): nums *= n# 这里是乘等，第一次是1×1,第二次是1×1×2,第三次是1×1×2×3，这样就实现了阶乘，再使用下面的方法将每次循环的结果加在一起就形成了阶乘之和。 sum += numsprint(sum) 给一个半径，求圆的面积和周长。圆周率3.14123r=int(input('r='))print('area='+str(3.14*r*r))print('circumference='+str(2*3.14*r)) 输入两个数，比较大小后，从小到大升序打印123456789a = input('first: ')b = input('second: ')if a &gt; b: print(b, a)else: print(a, b) # 三元表达式print(b,a) if a&gt;b else print(a,b) 获取最大值123456789101112# 请输入若干个整数，打印出最大值m = int(input('Input first number &gt;&gt;&gt;'))while True: c = input('Input a number &gt;&gt;&gt;') if c: n = int(c) if n &gt; m: m = n print('Max is', m) else: break# m是保存最大值的，c保存每次输入的数字并传给n，用n和m比较。这实际还是在做两个数的比较 输入n个数，求每次输入后的算数平均数12345678910n = 0 # 次数sum = 0 # 和while True: i = input('&gt;&gt;&gt;') if i == 'quit': break n += 1 sum += int(i) avg = sum/n print(avg) 打印九九乘法表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105for i in range(1,10): for j in range(1,10): print("%d*%d=%2d" % (i,j,i*j),end=" ") print("")1*1= 1 1*2= 2 1*3= 3 1*4= 4 1*5= 5 1*6= 6 1*7= 7 1*8= 8 1*9= 9 2*1= 2 2*2= 4 2*3= 6 2*4= 8 2*5=10 2*6=12 2*7=14 2*8=16 2*9=18 3*1= 3 3*2= 6 3*3= 9 3*4=12 3*5=15 3*6=18 3*7=21 3*8=24 3*9=27 4*1= 4 4*2= 8 4*3=12 4*4=16 4*5=20 4*6=24 4*7=28 4*8=32 4*9=36 5*1= 5 5*2=10 5*3=15 5*4=20 5*5=25 5*6=30 5*7=35 5*8=40 5*9=45 6*1= 6 6*2=12 6*3=18 6*4=24 6*5=30 6*6=36 6*7=42 6*8=48 6*9=54 7*1= 7 7*2=14 7*3=21 7*4=28 7*5=35 7*6=42 7*7=49 7*8=56 7*9=63 8*1= 8 8*2=16 8*3=24 8*4=32 8*5=40 8*6=48 8*7=56 8*8=64 8*9=72 9*1= 9 9*2=18 9*3=27 9*4=36 9*5=45 9*6=54 9*7=63 9*8=72 9*9=81 # 这种方法没有考虑到边界的问题方法一：for i in range(1,10): for j in range(1,10): if j &lt;= i: print(j,"*",i,"=",i*j,end=" ") print(" ") # 循环完一小轮之后要打印一个空行1 * 1 = 1 1 * 2 = 2 2 * 2 = 4 1 * 3 = 3 2 * 3 = 6 3 * 3 = 9 1 * 4 = 4 2 * 4 = 8 3 * 4 = 12 4 * 4 = 16 1 * 5 = 5 2 * 5 = 10 3 * 5 = 15 4 * 5 = 20 5 * 5 = 25 1 * 6 = 6 2 * 6 = 12 3 * 6 = 18 4 * 6 = 24 5 * 6 = 30 6 * 6 = 36 1 * 7 = 7 2 * 7 = 14 3 * 7 = 21 4 * 7 = 28 5 * 7 = 35 6 * 7 = 42 7 * 7 = 49 1 * 8 = 8 2 * 8 = 16 3 * 8 = 24 4 * 8 = 32 5 * 8 = 40 6 * 8 = 48 7 * 8 = 56 8 * 8 = 64 1 * 9 = 9 2 * 9 = 18 3 * 9 = 27 4 * 9 = 36 5 * 9 = 45 6 * 9 = 54 7 * 9 = 63 8 * 9 = 72 9 * 9 = 81方法二：for i in range(1,10): for j in range(i,10): print('&#123;&#125;x&#123;&#125;=&#123;&#125;\t'.format(i, j, i*j), end=' ')# print(str(i)+'*'+str(j)+'='+str(i*j),end=' ')# print(i,'*',j,'=',i*j,end=' ')# 上面这样打印也可以，只是很难看 print("") # 最后一行打印的是一个换行符1 * 1 = 1 1 * 2 = 2 1 * 3 = 3 1 * 4 = 4 1 * 5 = 5 1 * 6 = 6 1 * 7 = 7 1 * 8 = 8 1 * 9 = 9 2 * 2 = 4 2 * 3 = 6 2 * 4 = 8 2 * 5 = 10 2 * 6 = 12 2 * 7 = 14 2 * 8 = 16 2 * 9 = 18 3 * 3 = 9 3 * 4 = 12 3 * 5 = 15 3 * 6 = 18 3 * 7 = 21 3 * 8 = 24 3 * 9 = 27 4 * 4 = 16 4 * 5 = 20 4 * 6 = 24 4 * 7 = 28 4 * 8 = 32 4 * 9 = 36 5 * 5 = 25 5 * 6 = 30 5 * 7 = 35 5 * 8 = 40 5 * 9 = 45 6 * 6 = 36 6 * 7 = 42 6 * 8 = 48 6 * 9 = 54 7 * 7 = 49 7 * 8 = 56 7 * 9 = 63 8 * 8 = 64 8 * 9 = 72 9 * 9 = 81 方法三：for i in range(1,10): for k in range(1,i): print(end="\t ") # 这行就是为了打印前面的空行的，这里需要一个Tab键加一个空格键才能让输出对齐 for j in range(i,10): print('&#123;&#125;x&#123;&#125;=&#123;&#125;\t'.format(i, j, i*j), end=' ') print("")1x1=1 1x2=2 1x3=3 1x4=4 1x5=5 1x6=6 1x7=7 1x8=8 1x9=9 2x2=4 2x3=6 2x4=8 2x5=10 2x6=12 2x7=14 2x8=16 2x9=18 3x3=9 3x4=12 3x5=15 3x6=18 3x7=21 3x8=24 3x9=27 4x4=16 4x5=20 4x6=24 4x7=28 4x8=32 4x9=36 5x5=25 5x6=30 5x7=35 5x8=40 5x9=45 6x6=36 6x7=42 6x8=48 6x9=54 7x7=49 7x8=56 7x9=63 8x8=64 8x9=72 9x9=81 # 实际输出要更整齐一些方法四：for i in range(1,10): for k in range(1,10-i): print(end="\t ") # 打印每一行前面的Tab键，第一行就要打印9个 for j in range(1,i+1): print("&#123;&#125;*&#123;&#125;=&#123;&#125;".format(i,j,i*j), end="\t ") # \t放在end=""中好像更容易理解 print("") 1*1=1 2*1=2 2*2=4 3*1=3 3*2=6 3*3=9 4*1=4 4*2=8 4*3=12 4*4=16 5*1=5 5*2=10 5*3=15 5*4=20 5*5=25 6*1=6 6*2=12 6*3=18 6*4=24 6*5=30 6*6=36 7*1=7 7*2=14 7*3=21 7*4=28 7*5=35 7*6=42 7*7=49 8*1=8 8*2=16 8*3=24 8*4=32 8*5=40 8*6=48 8*7=56 8*8=64 9*1=9 9*2=18 9*3=27 9*4=36 9*5=45 9*6=54 9*7=63 9*8=72 9*9=81方法五：for i in range(1,10): for j in range(1,i+1): print('&#123;&#125;*&#123;&#125;=&#123;&#125;'.format(i,j,i*j), end="") # 这种把算式打印在前面，之后再加分隔符的方法中，分隔符使用什么都可以，可以是空格或Tab键或什么也不加 print()1*1=1 2*1=2 2*2=4 3*1=3 3*2=6 3*3=9 4*1=4 4*2=8 4*3=12 4*4=16 5*1=5 5*2=10 5*3=15 5*4=20 5*5=25 6*1=6 6*2=12 6*3=18 6*4=24 6*5=30 6*6=36 7*1=7 7*2=14 7*3=21 7*4=28 7*5=35 7*6=42 7*7=49 8*1=8 8*2=16 8*3=24 8*4=32 8*5=40 8*6=48 8*7=56 8*8=64 9*1=9 9*2=18 9*3=27 9*4=36 9*5=45 9*6=54 9*7=63 9*8=72 9*9=81 打印100以内的斐波那契数列及打印第101项12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 费波那契数列由0和1开始，之后的费波那契系数就是由之前的两数相加而得出。首几个费波那契系数是：# 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233……（OEIS中的数列A000045）# 特别指出：0不是第一项，而是第零项。# 打印100以内的斐波那契数a=0b=1print(a)print(b)for i in range(1,100): c = a + b if c &gt; 100: break print(c) a=b b=c# 如果小于100就打印，大于100就停止。# 打印101项斐波那契数a = 0b = 1# 手动打印前两项print('&#123;&#125;,&#123;&#125;'.format(0, a))print('&#123;&#125;,&#123;&#125;'.format(1, b))index = 1while True: c = a + b a = b b = c index += 1 print('&#123;&#125;,&#123;&#125;'.format(index, c)) # 这里的index就是显示中前面的序号 if index == 101: break # 只打印第101项a=0b=1#print(a)#print(b)for i in range(1,101): c = a + b a=b b=c if i &lt; 100: continue print(c) # 打印一定要放在最后，因为如果放在c = a + b下方，那么就无法将if判断加入进去了 a = 0b = 1# print('&#123;&#125;,&#123;&#125;'.format(0,a))# print('&#123;&#125;,&#123;&#125;'.format(1,b))index = 1while True: c = a + b a,b = b,c index += 1 if index == 101: print('&#123;&#125;,&#123;&#125;'.format(index,c)) break 求素数1234567891011121314151617181920212223方法1# 最简单的思路，按照定义来，假设有一个数n(n&gt;1)，从2开始判断，一直判断到n-1n = 12577 # 避开3、5、10、2的倍数flag = Falsefor i in range(2,n): if n % i == 0: # 找到条件是什么 flag = True print(i) # 这里打印的是可以整除的数字 breakif flag: print(n, 'is not a prime number. ')else: print(n, 'is a prime number. ') 方法2n = 1577 # 避开3、5、10、2的倍数# 对这个数从2开始测试到n-1for i in range(2,n): if n % i == 0: # 找到条件是什么 print(n, 'is not a prime number. ') breakelse: print(n, 'is a prime number') 求10万内的所有素数123456789101112131415161718192021222324252627282930313233343536373839404142434445# 质数（Prime number），又称素数，指在大于1的自然数中，除了1和该数自身外，无法被其他自然数整除的数（也可定义为只有1与该数本身两个正因数的数）。# 大于1的自然数若不是素数，则称之为合数（也称为合成数）。# 算术基本定理确立了素数于数论里的核心地位：任何大于1的整数均可被表示成一串唯一素数之乘积。# 为了确保该定理的唯一性，1被定义为不是素数，因为在因式分解中可以有任意多个1（如3、1×3、1×1×3等都是3的有效约数分解）。import timet = [2] # 素数是从2开始的t0 = time.time()count = 1# 去掉所有偶数，从3开始迭代，步进为2for x in range(3,100001,2): if x &gt; 5 and x % 10 == 5:# 所有大于10的质数中，个位数只有1、3、7、9，大于5且以5结尾的整数都能被5整除，这里首先过滤掉大于5且以5结尾的整数 continue for i in range(3, int(x ** 0.5) + 1, 2): # 这里的int最后加1,是因为前包后不包，所以要加1. 这一步就是为了测试当前的数字是否可以被i这个数字整除。# 比如这时x是49,那么就要测试49是否可以被从3开始，到49开平方后加1的数字，并且去除了偶数，也就是剩下的这些数字整除，如果不能就是素数。# 这一步是想表达，如果一个整数可以被其平方根因子前面的数整除就一定可以被平方根因子后面的数整除，所以只算平方根因子前面的数就可以了。# 一个整数的前后对应的两个因子的乘积等于这个整数，所以一个整数如果平方根之前有一个因子，那平方根之后肯定有一个对应的因子，中间是平方根# 上面所说的“一个整数的前后对应的两个因子的乘积等于这个整数”，是想表示如2*50=100，100就是那个整个，2就是前面的因子，50是后面的因子# 平方根就在这两个因子之间。 if x % i == 0: break else: count += 1 t.append(x)# 这个else是for语句的，当x可以整除i时，就跳出循环，否则就在count中加一个计数，并将x回到t列表中print(t)print('花费时间: &#123;&#125;'.format(time.time() - t0))print('质数个数: &#123;&#125;'.format(count))print('质数个数: &#123;&#125;'.format(len(t)))# 讲解:for i in range(2, 100): if not 100 % i: # 如果100与i取余不为1,那么就打印 print(i) # 100 = 2 x 50# 100 = 4 x 25# 100 = 5 x 20# 100 = 10 x 10# 这样很容易看出，在平方根10之前，如果100有一个因子，那么平方根后面一定有一个对应的因子，而平方根`10x10`是临界点。# 所以被除数可以从平方根处砍掉后面的部分。# 上面的意思是想说明，2*50=100和50*2=100是一个意思，所以在平方根上面的因子计算完就可以了，可以忽略掉平方根下面的因子# 由于相差一个指数，一个整数的平方根通常都比自身小很多，数值越大，相差越大。# 比如100比10大90，10000比100大9900，这样看就发现数据量减少了不止一星半点。 打印菱形12345678910111213141516171819202122232425# 思路：# 行号 个数 前空格 总空格数# 1 1 3 6# 2 3 2 4# 3 5 1 2# 4 7 0 0# 5 5 1 2# 6 3 2 4# 7 1 3 6# 这是中心对称的# 我们关注的是一行如果打满星号总共的数量与前空格一列，每行菱形前面的空格从3-0,再从0-3for i in range(-3,4): if i &lt; 0: prespace = -i # 这里是将数字变为正数 else: prespace = i print(' '*prespace+'*'*(7-prespace*2)) # 这是发现的公式。' '*prespace是要打印的空格数，'*'*(7-prespace*2))是要打印几个星号。 # 三目运算符方法for i in range(-3,4): prespace=-i if i &lt; 0 else i # 这里不能写成prespace=-i if (i &lt; 0) else prespace=i，这样会报语法错误。 print(' '*prespace+'*'*(7-prespace*2)) 打印对顶三角形123456789101112131415# 思路：# 行号 对称序列 星号数 总空格数 前置空格数 后置空格数# 1 3 7 0 0 0 # 2 2 5 2 1 1# 3 1 3 4 2 2# 4 0 1 6 3 3# 5 1 3 4 2 2# 6 2 5 2 1 1# 7 3 7 0 0 0# 可以看出，只与前置空格、起点、终点有关n = 7e = n//2 # 因为是对称问题所以除2？for i in range(-e, n-e): prespace = -i if i&lt;0 else i # 这一步是将数字都变为正数 print(' '*(e-prespace) + '*'*(2*prespace+1)) 打印闪电12345678910111213141516171819202122232425# 思路：# 行号 个数 前空格 后空格数 总空格数 数据# 1 1 3 3 6 -3# 2 2 2 3 5 -2# 3 3 1 3 4 -1# 4 7 0 0 0 0# 5 3 3 1 4 1# 6 2 3 2 5 2# 7 1 3 3 6 3# 看一下上面数据一列方法1for i in range(-3,4): if i &lt; 0: print(' '*(-i)+'*'*(4+i)) elif i &gt; 0: print(' '*3+'*'*(4-i)) else: print('*'*7)方法2j = '*'for i in range(-3,4): if i == 0: print(j*7) print(" "*(-i) + j*(i+4)) if i&lt;0 else print(3*" " + j*(3-i)) 解决猴子吃桃问题123456789# 猴子第一天摘下若干个桃子，当即吃了一半，还不过瘾，又多吃了一个。第二天早上又将剩下的桃子吃掉一半，又多吃了一个。以后每天早上都吃了前一天剩下的一半零一个。到了第10天早上想吃时，只剩下一个桃子了。求第一天共摘了多少个桃子。# 猴子应该第九天吃完时就已经知道只剩下一个桃子了。n=1 # 这是最后剩下的桃子的数目for _ in range(1,10): # 如果是一个不关心或没用的变量可以使用下划线代替，这个变量在这里只是为了迭代使用的。 n=(n+1)*2 print(n)# 从题目中得出公式：x/2-1=n，x是桃子的总数，n是剩下桃子的数目，反过来就得到(n+1)*2就是总的桃子的数目。将这个公式迭代9次就是总的数目。# 所以用range(1,10) 杨辉三角123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228----------- 方法一-----------triangle=[[1],[1,1]]for i in range(2,6): # 从2开始是因为前两个列表已经有了，所以从2开始 cur = [1] # 这是每个元素的第一个1 pre = triangle[i-1] # 这里定义的pre是要计算的列表元素的上一个元素，也就是triangle列表中的哪个小的列表。如第一次要计算的就是# 第三个元素，所以pre就是第二个。说明pre等于triangle列表中的第几个列表，如i等于1，那么，pre就等于# triangle[0]，因为这是triangle中的第一个列表。当第一次i等于2时这里是[1,1] for j in range(len(pre)-1): # len(pre)是计算pre这个列表中有几个元素。这个循环就是在凑前后两个1中间的部分。第一次循环时，len(pre)的# 结果是2，减去1后j等于0。这里这样做是因为在杨辉三角中每行的行号与这一行中元素的个数是一样的。如第三行# 的列表中就有三个元素，这里减1是因为上面的cur已经定义了每个元素的第一个1，最后的1还没追加，所以减去1# 就是两个1中间的元素的个数了 cur.append(pre[j]+pre[j+1]) # pre[j]+pre[j+1]第一次计算的结果是2，也就是pre[0]+pre[0+1]，这时的pre等于[1,1]，所以pre的第0个# 和第1个元素都是1，所以相加得2。之后将pre[2]追加到了cur中，cur这时是[1]，所以结果就是[1,2]。再加上# 下面追加的1，就成了第三个元素[1,2,1] cur.append(1) # 这是向cur的一个列表中插入1，如原来是[1]，插入后就是[1,1]，这插入的应该是每个元素最后一个1。上面的循环# 结束到这一步，也就意味着一个元素计算完毕，下面追加到triangle列表中，之后就可以进入下个循环了。 triangle.append(cur) # 这里再将cur追加到现在的triangle中，就有了[[1], [1, 1], [1, 2, 1]]print(triangle)# 输出结果：[[1], [1, 1], [1, 2, 1], [1, 3, 3, 1], [1, 4, 6, 4, 1], [1, 5, 10, 10, 5, 1]]# 方法一变体triangle=[]n = 4for i in range(n): row = [1]# 这是每一个元素的第一个1 triangle.append(row)# 追加row到triangle列表中 if i == 0: continue for j in range(i-1): # 当i是2的时候会进入这个循环，计算两个1中间的部分，这里j是0 row.append(triangle[i-1][j]+triangle[i-1][j+1])# triangle[i-1][j]中的[i-1]表示triangle中的第几个小列表，之后的[j]表示列表中的第几个元素。如果# i是2的话，那么triangle[i-1]就是triangle中的第1个小列表，也就是[1,1]，这时j等于0,# triangle[i-1][j]的结果就是1，triangle[i-1][j+1]的结果也是1，但它们表示[1,1]中前后两个不同的1，# 再将它们相加就是2，这就算出了两个1中间的部分。当i等于3时，这里会循环两次，所以能算出两个3 row.append(1)# 这是每个元素的最后一个1print(triangle)# 输出结果：[[1], [1, 1], [1, 2, 1], [1, 3, 3, 1]]======================================================================================triangle = []row = [1]triangle.append(row)row.append(1)row.append(999)print(triangle)# 发现这样的问题，虽然按顺序执行会先将row插入到triangle中，但之后再向row中插入一个1和999，这时triangle# 不会是[[1]]，而是[[1,1,999]]。可以向列表中的元素列表中直接添加子元素======================================================================================------------------- 方法二-while-------------------n = 6oldline = [] # oldline就是为了凑每行的[1]和1之后的部分newline = [1]# length = 0print(newline) # 先打印出第一行的[1]for i in range(1,n): # 这里会循环1-5 oldline = newline.copy()# 这是浅拷贝。先把每行的第一个1凑出来。第二次循环时，这里的oldline就会复制成了[1,1]，因为newline变了 oldline.append(0)# 尾部加0，这时的oldline是[1,0]，向oldline中追加0是为了下面计算各元素的值 newline.clear() # 清空newline，这时的newline是[] offset = 0 while offset &lt;= i: # 满足条件进入循环，这里计算的是从第二行开始的数据 newline.append(oldline[offset - 1] + oldline[offset])# 这里开始凑每行中的所有内容，第一次i是1，offset是0，oldline[0-1] + oldline[0]，这时oldline[-1]# 是0，oldline[0]是1，这两个数相加也就是[1]，把[1]追加到newline中，下面offset自增加1，因为offset# 和i都是1，所以还会进一次循环，newline现在是[1]，oldline[1-1] + oldline[1]，这时oldline[0]是1，oldline[1]是0，这两个数相加也是[1]，追加到newline这个列表中，这时newline是[1,1]。之后offset# 再增加1，这时offset大于i，退出循环。最后就打印出了第二行的[1,1] offset += 1 print(newline) ---------------- 方法二-for----------------n = 6oldline = []newline = [1]# length = 0print(newline)for i in range(1,n): oldline = newline.copy()# 这是浅拷贝 oldline.append(0)# 尾部加0,相当于两端加0 newline.clear() offset = 0 for j in range(i+1): newline.append(oldline[j-1]+oldline[j]) print(newline)# 这个方法与上面的while方面的思路是一样的。======================================================================================# 如何比较两段代码的效率？效率一是看时间，一是看进入循环的次数# 算10以内的质数-1import datetime # 要装载这个模块n = 100000pn = []count = 0 # 这是为了计数。用count计算进入循环的次数start = datetime.datetime.now() # 设置一个开始时间for x in range(2,n): for i in pn: # 通过这样的方式，向pn列表中添加元素。第一次pn是空，2会被添加到pn中。之后随着pn的增长，x会与pn中所# 有的数字进行取余，如果结果是0就跳出与pn列表中数字取余的循环。否则，这个与pn列表中数字取余的数字x# 就是质数 count += 1 if x % i == 0: break else: pn.append(x)#print(pn)delta = (datetime.datetime.now() - start).total_seconds()# 用现在的时间减去开始时间，.total_seconds计算全部时间差。print(len(pn))print(count)print(delta)# 算质数-2import datetimeimport mathn = 100000pn = []flag = Falsecount = 0start = datetime.datetime.now()for x in range(2,n): for i in pn: count += 1 if x % i == 0: # 这是如果进来了，就不是质数。实际与2、3、5等取余为0的都会在这个条件下被屏蔽掉。 flag = True break if i &gt;= math.ceil(x**0.5): # 这里如果进来了，就是质数。ceil() 函数返回数字的上入整数。x**0.5就是对x开方。到这里的都是筛选过一# 次的数字了 flag = False break# 先用x与i取余，如果是0,就表示不是质数。如果结果都不为0,再用 if not flag: pn.append(x)# print(pn)delta = (datetime.datetime.now() - start).total_seconds()print(len(pn)) # 计算打印的个数print(count)print(delta)======================================================================================------------ 方法三------------# 尾部追加效率最高# 能不能一次性开辟空间。所谓一次性开辟，就是将一列先算出来，不断向后追加，直到追加完最后一个1。中间部分先用数字填充，下面两例使用0或1来填充。如[1,0,1] [1,1,1,1]# 列表解析式# 循环迭代# 能不能少算一半的数字# 思路：先开辟新列表，把列表中元素的个数先定下来，之后再改。下面计算包括中间点向左部分的数字，# 也就是range(1,i//2+1)，之后每计算出中间点向左部分的数字时，都会用if判断语句在反方向相对应的位置加入# 相同的一个数字。最后修改的是中间部分的数字。triangle = []n = 6for i in range(n): # 这里的循环从0-5 row = [1] # 开始的1 for k in range(i): # 当i是0的时候，不会执行for k in循环下面的语句，因为k是空。 row.append(1) if k == i-1 else row.append(0)# 如果k等于i-1，那么就向row后追加1，否则就追加0。上面这条语句是在中间填0，尾部填1 triangle.append(row) # 第一次因为i是0，所以直接到这里，将row插入到triangle列表中，之后到下面的语句，当i为0时跳出此轮循环，# 返回到循环的首部。第二次因为i是1，所以执行上面循环的语句，向row中插入1，row变成了[1,1] if i == 0: continue for j in range(1,i//2+1): # 当i是1时，这里是for j in range(1,1)，因为是range(1,1)所以不会向下执行。i=2时，也就是计算到第三行# 才能进来。这是少算一半数字吗？只算中点以前的数字，然后根据结果追加数字，在中间点的数字前或后，所以这里# 要除2再加1，因为是前包后不包，所以要加1# 当i是4时，这里循环两次，j是1时，triangle[3][0] + triangle[3][1]，就是[1,3,3,1]，可以算出左半边# 的4，下面把row[1]=4，这时row是[1,4,1,1,1]，再向下执行到if语句时，会在反方向对应的位置加入相同的数# 字，也就成了[1,4,1,4,1]，j是2时，triangle[3][1]+triangle[3][2]，就是[1,3,3,1]中的3加3，也就# 是中间的数字6被计算出来了。 val = triangle[i-1][j-1] + triangle[i-1][j] row[j] = val if i != 2*j: # 条件满足，修改中点以后数据的值，从后向前数，偶数行都会满足这里的条件，或者说，每行中前后两个数字能有对# 称的，都会满足这里的条件，只有计算到奇数的中间点数字时，不能满足这里的条件 row[-j-1] = valprint(triangle)# 这个方法就是先将一列计算出来，中间部分先用数字填充，最后再一个一个修改中间的数字。# 方法三变体triangle = []n = 6for i in range(n): row = [1] * (i+1) # 一次性开辟 triangle.append(row) for j in range(1,i//2+1): # i=2第三行才能进来 val = triangle[i-1][j-1] + triangle[i-1][j] row[j] = val if i != 2*j: # 奇数个数的中间点数字跳过，也就是只有计算偶数行时才会进入这里，因为计算奇数行时，i一定是一个偶数 row[-j-1] = valprint(triangle)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[varnish概念]]></title>
    <url>%2F2019%2F06%2F19%2Fvarnish%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概念 varnish的基本介绍 ​ Varnish与一般服务器软件类似，就是一个web缓存代理服务器，分为master(management)进程和child(worker，主要做cache的工作)进程。master进程读入命令，进行一些初始化，然后fork(分流)并监控child进程。child进程分配若干线程进行工作，主要包括一些管理线程和很多woker线程。 ​ Management进程主要实现应用新的配置、编译VCL、监控varnish、初始化varnish以及提供一个命令行接口等。 Management进程会每隔几秒钟探测一下Child进程以判断其是否正常运行，如果在指定的时长内未得到Child进程的回应，Management将会重启此Child进程。 Child进程包含多种类型的线程，常见的如： ​ Acceptor线程：接收新的连接请求并响应； ​ Worker线程：child进程会为每个会话启动一个worker线程，因此，在高并发的场景中可能会出现数百个worker线程甚至更多； ​ Expiry线程：从缓存中清理过期内容； ​ Varnish依赖“工作区(workspace)”以降低线程在申请或修改内存时出现竞争的可能性。在varnish内部有多种不同的工作区，其中最关键的当属用于管理会话数据的session工作区。 varnish与squid的区别 ​ varnish和squid在中小规模的应用上，varnish足够轻量级，足够好用，但是在巨大的并发请求来说，单个varnish所能够承载的并发 访问量大概在5000个连接请求左右，超出5000个可能就得不稳定了；而在这里squid就能表现出良好的性能了，因此在大规模的企业级应用中仍然是以squid居多，而在中小规模的自己公司的反向代理缓存中varnish居多； Varnish的优势 Varnish的稳定性很高，两者在完成相同负荷的工作时，Squid服务器发生故障的几率要高于Varnish，因为使用Squid要经常重启； Varnish访问速度更快，因为采用了“Visual Page Cache”技术，所有缓存数据都直接从内存读取，而squid是从硬盘读取，因而Varnish在访问速度方面会更快； Varnish可以支持更多的并发连接，因为Varnish的TCP连接释放要比Squid快，因而在高并发连接情况下可以支持更多TCP连接； Varnish可以通过管理端口，使用正则表达式批量的清除部分缓存，而Squid是做不到的； squid属于是单进程使用单核CPU，但Varnish是通过fork形式打开多进程来做处理，所以可以合理的使用所有核来处理相应的请求； Varnish的劣势 varnish进程一旦Hang、Crash或者重启，缓存数据都会从内存中完全释放，此时所有请求都会发送到后端服务器，在高并发情况下，会给后端服务器造成很大压力； 在varnish使用中如果单个url的请求通过HA/F5等负载均衡，则每次请求落在不同的varnish服务器中，造成请求都会被穿透到后端；而且同样的请求在多台服务器上缓存，也会造成varnish的缓存的资源浪费，造成性能下降； Varnish劣势的解决方案 针 对劣势一：在访问量很大的情况下推荐使用varnish的内存缓存方式启动，而且后面需要跟多台squid服务器。主要为了防止前面的varnish服 务、服务器被重启的情况下，大量请求穿透varnish，这样squid可以就担当第二层CACHE，而且也弥补了varnish缓存在内存中重启都会释 放的问题； 针对劣势二：可以在负载均衡上做url哈希，让单个url请求固定请求到一台varnish服务器上; varnish的日志说明 ​ 为了与系统的其它部分进行交互，Child进程使用了可以通过文件系统接口进行访问的共享内存日志(shared memory log)，因此，如果某线程需要记录信息，其仅需要持有一个锁，而后向共享内存中的某内存区域写入数据，再释放持有的锁即可。而为了减少竞争，每个 worker线程都使用了日志数据缓存。 ​ 共享内存日志大小一般为90M，其分为两部分，前一部分为计数器，后半部分为客户端请求的数据。varnish提供了多个不同的工具如 varnishlog、varnishncsa或varnishstat等来分析共享内存日志中的信息并能够以指定的方式进行显示。 VCL基本介绍 ​ Varnish Configuration Language (VCL)是varnish配置缓存策略的工具，它是一种基于“域”(domain specific)的简单编程语言，它支持有限的算术运算和逻辑运算操作、允许使用正则表达式进行字符串匹配、允许用户使用set自定义变量、支持if判断语句，也有内置的函数和变量等。使用VCL编写的缓存策略通常保存至.vcl文件中，其需要编译成二进制的格式后才能由varnish调用。事实上，整个缓存策略就是由几个特定的子例程如vcl_recv、vcl_fetch等组成，它们分别在不同的位置(或时间)执行，如果没有事先为某个位置自定义子例程，varnish将会执行默认的定义。 ​ VCL策略在启用前，会由management进程将其转换为C代码，而后再由gcc编译器将C代码编译成二进制程序。编译完成后，management负责将其连接至varnish实例，即child进程。正是由于编译工作在child进程之外完成，它避免了装载错误格式VCL 的风险。因此，varnish修改配置的开销非常小，其可以同时保有几份尚在引用的旧版本配置，也能够让新的配置即刻生效。编译后的旧版本配置通常在 varnish重启时才会被丢弃，如果需要手动清理，则可以使用varnishadm的vcl.discard命令完成。 varnish的后端存储 ​ varnish的缓存对象在每次服务重启时都会被清空并重新建立，所以这些服务器都是不应该随便去重启的，varnish为了把数据更持久化的存储，引入了更多的存储机制，所以varnish支持多种不同的后端存储； ​ varnish支持多种不同类型的后端存储，这可以在varnishd启动时使用-s选项指定。后端存储的类型包括： file：使用特定的文件存储全部的缓存数据，并通过操作系统的mmap()系统调用将整个缓存文件映射至内存区域(如果条件允许)； malloc：使用malloc()库调用在varnish启动时向操作系统申请指定大小的内存空间以存储缓存对象； persistent(experimental)：与file的功能相同，但可以持久存储数据(即重启varnish数据时不会被清除)；仍处于测试期； ​ varnish无法追踪某缓存对象是否存入了缓存文件，从而也就无从得知磁盘上的缓存文件是否可用，因此，file存储方法在varnish停止或重启时会清除数据。而persistent方法的出现对此有了一个弥补，但persistent仍处于测试阶段，例如目前尚无法有效处理要缓存对象总体大小超出缓存空间的情况，所以，其仅适用于有着巨大缓存空间的场景。 ​ 选择使用合适的存储方式有助于提升系统性，从经验的角度来看，建议在内存空间足以存储所有的缓存对象时使用malloc的方法，反之，file存储将有着更好的性能的表现。然而，需要注意的是，varnishd实际上使用的空间比使用-s选项指定的缓存空间更大，一般说来，其需要为每个缓存对象多使用差不多1K左右的存储空间，这意味着，对于100万个缓存对象的场景来说，其使用的缓存空间将超出指定大小1G左右。另外，为了保存数据结构等，varnish自身也会占去不小的内存空间。 涉及VCL语法的改变点 vcl配置文件需明确指定版本：即在vcl文件的第一行写上 vcl 4.0; vcl_fetch函数被vcl_backend_response代替，且req.*不再适用vcl_backend_response； 后端源服务器组director成为varnish模块，需import directors后再在vcl_init子例程中定义； 自定义的子例程(即一个sub)不能以vcl_开头，调用使用call sub_name； error()函数被synth()替代； return(lookup)被return(hash)替代； 使用beresp.uncacheable创建hit_for_pss对象； 变量req.backend.healty被std.healthy(req.backend)替代； 变量req.backend被req.backend_hint替代； 关键字remove被unset替代； 详见：https://www.varnish-cache.org/docs/4.0/whats-new/index.html#whats-new-index 架构及文件缓存的工作流程 Varnish 分为 master 进程和 child 进程； Master 进程读入存储配置文件，调用合适的存储类型，然后创建 / 读入相应大小的缓存文件，接着 master 初始化管理该存储空间的结构体，然后 fork 并监控 child 进程； Child 进程在主线程的初始化的过程中，将前面打开的存储文件整个 mmap 到内存中，此时创建并初始化空闲结构体，挂到存储管理结构体，以待分配； 对外管理接口分为3种，分别是命令行接口、Telnet接口和Web接口； 同时在运行过程中修改的配置，可以由VCL编译器编译成C语言，并组织成共享对象(Shared Object)交由Child进程加载使用； Child 进程分配若干线程进行工作，主要包括一些管理线程和很多 worker 线程，可分为： Accept线程：接受请求，将请求挂在overflow队列上； Work线程：有多个，负责从overflow队列上摘除请求，对请求进行处理，直到完成，然后处理下一个请求； Epoll线程：一个请求处理称为一个session，在session周期内，处理完请求后，会交给Epoll处理，监听是否还有事件发生； Expire线程：对于缓存的object，根据过期时间，组织成二叉堆，该线程周期检查该堆的根，处理过期的文件，对过期的数据进行删除或重取操作； varnish的工作原理及工作流程 官方提供的工作流程图: vcl的工作方式是基于状态引擎(state engine)来实现的；上图说明： ​ vcl_recv的结果如果可以查询缓存并可以识别，那就要到vcl_hash这步了，如果无法识别那就通过pipe(管道)送给vcl_pipe，如果能识别，但不是一个可缓存的对象，那就通过pass送到vcl_pass去。vcl_hash之后就可查看缓存中有没有了，有这个请求的对象就表示命中 (vcl_hit)，如果没有那就表示未命中(vcl_miss)，如果命中的就可以直接通过deliver直接送给vcl_deliver响应了，如果未命中就通过fetch交给vcl_fatch去后端服务器上去取数据，取回数据之后如果数据可以缓存就缓存(cache)，本地缓存完之后再构建响应，如果不可以缓存就不做缓存交给vcl_deliver响应了；而如果命中了交给vcl_pass，交给pass之后就要到Fetch objet from backend后端服务器上去取数据了，这是因为这个命中的对象可能是过期或者是要做单独额外的处理的；这就是vcl的状态引擎过程。 Varnish 处理 HTTP 请求的过程如下 Receive 状态（vcl_recv）：也就是请求处理的入口状态，根据 VCL 规则判断该请求应该 pass（vcl_pass）或是 pipe（vcl_pipe），还是进入 lookup（本地查询）； Lookup 状态：进入该状态后，会在 hash 表中查找数据，若找到，则进入 hit（vcl_hit）状态，否则进入 miss（vcl_miss）状态； Pass（vcl_pass）状态：在此状态下，会直接进入后端请求，即进入 fetch（vcl_fetch）状态； Fetch（vcl_fetch）状态：在 fetch 状态下，对请求进行后端获取，发送请求，获得数据，并根据设置进行本地存储； Deliver（vcl_deliver）状态：将获取到的数据发给客户端，然后完成本次请求； 注：Varnish4中在vcl_fetch部分略有出入，已独立为vcl_backend_fetch和vcl_backend_response2个函数； 内置函数(也叫子例程) vcl_recv：用于接收和处理请求；当请求到达并成功接收后被调用，通过判断请求的数据来决定如何处理请求； vcl_pipe：此函数在进入pipe模式时被调用，用于将请求直接传递至后端主机，并将后端响应原样返回客户端； vcl_pass：此函数在进入pass模式时被调用，用于将请求直接传递至后端主机，但后端主机的响应并不缓存直接返回客户端； vcl_hit：在执行 lookup 指令后，在缓存中找到请求的内容后将自动调用该函数； vcl_miss：在执行 lookup 指令后，在缓存中没有找到请求的内容时自动调用该方法，此函数可用于判断是否需要从后端服务器获取内容； vcl_hash：在vcl_recv调用后为请求创建一个hash值时，调用此函数；此hash值将作为varnish中搜索缓存对象的key； vcl_purge：pruge操作执行后调用此函数，可用于构建一个响应； vcl_deliver：将在缓存中找到请求的内容发送给客户端前调用此方法； vcl_backend_fetch：向后端主机发送请求前，调用此函数，可修改发往后端的请求； vcl_backend_response：获得后端主机的响应后，可调用此函数； vcl_backend_error：当从后端主机获取源文件失败时，调用此函数； vcl_init：VCL加载时调用此函数，经常用于初始化varnish模块(VMODs) vcl_fini：当所有请求都离开当前VCL，且当前VCL被弃用时，调用此函数，经常用于清理varnish模块； VCL中内置公共变量 变量(也叫object)适用范围 变量类型详解 req：The request object，请求到达时可用的变量 bereq：The backend request object，向后端主机请求时可用的变量 beresp：The backend response object，从后端主机获取内容时可用的变量 resp：The HTTP response object，对客户端响应时可用的变量 obj：存储在内存中时对象属性相关的可用的变量 具体变量详见：https://www.varnish-cache.org/docs/4.0/reference/vcl.html#reference-vcl]]></content>
      <categories>
        <category>缓存服务</category>
      </categories>
      <tags>
        <tag>varnish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql问题解决]]></title>
    <url>%2F2019%2F06%2F11%2Fmysql%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[登录数据库后无法对数据库操作12345678910111213141516171819202122# 登录数据库后无法对数据库操作，使用任何命令都会提示“You must reset your password using ALTER USER statement before executing this statement.”# 有一说是因为密码过期，所以会这样。解决方法如下：vim /usr/lib/systemd/system/mysqld.service ExecStart=/usr/sbin/mysqld --daemonize --skip-grant-tables --skip-networking --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS# 加入--skip-grant-tables --skip-networking，可以免密码登录mysql# 登录use mysql；desc user；authentication_string | text | YES | | NULL | || password_expired | enum('N','Y') | NO | | N # 说是从上面两条信息可以看出password_expired过期。UPDATE user SET authentication_string=PASSWORD('DaaS_mysql_201!'),password_expired='N' WHERE User='root'; select authentication_string,password_expired from user where user='root';+-------------------------------------------+------------------+| authentication_string | password_expired |+-------------------------------------------+------------------+| *5ECB9CC025100F03131724B02A092F02D9417C96 | N |+-------------------------------------------+------------------+desc user;# 使用此命令又看了一次，与上面查询的没有区别。所以不知道如何证明是过期了？# 之后将上面的免密码登录恢复回去。再操作就正常了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决服务器千兆网卡显示只有百兆速度]]></title>
    <url>%2F2019%2F05%2F30%2F%E8%A7%A3%E5%86%B3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8D%83%E5%85%86%E7%BD%91%E5%8D%A1%E6%98%BE%E7%A4%BA%E5%8F%AA%E6%9C%89%E7%99%BE%E5%85%86%E9%80%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940ethtool eno1Settings for eno1: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supported pause frame use: Symmetric Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: Symmetric Advertised auto-negotiation: Yes Speed: 100Mb/s# 使用命令查看时，虽然显示是千兆网卡，但Speed只有100Mb/sethtool -s eno1 speed 1000# 使用上面命令可能将网卡重新设置为1000Mb/svim /etc/sysconfig/network-scripts/ifcfg-eno1ETHTOOL_OPTS="speed 1000 duplex full autoneg off"# 在网卡配置中加入上面一行，可以强制将网卡设置为千兆。==============================================================================================ethtool命令的简单使用ethtool ethX# 查看网卡信息ethtool –h # 显示ethtool的命令帮助(help)ethtool –i ethX # 查询ethX网口的相关信息ethtool –d ethX # 查询ethX网口注册性信息ethtool –r ethX # 重置ethX网口到自适应模式ethtool –S ethX # 查询ethX网口收发包统计ethtool –s ethX [speed 10|100|1000] [duplex half|full] [autoneg on|off] [port tp|aui|bnc|mii] # [speed 10|100|1000] 设置网口速率10/100/1000M# [duplex half|full] 设置网口半/全双工# [autoneg on|off] 设置网口是否自协商# [port tp|aui|bnc|mii] 设置网口类型]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tilix连接远程主机]]></title>
    <url>%2F2019%2F05%2F29%2FTilix%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[打开首选项–&gt;书签–&gt;添加书签 输入信息 连接测试 创建密码，在确定添加时可能会要求输入密码，不然无法添加 连接时，选择书签中创建的远程服务器成功后，可以再从助手中选择创建的密码，这样就可以连接上远程服务器了。如果之前就将本机的公钥发送到了远程的主机，就不需要再选择密码了，选择远程主机时就可以连接上了。 如果创建的远程连接信息有误，可以到Profiles -&gt; Edit Profile -&gt; Bookmarks中修改或删除 如果连接时需要密钥对，需要在输入完Name、Host、User后，在Parameters中输入-i “awsTest.pem”。这样就可以登录了。另外，如登录aws时，官方还会提供登录的方法。如登录时Redhat系统要使用ec2-user用户，ubuntu系统使用ubuntu，看一下官方的提示信息。进入系统后可以使用sudo passwd修改root密码。如果连接时的密钥没有了，可以在aws页面中的密钥对页面里重新创建。下图为官方提供的方法与tilix的配置方法]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用默认终端连接远程服务器(.ssh/config的作用)]]></title>
    <url>%2F2019%2F05%2F29%2F%E4%BD%BF%E7%94%A8%E9%BB%98%E8%AE%A4%E7%BB%88%E7%AB%AF%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8-ssh-config%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132如果使用系统上的默认终端连接多个远程终端？1. 创建公钥并传到远程服务器ssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub 10.129.14.42. 配置vim .ssh/config# 此文件开始是没有的，手动添加即可Host dl-gw-01 # 在ssh连接时要使用的远程主机名，这个名字是自定义的 HostName 10.129.14.4 # 远程主机地址 Port 22 # 远程主机ssh端口 User root # 远程主机的用户名3. 关闭服务器上的密码认证，开启公钥认证，在/etc/ssh/sshd_conf中修改下面即可PubkeyAuthentication yes # 开启公钥认证PasswordAuthentication no # 关闭密码认证4. .ssh/config的使用方法Host dl-gw-01 HostName 10.129.14.4 Host dl-gw-02 HostName 10.129.14.5 Host dl-gw-* User root # 这样使用的方式是一个通用配置，只要是dl-gw-开头的主机都使用root用户登录 Host * Port 22 # 这样使用通用配置也可以 5. 连接ssh dl-gw-01 参考：https://www.cnblogs.com/xjshi/p/9146296.html]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>ssh连接远程终端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络工具使用]]></title>
    <url>%2F2019%2F05%2F24%2F%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[针对协议抓包1234tcpdump -i ens1f0 icmp -vv -nn# 可以直接指定协议，但后面不能使用host参数。测试发现，如果不加-nn选项，tcpdump不会抓到任何包# -n是对地址以数字方式显式，否则显式为主机名，也就是说-n选项不做主机名解析。-nn除了-n的作用外，还把端口显示为数值，否则显示端口服务名。# -v是显示详细信息，加一个v就可以显示更详细的信息，最多是-vvv。 使用指定网卡ping1ping -I ens1f0 10.129.14.65 CentOS服务器多网卡配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950问题：在某服务器上安装CentOS7.3系统，配置两个网段的IP地址，一为10.129.14.16/27，一为10.129.14.40/27。客户端使用10.129.27/27，网关10.129.14.1。使用客户端ping服务器两地址时，只能ping能10.129.14.16/27，ping10.129.14.40/27时页面停住不动，查看服务器，应该是ping包可以到达服务器，但无法返回。解决：1. 配置服务器网卡vim /etc/sysconfig/network-scripts/ifcfg-enp96s0f0TYPE="Ethernet"BOOTPROTO=noneDEFROUTE="yes"NAME="enp96s0f0"UUID="5f90c86f-c21f-489e-ae8f-cf36e6eac588"DEVICE="enp96s0f0"ONBOOT="yes"DNS1="202.96.209.6"DNS2="202.96.209.133"IPADDR=10.129.14.16PREFIX=27#GATEWAY=10.129.14.1# 注释网卡配置中的GATEWAY一项，多块网卡都要注释2. 配置策略路由表vim /etc/iproute2/rt_tables 252 enp96s0f1-32251 enp96s0f0-0# 加入上面两行，前面的数字是路由表的编号，后面是自定义的表名。路由表的编号是自定义的，但linux最多可管理255个表，不要超过这个数字，另外，rt_table中原有的编号不要动，自定义的表编号也不要与原有的编号冲突。3. 配置策略路由# 将路由规则加入CentOS7中的/etc/rc.d/init.d/network中可以使重启网卡时路由依然生效，方法如下vim /etc/rc.d/init.d/networkip route flush table enp96s0f0-0# 先清空策略路由表ip route add default via 10.129.14.1 dev enp96s0f0 src 10.129.14.16 table enp96s0f0-0# 添加一条策略路由规则，下一跳到10.129.14.1，网卡是enp96s0f0，源地址为10.129.14.16，添加到策略路由表enp96s0f0-0ip rule add from 10.129.14.16 table enp96s0f0-0# 将从10.129.14.16经过的数据包都从enp96s0f0-0策略路由表中走ip route flush table enp96s0f1-32ip route add default via 10.129.14.33 dev enp96s0f1 src 10.129.14.40 table enp96s0f1-32ip rule add from 10.129.14.40 table enp96s0f1-32ip route add default via 10.129.14.1 dev enp96s0f0exit $rc# 这里要注意，一定要添加在最后一行的exit $rc之上。systemctl daemon-reloadsystemctl restart networkip route# 查看路由，加入的默认路由生效了ip rule# 查看生效的策略路由表# 最后，测试的机器上也要加一条到某网段的路由，如sudo ip route add 10.129.14.32/27 via 10.129.14.1。因为默认会从无线走如果不加这条路由规则，就要将无线断开或删除这条默认路由# 这时客户端就可以ping通服务器的两个ip地址了]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper问题解决]]></title>
    <url>%2F2019%2F05%2F24%2Fzookeeper%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[查看状态显示”not running”12345678910# 查看zookeeper集群状态显示有"not running"字样bin/zkServer.sh status# 查看状态tail -100 zookeeper.out# zookeeper的启动信息在此文件中，此文件在zkServer.sh中定义，内容大概为"_ZOO_DAEMON_OUT="$ZOO_LOG_DIR/zookeeper.out"# 启动失败时，在此文件中显示"Unexpected exception causing shutdown while sock still open"，解决办法一般有三，如下：# 1. 将zookeeper主机名更改为IP地址# 2. 以递减的id序列启动zookeeper实例。# 3. 将initSize从5增加到100# 此次大连广电的zookeeper集群不能启动的原因是没有把/xor/data0和data1里的zookeeper目录下的所有文件的属主和属组改为hadoop，因为启动zookeeper的是hadoop，不知道是哪设置的，在supervisord.conf中改user是没用的。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>zookeeper问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分区工具parted]]></title>
    <url>%2F2019%2F05%2F16%2F%E5%88%86%E5%8C%BA%E5%B7%A5%E5%85%B7parted%2F</url>
    <content type="text"><![CDATA[1234567891011partedselect /dev/sdb #切换磁盘mklable gpt # 切换为gpt模式mkpart primary 0 -1 # 创建磁盘，命名为primary，0 -1表示分配所有磁盘空间toggle 1 lvm # 将第1个分区改为lvmprint # 查看# 这里有一个问题，分配大于2TB空间的磁盘，在查看分区时会有一个Partition 1 does not start on physical sector boundary.的提示# 也可以使用gdisk工具分配大于2TB空间的磁盘，使用方法与fdisk类似。unit TB # 设置单位为TBmkpart primary 0 3 # 设置为一个主分区,大小为3TB，开始是0，结束是3]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分区工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7系统升级]]></title>
    <url>%2F2019%2F05%2F16%2FCentOS7%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617vim /etc/yum.repos.d/CentOS-local.repo[base]name=CentOS-$releasever - Basebaseurl=https://mirrors.aliyun.com/centos/7.6.18.10/os/$basearch/gpgcheck=0enabled=1[updates]name=CentOS-$releasever - Updatesbaseurl=https://mirrors.aliyun.com/centos/7.6.18.10/updates/$basearch/gpgcheck=0enabled=1yum clean allyum repolistyum -y updatereboot]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>系统升级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samba使用]]></title>
    <url>%2F2019%2F05%2F16%2Fsamba%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[samba配置不使用用户名密码登录1234567891011121314151617vim /etc/samba/smb.conf[global] workgroup = SAMBA security = user map to guest = Bad User # 共享级别，用户不需要账号和密码即可访问[opt] comment = opt browseable = yes path = /opt guest ok = yes writable = yes forceuser = root forcegroup = root # 将新文件的所有者和组属性设置为属于root用户 samba共享文件无法写入解决给共享目录加入写入权限可解决此问题，如添加777权限。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP子网划分]]></title>
    <url>%2F2019%2F05%2F10%2FIP%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[概念 CIDR：Classless Inter-Domain Routing，元类域间路由选择。形式如：192.168.10.32/28。前面的数字是我们的网络地址，后面的28表示用28位来表示网络位，用32-28=4位来表示主机位。通过这种记法，我们能明确两个信息： 网络地址：192.168.10.32 子网掩码：255.255.255.240 子网掩码与CIDR表示法的关系 其中/8-/15位掩码只能用于A类网络，/16-/23可用于A类和B类网络，而/24-/30可用于A类、B类和C类网络。 子网掩码 CIDR值 255.0.0.0 /8 255.128.0.0 /9 255.192.0.0 /10 255.224.0.0 /11 255.240.0.0 /12 255.248.0.0 /13 255.252.0.0 /14 255.254.0.0 /15 255.255.0.0 /16 255.255.128.0 /17 255.255.192.0 /18 255.255.224.0 /19 255.255.240.0 /20 255.255.248.0 /21 255.255.252.0 /22 255.255.254.0 /23 255.255.255.0 /24 255.255.255.128 /25 255.255.255.192 /26 255.255.255.224 /27 255.255.255.240 /28 255.255.255.248 /29 255.255.255.252 /30 方法选定的子网掩码将创建多少个子网 2^x个，其中x是子网掩码借用的主机位数。如：192.168.10.32/28，我们知道C类ip的默认子网掩码为：255.255.255.0。这个IP的28位子网掩码是：255.255.255.240。原本最后一个字节应该是0（00000000），现在却是240（11110000）。故其借用了主机位4位来充当网络位。可创建的子网数是2^4，就是16个 每个子网可包含多少台主机 2^y-2台，其中y是没被借用的主机位的位数。减2是因为，主机位全为0的部分是这个子网的网段号（Net_id），全为1的部分是这个网段的广播地址。 有哪些合法的子网 算出子网的步长（增量）。使用256减去子网最后一位，计算出子网步长。如256-192 = 64，即子网掩码为192时，步长为64。从0开始不断增加，直到到达子网掩码值，中间的结果就是子网，即0、64、128和192 每个子网的广播地址 主机位全为1就是该子网的广播地址。一般我们这样计算：广播地址总是下一个子网前面的数。前面确定了子网为0、64、128和192，例如，子网0的广播地址为63，因为下一个子网为64；子网64的广播地址为127，因为下一个子网为128，以此类推。最后一个子网的广播地址总是255 每个子网可包含哪些主机地址 合法的主机地址位于两个子网之间，但全为0和全为1的地址除外。例如，如果子网号（网段号）为64，而广播地址为127，则合法的主机地址范围为65-126，即子网地址和广播地址之间的数字。 实例 问题：将10.129.14.0/25划分为四个网段 确定子网掩码 因为现在的子网掩码已经是255.255.255.128，所以要通过借位划分子网掩码，现在子网掩码二进制为11111111.11111111.11111111.10000000，在最后的10000000要再借两位才能实现将子网划分为4个，这里将11111111.11111111.11111111.10000000看作标准子网掩码，子网的数量等于2^x，x是子网掩码借用的主机位数，所以要借两位，子网掩码为11111111.11111111.11111111.11100000 计算子网 因为上面计算出了子网掩码为255.255.255.224，使用256-224=32，这样就计算出了步长。子网为：0、32、64、128 子网地址 10.129.14.0 - 10.129.14.31 10.129.14.32 - 10.129.14.63 10.129.14.64 - 10.129.14.95 10.129.14.96 - 10.129.14.127 每个子网的主机数量是2^5，也就是32个。每个网段的第一个地址是网络地址，最后一个是广播地址不能使用，可以使用第二个地址作为网关，如10.129.14.32 - 10.129.14.63，10.129.14.32是网络地址，10.129.14.63是广播地址，10.129.14.33可以作为网关使用。那么每个网段真正可以使用的是30个地址]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>子网划分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cobbler部署]]></title>
    <url>%2F2019%2F05%2F07%2Fcobbler%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[介绍 Cobbler是一个Linux服务器安装的服务，可以通过网络启动(PXE)的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理DHCP，DNS等。 Cobbler可以使用命令行方式管理，也提供了基于Web的界面管理工具(cobbler-web)，还提供了API接口，可以方便二次开发使用。 Cobbler是较早前的kickstart的升级版，优点是比较容易配置，还自带web界面比较易于管理。 Cobbler内置了一个轻量级配置管理系统，但它也支持和其它配置管理系统集成，如Puppet，暂时不支持SaltStack。 Cobbler官网 cobbler集成的服务 PXE服务支持 DHCP服务管理 DNS服务管理(可选bind,dnsmasq) 电源管理 Kickstart服务支持 YUM仓库管理 TFTP(PXE启动时需要) Apache(提供kickstart的安装源，并提供定制化的kickstart配置) 安装1234567891011121314151617181920212223242526272829303132=======================================================================================环境：系统：CentOS7.3.1611防火墙：关闭SELinux：关闭=======================================================================================[root@cobbler ~]# yum install -y epel-release[root@cobbler ~]# yum install -y cobbler cobbler-web tftp-server tftp dhcp httpd syslinux rsync pykickstart[root@cobbler ~]# rpm -ql cobbler/etc/cobbler # 配置文件目录/etc/cobbler/settings # cobbler主配置文件，这个文件是YAML格式，Cobbler是python写的程序。/etc/cobbler/dhcp.template # DHCP服务的配置模板/etc/cobbler/tftpd.template # tftp服务的配置模板/etc/cobbler/rsync.template # rsync服务的配置模板/etc/cobbler/iso # iso模板配置文件目录/etc/cobbler/pxe # pxe模板文件目录/etc/cobbler/power # 电源的配置文件目录/etc/cobbler/users.conf # Web服务授权配置文件/etc/cobbler/users.digest # 用于web访问的用户名密码配置文件/etc/cobbler/dnsmasq.template # DNS服务的配置模板/etc/cobbler/modules.conf # Cobbler模块配置文件/var/lib/cobbler # Cobbler数据目录/var/lib/cobbler/config # 配置文件/var/lib/cobbler/kickstarts # 默认存放kickstart文件/var/lib/cobbler/loaders # 存放的各种引导程序/var/www/cobbler # 系统安装镜像目录/var/www/cobbler/ks_mirror # 导入的系统镜像列表/var/www/cobbler/images # 导入的系统镜像启动文件/var/www/cobbler/repo_mirror # yum源存储目录/var/log/cobbler # 日志目录/var/log/cobbler/install.log # 客户端系统安装日志/var/log/cobbler/cobbler.log # cobbler日志 配置dhcp1234567891011121314151617181920212223242526272829303132[root@cobbler dhcp]# mv dhcpd.conf&#123;,.bak&#125;[root@cobbler dhcp]# cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.conf[root@cobbler dhcp]# vim dhcpd.confoption domain-name "yhsm.com";# 指定域名，与/etc/resolv.conf中的是一样的。option domain-name-servers 114.114.114.114;# 这应该是一个可用的DNS地址option routers 172.16.99.2;# 指定网关，因为是虚拟机，所以这里指定的网关也就是NAT网卡的网关default-lease-time 3600;max-lease-time 86400;log-facility local7;subnet 172.16.99.0 netmask 255.255.255.0 &#123;# 为哪个网段分配IP地址 range 172.16.99.100 172.16.99.120; # 分配地址的范围 filename "pxelinux.0"; # filename: 指明引导文件名称；基于网络引导时用到的bootloder文件 next-server 172.16.99.100; # next-server：提供引导文件的服务器IP地址；一般指定的服务器是一个tftp服务器，这里的tftp与cobbler服务在同一台主机上&#125;# 注意，每行以分号结尾。除了这些行，其他行均可注释[root@cobbler dhcp]# systemctl start dhcpd[root@cobbler dhcp]# ss -tlun# DHCP监听在UDP的67号端口，客户端监听在UDP的68号端口[root@cobbler ~]# dhclient -r# 使用此命令可以将dhcp分配的地址删除掉[root@cobbler ~]# dhclient -d# 使用此命令可能重新获取地址，如果已经有了dhcp分配的地址，可以续租# 上面两条命令也可以在客户端操作，这里直接使用服务端来测试了。所以地址可以会有变化。另外，要关闭虚拟机NAT的dhcp功能，并查看一下NAT的网关。如下图[root@cobbler ~]# less /var/lib/dhcpd/dhcpd.leases# 查看分配出去的地址，这个是租约文件 选择正在使用的NAT网卡，关闭dhcp功能，再查看NAT配置 查看NAT配置 启动tftp服务12[root@cobbler ~]# systemctl start tftp.socket[root@cobbler ~]# systemctl enable tftp.socket 启动rsync服务12[root@cobbler ~]# systemctl start rsyncd.socket[root@cobbler ~]# systemctl enable rsyncd.socket 启动httpd服务123[root@cobbler ~]# systemctl start httpd[root@cobbler ~]# systemctl enable httpd# 一定要先启动httpd才能启动cobbler 准备PXE12[root@cobbler ~]# cp /usr/share/syslinux/&#123;pxelinux.0,menu.c32&#125; /var/lib/cobbler//loaders/# pxelinux.0是基于网络引导时用到的bootloder引导文件，menu.c32是菜单文件 配置cobbler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230[root@cobbler ~]# useradd cblrtest[root@cobbler ~]# echo "centos" | passwd --stdin cblrtest[root@cobbler ~]# cat /etc/shadow|grep cblrtest[root@cobbler ~]# vim /etc/cobbler/settings---allow_duplicate_hostnames: 0allow_duplicate_ips: 0allow_duplicate_macs: 0allow_dynamic_settings: 0anamon_enabled: 0authn_pam_service: "login"auth_token_expiration: 3600build_reporting_enabled: 0build_reporting_sender: ""build_reporting_email: [ 'root@localhost' ]build_reporting_smtp_server: "localhost"build_reporting_subject: ""build_reporting_ignorelist: [ "" ]cheetah_import_whitelist: - "random" - "re" - "time"createrepo_flags: "-c cache -s sha"default_kickstart: /var/lib/cobbler/kickstarts/default.ksdefault_name_servers: []default_ownership: - "admin"default_password_crypted: "6$5CswA7bf$4o4nzSBWsCEU3IzWcpAloQ07P9SXp4fhHRJTkI9yxbPK9g49wsrINHMPeUjVp4JUzaiPUQfkpDW4COCJpRW0E."# 设置新装系统的默认root密码，这是现在的root用户的密码default_template_type: "cheetah"default_virt_bridge: xenbr0default_virt_file_size: 5default_virt_ram: 512default_virt_type: xenpvenable_gpxe: 0enable_menu: 1func_auto_setup: 0func_master: overlord.example.orghttp_port: 80kernel_options: ksdevice: bootif lang: ' ' text: ~kernel_options_s390x: RUNKS: 1 ramdisk_size: 40000 root: /dev/ram0 ro: ~ ip: off vnc: ~ldap_server: "ldap.example.com"ldap_base_dn: "DC=example,DC=com"ldap_port: 389ldap_tls: 1ldap_anonymous_bind: 1ldap_search_bind_dn: ''ldap_search_passwd: ''ldap_search_prefix: 'uid='ldap_tls_cacertfile: ''ldap_tls_keyfile: ''ldap_tls_certfile: ''mgmt_classes: []mgmt_parameters: from_cobbler: 1puppet_auto_setup: 0sign_puppet_certs_automatically: 0puppetca_path: "/usr/bin/puppet"remove_old_puppet_certs_automatically: 0manage_dhcp: 0# 用Cobbler管理DHCP就改为1，但重启后不知什么原因dhcpd.conf文件与之前配置的不同，所以这里使用默认的0。manage_dns: 0bind_chroot_path: ""bind_master: 127.0.0.1manage_tftpd: 1manage_rsync: 0manage_forward_zones: []manage_reverse_zones: []next_server: 172.16.99.100# 这是提供PXE对外的地址的。如果用Cobbler管理DHCP，修改本项power_management_default_type: 'ipmitool'power_template_dir: "/etc/cobbler/power"pxe_just_once: 1pxe_template_dir: "/etc/cobbler/pxe"consoles: "/var/consoles"redhat_management_type: "off"redhat_management_server: "xmlrpc.rhn.redhat.com"redhat_management_key: ""redhat_management_permissive: 0register_new_installs: 0reposync_flags: "-l -n -d"restart_dns: 1restart_dhcp: 1run_install_triggers: 1scm_track_enabled: 0scm_track_mode: "git"server: 172.16.99.100# 设置cobbler对外联系的地址client_use_localhost: 0client_use_https: 0snippetsdir: /var/lib/cobbler/snippetstemplate_remote_kickstarts: 0virt_auto_boot: 1webdir: /var/www/cobblerxmlrpc_port: 25151yum_post_install_mirror: 1yum_distro_priority: 1yumdownloader_flags: "--resolve"serializer_pretty_json: 0replicate_rsync_options: "-avzH"replicate_repo_rsync_options: "-avzH"always_write_dhcp_entries: 0proxy_url_ext: ""proxy_url_int: ""[root@cobbler ~]# systemctl start cobblerd[root@cobbler ~]# systemctl enable cobblerd[root@cobbler ~]# cobbler checkThe following are potential configuration items that you may want to fix:1 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux2 : change 'disable' to 'no' in /etc/xinetd.d/tftp3 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.4 : enable and start rsyncd.service with systemctl5 : debmirror package is not installed, it will be required to manage debian deployments and repositories6 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use themRestart cobblerd and then run 'cobbler sync' to apply changes.# 如果有“httpd does not appear to be running and proxying cobbler, or SELinux is in the way. Original traceback:”的提示，那么就重启一下http服务器。# 这是检查的结果，1是没有关SElinux，实际已经关了；2是需要将/etc/xinetd.d/tftp中的disable改为no。3是没有loader文件，可以运行提示的命令下载，没有必要；4是没有启动rsync服务，实际启动了，监听在873端口；5是与debian相关的，没有用；6是与fence设备相关，不需要[root@cobbler ~]# vim /etc/xinetd.d/tftp service tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no # 此项之前是yes per_source = 11 cps = 100 2 flags = IPv4&#125;[root@cobbler ~]# systemctl restart tftp.socket[root@cobbler ~]# cobbler checkThe following are potential configuration items that you may want to fix:1 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux2 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.3 : enable and start rsyncd.service with systemctl4 : debmirror package is not installed, it will be required to manage debian deployments and repositories5 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use themRestart cobblerd and then run 'cobbler sync' to apply changes.# 再次检查就没有上面第二项提示了，但要求重启cobblerd并执行命令。[root@cobbler ~]# systemctl restart cobblerd[root@cobbler ~]# cobbler sync# 同步所有配置task started: 2019-05-07_200411_synctask started (id=Sync, time=Tue May 7 20:04:11 2019)running pre-sync triggerscleaning treesremoving: /var/lib/tftpboot/grub/imagescopying bootloaderscopying: /var/lib/cobbler/loaders/pxelinux.0 -&gt; /var/lib/tftpboot/pxelinux.0copying: /var/lib/cobbler/loaders/menu.c32 -&gt; /var/lib/tftpboot/menu.c32copying: /usr/share/syslinux/memdisk -&gt; /var/lib/tftpboot/memdiskcopying distros to tftpbootcopying imagesgenerating PXE configuration filesgenerating PXE menu structurerendering TFTPD filesgenerating /etc/xinetd.d/tftpcleaning link cachesrunning post-sync triggersrunning python triggers from /var/lib/cobbler/triggers/sync/post/*running python trigger cobbler.modules.sync_post_restart_servicesrunning shell triggers from /var/lib/cobbler/triggers/sync/post/*running python triggers from /var/lib/cobbler/triggers/change/*running python trigger cobbler.modules.manage_gendersrunning python trigger cobbler.modules.scm_trackrunning shell triggers from /var/lib/cobbler/triggers/change/**** TASK COMPLETE ***上传镜像到服务器[root@cobbler ~]# mount -o loop /root/CentOS-7-x86_64-DVD-1611.iso /media/# 将系统中的镜像挂载到media/目录[root@cobbler ~]# cobbler import --name="CentOS-7_x86_64-1503" --path=/mediatask started: 2019-05-07_201016_importtask started (id=Media import, time=Tue May 7 20:10:16 2019)Found a candidate signature: breed=redhat, version=rhel6Found a candidate signature: breed=redhat, version=rhel7Found a matching signature: breed=redhat, version=rhel7Adding distros from path /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503:creating new distro: CentOS-7-1503-x86_64trying symlink: /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503 -&gt; /var/www/cobbler/links/CentOS-7-1503-x86_64creating new profile: CentOS-7-1503-x86_64associating reposchecking for rsync repo(s)checking for rhn repo(s)checking for yum repo(s)starting descent into /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503 for CentOS-7-1503-x86_64processing repo at : /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503need to process repo/comps: /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503looking for /var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503/repodata/*comps*.xmlKeeping repodata as-is :/var/www/cobbler/ks_mirror/CentOS-7_x86_64-1503/repodata*** TASK COMPLETE ***# 导入镜像，生成distro，生成的镜像存在/var/www/cobbler/ks_mirror下。所以/var/www/cobbler要有足够的空间。# --path 镜像路径# --name 为安装源定义一个名字# --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64# 安装源的唯一标示就是根据name参数来定义，本例导入成功后，安装源的唯一标示就是：CentOS-7_x86_64-1503，如果重复，系统会提示导入失败。[root@cobbler ~]# cobbler distro list CentOS-7-1503-x86_64[root@cobbler ~]# cobbler profile list CentOS-7-1503-x86_64# 这时查看都应该有一个刚才创建的文件名# 镜像存放目录，cobbler会将镜像中的所有安装文件拷贝到本地一份，放在/var/www/cobbler/ks_mirror下的CentOS-7_x86_64-1503目录下。因此/var/www/cobbler目录必须具有足够容纳安装文件的空间。[root@cobbler ~]# cobbler sync# 同步数据。这个命令是为了将数据同步到/var/lib/tftpboot/pxelinux.cfg/default文件，也就是安装时的菜单# cobbler check 核对当前设置是否有问题# cobbler list 列出所有的cobbler元素# cobbler report 列出元素的详细信息# cobbler sync 同步配置到数据目录,更改配置最好都要执行下# cobbler reposync 同步yum仓库# cobbler distro 查看导入的发行版系统信息# cobbler system 查看添加的系统信息# cobbler profile 查看配置信息 测试1234创建虚拟机，使用网络启动，之后会被分配IP地址，并提供一个安装界面。上面的cobbler会自动提供一个最小化安装的kickstart问题：1. No space left on device这是因为虚拟机内存不到2G，调整为2G后解决。 指定ks.cfg文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@cobbler ~]# cd /var/lib/cobbler/kickstarts/[root@cobbler kickstarts]# lsdefault.ks legacy.ks sample_esx4.ks sample.ksesxi4-ks.cfg pxerescue.ks sample_esxi4.ks sample_old.seedesxi5-ks.cfg sample_autoyast.xml sample_esxi5.ks sample.seedinstall_profiles sample_end.ks sample_esxi6.ks# 自带很多。默认使用的ks文件为sample_end.ks。# 在第一次导入系统镜像后，Cobbler会给镜像指定一个默认的kickstart自动安装文件在/var/lib/cobbler/kickstarts下的sample_end.ks。[root@cobbler kickstarts]# vim sample_end.ksauth --useshadow --enablemd5bootloader --location=mbrclearpart --all --initlabeltextfirewall --enabledfirstboot --disablekeyboard uslang en_USurl --url=$treeselinux --disabledfirewall --disabled# 加入关闭selinux和firewall$yum_repo_stanza$SNIPPET('network_config')rebootrootpw --iscrypted $default_password_cryptedselinux --disabledskipxtimezone America/New_Yorkinstallzerombrautopart%pre$SNIPPET('log_ks_pre')$SNIPPET('kickstart_start')$SNIPPET('pre_install_network_config')$SNIPPET('pre_anamon')%end%packages@^web-server-environment@base@core@web-serverkexec-tools%end# 修改%packages段，这是要安装的包，这里选择安装web-server的包。%post --nochroot$SNIPPET('log_ks_post_nochroot')%end%post$SNIPPET('log_ks_post')$yum_config_stanza$SNIPPET('post_install_kernel_options')$SNIPPET('post_install_network_config')$SNIPPET('func_register_if_enabled')$SNIPPET('download_config_files')$SNIPPET('koan_environment')$SNIPPET('redhat_register')$SNIPPET('cobbler_register')$SNIPPET('post_anamon')$SNIPPET('kickstart_done')%end# [root@cobbler kickstarts]# cobbler profile edit --name=CentOS-7-1503-x86_64 --kickstart=/var/lib/cobbler/kickstarts/anaconda-ks.cfg# 编辑profile，此命令可以修改关联的ks文件，也就是不再使用默认的ks文件。# 另外，安装后只有根分区、boot分区和swap 参考：老男孩Cobbler无人值守安装教程]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>自动部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thunderbird使用]]></title>
    <url>%2F2019%2F05%2F06%2FThunderbird%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[邮件分类 创建分类目录，在Index上右键，选择New Folder 自定义过滤名称 打开要归类的邮件 在From中右键发件人的邮箱地址，选择Create Filter From … 自定义过滤名称，选择要过滤后保存的位置为刚创建的目录 选择Run Now开始过滤 删除本地邮件的同时，删除远程服务器上的邮件只要添加邮箱时选择了IMAP，就会在删除本地邮件时，同时删除远程服务器上的邮件。如果是POP，就会只删除本地的邮件。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>邮箱使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitKraken简单使用]]></title>
    <url>%2F2019%2F04%2F30%2FGitKraken%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍 GitKraken是一套git的GUI管理工具。GitKarken有分付費版和免費版，在大部分的狀況下，使用免費版就非常足夠了。 使用方法 打开GitKraken，这时会要求登录，点击页面最上方的”Sign in with GitHub” 这时会跳转到GitKraken的页面并要求登录github，输入帐号和密码登录github就可以了 选择打开一个本地的repo 选择一个本地的git项目，如/root/works/GitHub/ruopu89.github.io 这时就已经打开本地的项目了，之后需要创建一个gitkraken的密钥，这样才可以使用此软件上传代码到github，首先进行Preferences 这里需要创建一个GitKraken的密钥，创建密钥后会自动被添加到github中。使用root的密钥不能成功上传 添加密钥之后就可以上传了，红框分别指明了添加，提交和上传按键]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git_gui</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控Redis]]></title>
    <url>%2F2019%2F04%2F26%2Fzabbix%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[安装Redis12345678[root@zabbixagent ~]# yum install -y redis[root@zabbixagent ~]# vim /etc/redis.confbind 0.0.0.0requirepass redisqwer1234[root@zabbixagent ~]# systemctl start redis[root@zabbixagent ~]# systemctl enable redis[root@zabbixagent ~]# ss -tln|grep 6379LISTEN 0 128 *:6379 *:* 配置zabbix-agent123456789101112131415161718192021222324252627282930313233343536373839[root@zabbixagent ~]# cd /etc/zabbix/zabbix_agentd.d/[root@zabbixagent zabbix_agentd.d]# vim all.confUserParameter=redis_status[*],/etc/zabbix/zabbix_agentd.d/redis_status.sh "$1" "$2" "$3"[root@zabbixagent zabbix]# vim redis_status.sh# 测试中，如果将脚本放在zabbix_agentd.d目录下，重启zabbix-agent时会报错"invalid entry "redis_status()&#123;" (not following "parameter=value" notation) in config file "/etc/zabbix/zabbix_agentd.d/redis_status.sh", line 3"，所以将脚本放在了/etc/zabbix目录下，或在/etc/zabbix下创建一个scripts目录也可以。#!/bin/bash#redis_status()&#123; R_PORT=$1 R_COMMAND=$2 # (echo -en "INFO \r\n";sleep 1;)|nc 127.0.0.1 "$R_PORT" &gt; /tmp/redis_"$R_PORT".tmp redis-cli -h 127.0.0.1 -p $R_PORT -a "redisqwer1234" INFO &gt; /tmp/redis_"$R_PORT".tmp # 连接redis数据库，将数据库信息输出到文件 REDIS_STAT_VALUE=$(grep ""$R_COMMAND":" /tmp/redis_"$R_PORT".tmp|cut -d':' -f2) echo $REDIS_STAT_VALUE&#125;help()&#123; echo "$&#123;0&#125; + redis_status + PORT + COMMAND"&#125;main()&#123; case $1 in redis_status) redis_status $2 $3 ;; *) help ;; esac&#125;# 调用main函数时，输入的$2和$3会作为$1和$2传入redis_status函数main $1 $2 $3# 這個腳本主要是使用INFO命令在redis中取出相關數值並保存到/tmp目錄下，之後根據取出的每項的數值進行監控。因為redis中設置了驗證功能，所以沒有使用nc命令，而是使用redis-cli命令進行取值，redis-cli的-a選項是指定驗證密碼的，最後的INFO是要執行的命令，這樣就可以在不進行redis-cli的情況下將相關數據打印到屏幕上了。[root@zabbixagent zabbix_agentd.d]# chmod +x redis_status.sh [root@zabbixagent zabbix_agentd.d]# ./redis_status.sh redis_status 6379 used_memory813456[root@zabbixagent zabbix_agentd.d]# bash redis_status.sh redis_status 6379 used_cpu_sys0.36# 测试，取出CPU中的某个数据下面创建监控项与图形、触发器即可。]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控MySQL]]></title>
    <url>%2F2019%2F04%2F25%2Fzabbix%E7%9B%91%E6%8E%A7MySQL%2F</url>
    <content type="text"><![CDATA[流程 Client 在agent端安裝percona包 將安裝percona包後產生的userparameter_percona_mysql.conf配置文件複製到agent端的conf.d目錄下 在/var/lib/zabbix/percona/scripts/目錄下創建ss_get_mysql_stats.php.cnf配置文件 在agent端的mysql配置文件中加入mysql的用戶名和密碼 將/tmp/localhost-mysql_cacti_stats.txt文件的屬主和屬組改為zabbix 重啟mysql和zabbix-agent 用percona中的腳本測試 ZabbixServer管理頁面 下載網上的percona模板进行监控。下载地址：http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml percona官网：https://www.percona.com/downloads/percona-monitoring-plugins/ 下载Percona Monitoring Plugins最新tar.gz源码包。解压里面有cacti、nagios、zabbix不同监控模块，但zabbix/templates/目录下的zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6模板有問題，導入後不能添加。這裡導入上面下載的網上的模板，然后通过Zabbix Web界面 (Configuration -&gt; Templates -&gt; Import) 导入XML模板，注意要另外选择上Screens。最后配置主机关联上Percona MySQL Server Template模板即可。 查看添加的監控項的圖形數據 安装配置Percona监控MySQL12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152------------- Client-------------[root@zabbixagent ~]# wget https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm[root@zabbixagent ~]# rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm# 下載percona-zabbix-templates-1.1.8-1.noarch.rpm包到客戶端並安裝[root@zabbixagent ~]# rpm -ql percona-zabbix-templates/var/lib/zabbix/percona/var/lib/zabbix/percona/scripts/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php/var/lib/zabbix/percona/templates/var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.8.xml# get_mysql_stats_wrapper.sh用于监控获取MySQL状态# ss_get_mysql_stats.php配置连接数据库用户名和密码，使用shell来调用php# userparameter_percona_mysql.conf是zabbix-agent端监控MySQL的配置文件 # zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.8.xml是zabbix模板文件 [root@zabbixagent ~]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/# 複製配置文件到zabbix客戶端[root@zabbixagent ~]# systemctl restart zabbix-agent[root@zabbixagent ~]# yum install mariadb-server php php-mysql# 在不能联网的情况下，如果安装php-mysql可能要依赖 mysql-community-libs-compat-5.7.22-1.el7.x86_64.rpm包。可以到https://centos.pkgs.org/7/mysql-5.7-x86_64/mysql-community-libs-compat-5.7.22-1.el7.x86_64.rpm.html下载[root@zabbixagent ~]# systemctl start mariadb[root@zabbixagent ~]# mysql_secure_installation[root@zabbixagent ~]# chown -R zabbix. /var/lib/zabbix/[root@zabbixagent ~]# vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf&lt;?php$mysql_user='root';$mysql_pass='centos';# 在这个php文件中加入mysql的用户名和密码[root@zabbixagent scripts]# bash /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg0# 测试mysql状态[root@zabbixagent scripts]# vim /etc/my.cnf[mysql]user=rootpassword=centossocket=/var/lib/mysql/mysql.sock[root@zabbixagent scripts]# chown zabbix.zabbix /tmp/localhost-mysql_cacti_stats.txt[root@zabbixagent scripts]# bash /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh running-slave0[root@zabbixagent scripts]# bash /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg0[root@zabbixagent scripts]# systemctl restart mariadb zabbix-agent[root@zabbixagent scripts]# wget http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml# 下载模板到本地# /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.8.xml是安装percona时生成的模板，但导入此模板时会报错："标签无效 "/zabbix_export/date": "YYYY-MM-DDThh:mm:ssZ" 预计"，有说可以将模板先导入zabbix2.4版本中再导出，之后再导入3.0版本就不会有这个问题了。打开管理页面中配置 --&gt; 模板 --&gt; 导入，之后选择上面下载的模板，勾选图形和聚合图形的前两项，点击导入即可。导入成功后，会有一个叫Template Percona MySQL Server的模板导入进来。之後將模板克隆一份並改為主動監控模式。然後在主機部分關聯此模板。最後就可以在Monitoring中查看到Graphs了，另外導入的模板中還包括大量Screen都可以為主機添加上，以便在Screen中展示。在主动采集数据模式下，此模板才会显示正常启动。如果是被动采集模式，模板中的监控项均会显示不支持的。如果是被动模式，会提示"Timeout while executing shell script"，这可以调大客户端的Timeout选项为30 自定義腳本監控MySQL主从复制12345678910111213141516171819202122232425262728293031323334------------- Client-------------[root@zabbixagent scripts]# cd /etc/zabbix/zabbix_agentd.d/[root@zabbixagent zabbix_agentd.d]# vim mysql_monitor.sh#!/bin/bash#Seconds_Behind_Master()&#123;NUM=`mysql -uroot -hlocalhost -e "show slave status\G" | grep "Seconds_Behind_Master:" | awk -F: '&#123;print $2&#125;'`echo $NUM&#125;master_slave_check()&#123;NUM1=`mysql -uroot -hlocalhost -e "show slave status\G;" | grep "Slave_IO_Running" | awk -F: '&#123;print $2&#125;' | sed 's/^[\t]*//g'`NUM2=`mysql -uroot -hlocalhost -e "show slave status\G;" | grep "Slave_SQL_Running:" | awk -F: '&#123;print $2&#125;' | sed 's/^[\t]*//g'`if test $NUM1 == "Yes" &amp;&amp; test $NUM2 == "Yes" ; then echo 50else echo 100fi&#125;main()&#123;case $1 inSeconds_Behind_Master)Seconds_Behind_Master;;;master_slave_check)master_slave_check;;;esac&#125;main $1[root@zabbixagent zabbix_agentd.d]# vim all.confUserParameter=mysql_monitor[*],/etc/zabbix/zabbix_agentd.d/mysql_monitor.sh "$1"[root@zabbixagent zabbix_agentd.d]# systemctl restart zabbix-agent]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix主动监控配置]]></title>
    <url>%2F2019%2F04%2F25%2Fzabbix%E4%B8%BB%E5%8A%A8%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zabbix Proxy 介绍 Zabbix Proxy 可以代替 Zabbix Server 检索客户端的数据，然后把数据汇报给 Zabbix Server，并且在一定程度上分担了 Zabbix Server 的压力。Zabbix Proxy 可以非常简便的实现了集中式、分布式监控。 Zabbix Proxy 使用场景: 监控远程区域设备 监控本地网络不稳定区域 当 Zabbix 监控上千设备时，使用它来减轻 Server 的压力 简化 Zabbix 的维护 Zabbix Proxy 仅仅需要一条 TCP 连接到 Zabbix Server，所以防火墙上仅仅需要加上一条规则即可。Zabbix Proxy 数据库必须和 Zabbix Server 分开，否则数据会被破坏，毕竟这两个数据库的表大部分都相同。总之记住，数据库分开即可。Zabbix Proxy 收集到数据之后，首先将数据缓存在本地，然后在一定的时间之后传递给 Zabbix Server。这个时间由 Zabbix Proxy 配置文件中参数 ProxyLocalBuffer and ProxyOfflineBuffer 决定。 Zabbix Proxy 是一个数据收集器，它不计算触发器、不处理事件、不发送报警。 官方文档 https://www.zabbix.com/documentation/current/manual/concepts/proxyhttps://www.zabbix.com/documentation/3.4/zh/manual/concepts/proxyhttps://www.zabbix.com/download 安装与配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119===========================================================================================环境：系统：CentOS Linux release 7.4.1708 (Core)主机信息：zabbixServer：192.168.2.140zabbixProxy: 192.168.2.137zabbixAgent: 192.168.2.138===========================================================================================---------------------- zabbixProxy----------------------******** 安装********[root@zabbixproxy ~]# wget https://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm[root@zabbixproxy ~]# yum install -y zabbix-release-3.0-1.el7.noarch.rpm [root@zabbixproxy ~]# yum install -y zabbix-proxy-mysql.x86_64 zabbix-get.x86_64 zabbix-agent.x86_64 zabbix-sender.x86_64 mariadb-server***************** mysql端配置*****************[root@zabbixproxy ~]# vim /etc/my.cnf[mysqld]skip_name_resolve=ONinnodb_file_per_table=ON[root@zabbixproxy ~]# systemctl start mariadb.service[root@zabbixproxy ~]# systemctl enable mariadb.service[root@zabbixproxy ~]# mysql_secure_installation[root@zabbixproxy ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; CREATE DATABASE zabbix_proxy CHARSET 'utf8';# 因为zabbix的库中没有创建数据库的命令，所以这里手动创建MariaDB [(none)]&gt; GRANT ALL ON zabbix_proxy.* TO 'zproxy'@'%' IDENTIFIED BY 'zproxy';MariaDB [(none)]&gt; FLUSH PRIVILEGES;[root@zabbixproxy ~]# cp /usr/share/doc/zabbix-proxy-mysql-3.0.27/schema.sql.gz /root[root@zabbixproxy ~]# gzip -d schema.sql.gz [root@zabbixproxy ~]# mysql -uzproxy -h127.0.0.1 -pzproxy zabbix_proxy &lt; schema.sql [root@zabbixproxy ~]# mysql -uzproxy -pzproxyMariaDB [(none)]&gt; use zabbix_proxyMariaDB [zabbix_proxy]&gt; SHOW TABLES;***************** Proxy端配置*****************[root@zabbixproxy ~]# cd /etc/zabbix/[root@zabbixproxy zabbix]# cp zabbix_proxy.conf&#123;,.bak&#125; [root@zabbixproxy zabbix]# vim zabbix_proxy.confProxyMode=0# 0是主动模式，1是被动模式Server=192.168.2.140ServerPort=10051# zabbix-server的地址和端口Hostname=Zabbix_proxy# 代理服务器名称，需要与zabbix管理頁面中添加代理时候的proxy name一致LogFile=/var/log/zabbix/zabbix_proxy.logLogFileSize=10DebugLevel=3# 在第一次启动时可将级别调大，以方便排错，如改为4PidFile=/var/run/zabbix/zabbix_proxy.pidDBHost=localhostDBName=zabbix_proxyDBUser=zproxyDBPassword=zproxyDBPort=3306ProxyLocalBuffer=72# 设置zabbix proxy暂存在本地mysql的监控数据的时间。默认是0，不暂存。即使zabbix proxy已经把数据发送给了zabbix server，还是会暂存数据在本地设置的时间。取值范围是0~720小时ProxyOfflineBuffer=720# 设置当zabbix proxy与zabbix server无法连接时保留监控数据的时间间隔。默认是1小时，取值是1~720小时。这个参数特别有用，在维护中，停掉zabbix server后如果没有设置zabbix proxy的这个参数，所以当维护结束后启动zabbix server，会发现有段时间内的数据没有。这是因zabbix proxy按照默认的保留时间执行housekeeper把过期的数据删除了。# 这个时间最好根据要维护的时间来设定，比如要维护10个小时，那么就要设置ProxyOfflineBuffer=10HeartbeatFrequency=60# 每隔60秒探测一下服务器的活动状态，心跳间隔检测时间，默认60秒，范围0-3600秒，被动模式不使用ConfigFrequency=5# 代理在几秒钟内从zabbix服务器检索配置数据的频率DataSenderFrequency=5# 数据发送时间间隔，默认为1秒，范围为1=3600秒，被动模式不使用StartPollers=50# 轮询器的预分叉实例数。启动的线程数，与客户端的数据保持一致JavaGateway=192.168.2.140JavaGatewayPort=10052# java-gateway服务器地址和端口StartJavaPollers=10# javagateway的启动进程数，与监控的java应该一致SNMPTrapperFile=/var/log/snmptrap/snmptrap.logTimeout=30ExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000[root@zabbixproxy zabbix]# systemctl start zabbix-proxy[root@zabbixproxy zabbix]# ss -tln|grep 10051LISTEN 0 128 *:10051 *:* LISTEN 0 128 :::10051 :::* # zabbix-proxy也会监听10051端口---------------------- zabbixAgent----------------------***************** agent端配置*****************[root@zabbixagent ~]# cd /etc/zabbix/[root@zabbixagent zabbix]# cp zabbix_agentd.conf&#123;,.bak&#125;[root@zabbixagent zabbix]# vim zabbix_agentd.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0Server=192.168.2.137ServerActive=192.168.2.137# 這裡的Server與ServerActive兩項設置都是有用的，如果註釋了Server一行，啟動會報錯，這裡都輸入Proxy端的地址即可。StartAgents=0# 如果加入了此项，就可以关闭被动模式，也可以注释掉Server项。不建议使用此项并注释Server项，有可能使agent端无法启动Hostname=192.168.2.138Include=/etc/zabbix/zabbix_agentd.d/*.conf[root@zabbixagent zabbix]# systemctl restart zabbix-agent---------------------- zabbixProxy----------------------[root@zabbixproxy zabbix]# zabbix_get -s 192.168.2.138 -k "system.cpu.switches"1386544# 获取客户端的cpu参数，会返回一个值 下面进入web管理页面进行配置 创建 添加proxy名称，改为主动模式，之后就可添加了。這裡的Proxy name一定要與Proxy端的配置文件中的Hostname定義為一樣的名字。 进入模板页面 克隆模板，首先选择一个模板进入 选择下方的全克隆 改名保存，点击最下方的添加就是保存 进入配置主机页面，可以看到主机的名称变了，这是因为上面添加proxy时加入了这个tomcat主机，点击tomcat一行中的监控项，进入监控项页面 选择所有的项，注意这里一共有三页都要选中，再点击批量更新 修改第一项为主动式，之后就可以保存了 测试，将test主机的代理模式改为了proxy，之后可以看到同样是proxy代理，下面的tomcat显示状态为绿色，test显示状态为红色。实际在添加proxy并加入tomcat主机时已经将tomcat的代理方式改为了proxy了。]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控tomcat]]></title>
    <url>%2F2019%2F04%2F24%2Fzabbix%E7%9B%91%E6%8E%A7tomcat%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158------------- Client-------------[root@zabbixagent ~]# vim /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix Official Repository - $basearchbaseurl=http://repo.zabbix.com/zabbix/3.0/rhel/7/$basearch/enabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX[zabbix-non-supported]name=Zabbix Official Repository non-supported - $basearchbaseurl=http://repo.zabbix.com/non-supported/rhel/7/$basearch/enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIXgpgcheck=0[root@zabbixagent ~]# yum install -y zabbix-agent.x86_64 zabbix-sender.x86_64[root@zabbixagent ~]# vim /etc/zabbix/zabbix_agentd.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0Server=127.0.0.1,192.168.2.140ServerActive=192.168.2.140Hostname=Zabbix server# 在主动式提交采集数据时需要注意这里的Hostname要与web页面中添加的主机名称一致。Include=/etc/zabbix/zabbix_agentd.d/[root@zabbixagent ~]# systemctl start zabbix-agent------------- Server-------------[root@zabbix ~]# yum install -y zabbix-java-gateway.x86_64# 安装java-gateway用以监控tomcat[root@zabbix ~]# cp /etc/zabbix/zabbix_java_gateway.conf&#123;,.bak&#125;[root@zabbix ~]# vim /etc/zabbix/zabbix_java_gateway.confLISTEN_IP="0.0.0.0"# 监听所有地址LISTEN_PORT=10052# 监听端口PID_FILE="/var/run/zabbix/zabbix_java.pid"START_POLLERS=5# 启动线程数TIMEOUT=30[root@zabbix ~]# systemctl start zabbix-java-gateway[root@zabbix ~]# ss -tln|grep 10052LISTEN 0 50 :::10052 :::*[root@zabbix ~]# vim /etc/zabbix/zabbix_server.confListenPort=10051SourceIP=192.168.2.140LogType=fileLogFile=/var/log/zabbix/zabbix_server.logLogFileSize=10DebugLevel=3PidFile=/var/run/zabbix/zabbix_server.pidDBHost=localhostDBName=zabbixDBUser=zbxuserDBPassword=zbxpassDBSocket=/var/lib/mysql/mysql.sockDBPort=3306StartPollers=50# 轮询器的预分叉实例数。StartTrappers=20# 此项不要调的过大，测试中调为200，致使zabbix-server服务无法正常启动，提示连接不到数据库# 捕捉器的预分叉实例数。# Trapper接受来自Zabbix发送器、活动代理和活动代理的传入连接。# 必须至少运行一个Trapper进程，才能在前端显示服务器可用性和查看队列。JavaGateway=127.0.0.1JavaGatewayPort=10052StartJavaPollers=50SNMPTrapperFile=/var/log/snmptrap/snmptrap.logCacheSize=512M# 用于存储主机、项和触发器数据的共享内存大小。Timeout=10AlertScriptsPath=/usr/lib/zabbix/alertscriptsExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000[root@zabbix ~]# systemctl restart zabbix-server[root@zabbix ~]# vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemdskip_name_resolve = ONinnodb_file_per_table = ONmax_connections=1000table_open_cache=2048max_allowed_packet=128Mquery_cache_size=1024Mquery_cache_limit=2Mwait_timeout=10800net_read_timeout=3600symbolic-links=0[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid!includedir /etc/my.cnf.d[root@zabbix ~]# systemctl restart mariadb------------- Client-------------[root@zabbixagent ~]# yum install -y java-1.8.0-openjdk-devel tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp[root@zabbixagent ~]# vim /etc/profile.d/java.shexport JAVA_HOME=/usr[root@zabbixagent ~]# source /etc/profile.d/java.sh[root@zabbixagent ~]# java -versionopenjdk version "1.8.0_212"OpenJDK Runtime Environment (build 1.8.0_212-b04)OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)[root@zabbixagent ~]# vim /usr/libexec/tomcat/server#!/bin/bashCATALINA_OPTS="$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 # 要监听的端口 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false # 注意要在脚本最上方加入这些内容，如果不加，在监控中会不能监控JVM，提示“java.rmi.ConnectIOException: error during JRMP connection establishment; nested exception is: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure”。下面一项也可以加上。 -Dcom.sun.management.jmxremote.ssh=false -Djava.rmi.server.hostname=192.168.2.138" # 这里输入的是tomcat的监听地址[root@zabbixagent ~]# systemctl start tomcat[root@zabbixagent ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 *:10050 *:* LISTEN 0 100 :::8080 :::* LISTEN 0 128 :::22 :::* LISTEN 0 50 :::12345 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 50 :::42204 :::* LISTEN 0 50 :::35969 :::* LISTEN 0 128 :::10050 :::* LISTEN 0 1 ::ffff:127.0.0.1:8005 :::* LISTEN 0 100 :::8009 :::* # 这时tomcat监听了12345端口[root@zabbixagent ~]# tomcat versionServer version: Apache Tomcat/7.0.76Server built: Mar 12 2019 10:11:36 UTCServer number: 7.0.76.0OS Name: LinuxOS Version: 3.10.0-693.el7.x86_64Architecture: amd64JVM Version: 1.8.0_212-b04JVM Vendor: Oracle Corporation[root@zabbixagent ~]# wget http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.76/bin/extras/catalina-jmx-remote.jar[root@zabbixagent ~]# cp catalina-jmx-remote.jar /usr/share/tomcat/lib/[root@zabbixagent ~]# systemctl restart tomcat 下面在web页面添加主机，并对主机进行监控 添加主机 添加主机时需要写明主机名称，可见名称为可选项，加入一个主机组，下面的agent代理程序接口的地址为客户端对zabbix-agent监听的地址，端口为10050, 因为要监控java程序，所以使用JMX接口，监听在12345端口上。 添加模板，先按链接指示器中select选择模板，选好后点Add，最后完成点Update。在4.0版本中模板叫Template App Apache Tomcat JMX，Template App Generic Java JMX 添加好之后，过一会ZBX和JVM都应该变绿，表示被监控了，如果是红色的，可以点一下红色的项，会有错误提示，或可以刷新页面或点两下Enabled来刷新]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控方式]]></title>
    <url>%2F2019%2F04%2F23%2Fzabbix%E7%9B%91%E6%8E%A7%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[方式Active agents使用Zabbix agent创建监控项时有两种方式，即Active（主动式）agent和Passive （被动式）agent。这里所说的主动或被动指的是客户端主动发送数据或被动等待Server端来采集数据。 在Active agent模式下，Zabbix agent启动后，由agent端初始化和Zabbix server之间的通信，向Zabbix server发出获取监控项清单的请求，server端收到请求后响应agent发出的请求，并将监控项清单发送给agent。agent端定期和Zabbix server通信，保证获得最新的监控项清单。agent则根据监控项清单查询监控项的数据并将结果发送给Zabbixserver。 为了启用Active agent模式，需要在zabbix_agentd.conf文件中配置ServerActive参数，告诉agent可以联系到哪些服务器（默认端口是10051）。通过配置RefreshActiveChecks参数，可以设置agent端多长时间向server询问一次监控项清单，默认是120秒。在默认设置下server端改变active agent监控项有关的一些设置后，server端需要1分钟刷新配置缓存（通过server配置文件中的参数CacheUpdateFrequency设置，默认是60秒），agent需要等待2分钟才能够知道监控项的变化。如果从server查询监控项清单失败（网络问题或其他原因），agent端会等待1分钟后重新向server发出查询请求。Active agent也有自己的缓存，可以通过BufferSend或BufferSize进行设置， BufferSend参数设置监控项数据在缓存中保留的时间，默认是5秒（可以设置到3600）。BufferSize参数设置保留监控项数据的缓存大小，默认是100（可以设置到65535） 配置Active agent监控项的步骤： Zabbix agent安装完成后，打开配置文件zabbix_agentd.conf。 设置ServerActive参数，格式为IP:port 或DNS主机名:port。在这里我们可以设置多个server或proxy的DNS主机名或IP地址，用逗号分隔。 设置Hostname参数，这个名字必须是唯一的并和Zabbixserver中Configuration –&gt;Hosts页面中添加的主机名称相同。也与主机名无关，只是zabbix_agentd.conf配置文件中Hostname名称与ZabbixServer的web页面中配置–&gt;主机中添加的主机名要一致 验证Zabbix server的10051端口能够访问。 重启zabbix_agent（systemctl restart zabbix-agent.service）。 检查agent日志（tail -f/var/log/zabbix/zabbix_agentd.log）。 在主机中添加主动式监控项（Configuration –&gt; Hosts –&gt; Items –&gt; Create item）。选择监控项的Type（类型）为Zabbix agent（active）。 Passive agentsPassive agent为我们提供了一种简单易行的方法，Zabbixserver或proxy根据监控项中配置的Update interval（数据更新间隔），定期向agent端发出查询请求，如CPU负载、磁盘使用空间等等。agent根据请求收集监控项数据并返回给server或proxy。整个过程就是简单的一问一答，你要什么值我给你什么值，从agent角度来看是被动的回答。 配置Passive agent监控项的步骤： 安装Zabbix agent，打开配置文件zabbix_agentd.conf。 设置Server参数，格式为IP 或DNS主机名。在这里我们可以设置多个server或proxy的DNS主机名或IP地址，用逗号分隔。 注释掉ServerActive和Hostname这两个参数，在Passive agent模式中不需要这两个参数，如果你想同时使用active agent，这两个参数必须配置。 验证agent端的10050端口能够访问。 重启zabbix_agent（systemctl restart zabbix-agent.service）。 检查agent日志（tail -f /var/log/zabbix/zabbix_agentd.log）。 在主机中添加被动式监控项（Configuration –&gt; Hosts –&gt; Items –&gt; Create item）。选择监控项的Type（类型）为Zabbix agent。 Extending agentsZabbix中提供了一些标准的监控项可以使用Key，当你添加Zabbix agent监控项时可以选择使用，但在实际环境中这些标准的Key并不能满足特定的监控需求，在Zabbix中可以使用多种方法进行扩展，其中一个方法就是在agent配置文件中使用UserParameter进行扩展。 通过UserParameter参数扩展监控项的key，可以灵活的实现多种监控需求。Zabbix中定义UserParameter的格式为UserParameter=\&lt;key>,\&lt;command>。 配置UserParameter的步骤： 打开agent配置文件zabbix_agentd.conf。 设置UserParameter参数。例如：UserParameter=mysql.threads,mysqladmin -u root –p\&lt;password> status|cut -f3 -d”:”|cut -f1-d”Q” ，该参数返回MySQL线程的数量给自定义的key：mysql.threads。 保存配置文件，重新启动Zabbix agent服务。 Web前端Configuration –&gt; Hosts–&gt; Items页面中添加监控项。 Name字段中设置监控项名称，例如 MySQL Threads。 Type字段中选择Zabbix agent或者Zabbix agent（active）。 Key字段中填写mysql.threads，这里填写的内容必须和UserParameter中定义的一样。 Type of Information字段中选择Numeric数字的（unsigned）。 Data type中选择Decimal十进制。 其他配置参数保持不变。点击Add按钮保存。 Monitoring –&gt; Latest data页面查看监控项MySQL Threads。 监控项Simple checksZabbix 中simple checks是基于ICMP ping或者端口检测来确定主机是否在线或服务端口能否正常连接。这种方式下主机中不需要安装Zabbix agent，当我们检测主机或端口的可用性时simplechecks返回的值为1或者0，当我们检测性能时返回的是浮点数（如检测ping的响应时间时返回值0.02秒），如果检测失败则返回0。 为了降低网络流量，更高效的进行ICMP检测，Zabbix执行icmppingsec、icmpping 和 icmppingloss检测时使用了一个第三方的工具fping和fping6，依赖linux不同的发行版安装的版本各有不同，建议使用fping 3.0以上的版本。在CentOS系统中需要安装fping时可以通过命令yum install fping完成安装。 Zabbix中默认定义了3个用于ICMP检测的监控项和2个用于TCP/UDP连接检测的监控项，分别是： Icmpping：主机响应ICMP ping返回1，否则返回0。 Icmppingloss：返回丢失ICMP ping数据包的百分比。 Icmppingsec：返回ICMP ping的响应时间，单位是秒。如果主机没有响应（timeout reached）则返回0。如果返回值小于0.0001秒时返回值将被设置为0.0001。 Net.tcp.service / net.udp.service：主机上指定的服务正常运行并能建立TCP / UDP连接时返回1，否则返回0。 Net.tcp.service.perf / net.udp.service.perf：返回连接到指定TCP / UDP端口的服务所使用的时间，单位是秒。如果服务没有运行则返回0.000000。 net.tcp.service 和net.tcp.service.perf支持我们知道的大部分协议，如SSH、FTP、HTTP等。这两个项目是非常有用的，我们可以对特定的IP和端口进行简单的TCP握手连接完成可用性的检测，同时对主机或应用的性能不会有任何影响。 下面一起来看看这几个项目的用法。 Icmpping 格式：Icmpping[\&lt;target>,\&lt;packets>,\&lt;interval>,\&lt;size>,\&lt;timeout>]。其中target是主机IP或DNS主机名；packets是数据包的数量；interval是数据包之间的间隔时间，单位是微秒；size是数据包的大小，单位是bytes；timeout是超时时间，单位是微秒。例如icmpping[,20,50,256,100]，如果你不想定义target、packet等值，可以不填写任何参数，可以写成icmpping[,4]，只要4个数据包有1个响应，监控项就会返回1。 Icmppingloss 格式：icmppingloss[\&lt;target>,\&lt;packets>,\&lt;interval>,\&lt;size>,\&lt;timeout>]。其中target是主机IP或DNS主机名；packets是数据包的数量；interval是数据包之间的间隔时间，单位是微秒；size是数据包的大小，单位是bytes；timeout是超时时间，单位是微秒。 Icmppingsec 格式：icmppingsec[\&lt;target>,\&lt;packets>,\&lt;interval>,\&lt;size>,\&lt;timeout>,\&lt;mode>]。其中target是主机IP或DNS主机名；packets是数据包的数量；interval是数据包之间的间隔时间，单位是微秒；size是数据包的大小，单位是bytes；timeout是超时时间，单位是微秒。 net.tcp.servic 格式：net.tcp.service[service,\&lt;ip>,\&lt;port>]。其中service是TCP协议的名称，如：ssh、ldap、smtp、ftp、http、pop、nntp、imap、Telnet等等；IP是IP地址或DNS主机名（默认使用定义监控项的主机的IP或DNS主机名）；port是端口号（默认使用服务标准的端口号）。例如：net.tcp.service[ftp,45]。当前不支持加密协议的检测，像IMAP的993端口或POP的995端口，但我们可以用net.tcp.service[tcp,\&lt;ip>,port]来完成对它们的检测。Zabbix 从v2.0起支持https和telnet。 net.tcp.service.perf 格式：net.tcp.service.perf[service,\&lt;ip>,\&lt;port>]。其中service是TCP协议的名称，如：ssh、ldap、smtp、ftp、http、pop、nntp、imap、Telnet等等；IP是主机的IP地址或DNS主机名（默认使用定义该监控项主机的IP或DNS主机名）；port是端口号（默认使用服务标准的端口号）。例如：net.tcp.service.perf [ssh]。当前不支持加密协议的检测，像IMAP在993端口或POP在995端口上，但我们可以用net.tcp.service.perf [tcp,\&lt;ip>,port]来完成对它们的检测。 net.udp.service 格式：net.udp.service[service,\&lt;ip>,\&lt;port>]。其中service是UDP协议的名称，如：ntp；IP是主机的IP地址或DNS主机名（默认使用定义该监控项主机的IP或DNS主机名）；port是端口号（默认使用服务标准的端口号）。例如：net.udp.service[ntp,45]，在UDP端口45上检测NTP服务的可用性。 net.udp.service.perf 格式：net.udp.service.perf[service,\&lt;ip>,\&lt;port>]。其中service是UDP协议的名称，如：ntp；IP是主机的IP地址或DNS主机名（默认使用定义该监控项主机的IP或DNS主机名）；port是端口号（默认使用服务标准的端口号）。例如：net.udp.service.perf [ntp]，可以检测NTP服务的响应时间。 Simple checks是一种简单而高效的监控方式，由于其不需要传输复杂的监控数据，因此在监控成百上千的主机和服务的可用性时，对整体的网络流量产生的影响是最小的。 配置Simple checks的步骤： 创建一个新的监控项（Configuration –&gt; Template –&gt; Items–&gt; Create item 或Configuration –&gt; Host –&gt; Items –&gt; Create item）。 在监控项配置页面中： 填写Name ，例如：Check SSH port $3。（$3是key中的第三个参数{$SSH_PORT}）。 选择Type为Simple check。 填写Key，例如：net.tcp.service[ssh,,{$SSH_PORT}]，{$SSH_PORT}是定义的macro。 Type of information选择Numeric。 Data type选择Decimal。 如果需要可以在NewApplication中填写一个监控项组的名称，如：ssh check。 其他配置参数可以保持不变，点击Add按钮保存。 Monitoring –&gt; Latest data页面查看监控项。 SNMP agents监控交换机、路由器、UPS等设备时，你是没有办法通过Zabbixagent进行监控的，原因是这些设备中没有办法安装agent程序，但这并不代表Zabbix不能对这些设备进行监控，利用标准的SNMP协议，可以轻松实现Zabbix对这些设备的监控。 SNMP（简单网络管理协议）是TCP/IP协议簇的一个应用层协议，是一种广泛用于监测网络设备（例如：交换机、路由器、UPS等）的网络协议。在每个被监控的设备中都会运行设备自带的SNMP agent， Zabbix使用SNMP协议向被监控设备的SNMP agent发出查询指令，并由SNMP agent返回查询的值。 在设置SNMP agent监控项之前，我们先要确定OID（SNMP对象标识符）。SNMP将被管理对象用一个树来组织，被管理对象用OID表示，如：1.3.6.1.2.1.1.3 代表sysUpTime。实际环境中会使用很多厂商的产品，每个产品中定义的OID不尽相同，所以准备使用SNMP agent 监控设备前，需要厂商提供设备的MIB文件。MIB文件是基于SMI语法定义的说明某个OID在OID树中的位置、数据类型、描述等信息的文本文件，如果没有MIB文件，你很难理解一串数字代表的含义是什么。 Zabbix Internal checksZabbix Internal主要是用来监测Zabbixserver 或 proxy server自身的性能。Zabbix Internal由Zabbix server 或proxy server进行计算，从Zabbix 2.4版本开始，即使在主机维护状态下也会处理Zabbix Internal。Zabbix server处理Zabbix Internal时不依赖agent，你只需要拥有超级管理员的权限即可。 Zabbix在系统中已经预设了针对Zabbix server和 proxy server的模板，模板的名称是Template App Zabbix Server 和 Template App Zabbix Proxy。 配置Zabbix Internal的步骤： 创建一个新的监控项（Configuration –&gt; Template –&gt; Items –&gt; Create item 或Configuration –&gt; Host –&gt; Items –&gt; Create item）。 Name中填写监控项的名称。 Type中选择Zabbix internal。 Key中选择（单击右侧的Select按钮）zabbix[process,\&lt;type>,\&lt;num>,\&lt;state>]，在这里我们使用zabbix[process,poller,avg,busy]。 Type of information选择Numeric (float)。 Units（单位）填写% 。 其他参数可以保持原状，单击Add按钮保持。 Monitoring –&gt; Latest data页面查看监控项。 Zabbix trapperZabbix使用agent、IPMI或SNMP的方式收集监控数据时，有时候会因为监控项Key中使用的脚本执行时间过长而超时，从而无法获取数据。因此Zabbix 提供了trapper的监控方式，利用zabbix-sender工具可以主动将数据从被监控主机发送到Zabbix server，这种方式中不需要在被监控主机中安装Zabbix agent。 IPMI agentsIPMI（Intelligent PlatformManagement Interface）是一个开放标准的硬件管理接口规范，定义了嵌入式管理子系统进行通信的特定方法。现在主流的服务器使用远程控制卡（例如Dell的DRAC、HP的ILO等）都可以进行远程控制管理，通过IPMI你可以远程开机、关机、重启，远程查看服务器当前的运行状态，可以安装操作系统，实现远程管理。Zabbix server通过IPMI可以直接监控服务器硬件，即使是服务器的电源处在关闭的状态下也是没有问题的。 JMX agentsZabbix通过JMX（Java Management Extensions）可以对Java Application进行监控，Zabbix利用原生的Zabbix Java gateway，一个Java守护进程监控JMX应用。当Zabbix想要知道某个JMX counter当前的数据时，它只去询问ZabbixJava gateway，而gateway会去查询需要的数据，所有这些查询都是通过JMX管理API完成的。 使用时，一个Java应用不需要额外安装任何其他的软件，也不需要实现或扩展新的代码来处理Zabbix的查询，仅仅需要在Java 应用的配置文件中设置一些参数，支持远程JMX的监控。]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix web页面]]></title>
    <url>%2F2019%2F04%2F22%2Fzabbix-web%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[概念 hosts（主机） Zabbix中需要监控的服务器、交换机及其他设备我们都统一称作host，这些设备与Zabbix服务器之间通过网络连接。在Configuration –&gt; Hosts 页面中管理主机。 host groups（主机组）为了便于管理，可以把具有相同属性的主机归类，主机组中可以包含主机和模板。归类可按照地理区域、业务单元、设备用途、应用种类等方式划分。在Configuration –&gt; Host groups页面中管理配置。 Item（监控项）需要监控的指标如CPU负载、内存使用率等，这些监控指标在Zabbix中称为item，监控项可以包含在主机或模板中。可以在Configuration –&gt; Hosts –&gt; items页面或 Configuration –&gt; Templates –&gt; items页面中进行管理配置。 Template（模板）模板中可以添加items（监控项）、triggers（触发器）、screens（展示屏）、graphs（图形）、application（监控项组）、low-level discovery（低级发现）、webscenarios（web场景）。具有相同监控需求的主机可以使用相同的模板，使用模板可以实现自动化配置，批量完成监控任务。在Configuration –&gt; Templates 页面中管理配置。 trigger（触发器）当我们收集监控项的数据后，可以使用逻辑表达式来评估监控项的数据处于何种状态，根据我们设定的thresholds（阈值）判断是否正常，其结果表现为OK（正常）或PROBLEM（故障），触发器可以包含在主机或模板中。在Configuration –&gt; Hosts –&gt; Triggers页面或 Configuration –&gt; Templates –&gt; Triggers页面中管理配置。 events（事件）当一个触发器的结果发生变化时（即触发器的状态由OK变为PROBLEM或者由PROBLEM变为OK），在Zabbix中会生成一个事件。Agent auto-registration（代理自动注册）和网络设备auto discovery（自动发现）也会生成事件。可以在Monitoring–&gt; Events 页面中查看事件详情。 action（动作）有时候我们会依据特定的事件采取某种动作，比如说当某个触发器的状态变为PROBLEM时发送一封告警邮件。动作由一个operation（操作）和一个condition（条件）组成。在Configuration –&gt; Actions 中管理配置。 escalation（告警升级）在实际环境中，有时候需要根据情况将告警发送给不同的人，比如说出现故障后先给管理员发送告警邮件，并每过10分钟重复发送告警邮件给管理员，如果30分钟后故障依然没有解决，这时就给部门经理发送告警邮件。我们可以在Configuration –&gt; Actions 页面中Operations标签中配置。 media（告警方式）Zabbix支持多种告警方式，包括E-mail（邮件）、SMS（短信）、Jabber、EZ Texting（只在国外使用）和自定义告警方式，通过扩展可以使用微信、钉钉发送告警，在Administration –&gt; Media Types页面进行配置。 remote commands（远程命令）远程命令是在Zabbix server和被监控主机上执行的命令或Scripts（脚本程序），用来完成特定的任务，例如重启Apache服务。在Administration–&gt; Scripts中配置。 applications（监控项组/应用集）在Zabbix中管理用户时有对应的用户组，管理主机时有对应的主机组，管理监控项时也有对应的监控项组，就是applications。在Configuration–&gt; Hosts –&gt; Applications 或者Configuration–&gt; Templates –&gt; Applications中配置。 notification（通知）通过用户选择的告警方式发送的有关事件、触发器状态等内容的告警信息。 Severity（告警级别）Zabbix中通过Severity定义了触发器的不同严重程度，默认有6个值，分别为 Not classified，nformation，Warning，Average，High，Disaster。 web页面结构 主菜单：由Zabbix logo和Monitoring（监控数据）、Inventory（资产记录）、Reports（报告）、Configuration（配置）、Administration（管理）菜单组成。Guest用户登录后不会显示 Configuration和Administration菜单项。 用户相关菜单：包括搜索框、帮助、用户配置及退出按钮。 子菜单：二级菜单，内容随主菜单的选择而变化。 操作区域：根据不同菜单项的选择，在该区域内会出现不同的操作内容。 子菜单管理 一般一般页面中主要是Zabbix系统中一些通用的管理配置功能，通过右上角下拉框选择不同的项目完成相关配置和管理。下面介绍下拉框内容： 图形化使用者接口 页面中配置参数的含义如下： 默认主题(Default theme)：系统默认的页面显示主题风格。用户在自己的profile中Theme设置为System default时，登录Web前端页面后会使用本参数设置的页面主题风格（默认为Blue）。更换主题后需重新登录才能生效。 下拉的第一个输入项(Dropdown first entry)：下拉框内的首选。在前端页面中，经常会有选择下拉框的操作，本参数就是设置下拉框的第一个选项是All或者None。另外通过选中remember selected记住当前下拉框的操作，例如你在Hosts页面中在Group下拉框中选择Router这个主机组完成操作后，当你下一次回到Hosts页面时Group下拉框中会自动选择Router。 搜索/过滤组件限制(Search/Filter elements limit)：搜索或使用过滤器时在页面列表中显示的记录数。例如将参数设置为10后，在页面查询的结果超过10条记录时，会显示为“Displaying 1 to 10 of 10+found”，你会看到在10后面多了个+号。 表格位中最多可展示的组件数量(Max count of elements to show inside table cell)：页面表格的单元格中最多显示多少个元素。例如将参数设置为1后，在Host groups页面中Templates模板中的MEMBERS（成员）名称只显示1个。 启用事件确认(Enable event acknowledges)：勾选此项后在Monitoring –&gt; Dashboard页面的Last 20 issues和Monitoring–&gt; Events页面中可以看到ACK列，否则看不到ACK列。默认是勾选的。 查看事件不能久于(日)(Show events not older than (in days))：定义在Monitoring –&gt; Triggers页面中显示多少天的事件，默认是7天。 可展示的每触发器最多事件计数(Max count of events per trigger to show)：定义在Monitoring –&gt; Triggers页面中每个Trigger显示多少个事件，默认是100。 当Zabbix服务器停机时显示警告(Show warning if Zabbix server is down)：勾选此项后当Zabbix server无法访问时（有可能宕机），在浏览器中会显示一条警告信息提示用户。默认是勾选的。 管家此页面的主要作用是定期删除Zabbix数据库中的旧数据 页面中配置参数的含义如下： Enable internal housekeeping：启用或禁用Housekeeping功能。 Trigger data storage period (in days)：触发器数据的保留天数。 Internal data storage period (in days)：内部数据的保留天数。 Network discovery data storage period (in days)：网络发现数据的保留天数。 Auto-registration data storage period (in days)：自动注册数据的保留天数。 Data storage period (in days)：数据库中events and alerts、IT services、audit、user sessions、history和trends数据的保留天数。 Override item history period：覆盖监控项中配置的历史保留天数。如果勾选此项，在本页面history中设置的Data storageperiod (in days) 会覆盖监控项中配置的Historystorage period (in days)。 Override item trend period：覆盖监控项中配置的trend保留天数。如果勾选此项，在本页面trends中设置的Data storage period (in days) 会覆盖监控项中配置的Trend storage period (in days)。 设置好参数后单击Update按钮将更新设置的参数，单击Resetdefaults按钮会重置这些参数为系统默认的值。 图片我们在图片页面中可以看到很多Zabbix系统中使用的图片，主要有两种类型：Icon（图标）和 Background（背景），这些图片都保存在数据库中。Icon主要用来在拓扑图中表示各种被监控的设备，Background用来做拓扑图的背景图片。 根据你选择的图片类型，单击页面右上角的Create icon按钮或者Createbackground按钮，选择需要上传的图片，在Name字段中设置图片的名称后，点击Add按钮就可以添加图片到系统中 图标映射我们可以通过主机的资产记录信息创建主机的图标映射，然后在拓扑图中使用。当某个主机的资产记录匹配设定的图标映射关系时，拓扑图中会自动显示设定的图标。 正则表达式Zabbix支持正则表达式，有两种使用方法：在支持正则表达式的地方手工填写或引用全局正则表达式。那什么地方支持正则表达式呢？主要是在主机或模板中设置发现规则时，在Filter中使用。 在Regular expressions页面我们可以管理和配置全局正则表达式。单击页面右上角New regular expression按钮创建新的正则表达式 创建自定义的正则表达式时，我们要注意在Zabbix中正则表达式返回的是TRUE或者是FALSE。 宏Zabbix中Macros（宏变量）可以在主机和模板中创建，也可以在Macros页面中创建全局宏变量。定义宏变量时必须遵守指定的格式：{$macro}，名称可由A-Z，0-9，_ 和 . 组成。 Zabbix解析处理宏变量的过程如下：首先检查主机中是否设置了宏变量，如果有直接使用该宏变量。主机中没有发现宏变量，则检查链接到主机的所有模板中是否设置了宏变量，如果有直接使用。模板中也没有发现宏变量，则检查是否设置了全局宏变量，如果有则直接使用。 值映射Value mapping页面中允许创建和管理值映射关系，通过值映射我们可以更直观的了解监控项返回的状态值。例如我们定义交换机端口的状态值映射关系：0 –&gt; DOWN 和1 –&gt; UP。然后定义交换机端口状态的监控项时，在show value字段中使用上面设置的值映射，在Monitoring –&gt; Latest data页面中查看交换机端口的状态时，你会看到交换机端口的状态是DOWN或者是UP，而不是0或1。 工作时间Working time页面用来定义工作时间，工作时间是一个系统范围的参数。 定义工作时间必须遵循下面的格式：d-d,hh:mm-hh:mm。其中d-d的意思是从星期几到星期几，比如说设置成 1-7，即表示从星期一到星期日。hh:mm-hh:mm的意思是从几点几分到几点几分，其中hh是24小时制，可以设置成00到24，mm是分钟，可以设置成00到59。 也可以同时定义多组时间，之间用 ;（分号）分隔。比如1-5,09:00-18:00;6-7,09:00-12:00，意思是星期一到星期五早上9:00到18:00，星期六和星期日的早上9:00到12:00。 根据定义的工作时间，图形中会显示不同的背景颜色，工作时间背景颜色显示为白色，非工作时间背景颜色显示为灰色。当我们查看图形时通过背景颜色就可以知道故障发生在工作时间还是非工作时间 触发器严重性在这里我们可以自定义触发器的告警级别，包括名称和颜色。建议不要修改这个页面中告警级别的名称，否则需要同时修改各个语言文件中的翻译。 触发器显示选项Triggerdisplaying options页面中可以配置和触发器状态显示有关的一些参数，可以定义acknowledged/unacknowledgedevents的颜色和blinking选项（是否闪烁），以及显示状态为OK的触发器和触发器状态发生变化后闪烁的时间。 其它配置参数Other configuration parameters页面里将一些不太好归类的参数放在一起 页面中参数的含义如下： Refresh unsupported items (insec)：有时候一些监控项在userparameters中配置错误或不能被agent支持而变成unsupported状态，但是Zabbix会按照此处设定的刷新时间定期的将监控项的状态从unsupported变成active。单位为秒，可设定为任意数字。如果设置为0，unsupported状态的监控项不会变成active。 Group for discovered hosts：通过network discovery和 agent auto-registration方式添加的主机会自动归属于此处设置的主机组中。 Default host inventory mode：创建新主机或Host prototype（主机原型）时Host Inventory（主机资产记录）的默认模式。如果创建新主机时设置了Host Inventory，这个默认值会被覆盖。在这里可以设置为禁止、手动配置和自动配置。 User group for database downmessage：当数据库发生问题时发送告警信息给选择的用户组，如果选择None则不发送。Zabbix使用一个特定的进程Database watchdog来监控数据库，当数据库发生问题时watchdog会发送告警通知给用户组，Zabbix服务器不会停止工作，它会一直等待，直到数据库恢复正常。 Log unmatched SNMP traps：Zabbix接收到的SNMP traps不能与任何一个监控项的配置匹配时，将其记录到日志中。 agent代理程序部署Zabbix分布式架构时，需要通过Proxies页面添加Proxy服务器。在这个页面可以创建和管理Proxy。单击页面右上角的Create proxy按钮可以创建新的Proxyserver，也可以选择一个或多个Proxy，单击左下方的Enable Hosts按钮启用Proxy；单击Disable Hosts按钮禁用Proxy；单击Delete按钮删除Proxy。 认证Zabbix中用户认证方式主要有三种：internal、LDAP 和HTTP authentication，系统默认使用internal认证方式。 HTTP认证方式是基于Apache Web服务器的身份认证，使用这种方式时用户必须在Zabbix系统中已经存在，只是用户密码不再被使用。 LDAP认证方式也是比较常用的，通常和公司内部的LDAP（支持Microsoft Active Directory 和 OpenLDAP）系统集成用于检测用户的合法性。使用LDAP认证之前，需要确认用户已经在Zabbix系统中存在，只是用户密码不再被使用。 用户群组使用User groups页面可以完成用户组的创建和管理。单击页面右上角的Create user group 按钮可以创建新用户组，也可以选择一个或多个用户组，单击左下方的Enable按钮启用选中的用户组；单击Disable按钮禁用选中的用户组；单击Enable debug mode按钮启用debug模式；单击Disable debug mode按钮禁用debug模式；单击Delete按钮可以删除选中的用户组。 用户使用Users页面可以完成用户创建和管理。单击页面右上角的Createuser按钮可以创建新用户，也可以选择一个或多个用户，单击左下方的Unblock按钮允许登录状态为Blocked的用户可以重新访问前端页面；单击Delete按钮可以删除选中的用户。 报警媒介类型通过Media types页面可以完成告警方式的创建和管理。单击页面右上角的Create media type 按钮可以创建告警方式，也可以选择一个或多个告警方式，单击左下方的Enable按钮启用选中的告警方式；单击Disable按钮禁用选中的告警方式；单击Delete按钮可以删除选中的告警方式。 脚本Zabbix中我们可以开发一些脚本来扩充系统的功能，在Scripts页面中可以创建和管理脚本。单击页面右上角的Create script 按钮可以创建脚本，也可以选择一个或多个脚本，单击左下方的Delete按钮删除脚本。 脚本定义好后，在Dashboard、Latest data、Status of triggers、Events和Maps页面中出现的主机名称上单击鼠标，在弹出菜单中点击脚本名称就可以执行了，脚本执行的结果会在一个新的浏览器页面中显示。脚本可以在Zabbix server上执行，也可以在agent上执行。 单击Scripts页面右上角的Createscript按钮，填写脚本名称、需要执行的命令等，然后点击Add按钮就可以保存创建的脚本。 配置页面参数的含义如下： Name：脚本的名称。在这里不仅定义脚本名称，还可以定义菜单中显示的目录层次，例如：Tools/test script或者Tools/Tools/testscript 多级目录。名称中含有“/”或“\”，必须用反斜杠 \ 进行转义，例如： \ 或 \/ 。 Type：脚本的类型。可以是IPMI或Script。 Execute on：选择脚本在哪里执行，可以选择Zabbix server或Zabbix agent。如果选择在agent上执行脚本，需要在agent配置文件中将EnableRemoteCommands 设置为 1 。 Commands：脚本中执行的命令。这些命令必须是全路径的，如：/usr/bin/nmap。在命令中可以使用宏变量，包括：{HOST.CONN}、{HOST.IP}、{HOST.DNS}、{HOST.HOST}、{HOST.NAME} 及用户定义的宏变量。为了防止宏变量的值中有空格（例如Host name），需要用引号括起来。 Command：脚本类型为IPMI时需要执行的IPMI 命令。 Description：脚本的描述信息。 User group：选择可以执行脚本的用户组，All指所有的用户组。 Host group：选择可以执行脚本的主机组，All指所有的主机组。 Required host permissions：选择主机组的权限。Read或Write。只有具有相应权限级别的用户可以执行脚本。 Enable confirmation：勾选此项后，脚本执行前会弹出确认窗口，经过你确认后脚本才会执行，防止无意间执行一些危险的脚本命令。 Confirmation text：确认窗口中的提示内容，可以包含{HOST.CONN}、{HOST.IP}、{HOST.DNS}、{HOST.HOST}、{HOST.NAME} 及用户定义的宏变量。 评估Zabbix性能时，很重要的一个方法就是查看这个页面显示的数据，如果在队列中没有数据，说明Zabbix系统性能很好，如果有很多数据堆积在队列中就说明Zabbix性能遇到了瓶颈，不能及时处理队列中的数据，这时就需要对Zabbix服务器进行调优。 通过选择右上角的下拉框选项，可以从Overview、Overview by proxy和Details三种视图展现队列中的数据。]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix安装与配置]]></title>
    <url>%2F2019%2F04%2F22%2Fzabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[介绍 Zabbix是一个企业级的开源监控软件，可以监控IT基础架构的可用性和应用的性能，为用户提供集中管理、分布式监控的一站式（all in one）监控解决方案，是一款真正的开源产品（True Open source）。采用GPL协议发布，不论是商业或非商业的使用没有任何限制，可以说是绝对的自由使用。 Zabbix最基本的目的是收集监控数据，将收集的数据统一保存到数据库中进行分析处理，利用Web前端页面可以轻松的将这些监控数据实时展示出来。通过与设定的阈值进行比较触发特定的事件并产生相应的动作，发出告警通知或执行远程命令。Zabbix 提供了多种监控方式用来监控基础架构的各个方面，不仅有专用的Agent，还支持External checks、SNMP、IPMI、JMX monitoring、SSH checks等多种方式收集监控数据，具有丰富的功能和灵活的扩展性。事实上，几乎所有你能想到的都可以在Zabbix中实现监控。 概念组件 Zabbix监控系统包含四个主要组件：Zabbixserver、Zabbix proxy、Zabbix database和Zabbix GUI。每个组件都有其自身的特点和要求： Zabbix server：这是核心引擎，负责收集或接收来自被监控设备的数据。它是用C语言开发的，与Zabbix agents、Zabbix proxy和 Zabbix database进行通信。它是最主要的组件，管理所有的规则（包括收集监控数据、触发器、告警等等）。 Zabbix GUI：这是 Zabbix Web前端管理页面，用户通过Web前端页面可以查看Zabbixserver收集的数据，也可以对Zabbix server进行配置。它是用 PHP 开发的，使用支持 PHP程序运行的 web 服务器 (Apache或Nginx)，并与 Zabbix 数据库通信。 Zabbix database： 这是 Zabbix 数据存储库。 Zabbix的后端数据库可以是 Oracle、 IBM DB2、PostgreSQL、MySQL 或 SQLite3。在这本书中，我们将使用MySQL 作为数据库。 Zabbix proxy：这是一个可选的组件，利用它来实现分布式监控架构或分担Zabbix server的负载，提高Zabbix server的性能。它的主要功能是协助 Zabbix server从被监视的主机或设备收集数据。Zabbix proxy收集的数据首先存放到本地临时数据库中，随后定时发送到 Zabbix server中，即便Zabbix server和Zabbix proxy的连接断开也不会导致数据的丢失（数据保留的时间可在proxy的配置文件中设置）。在3.0版本中原生支持Zabbix server和Zabbix proxy之间的数据加密传输（基于证书或者基于共享秘钥的加密都是支持的）。 架构 Zabbix是一个三层架构，在实现时我们需要安装以下三个服务器，即Web服务器、Database服务器和Zabbix服务器。如果需要监控的规模比较小（几台或几十台主机），三个服务器可以同时安装在一个物理服务器中，这种方式的优点是安装配置简单快速，初期部署成本比较低。随着监控规模的不断扩大，需要保存和处理更多的监控数据，也会有更多的运维人员访问Zabbix Web前端页面，这样势必会让Zabbixserver的处理性能下降，出现断图、Web前端页面访问慢等问题。这时我们可以将Web服务器、Database服务器和Zabbix服务器拆分，分别安装到不同的物理服务器中。这种方式中每个服务器组件使用专用的硬件资源，可以解决相应的性能问题，但是需要增加服务器硬件的投入。 zabbix数据处理流程 在标准的Zabbix数据处理流程中，主要是通过几个不同的数据源端发送数据到Zabbix server，所有的数据都会保存到数据库中，并通过Web GUI为用户展现结果。发送数据的主要源包括： Zabbix agent Zabbix sender Other agent （如脚本或者自定义的第三方的agent） Zabbix proxy zabbix部署架构 Zabbix在大部分场景中以集中式架构部署即可满足要求，所谓集中式架构就是无论Zabbix server、Database server和Web server是否安装在同一台服务器中，所有的监控数据都是由Zabbix server收集。如果你需要监控的IT基础架构有多个分中心或分支机构，建议采用分布式架构部署，在每个分中心或分支机构增加Zabbix proxy，由Zabbix proxy收集本地的监控数据后统一传输到Zabbix server中存储和处理，实现分布式架构、集中监控的方案。 安装与配置Server端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109===========================================================================================环境：系统：CentOS Linux release 7.4.1708 (Core)，地址：192.168.2.140，此次测试将Server端与agent端安装在同一台主机上。关闭防火墙与SELinux。===========================================================================================------------------------------ 安装mariadb数据库------------------------------[root@zabbix ~]# yum install mariadb-server[root@zabbix ~]# vim /etc/my.cnf[mysqld]skip_name_resolve = ONinnodb_file_per_table = ON[root@zabbix ~]# systemctl start mariadb.service[root@zabbix ~]# systemctl enable mariadb.service[root@zabbix ~]# mysql_secure_installation[root@zabbix ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; CREATE DATABASE zabbix CHARSET 'utf8';MariaDB [(none)]&gt; GRANT ALL ON zabbix.* TO 'zbxuser'@'%' IDENTIFIED BY 'zbxpass';MariaDB [(none)]&gt; FLUSH PRIVILEGES;----------------------------- 安装zabbix_server-----------------------------[root@zabbix ~]# wget https://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm# 4.0版本下载地址：https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm [root@zabbix ~]# yum install -y zabbix-release-3.0-1.el7.noarch.rpm# 下载源文件并安装[root@zabbix ~]# vim /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix Official Repository - $basearchbaseurl=http://repo.zabbix.com/zabbix/3.0/rhel/7/$basearch/enabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX[zabbix-non-supported]name=Zabbix Official Repository non-supported - $basearchbaseurl=http://repo.zabbix.com/non-supported/rhel/7/$basearch/enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIXgpgcheck=0# 将gpgcheck都改为0# 上面的repo地址可能连接有问题，可以将[zabbix]中的baseurl改为阿里地址，https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/。[root@zabbix ~]# yum install -y zabbix-server-mysql.x86_64 zabbix-web.noarch zabbix-get.x86_64 zabbix-web-mysql.noarch zabbix-agent.x86_64 zabbix-sender.x86_64 httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml # 安装4.0版本需要先安装libiksemel.so.3，libiksemel.so.3在iksemel-1.4-6.sdl7.x86_64.rpm包中，下载地址：https://centos.pkgs.org/7/puias-unsupported-x86_64/iksemel-1.4-6.sdl7.x86_64.rpm.html# 安装zabbix相关包# zabbix程序组件# zabbix_server：服务端守护进程# zabbix_aget：agent守护进程# zabbix_proxy：代理服务器，可选；# zabbix_database：存储系统，mysql/pgsql# zabbix_web：web GUI# zabbix_get:命令行工具，测试向agent端发起数据采集请求使用# zabbix_sender：命令行，测试向server端发送数据# zabbix_java_gateway：java网关------------------ 导入数据库------------------[root@zabbix ~]# cp /usr/share/doc/zabbix-server-mysql-3.0.27/create.sql.gz /root[root@zabbix ~]# gzip -d create.sql.gz[root@zabbix ~]# mysql -uzbxuser -h 127.0.0.1 -pzbxpass zabbix &lt; ./create.sql[root@zabbix ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; USE zabbix;MariaDB [(none)]&gt; SHOW tables;# 这时可以看到导入的表----------------------------- 配置zabbix_server-----------------------------[root@zabbix ~]# cd /etc/zabbix/[root@zabbix ~]# cp zabbix_server.conf&#123;,.bak&#125;[root@zabbix ~]# vim zabbix_server.confListenPort=10051# zabbix-server默认监听端口为10051SourceIP=192.168.2.140# 如果Server端有多个IP，此项一定要定义，这是被客户端允许采样的IPLogType=file# 日志格式，有三种，默认是file，表示自己记录到一个文件中。这个file就是下面LogFile定义的路径LogFile=/var/log/zabbix/zabbix_server.logLogFileSize=10# 指明日志文件大小，大于这里指定的数字将会滚动。日志是否滚动，0表示不滚动DebugLevel=3# 日志级别，3表示正常，数字越大越详细，最大是5PidFile=/var/run/zabbix/zabbix_server.pidDBHost=localhost# zabbix数据库的地址DBName=zabbix# 数据库名字DBUser=zbxuser# 连接数据库用的用户名DBPassword=zbxpassDBSocket=/var/lib/mysql/mysql.sock# 连接数据库用的sock，用rpm包安装的mysql，sock在/var/lib/mysql/mysql.sock，这是在my.cnf中定义的DBPort=3306SNMPTrapperFile=/var/log/snmptrap/snmptrap.logTimeout=4AlertScriptsPath=/usr/lib/zabbix/alertscriptsExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000[root@zabbix ~]# systemctl start zabbix-server[root@zabbix ~]# ss -tln# 查看是否监听10051端口[root@zabbix ~]# cd /etc/httpd/conf.d/[root@zabbix ~]# vim zabbix.confphp_value date.timezone Asia/Shanghai # 配置时区[root@zabbix ~]# systemctl start httpd下面进入页面访问安装，地址:IP/zabbix 上图输入在mysql中设置的用户名与密码 上图只输入服务器地址与端口即可 上图页面中提示你Zabbix前端已经成功安装，并在目录/etc/zabbix/web/中创建了配置文件zabbix.conf.php。 在上图的Web前端登录页面中，我们输入Zabbix默认的用户名和密码，用户名：Admin，密码：zabbix agent端12345678910111213141516171819202122232425262728---------------------------- 安装zabbix_agent----------------------------[root@zabbix ~]# yum install zabbix-agent zabbix-sender# 这里以在server端安装agent端为例，可按此方法在其他主机安装agent端[root@zabbix ~]# cd /etc/zabbix/[root@zabbix ~]# cp zabbix_agentd.conf&#123;,.bak&#125;[root@zabbix ~]# vim zabbix_agentd.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0Server=127.0.0.1,192.168.2.140# 被动模式下需要设置，从哪个服务器连接agent，这里要输入的是zabbix_server的地址。ServerActive=127.0.0.1# 主动模式下需要设置，向哪个服务器发送数据，这里要输入的是zabbix_server的地址。# 主动与被动指的是客户端主动还是被动Hostname=Zabbix server# 主动模式下必须设置，被动模式不需要Include=/etc/zabbix/zabbix_agentd.d/[root@zabbix ~]# systemctl start zabbix-agent[root@zabbix ~]# ss -tln# 查看是否监听10050端口[root@zabbix ~]# zabbix_get -s 192.168.2.140 -k "system.cpu.switches"1456242# 测试，采集CPU的某个值[root@zabbix ~]# zabbix_get -s 192.168.2.140 -k "system.cpu.switches"zabbix_get [4179]: Get value error: cannot connect to [[192.168.2.140]:10050]: [111] Connection refused# 如果agent服务未启动，采集时会报错。 配置中文页面 点击右上角的Admin图标，进入页面选择Language为Chinese(zh_CN)，再次刷新页面后就会变为中文，但还是会有问题。就是在图形展示时，图形下的说明文字会有乱码问题，解决方法如下： 1234567891011从windows系统中复制simkai.ttf（楷体）字体到CentOS系统[root@zabbix ~]# cp simkai.ttf /usr/share/fonts/# 将字体复制到/usr/share/fonts/[root@zabbix ~]# chmod +r /usr/share/fonts/simkai.ttf# 不知此步是否有用，因为看到有教程中simkai.ttf的权限是544[root@zabbix ~]# alternatives --install /usr/share/zabbix/fonts/graphfont.ttf zabbix-web-font /usr/share/fonts/simkai.ttf 100# 这是将字体加入到zabbix-web-font中[root@zabbix ~]# alternatives --display zabbix-web-font...Current `best' version is /usr/share/fonts/simkai.ttf.# 显示zabbix-web-font目前的字体，应该有上面的字样]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis使用]]></title>
    <url>%2F2019%2F04%2F10%2Fredis%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[查询redis库中数据的类型123172.16.201.120:7000&gt; TYPE recommend_datasource_ghzongyilist# 使用TYPE可以查看数据的类型]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logrotate配置使用]]></title>
    <url>%2F2019%2F04%2F04%2Flogrotate%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念 logrotate是个十分有用的日志切割工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 配置文件12345678910111213141516171819202122232425262728293031323334[root@webdav ~]# vim /etc/logrotate.conf# see "man logrotate" for details# rotate log files weekly weekly# 每周轮替一次，也就是多久生成一个新的日志文件# keep 4 weeks worth of backlogsrotate 4# 保留4个轮替日志 # create new (empty) log files after rotating old onescreate# 轮替后创建新的日志文件 # use date as a suffix of the rotated filedateext# 使用时间作为轮替文件的后缀 # uncomment this if you want your log files compressed#compress# 如果需要压缩日志，去除注释# RPM packages drop log rotation information into this directoryinclude /etc/logrotate.d# 让/etc/logrotate.d目录下面配置文件内容参与轮替 # no packages own wtmp and btmp -- we'll rotate them here/var/log/wtmp &#123; # 轮替对象为/var/log/中的wtmp文件 monthly # 每个月轮替一次 create 0664 root utmp #创建新的日志文件的权限，所属用户所属组 minsize 1M # 日志大小大于1M后才能参与轮替 rotate 1 # 保留一个轮替日志文件 &#125;/var/log/btmp &#123; missingok # 如果日志文件不存在，继续进行下一个操作，不报错 monthly create 0600 root utmp rotate 1&#125; 常用参数 参数 描述 daily 每天轮替一次 weekly 每周轮替一次 monthly 每月轮替一次 yearly 每年轮替一次 rotate 保留几个轮替日志文件 ifempty 不论日志是否空，都进行轮替 notifempty 若日志为空，则不进行轮替 create 旧日志文件轮替后创建新的日志文件 size 日志达到多少后进行rotate minsize 文件容量一定要超过多少后才进行rotate nocompress 轮替但不进行压缩 compress 压缩轮替文件 dateext 轮替旧日志文件时，文件名添加-%Y %m %d形式日期，可用dateformat选项扩展配置。 nodateext 旧日志文件不使用dateext扩展名，后面序数自增如”*.log.1” dateformat 只允许%Y %m %d和%s指定符。注意：系统时钟需要设置到2001-09-09之后，%s才可以正确工作 sharedscripts 作用域下文件存在至少有一个满足轮替条件的时候，执行一次prerotate脚本和postrotate脚本。 prerotate/endscript 在轮替之前执行之间的命令，prerotate与endscript成对出现。 postrotate/endscript 在轮替之后执行之间的命令，postrotate与endscript成对出现。 olddir 将轮替的文件移至指定目录下 missingok 如果日志文件不存在，继续进行下一个操作，不报错 切割日志生效时间1234567891011121314151617[root@xor-paasjobworker ~]# cat /etc/anacrontab # /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobsRANDOM_DELAY=45 # 随机延迟时间是45分钟# the jobs will be started during the following hours onlySTART_HOURS_RANGE=3-22# 生效时间范围是3点到22点#period in days delay in minutes job-identifier command1 5 cron.daily nice run-parts /etc/cron.daily7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly 实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[root@RBO1-POSTER3 ~]# yum install -y logrotate[root@RBO1-POSTER3 ~]# systemctl start rsyslog# 安装好logrotate后要启动rsyslog[root@RBO1-POSTER3 ~]# vim /etc/logrotate.d/nginx/var/log/nginx/*.log &#123;# 定义一个对nginx的log日志进行切割的脚本，上面是日志的地址，如果有多个路径可以使用空格或换行来分隔# daily # 这里注释的意义不大，因为如果不配置，也会使用logrotate.conf的默认配置 size = 50M # 50M切割一次 missingok # 如果日志文件不存在，继续进行下一个操作，不报错 rotate 5 # 保留5个日志文件，这并不包括本身的日志文件，只是切割后的日志文件# compress# delaycompress notifempty# create 640 nginx adm sharedscripts postrotate if [ -f /var/run/nginx.pid ]; then kill -USR1 `cat /var/run/nginx.pid` fi endscript# 这个脚本的功能应该是先判断nginx.pid文件是否存在，如果存在证明nginx服务启动了，之后让nginx向新的日志文件中写入日志，kill发送-USR1信号给nginx的pid。信号的具体作用没弄明白。&#125;[root@RBO1-POSTER3 ~]# /usr/sbin/logrotate --force /etc/logrotate.d/nginx# 这是强制执行一次脚本，使用logrotate命令加--force选项，最后指定要执行的脚本。也可以使用短选项-f，再配以-v选项显示详细信息[root@RBO1-POSTER3 ~]# ll /var/log/nginx/总用量 427804-rw-r--r--. 1 nginx root 34053285 4月 4 10:47 access.log-rw-r--r--. 1 nginx root 42083626 4月 4 10:00 access.log.1-rw-r--r--. 1 nginx root 39990852 4月 4 09:00 access.log.2-rw-r-----. 1 nginx root 276662461 4月 3 14:21 access.log-20190403-rw-r--r--. 1 nginx root 26968952 4月 4 08:00 access.log.3-rw-r--r--. 1 nginx root 12106704 4月 4 07:00 access.log.4-rw-r--r--. 1 nginx root 3937887 4月 4 06:00 access.log.5-rw-r--r--. 1 nginx root 14267 4月 4 10:47 error.log-rw-r--r--. 1 nginx root 5876 4月 4 09:56 error.log.1-rw-r--r--. 1 nginx root 3470 4月 4 08:45 error.log.2-rw-r-----. 1 root root 2184157 4月 3 08:35 error.log-20190403-rw-r--r--. 1 nginx root 2762 4月 4 07:54 error.log.3-rw-r--r--. 1 nginx root 338 4月 4 06:51 error.log.4-rw-r--r--. 1 nginx root 337 4月 4 05:33 error.log.5# 强制执行多次后发现，会有一个以日志命名的日志，这是logrotate脚本正常执行的结果，以数字结尾的日志共有5个，这是强制执行脚本后产生的，还有一个本身的日志。所以强制执行脚本后，也不会按配置文件中定义的只保留5个轮替日志文件，正常产生的轮替日志是不会被删除的。另外，如果需要按小时执行轮替就需要使用crontab定时任务，logrotate最小只支持按天轮替。[root@RBO1-POSTER3 ~]# crontab -e*/60 * * * * /usr/sbin/logrotate --force /etc/logrotate.d/nginx# 每60分钟执行一次，这与按每小时执行是不一样的。[root@xor-paasjobadmin ~]# logrotate -d /etc/logrotate.d/nginx reading config file /etc/logrotate.d/nginxAllocating hash table for state file, size 15360 BHandling 1 logsrotating pattern: /xor/data2/log/nginx/*log after 1 days (30 rotations)empty log files are not rotated, old logs are removedconsidering log /xor/data2/log/nginx/4k_access.log log does not need rotating (log has been rotated at 2019-6-20 12:0, that is not day ago yet)considering log /xor/data2/log/nginx/4k_error.log log does not need rotating (log has been rotated at 2019-6-20 12:0, that is not day ago yet)not running postrotate script, since no logs were rotated# 使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。[root@xor-paasjobadmin ~]# cat /etc/cron.daily/logrotate man-db.cron mlocate [root@xor-paasjobadmin ~]# cat /etc/cron.daily/logrotate #!/bin/sh/usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"fiexit 0# logrotate定时任务。logrotate需要的cron任务应该在安装时就自动创建了 在指定时间切割12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 日志转储流程# crond服务加载/etc/cron.d/0hourly ---&gt;在每小时的01分执行/etc/cron.hourly/0anacron脚本 ---&gt;执行anacron ---&gt;根据/etc/anacrontab的配置执行/etc/cron.daily，/etc/cron.weekly，/etc/cron.monthly ---&gt;执行/etc/cron.daily/下的logrotate脚本 ---&gt;执行logrotate ---&gt;根据/etc/logrotate.conf配置执行脚本/etc/logrotate.d/nginx ---&gt;转储nginx日志成功# 定义每天00点00分转储varnish日志--------- 方法一---------vim /etc/anacrontab# /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobs#RANDOM_DELAY=45RANDOM_DELAY=0 # 表示延迟为0分钟# the jobs will be started during the following hours only#START_HOURS_RANGE=3-22START_HOURS_RANGE=0-22 # 执行从0点到22点#period in days delay in minutes job-identifier command1 0 cron.daily nice run-parts /etc/cron.daily # 延迟为0分钟7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly# 修改红字部分# period in days 是表示1天、7天、1个月执行一次# delay in minutes 是延迟的分钟数# nice设置优先级为10，范围为-20（最高优先级）到19（最低优先级）# run-parts 是一个脚本，表示会执行它后面目录里的脚本vim /etc/cron.d/0hourly# Run the hourly jobsSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root00 * * * * root run-parts /etc/cron.hourly# 修改红字部分，表示每小时的每0分钟开始执行# 这种方法会影响到 /etc/cron.daily，/etc/cron.weekly，/etc/cron.monthly 下所有脚本的自动执行时间--------- 方法二---------mkdir -p /etc/logrotate.daily.0mv /etc/logrotate.d/varnish /etc/logrotate.daily.0/# 新建一个目录，将varnish的logrotate任务放入，这样此目录中的任务就不受logrotate的配置文件控制了crontab -e00 00 * * * /usr/sbin/logrotate -f /etc/logrotate.daily.0/varnish &gt; /dev/null 2&gt;&amp;1# 通过定时任务来执行这个logrotate任务。vim /etc/logrotate.daily.0/varnish/xor/data2/log/varnish/varnishncsa.log &#123; daily rotate 30 compress delaycompress missingok postrotate /bin/kill -HUP `cat /var/run/varnishncsa.pid /run/varnishncsa/varnishncsa.pid 2&gt;/dev/null` 2&gt; /dev/null || true endscript&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>日志切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS配置使用]]></title>
    <url>%2F2019%2F04%2F03%2FNFS%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念 ext3、ext2等文件系統工作在內核空間，任何程序只要能夠執行都工作在用戶空間，如mke2fs命令工作在用戶空間，NFS是文件系統，工作在內核空間；內核空間中的程序只有內核自我能夠管理。 向磁盤讀寫數據要通過內核調用也叫函數調用，如read()，write()，函數執行要經過一個過程，所以函數調用又叫過程調用；一般本地應用程序實現某個操作的時候都是通過本地的過程調用來完成的，叫作local procedure call，就是本地的兩個程序或程序與內核之間調用函數完成某種功能的過程；作爲程序員，如果想與某個程序交互，只要某個程序提供函數就可以交互了； LPC：本地過程調用，local procedure call RPC：遠程過程調用，Remote procedure call 客戶端與遠程服務器端通過一個RPC客戶端（RPC客戶端叫stub：存根客戶端）與服務器端（運行的是RPC server）聯系，實現數據的讀取，RPC服務器端監聽的套接字是隨機的。linux提供rpc服務的程序叫Portmap，監聽在111/tcp, 111/udp端口。 RPC（框架）是一種編程技術，可以簡化分布式應用程序的開發。从RPC的客戶端向RPC的服務器端發起通信，RPC服務器端再將用戶請求真正轉給客戶端真正請求的服務器端。c –&gt; rpc c –&gt; rpc s –&gt; s NFS Client → NFS Server RPC通信既可基於二進制也可基於文本格式進行數據交換，基於文本格式比較常見的叫XMLRPC，之後又發展出SOAP（Simple Object Access Protocol）簡單對象訪問協議。 RPC是一種協議或編程技術，連接兩臺主機，像一臺主機一樣實現數據交換。 將遠程的設備掛載到本地時，在本地才叫NFS系統。NFS也是一種協議，現在用NFSv3，NFSv4版本，服務器端只能驗證IP不能驗證用戶名 NFS對服務器來講有兩個組件 服務器端：nfs-utils，安裝此軟件包就可配置爲服務器端了。 因爲NFS是基於RPC運行的，所以要確保RPC在linux上的服務portmap已經啓動。portmap是監聽在111/tcp, 111/udp端口的。還可以使用rpcinfo -p來查看一臺主機上的所有rpc進程所監聽的端口號，如：rpcinfo -p localhost，會查到有很多端口監聽，這些是NFS啓動時向RPC請求的端口，nfs會啓動三個進程：nfsd(nfs的主服務)，mountd（接受客戶端掛載請求的）, quotad（限定客戶端在本地只能使用多大磁盤空間的）；nfsd監聽在2049/tcp端口，這是注冊使用的；mountd，quotad會改變端口，是半隨機的端口，是RPC服務幫助選取的，因爲是RPC隨機選取的，所以叫半隨機的端口，可能使用其他服務的端口，所以最好配置一個固定端口給這兩個服務，默認是使用隨機端口。nfslock是分布式文件鎖，當一臺主機在讀取NFS磁盤數據時，要先加鎖，這樣其他主機就不能讀取磁盤數據了，避免磁盤崩潰。NFS配置文件/etc/exports，在此配置文件中定義共享哪個文件系統，哪些可以使用文件系統，讓其可被掛載到本地像使用本地磁盤一樣使用。 NFS工作流程 對於NFSv3來講，客戶端先去聯系服務器上的portmap（RPC服務器），RPC服務器會告訴客戶端rpc.mountd所監聽的端口號，當這個端口號回傳給客戶端以後，客戶端會重新連接rpc.mountd，rpc.mountd返回給用戶一個初始化文件句柄或叫訪問令牌，也就是在配置文件中定義的IP地址訪問時才會發給令牌，這時客戶端來找nfsd，nfsd監聽在2049端口上。這時就能訪問了。 讓mountd和quotad等進程監聽在固定端口，編輯配置文件/etc/sysconfig/nfs，其中有MOUNTD_PORT=一項，定義好端口號即可。QUOTAD_PORT=也一樣。LOCKD_TCPPORT=, LOCKD_UDPPORT=是啓動鎖進程要監聽的端口。 实例基本配置1234567891011121314151617181920212223242526272829303132333435[root@webdav ~]# yum install -y nfs-utils[root@webdav ~]# netstat -tlnpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 0.0.0.0:20048 0.0.0.0:* LISTEN 97455/rpc.mountd tcp 0 0 0.0.0.0:43326 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:2049 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:42758 0.0.0.0:* LISTEN 97452/rpc.statd [root@webdav ~]# mkdir /shared[root@webdav ~]# vim /etc/exports/shared 192.168.2.0/24(ro) 192.168.1.0/24(rw)# 配置文件中每一行包含一個共享出去的文件系統以及哪些客戶端可使用此文件系統；每個客戶端後必須跟一個小括號，小括號中定義了客戶端訪問此文件系統時所具有的屬性# /path/to/somedir共享哪個目錄，可以是獨立的分區或目錄，建議使用獨立分區，之後是客戶端列表CLIENT_LIST，多個客戶列表之間用空格分隔。每個客戶端後面必須跟一個小括號，裏面定義了此客戶訪問特性，如訪問權限等。如：# 172.16.0.0/16(ro,async) 192.16.0.0/24(rw,sync)# async異步寫入，sync同步寫入，ro只讀，rw讀寫。# 客戶端可以是單個主機用FQDN或IP定義都可以；也可以用通配符，如*.example.com；也可以是IP/netmask的方式[root@webdav ~]# exportfs -r# 使用此命令重新导出[root@webdav ~]# showmount -e 192.168.2.128Export list for 192.168.2.128:192.168.1.0/24,192.168.2.0/24# -e表示顯示共享了哪些目錄，也可以選程主機上使用此命令查看某主機共享了哪些目錄================= debian系统挂载=================⚡ root@ruopu64  ~  apt install nfs-common # 安装包，如果不安装此包，挂载时会提示"mount: /mnt: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.&lt;type&gt; helper program."。 # 如果debian是服务端，要安装 nfs-kernel-server包⚡ root@ruopu64  ~  mount -t nfs 192.168.2.128:/shared /mnt⚡ root@ruopu64  ~  df -h文件系统 容量 已用 可用 已用% 挂载点...192.168.2.128:/shared 17G 1.3G 16G 8% /mnt showmount命令123456showmount -e NFS_SERVER# 查看NFS服務器“導出”的各文件系統，導出就是共享的意思showmount -a NFS_SERVER# 查看NFS服務器所有被掛載的文件系統及其客戶端對應列表showmount -d NFS_SERVER# 顯示NFS服務器所有導出的文件系統中被客戶端掛載了的文件系統列表 exportfs命令12345-a：跟-r或-u選項同時使用，表示重新掛載所有文件系統或取消導出所有文件系統-r：重新導出-u：取消導出-v：顯示詳細信息exportfs -rav：不必重啓服務，重新導出 设置访问权限123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899======== server========[root@webdav ~]# useradd hadoop[root@webdav ~]# id hadoopuid=1000(hadoop) gid=1000(hadoop) 组=1000(hadoop)# 查看用户与组ID[root@webdav ~]# setfacl -m u:hadoop:rwx /shared/[root@webdav ~]# su - hadoop[hadoop@webdav ~]$ cd /shared/[hadoop@webdav shared]$ touch a.hadoop[hadoop@webdav shared]$ lltotal 0-rw-rw-r-- 1 hadoop hadoop 0 Apr 3 16:24 a.hadoop======== client========[root@primary ~]# groupadd -g 1000 openstack[root@primary ~]# useradd -g 1000 -u 1000 openstack# 创建用户与组ID与服务器端一样的用户，只是用户名不同[root@primary ~]# mount -t nfs 192.168.2.128:/shared /mnt[root@primary ~]# ll /mnt总用量 0-rw-rw-r-- 1 openstack openstack 0 4月 3 2019 a.hadoop# 在客户端挂载NFS系统后，因为用户与组ID与服务器端一样，所以用户和组都变成了openstack======== server========[hadoop@webdav shared]$ exitlogout[root@webdav ~]# vim /etc/exports/shared 192.168.2.0/24(rw) 192.168.1.0/24(rw)[root@webdav ~]# exportfs -ra======== client========[root@primary ~]# su - openstack[openstack@primary ~]$ cd /mnt[openstack@primary mnt]$ lltotal 0-rw-rw-r-- 1 openstack openstack 0 Apr 3 2019 a.hadoop[openstack@primary mnt]$ touch b.openstack[openstack@primary mnt]$ lltotal 0-rw-rw-r-- 1 openstack openstack 0 Apr 3 2019 a.hadoop-rw-rw-r-- 1 openstack openstack 0 Apr 3 2019 b.openstack======== server========[root@webdav ~]# ll /shared/总用量 0-rw-rw-r-- 1 hadoop hadoop 0 4月 3 16:24 a.hadoop-rw-rw-r-- 1 hadoop hadoop 0 4月 3 16:41 b.openstack======== client========[openstack@primary mnt]$ exitlogout[root@primary ~]# rm /mnt/b.openstack rm：是否删除普通空文件 "/mnt/b.openstack"？yrm: 无法删除"/mnt/b.openstack": 权限不够# 這時是不能刪除的，root用戶是不能操作遠程主機上的文件的。======== server========[root@webdav ~]# vim /etc/exports/shared 192.168.2.0/24(rw,no_root_squash) 192.168.1.0/24(rw)# 可用选项如下：# no_root_squash：任何主機以root掛載此目錄都將是管理員了，这样root就可以删除远程文件了。# root_squash：將root用戶映射爲來賓賬號，這是默認功能，不加也會執行# all_squash：無論是誰都轉換爲來賓帳號。# anonuid, anongid：指定映射的來賓賬號的UID和GID[root@webdav ~]# exportfs -ra======== client========[root@primary ~]# umount /mnt[root@primary ~]# mount -t nfs 192.168.2.128:/shared /mnt[root@primary ~]# rm -rf /mnt/b.openstack[root@primary ~]# ll /mnt总用量 0-rw-rw-r-- 1 openstack openstack 0 4月 3 2019 a.hadoop# 文件被删除了[root@primary ~]# vim /etc/fstab 192.168.2.128:/shared /mnt nfs defaults,_rnetdev 0 0# mount的選項中有_rnetdev，表示如果主機不在或無法掛載就跳過[root@primary ~]# umount /mnt[root@primary ~]# mount -a[root@primary ~]# df -hFilesystem Size Used Avail Use% Mounted on192.168.2.128:/shared 17G 1.3G 16G 8% /mnt]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>网络存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux使用]]></title>
    <url>%2F2019%2F04%2F02%2Ftmux%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念 tmux采用C/S模型构建，输入tmux命令就相当于开启了一个服务器，此时默认将新建一个会话，然后会话中默认新建一个窗口，窗口中默认新建一个面板。会话、窗口、面板之间的联系如下： 一个tmux session（会话）可以包含多个window（窗口），窗口默认充满会话界面，因此这些窗口中可以运行相关性不大的任务。 一个window又可以包含多个pane（面板），窗口下的面板，都处于同一界面下，这些面板适合运行相关性高的任务，以便同时观察到它们的运行情况。 安装1⚡ ⚙ root@ruopu64  ~  apt install tmux 实例新建会话123456⚡ root@ruopu64  ~  tmux # 新建会话后，在屏幕的下方会有提示，如："[0] 0:zsh* "test" 13:51 02-4月-19"⚡ root@ruopu64  ~  exit# 退出会话⚡ root@ruopu64  ~  tmux new -s abc# 创建一个叫做abc的会话，提示信息："[abc] 0:zsh* "test" 13:53 02-4月-19" 断开当前会话123⚡ root@ruopu64  ~  tmux detach# 断开会话，下次还可继续操作。会话会在后台运行也可以使用快捷键Ctrl + b松开，再按d 进入断开的会话1234⚡ root@ruopu64  ~  tmux a -t abc# 进入名称为abc的会话⚡ root@ruopu64  ~  tmux attach-session# 进入第一个会话，可以将attach-session简写为a或at 启用鼠标滚动12341. 先按ctrl+B2. set -g mouse on# 这时就启用对所有窗口的鼠标滚动了，但不能选中文本进行复制粘贴3. 按住shift再点击鼠标右键，这时就可以看到复制粘贴了，也可以选中文本了 查看会话123456789⚡ root@ruopu64  ~  tmux list-sessions 1: 1 windows (created Tue Apr 2 13:55:52 2019) [70x21]2: 1 windows (created Tue Apr 2 13:56:05 2019) [70x21]abc: 1 windows (created Tue Apr 2 13:52:59 2019) [70x21] ⚡ root@ruopu64  ~  tmux ls1: 1 windows (created Tue Apr 2 13:55:52 2019) [70x21]2: 1 windows (created Tue Apr 2 13:56:05 2019) [70x21]abc: 1 windows (created Tue Apr 2 13:52:59 2019) [70x21]# 两条命令是一样的，只是将list-sessions简写为了ls 关闭会话1234⚡ root@ruopu64  ~  tmux kill-session -t 2# 关闭名称为2的会话 ⚡ root@ruopu64  ~  tmux kill-session # 关闭所有会话 快捷键 快捷键需要使用Ctrl+b激活控制台，再按下面的按键操作 系统操作 ? 列出所有快捷键；按q返回 d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话 D 选择要脱离的会话；在同时开启了多个会话时使用 Ctrl+z 挂起当前会话 r 强制重绘未脱离的会话 s 列出所有会话，选择并切换会话；在同时开启了多个会话时使用 : 进入命令行模式；此时可以输入支持的命令，例如kill-server可以关闭服务器 [ 进入复制模式；此时的操作与vi/emacs相同，按q/Esc退出 ~ 列出提示信息缓存；其中包含了之前tmux返回的各种提示信息 :new&lt;回车&gt; 启动新会话 $ 重命名当前会话 窗口操作 c 创建新窗口 &amp; 关闭当前窗口 数字键0~9 切换至指定窗口 p 切换至上一窗口 n 切换至下一窗口 l 在前后两个窗口间互相切换 w 通过窗口列表切换窗口 , 重命名当前窗口；这样便于识别 . 修改当前窗口编号；相当于窗口重新排序 f 在所有窗口中查找指定文本 面板操作 ” 将当前面板平分为上下两块 % 将当前面板平分为左右两块 x 关闭当前面板 ! 将当前面板置于新窗口；即新建一个窗口，其中仅包含当前面板 Ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小 Alt+方向键 以5个单元格为单位移动边缘以调整当前面板大小 Space 在预置的面板布局中循环切换；依次包括even-horizontal、even-vertical、main-horizontal、main-vertical、tiled q 显示面板编号 o 在当前窗口中选择下一面板 方向键 移动光标以选择面板 { 向前置换当前面板 } 向后置换当前面板 Alt+o 逆时针旋转当前窗口的面板 Ctrl+o 顺时针旋转当前窗口的面板]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群概念]]></title>
    <url>%2F2019%2F03%2F29%2F%E9%9B%86%E7%BE%A4%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[消息交换和基础结构层 Messaging and Infrastructure Layer：这一层也被称为心跳层，这一层主要包含了如发送心跳信息和集群中各种事务信息 Membership Layer：也叫CCM层，用来计算整个集群中的节点状态信息的大图景，以及同步这个信息给集群中的所有节点，如集群中有几个节点，可以投几票等信息。还有组织集群拓朴的组件，所以它可以拥有整个集群的全局视图。 资源分配层 CRM：资源分配层所采取的每个动作都是通过CRM来实现的，所以它是基础核心层，在每个节点上，CRM负责生成一个CIB，使每个节点都能了解整个集群的所有配置状态等。CRM会在集群中选举出一个节点当作DC，DC负责维持主CIB文档，所有对CIB的修改都应该通过DC来实现，而后由DC同步给其他节点，对CIB的读写都应该通过主CIB，也就是DC上的CIB，不能修改非DC的CIB，因为非DC的CIB是不会同步的。在一个集群中DC是唯一的，而且能做集群范围的修改操作及其他所有操作都是由DC来做出的。CIB是一个位于内存中的（也会同步到磁盘中），XML格式的，保存了集群每个条目的相关信息，包括集群状态，节点成员关系，定义的资源，及资源的关系等，如果要修改CIB的话可以使用各种客户端工具，如cibadmin这样的命令行工具或heartbeat GUI这样的图形化工具。DC还拥有PE和TE两个组件，一旦DC要做一个集群全局范围的修改，Policy Engine将用于实现计算集群的下一个状态，如当某一个节点离去了，此时位于这个节点上的所有资源应该被转移，之后运行在哪个节点就要由DC来决策，决策后还要修改CIB文档，PE还要将状态变化保存到CIB中，DC所做出的决策，如约束，是否爆头等都是由PE计算得出的，之后由TE负责执行。由TE将PE的决策发放给每个CRM，各CRM收到信息后，将指令发送给LRM，LRM将指令发给RA去执行。RA是脚本，可以执行基本的三个操作，start/stop/monitor 群集资源管理器 (CRM) 在资源分配层中执行的每个操作都要经过群集资源管理器。如果资源分配层的其他组件（或更高层中的组件）需要通讯，则它们通过本地 CRM 进行。在每个节点上，CRM 都会维护群集信息库 (CIB) 群集信息库 (CIB) 群集信息库是整个群集配置和当前状态在内存中的 XML 表示。它包含所有群集选项、节点、资源、约束及其之间的关系的定义。CIB 还将更新同步到所有群集节点。群集中有一个主 CIB，由指定协调器 (DC)进行维护。所有其他节点都包含 CIB 复本。 指定协调器 (DC) 群集中的一个 CRM 会被选为 DC。DC 是群集中唯一可以决定需要在整个群集执行更改（例如节点屏蔽或资源移动）的实体。DC 同时也是用于保存 CIB 主副本的节点。所有其他节点都从当前 DC 获取他们的配置和资源分配信息。DC 是在成员资格更改后从群集的所有节点中选出的。 策略引擎 (PE) 只要指定协调程序需要进行群集范围的更改（对新 CIB 作出反应），策略引擎就会根据群集的当前状态和配置计算其下一个状态。PE 还生成一个转换图，包含用于达到下一个群集状态的（资源）操作和依赖性的列表。PE 始终在 DC 上运行。 本地资源管理器 (LRM) LRM一般由CRM提供，代表 CRM 调用本地资源代理。因此它可以执行启动/停止/监视操作并将结果报告给 CRM。LRM 是其本地节点上所有资源相关信息的权威来源。 资源层 最高层是资源层。资源层包括一个或多个资源代理 (RA)。资源代理是已写入的用来启动、停止和监视某种服务（资源）的程序（通常是shell脚本）。资源代理仅由 LRM 调用。第三方可将他们自己的代理放在文件系统中定义的位置，这样就为各自的软件提供了现成群集集成。 Resource Layer：这里是一堆脚本ocf格式或lsb格式，建议使用ocf格式 概念 群集最多可包含 32 个 Linux 服务器。如果群集内的一台服务器发生故障，则群集内的任何其他服务器均可重启动此服务器上的资源（应用程序、服务、IP 地址和文件系统）。 集群中应该有奇数个节点，如果是偶数，应该引入仲裁设备，集群中的节点通过心跳信息通告自己的健康状态，而不是探测其他主机，这意味着每个节点上都要运行一个应用程序，这些应用程序在固定的IP地址和端口上工作，通常因为是一对多的通信关系，因此是通过多播的方式向多播域内发送心跳信息和集群事务信息，其他主机看到这个信息就知道这个主机是在线的，这种功能的实现的层次称为message layer，message layer不但能传送心跳，还能传送集群事务信息，比如：如果集群发生分裂的话，失去联系并不具备法定票数的主机会被杀死。这就是集群事务内的决策信息。任何应用要想实现高可用，就要调用message layer提供的多播模式传递心跳信息和集群事务信息完成集群内部资源运行的决策，但不是所有应用都有这种能力，这就需要由CRM集群资源管理器实现，它向上可以为不具备高可用能力的服务提供高可用性，让其可以利用message layer完成高可用。向下，它利用message layer传递过来的各节点的心跳和集群事务信息，形成一个大的决策图景，从而决策都由CRM决定。因为各种资源的启动方式各有不同，为了避免这种麻烦，在CRM之上又加入了一个层次，叫LRM本地资源管理器。本地资源管理器一般都是由集群资源管理器提供的，本地资源不能做出一个资源应该如何启动与关闭，而要借助资源代理RA来实现，这是第四个层次。在每个节点上都有众多的RA，它是帮助启动关闭监控资源的脚本 。 资源类型 Primitive：主资源，只能运行于集群内的某单个节点；只能启动一份，也称作native Group：组资源，这是一个容器类资源，它可以包含一个或多个资源，这些资源可通过“组”这个资源统一进行调度 Clone：克隆资源，可以在同一个集群内的多个节点运行多份克隆； Master/slave：主从资源，在同一集群内部于两个节点运行两份资源，其中一个为主一个为从 资源的约束的关系 location：位置约束，定义资源对节点的倾向性；用数值表示，从负无穷到正无穷 colocation：排列约束，定义资源彼此间“在一起”的倾向性；从负无穷到正无穷 分组：也能实现将多个资源绑定在一起；但不能让资源不在一起 Order：顺序约束，定义资源在同一个节点上启动时的先后顺序； 运行在哪个节点，是在资源管理器的接口上进行配置，配置有三：1.这个资源更倾向运行在哪个节点上；2.这个资源更倾向与哪个资源运行在一起，注意：一个资源不能称之为服务，比如构建一个高可用的web集群，需要IP地址，进程，页面文件等，所以高可用服务与高可用资源是两回事。高可用服务可能包括多个高可用资源。一个高可用集群中的高可用资源可能有多个，而且要分类在一起才能构建成一个服务，比如，要启动三个资源，IP在第一个节点上，进程在第二个节点上，页面文件在第三个节点上，这是没用的，因为它们要同进退的。所以哪些资源要运行在一起，不能分开。这叫资源的排列约束。这主要是定义资源在一起的倾向性的。3. 如果多个资源必须运行在同一个节点上，并提供同一个服务工作，那是否有先后次序关系呢？是否要先启动一个再启动一个。比如：是先挂载页面文件还是先启动web进程。这就是次序约束。 参考： SUSE Linux Enterprise High Availability Extension 11 SP4 高可用性指南]]></content>
      <categories>
        <category>Cluster</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[corosync&pacemaker集群部署]]></title>
    <url>%2F2019%2F03%2F29%2Fcorosync%26pacemaker%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[概念OpenAIS OpenAIS是基于SA Forum 标准的集群框架的应用程序接口规范。OpenAIS提供一种集群模式，这个模式包括集群框架，集群成员管理，通信方式，集群监测等，能够为集群软件或工具提供满足 AIS标准的集群接口，但是它没有集群资源管理功能，不能独立形成一个集群。OpenAIS组件包括AMF，CLM，CKPT，EVT，LCK，MSG，TMR，CPG，EVS等，因OpenAIS分支不同，组件略有不同。OpenAIS主要包含三个分支：Picacho，Whitetank，Wilson。Wilson是最新的，比较稳定的版本是从openais 1.0.0到openais1.1.4。Whitetank现在是主流分支版本，比较稳定的版本是openais0.80到openais0.86。Picacho第一代的OpenAIS的分支，比较稳定的版本是openais0.70和openais0.71。现在比较常用的是Whitetank和Wilson，两者之间有很多不同。OpenAIS从Whitetank升级到Wilson版本后，组件变化很大，Wilson把Openais核心架构组件独立出来放在Corosync（Corosync是一个集群管理引擎）里面。Whitetank包含的组件有AMF，CLM，CKPT，EVT，LCK ，MSG，CPG，CFG，EVS，aisparser，VSF_ykd，bojdb等。而Wilson只含有AMF，CLM，CKPT，LCK, MSG，EVT，TMR（TMR，Whitetank里面没有），这些都是AIS组件。其他核心组件被放到了Corosync内。Wilson被当做Corosync的一个插件。 corosync Corosync是OpenAIS发展到Wilson版本后衍生出来的开放性集群引擎工程。可以说Corosync是OpenAIS工程的一部分。OpenAIS从openais0.90开始独立成两部分，一个是Corosync；另一个是AIS标准接口Wilson。Corosync包含OpenAIS的核心框架用来对Wilson的标准接口的使用、管理。它为商用的或开源性的集群提供集群执行框架。Corosync执行高可用应用程序的通信组系统，它有以下特征： 一个封闭的程序组（A closed process group communication model）通信模式，这个模式提供一种虚拟的同步方式来保证能够复制服务器的状态。 一个简单可用性管理组件（A simple availability manager），这个管理组件可以重新启动应用程序的进程当它失败后。 一个配置和内存数据的统计（A configuration and statistics in-memory database），内存数据能够被设置，回复，接受通知的更改信息。 一个定额的系统（A quorum system），定额完成或者丢失时通知应用程序。 cman CMAN是红帽RHCS套件的核心部分，CCS是CMAN集群配置系统，配置cluster.conf，而cluster.conf其实就是openais的配置文件，通过CCS映射到openais。 总结 AIS就是一个通用的应用程序编程接口，OpenAIS是AIS的子项目，标准的集群框架的应用程序接口规范，而corosync是OpenAIS是具体实现。 实例基本实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111===========================================================================================环境：准备三台主机，地址：192.168.2.132（primary, node1）、192.168.2.133（secondary, node2）。192.168.2.128（node3）提供NFS服务。===========================================================================================---------------- node1&amp;2----------------[root@primary ~]# ntpdate ntp.aliyun.com# 同步时间[root@primary ~]# ssh-keygen -t rsa -P ''[root@primary ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.2.133# 让两节点使用密钥通信[root@primary ~]# yum install -y corosync pacemaker# 安装两个包------------- node1-------------[root@primary ~]# cd /etc/corosync/[root@primary corosync]# cp corosync.conf.examplecorosync.conf.example corosync.conf.example.udpu [root@primary corosync]# cp corosync.conf.example corosync.conf[root@primary corosync]# vim corosync.confcompatibility: whitetank# 是否兼容whitetank totem &#123; version: 2 secauth: on # 是否打开安装认证，不让其他主机加入，打开此功能后需要使用corosync-keygen生成密钥 threads: 0 # 工作时的线程数，0表示基于进程模式工作 interface &#123; # 定义多个节点之间通过哪个接口，基于哪个多播地址，监听什么端口完成多播通信 ringnumber: 0 # 环数目，一般为0，类似TTL值 bindnetaddr: 192.168.2.0 # 这通常是要绑定到的接口的*网络*地址，也就是本机所在的网络。这样可以确保您可以跨所有集群节点使用此配置文件的相同实例，而无需修改此选项。 mcastaddr: 239.165.134.13 # 多播地址 mcastport: 5405 # 多播监听端口 ttl: 1 &#125;&#125;logging &#123;# 指定日志系统 fileline: off # 是否记录fileline to_stderr: no # 是否发往标准错误输出，一般不发送 to_logfile: yes # 是否记录到日志文件中 logfile: /var/log/cluster/corosync.log # 日志位置 to_syslog: no # 也发往syslog一份，一般记录一份log即可，所以这里关闭了此功能 debug: off timestamp: on # 是否在日志中打开时间戳功能，如果是on，会影响系统性能 logger_subsys &#123; # 是否记录子系统，记录AMF，这是OpenAIS的子组件 subsys: AMF debug: off &#125;&#125;service &#123;# 加入此段，以插件形式运行pacemaker ver: 0 name: pacemaker use_mgmtd: yes # 此项可有可无 &#125;aisexec &#123; user: root group: root # 以root用户身份运行，此项可有可无 &#125;[root@primary corosync]# ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:83:af:ca brd ff:ff:ff:ff:ff:ff# 查看网卡是否支持MULTICAST[root@primary corosync]# corosync-keygen Corosync Cluster Engine Authentication key generator.Gathering 1024 bits for key from /dev/random.Press keys on your keyboard to generate entropy.Writing corosync key to /etc/corosync/authkey.# 从随机数中生成密钥，需要1024个字符，可能不够，如果不够，可以下载大文件产生IO数，使熵池中生成随机数[root@primary corosync]# ll 总用量 32-rw-r--r-- 1 root root 5384 7月 20 2011 amf.conf.example-r-------- 1 root root 128 4月 2 15:47 authkey# 生成了authkey文件，权限400[root@primary corosync]# scp authkey corosync.conf 192.168.2.133:/etc/corosync/[root@primary corosync]# service corosync start; ssh 192.168.2.133 'service corosync start'Starting Corosync Cluster Engine (corosync): [ OK ]Starting Corosync Cluster Engine (corosync): [ OK ]# 启动两个节点的corosync服务[root@primary corosync]# ss -tlun# 监听了5405多播端口[root@primary corosync]# tail -f /var/log/cluster/corosync.log# 查看日志中是否有报错信息[root@primary corosync]# grep -e "Corosync Cluster Engine" -e "configuration file" /var/log/cluster/corosync.log# 查看两个节点中是否有两条信息，如果有就证明启动成功了[root@primary corosync]# grep TOTEM /var/log/cluster/corosync.log# 查看初始化成员节点通知是否正常发出，应该可以查到内容[root@primary corosync]# grep ERROR: /var/log/cluster/corosync.log | grep –v unpack_resources# # 检查启动过程中是否有错误产生，错误信息表示packmaker不久之后将不再作为corosync的插件运行，因此，建议使用cman作为集群基础架构服务，此处可安全忽略。 [root@primary corosync]# grep pcmk_startup /var/log/cluster/corosync.log# 如果有信息说明启动完成 使用crmsh配置pacemaker crmsh工具在集群中的任一节点上安装均可，不需要每个节点都安装 1234567891011121314151617181920[root@primary corosync]# cd /etc/yum.repos.d/[root@primary yum.repos.d]# wget http://download.opensuse.org/repositories/network:/ha-clustering:/Stable/CentOS_CentOS-6/network:ha-clustering:Stable.repo# 下载opensuse的源，因为crmsh工具是opensuse提供的[root@primary yum.repos.d]# yum install -y crmsh pssh# 安装，连接速度很慢[root@primary yum.repos.d]# crm# 进入crm模式crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 16:03:21 2019Last change: Tue Apr 2 15:51:08 2019 by hacluster via crmd on primary2 nodes configured (2 expected votes)0 resources configuredOnline: [ primary secondary ]No resources# 查看状态，也可以直接使用crm status命令。可以看到DC是主机名为primary的节点，Online: [ primary secondary ]表示有两台主机都在线。 configure配置集群1234567891011121314151617181920212223242526272829303132333435363738394041[root@primary ~]# crm crm(live)# configure# 在子命令中使用此命令，表示配置集群模式 crm(live)configure# help# 查看configure的帮助crm(live)configure# shownode primarynode secondaryproperty cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.18-3.el6-bfe4e80420 \ cluster-infrastructure="classic openais (with plugin)" \ expected-quorum-votes=2# 这是configure中的子命令，显示当前集群配置信息，实际配置文件是XML格式的。显示的property表示集群的全局属性，全局属性是配置集群的基本特性的 crm(live)configure# show xml# 这样就可以看到xml格式的配置文件crm(live)configure# property batch-limit= enable-startup-probes= node-health-strategy= stonith-enabled= cluster-delay= have-watchdog= node-health-yellow= stonith-max-attempts= cluster-ipc-limit= is-managed-default= pe-error-series-max= stonith-timeout= # 执行此命令后，再按两次Tab键，可以看到可以配置的全局属性。stonity-enabled=表示是否必须配置stonith设备，默认为是。crm(live)configure# property stonith-enabled=stonith-enabled (boolean, [true]): Failed nodes are STONITH'd# 按两次Tab键后可以看到默认的值是True crm(live)configure# property stonith-enabled=false# 禁用stonithcrm(live)configure# verify# 校验配置是否有错，如果没错，不会显示任何信息crm(live)configure# shownode primarynode secondaryproperty cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.18-3.el6-bfe4e80420 \ cluster-infrastructure="classic openais (with plugin)" \ expected-quorum-votes=2 \ stonith-enabled=false# 再查看，多了stonith-enabled=false一项crm(live)configure# commit# 提交，这样才能生效。因为上面的配置都是在内存中完成的。 node1234567891011121314151617181920212223242526272829303132333435crm(live)configure# cd ..crm(live)# nodecrm(live)node# ls.. help fence show attribute back cd ready status-attr quit end utilization exit ls maintenance online bye ? status clearstate standby list up server delete # 查看可用的命令crm(live)node# showprimary: normalsecondary: normal# 显示当前在线节点，都是normal状态crm(live)node# standby# 把当前节点设置为备用状态 crm(live)node# showprimary: normal standby=onsecondary: normalcrm(live)node# online# 再让节点上线crm(live)node# status&lt;nodes&gt; &lt;node id="primary" uname="primary"&gt; &lt;instance_attributes id="nodes-primary"&gt; &lt;nvpair id="nodes-primary-standby" name="standby" value="off"/&gt; &lt;/instance_attributes&gt; &lt;/node&gt; &lt;node id="secondary" uname="secondary"/&gt;&lt;/nodes&gt;# 查看当前节点信息 resource1234567891011crm(live)node# cd ..crm(live)# resourcecrm(live)resource# helpcrm(live)resource# status# 查看资源状态crm(live)resource# stop resource-name# 停止资源crm(live)resource# start resource-name# 启动资源crm(live)resource# restart resource-name# 重启资源 ra资源代理123456789101112131415161718192021222324252627282930313233crm(live)resource# cd ..crm(live)# ra crm(live)ra# ls.. info quit end help providers up list cd classes meta ls back exit validate bye ? crm(live)ra# classeslsbocf / .isolation heartbeat linbit pacemakerservicestonith# 显示资源代理模式 crm(live)ra# list lsbabrt-ccpp abrt-oops abrtd acpid atdauditd autofs blk-availability bmc-snmp-proxy certmongercgconfig cgred cman corosync corosync-notifydcpuspeed crond cups drbd exchange-bmc-os-info# 查看lsb中有哪些资源代理可用crm(live)ra# list ocf heartbeatCTDB Delay Dummy Filesystem IPaddr IPaddr2 IPsrcaddrLVM MailTo Route SendArp Squid VirtualDomain Xinetdcrm(live)ra# list ocf pacemakerClusterMon Dummy HealthCPU HealthSMART Stateful SysInfo SystemHealth attribute ifspeedping pingd remote crm(live)ra# list service# service与lsb是一样的crm(live)ra# list stonithcrm(live)ra# help info# info可以查看帮助信息crm(live)ra# info ocf:heartbeat:IPaddr 配置资源primitive123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184------------- node1-------------crm(live)ra# cd ..crm(live)# configurecrm(live)configure# primitive webip ocf:heartbeat:IPaddr params ip=192.168.2.100 nic=eth1 cidr_netmask=24# webip是资源名称，ocf:heartbeat:IPaddr是资源代理，params 用来指明参数，IP地址，网卡，掩码。crm(live)configure# verifycrm(live)configure# commitcrm(live)configure# cd ..crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 16:26:40 2019Last change: Tue Apr 2 16:26:27 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)1 resource configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary# 可以看到webip资源添加到了节点1上crm(live)# exitbye[root@primary ~]# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:83:af:ca brd ff:ff:ff:ff:ff:ff inet 192.168.2.132/24 brd 192.168.2.255 scope global eth1 inet 192.168.2.100/24 brd 192.168.2.255 scope global secondary eth1 inet6 fe80::20c:29ff:fe83:afca/64 scope link valid_lft forever preferred_lft forever# 查看看到添加了一个IP[root@primary ~]# crm node standby# 要将哪个节点转为备节点，就在哪个节点上执行此命令[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 16:30:38 2019Last change: Tue Apr 2 16:30:34 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)1 resource configuredNode primary: standbyOnline: [ secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started secondary# 查看状态，online的就只有node2了------------- node2-------------[root@secondary ~]# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:af:e1:97 brd ff:ff:ff:ff:ff:ff inet 192.168.2.133/24 brd 192.168.2.255 scope global eth1 inet 192.168.2.100/24 brd 192.168.2.255 scope global secondary eth1 inet6 fe80::20c:29ff:feaf:e197/64 scope link valid_lft forever preferred_lft forever# 可以看到ip地址转到node2了------------- node1-------------[root@primary ~]# crm node online# 让节点1上线[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 16:32:28 2019Last change: Tue Apr 2 16:32:25 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)1 resource configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started secondary# 资源没有转回------------- node2-------------[root@secondary ~]# service corosync stopSignaling Corosync Cluster Engine (corosync) to terminate: [ OK ]Waiting for corosync services to unload:. [ OK ]# 停掉节点2的服务，看资源是转到节点1上------------- node1-------------[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition WITHOUT quorumLast updated: Tue Apr 2 16:34:22 2019Last change: Tue Apr 2 16:32:25 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)1 resource configuredOnline: [ primary ]OFFLINE: [ secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Stopped# 看资源是否转移，显示资源没有启动，因为一个服务停止了，所以只有一个节点在线，未超过半数，并且资源默认是关闭的，所以资源未启动 [root@primary ~]# crm configurecrm(live)configure# property no-quorum-policy=ignore# 设置没有法定票数时怎么办，设置为ignorecrm(live)configure# commitcrm(live)configure# exitbye[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition WITHOUT quorumLast updated: Tue Apr 2 16:36:29 2019Last change: Tue Apr 2 16:35:58 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)1 resource configuredOnline: [ primary ]OFFLINE: [ secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary# 这时可以看到资源启动了------------- node2-------------[root@secondary ~]# service corosync startStarting Corosync Cluster Engine (corosync): [ OK ]------------- node1-------------[root@primary ~]# crm resourcecrm(live)resource# status webipresource webip is running on: primary # 查看资源状态，显示资源在primary上crm(live)resource# migrate webip secondaryINFO: Move constraint created for webip to secondary# 转移资源 到secondary上，secondary是主机名crm(live)resource# status webipresource webip is running on: secondary # 显示资源在secondary上crm(live)resource# stop webip# 停止资源 crm(live)resource# status webipresource webip is NOT runningcrm(live)resource# start webip# 启动资源 crm(live)resource# status webipresource webip is running on: secondary crm(live)resource# status webip (ocf::heartbeat:IPaddr): Started# 查看所有资源crm(live)resource# unmigrate webipINFO: Removed migration constraints for webip# 转回到原来的节点crm(live)resource# status webipresource webip is running on: secondary # 因为没有倾向性，所以没有转移 高可用web123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487---------------- node1&amp;2----------------[root@primary ~]# yum install -y httpd[root@primary ~]# vim /var/www/html/index.htmlnode1:primary# 提供网页文件，另一台内容为node2:secondary[root@primary ~]# service httpd start[root@primary ~]# curl 192.168.2.132node1:primary[root@primary ~]# curl 192.168.2.133node2:secondary[root@secondary ~]# service httpd stop[root@secondary ~]# chkconfig httpd off# 因为要高可用此资源，所以不可以让服务自动启动------------- node1-------------[root@primary ~]# crm configure crm(live)configure# primitive webserver lsb:httpd# 添加资源crm(live)configure# verifycrm(live)configure# commit------------- node2-------------[root@secondary ~]# ss -tln# web服务在节点2上启动了------------- node1-------------[root@primary ~]# crm resourcecrm(live)resource# show webip (ocf::heartbeat:IPaddr): Started webserver (lsb:httpd): Started# 查看资源是启动的crm(live)resource# stop webserver# 停止资源crm(live)resource# show webip (ocf::heartbeat:IPaddr): Started webserver (lsb:httpd): Stopped (disabled)crm(live)resource# start webserver# 再启动crm(live)resource# show webip (ocf::heartbeat:IPaddr): Started webserver (lsb:httpd): Started# 这时资源还是在节点2上启动crm(live)resource# cd ..crm(live)# nodecrm(live)node# standby secondary# 让节点2成为备用节点crm(live)node# cd ..crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:10:10 2019Last change: Tue Apr 2 17:08:47 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredNode secondary: standbyOnline: [ primary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# 这时两个资源都在节点1上运行了crm(live)# node online secondary# 让节点2上线crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:11:16 2019Last change: Tue Apr 2 17:11:08 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started secondary # web资源又转移到了节点2上 ========================================================================================== 使用资源组的方式，让资源在同一个节点运行 ========================================================================================== crm(live)configure# group webservice webip webserver# 定义一个组叫webservice，组内有两个资源crm(live)configure# verifycrm(live)configure# commitcrm(live)configure# exitbye[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:14:15 2019Last change: Tue Apr 2 17:13:22 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: Resource Group: webservice webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# web资源又转移到节点1上了[root@primary ~]# crm configurecrm(live)configure# editnode primary \ attributes standby=offnode secondary \ attributes standby=offprimitive webip IPaddr \ params ip=192.168.2.100 nic=eth1 cidr_netmask=24 \ meta target-role=Startedprimitive webserver lsb:httpd \ meta target-role=Startedgroup webservice webip webserverproperty cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.18-3.el6-bfe4e80420 \ cluster-infrastructure="classic openais (with plugin)" \ expected-quorum-votes=2 \ stonith-enabled=false \ no-quorum-policy=ignore# 编辑配置文件crm(live)resource# cd ..crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:18:54 2019Last change: Tue Apr 2 17:18:36 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: Resource Group: webservice webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# 可以看到两个资源在一个资源组中crm(live)# configure delete webservice# 删除资源组，并不会报错，资源组马上被删除了crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:19:12 2019Last change: Tue Apr 2 17:19:10 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started secondary# 资源组没有了==========================================================================================定义排列约束，即将资源绑定在一起==========================================================================================crm(live)# configurecrm(live)configure# colocation webserver_with_webip inf: webserver webip# colocation定义排列约束，webserver_with_webip是自定义名称，inf表示定义分数，冒号后没有东西表示无穷大，这样两个资源就永远在一起了 crm(live)configure# verifycrm(live)configure# commit[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:26:39 2019Last change: Tue Apr 2 17:26:35 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# 提交后，两个资源就都在节点1上运行了==========================================================================================定义顺序约束，即资源的启动顺序。定义位置约束，即让资源倾向在哪个节点上运行。==========================================================================================crm(live)configure# order webip_before_webserver Mandatory: webip webserver# 定义顺序约束，先启动webip再启动webserver crm(live)configure# location webip_on_node2 webip 50: secondary# 定义位置约束，让webip资源尽量在节点2上运行 crm(live)configure# verifycrm(live)configure# commit[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:51:11 2019Last change: Tue Apr 2 17:50:50 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started secondary webserver (lsb:httpd): Started secondary # 提交后，资源都转到节点2运行了 crm(live)configure# delete webip_on_node2 crm(live)configure# shownode primary \ attributes standby=offnode secondary \ attributes standby=offprimitive webip IPaddr \ params ip=192.168.2.100 nic=eth1 cidr_netmask=24 \ meta target-role=Startedprimitive webserver lsb:httpd \ meta target-role=Startedorder webip_before_webserver Mandatory: webip webservercolocation webserver_with_webip inf: webserver webipproperty cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.18-3.el6-bfe4e80420 \ cluster-infrastructure="classic openais (with plugin)" \ expected-quorum-votes=2 \ stonith-enabled=false \ no-quorum-policy=ignorecrm(live)configure# location webip_on_node2 webip rule 50: #uname eq secondarycrm(live)configure# verifycrm(live)configure# commitcrm(live)node# standby secondary# 让节点2成为备用节点[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:55:23 2019Last change: Tue Apr 2 17:55:07 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredNode secondary: standbyOnline: [ primary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# 这时资源会转移到节点1crm(live)node# online secondary# 节点2上线[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 17:55:38 2019Last change: Tue Apr 2 17:55:34 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started secondary webserver (lsb:httpd): Started secondary# 资源又转回到节点2crm(live)configure# rsc_defaults resource-stickiness=50# 设置资源指黏性值，默认是0。之前的命令property default-resource-stickiness=50 已经不能使用了crm(live)configure# verifycrm(live)configure# commitcrm(live)configure# cd ..crm(live)# node standby secondary# 节点2下线[root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 18:10:12 2019Last change: Tue Apr 2 18:07:48 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredNode secondary: standbyOnline: [ primary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary # 资源到节点1 crm(live)# node online secondary # 节点2上线 [root@primary ~]# crm statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 18:11:19 2019Last change: Tue Apr 2 18:10:41 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary # 资源不再转移，与设置资源黏性有关 [root@primary ~]# killall httpd # 停止web服务 crm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Tue Apr 2 18:12:49 2019Last change: Tue Apr 2 18:10:41 2019 by root via crm_attribute on primary2 nodes configured (2 expected votes)2 resources configuredOnline: [ primary secondary ]Full list of resources: webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Started primary# 默认只高可用节点，资源停掉也不会关心，还是显示资源在节点1上运行===========================================================================================配置高可用web资源，设置监控===========================================================================================crm(live)# resourcecrm(live)resource# stop webservercrm(live)resource# stop webip# 停止资源crm(live)resource# cd ..crm(live)# configure editnode primary \ attributes standby=offnode secondary \ attributes standby=offproperty cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.18-3.el6-bfe4e80420 \ cluster-infrastructure="classic openais (with plugin)" \ expected-quorum-votes=2 \ stonith-enabled=false \ no-quorum-policy=ignorersc_defaults rsc-options: \ resource-stickiness=50# 删除上面定义的资源，下面重新定义crm(live)configure# primitive webip ocf:heartbeat:IPaddr params ip=192.168.2.100 nic=eth1 cidr_netmask=24 # 定义资源crm(live)configure# monitor webip 10s:20s# 单独定义monitor，后面是interval和timeout的时间crm(live)configure# verifycrm(live)configure# primitive webserver lsb:httpd op monitor interval=10s timeout=20s# 也可以将定义资源与监控在一起定义。一定要用op才能使用monitor命令。monitor表示监控，interval=10s timeout=20s是监控的轮询时间和超时时间，有了监控，就可以在资源停止时进行转移了 crm(live)configure# verifycrm(live)configure# group webservice webip webservercrm(live)configure# verifycrm(live)configure# commit[root@primary ~]# ss -tln# 现在服务运行在节点1上[root@primary ~]# killall httpd# 停止web服务[root@primary ~]# ss -tln# 10秒后，web服务会再次启动[root@primary ~]# yum install -y epel-release[root@primary ~]# yum install -y nginx[root@primary ~]# killall httpd[root@primary ~]# service nginx startStarting nginx: [ OK ]# 停止httpd服务，并启动nginx服务，为了不让httpd服务在节点1启动。看资源是否会转移到节点2上------------- node2-------------[root@secondary ~]# ss -tln[root@secondary ~]# ip a# 服务与地址都转到了节点2上------------- node3-------------# 使用此节点提供NFS服务[root@webdav ~]# yum install -y nfs-utils nginx[root@webdav ~]# systemctl start nfs[root@webdav ~]# mkdir /shared[root@webdav ~]# vim /shared/index.htmltest page[root@webdav ~]# vim /etc/exports/shared 192.168.2.0/24(rw,no_root_squash) 192.168.1.0/24(rw)[root@webdav ~]# exportfs -ra[root@webdav ~]# showmount -e 192.168.2.128------------- node1-------------[root@primary ~]# crm configurecrm(live)configure# primitive webstore ocf:heartbeat:Filesystem params device="192.168.2.128:/shared" directory="/var/www/html" fstype="nfs" op monitor interval=20s timeout=40s op start timeout=60s op stop timeout=60s# 定义一个存储资源，提供NFS地址与挂载地址、文件系统类型。最后设置监控。crm(live)configure# editgroup webservice webip webserver webstore# 将资源加入组crm(live)configure# verifycrm(live)configure# commitcrm(live)# statusStack: classic openais (with plugin)Current DC: secondary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Wed Apr 3 04:58:49 2019Last change: Wed Apr 3 04:57:53 2019 by hacluster via cibadmin on secondary2 nodes configured (2 expected votes)3 resources configuredOnline: [ primary ]OFFLINE: [ secondary ]Full list of resources: Resource Group: webservice webip (ocf::heartbeat:IPaddr): Started primary webserver (lsb:httpd): Stopped webstore (ocf::heartbeat:Filesystem): Stopped# 因为实验不是一起做的，提供NFS服务是第二次接着做，所以忘记上一次为什么资源会停止了，新加入的服务也停止了，使用节点上线与启动资源的命令也没有反应。所以下面准备重新启动服务[root@primary ~]# service corosync statuscorosync (pid 46159) is running...[root@primary ~]# kill -9 46159# 因为停止服务非常 慢，所以使用kill杀死服务，两个节点都重新启动服务[root@primary ~]# service corosync start[root@primary ~]# crm crm(live)# statusStack: classic openais (with plugin)Current DC: NONELast updated: Wed Apr 3 05:02:40 2019Last change: Wed Apr 3 04:57:53 2019 by hacluster via cibadmin on secondary2 nodes configured (2 expected votes)3 resources configuredOFFLINE: [ primary secondary ]Full list of resources: Resource Group: webservice webip (ocf::heartbeat:IPaddr): Stopped webserver (lsb:httpd): Stopped webstore (ocf::heartbeat:Filesystem): Stopped# 启动服务后，资源还是停止状态crm(live)# resource start webservicecrm(live)# statusStack: classic openais (with plugin)Current DC: primary (version 1.1.18-3.el6-bfe4e80420) - partition with quorumLast updated: Wed Apr 3 05:03:07 2019Last change: Wed Apr 3 05:03:03 2019 by root via cibadmin on primary2 nodes configured (2 expected votes)3 resources configuredOnline: [ primary secondary ]Full list of resources: Resource Group: webservice webip (ocf::heartbeat:IPaddr): Started secondary webserver (lsb:httpd): Started secondary webstore (ocf::heartbeat:Filesystem): Started secondary# 启动资源后正常了访问192.168.2.100，可以看到test page的字样证明成功了。# 停止节点2后，资源无法转移，后发现是在节点1上启动了nginx服务，停止nginx服务后仍然无法启动webserver资源。未找到原因，删除webserver资源重新添加后正常。]]></content>
      <categories>
        <category>Cluster</category>
      </categories>
      <tags>
        <tag>corosync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[drbd基本配置使用]]></title>
    <url>%2F2019%2F03%2F29%2Fdrbd%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念 DRBD即Distributed Relicated Block Device：分布式磁盘块设备， 可以解决磁盘单点故障。一般情况下只支持两个节点。 一般情况下文件写入磁盘的步骤是：写操作 –&gt; 文件系统 –&gt; 内存缓存中 –&gt; 磁盘调度器 –&gt; 磁盘驱动器 –&gt; 写入磁盘。而DRBD的工作机制如上图所示，数据经过buffer cache后有内核中的DRBD模块通过tcp/ip协议栈经过网卡和对方建立数据同步。 工作模式 主从模型 master/slave模型，在某一时刻只允许有一个主节点。主节点的作用是可以挂载使用，写入数据等；从节点只作为主节点的镜像，是主节点的备份。 主主模型 dula primary模型，2个节点都可以当做主节点来挂载使用。需要配合集群文件系统使用，通过分布式文件锁管理器避免同时写一个文件造成文件系统损坏的问题。 复制模型 A协议：异步复制（asynchronous），写操作到本机网卡时即认为成功，性能好，数据可靠性差。 B协议：半同步复制（semi sync），写操作到达备节点网卡即认为成功，数据可靠性介于A和C之间。 C协议：同步复制（ sync），备用节点写入磁盘即认为成功，性能差，数据可靠性高。也是drbd默认使用的复制协议 实例安装1234567891011121314151617181920212223242526272829===========================================================================================环境：主机两台，操作系统CentOS6.6，内核2.6.32-504.el6.x86_64。地址：192.168.2.132、192.168.2.133安装与配置在两个节点上是一样的===========================================================================================# 两台主机均按如下方法操作[root@primary drbd]# rpm -ivh drbd84-utils-8.9.2-1.el6.elrepo.x86_64.rpm kmod-drbd84-8.4.6-1.el6.elrepo.x86_64.rpm# 安装包取自生产环境。drbd84-utils-8.9.1-1.el6.elrepo包提供配置文件与工具，komd-drbd84-8.4.6-504.el6.x86_64.rpm包提供内核模块。注意两个包要一起安装，不然可能不会添加设备[root@template ~]# ls /dev/ddisk/ dm-1 drbd1 drbd11 drbd13 drbd15 drbd3 drbd5 drbd7 drbd9 dvdrw dm-0 drbd0 drbd10 drbd12 drbd14 drbd2 drbd4 drbd6 drbd8 dvd# 安装软件后可以看到添加了很多以drbd开头的设备[root@primary ~]# fdisk /dev/sdb# 在两个分区上提供大小一致的分区[root@primary ~]# ntpdate ntp1.aliyun.com# 同步时间[root@primary ~]# partprobe /dev/sdb[root@primary drbd]# vim /etc/sysconfig/networkNETWORKING=yesHOSTNAME=primary[root@primary drbd]# hostname primary# 修改主机名[root@primary drbd]# ssh-keygen -t rsa -P ''[root@primary drbd]# ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.2.133# 密钥通信[root@primary drbd]# vim /etc/hosts192.168.2.132 primary192.168.2.133 secondary[root@primary drbd]# scp drbd84-utils-8.9.2-1.el6.elrepo.x86_64.rpm kmod-drbd84-8.4.6-1.el6.elrepo.x86_64.rpm secondary:/root 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[root@primary ~]# cd /etc/drbd.d[root@primary drbd.d]# vim global_common.conf# 此配置文件提供全局配置，及多个drbd设备相同的配置 global &#123; usage-count no; # 是否加入改进计划 &#125;common &#123; handlers &#123; &#125; startup &#123; &#125; options &#123; &#125; disk &#123; on-io-error detach; # IO出问题时，就将节点卸载 &#125; net &#123; cram-hmac-alg "sha1"; # 使用的算法 shared-secret "mydrbdshared123"; # 共享密钥，建议用随机数生成 &#125; syncer &#123; rate 500M; # 同步速率 &#125;&#125;# glocal：全局属性，定义drbd自己的工作特性。common：通用属性，定义多组drbd设备通用特性 [root@primary drbd.d]# vim mystore.res# 此文件为自建文件resource mystore &#123;# 首先定义公共配置，这一段可以被下面的多段使用 device /dev/drdb0; # 定义设备 disk /dev/sdb1; # 定义磁盘，定义这两项就让磁盘与设备关联了？ meta-disk internal; # 在自己的dev内部构建使用# 下面定义单个节点的属性 on primary &#123; address 192.168.2.132:7789; &#125; on secondary &#123; address 192.168.2.132:7789; &#125;&#125;[root@primary drbd.d]# drbdadm create-md mystoreinitializing activity logNOT initializing bitmapWriting meta data...New drbd meta data block successfully created.# 初始化资源，mystore是资源名，是在mystore.res文件中定义的。在两个节点上分别执行 [root@primary drbd.d]# drbdadm create-md mystoreinitializing activity logNOT initializing bitmapWriting meta data...New drbd meta data block successfully created.[root@primary drbd.d]# service drbd startStarting DRBD resources: [ create res: mystore prepare disk: mystore adjust disk: mystore adjust net: mystore]....# 启动一个节点后，它会等待另一个节点也启动此服务，这时两个节点才会一起启动服务[root@primary drbd.d]# cat /proc/drbdversion: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00 0: cs:Connected ro:Secondary/Secondary ds:Inconsistent/Inconsistent C r----- ns:0 nr:0 dw:0 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:3140544# 查看运行状态，现在两个都是Secondary，没有同步 [root@primary drbd.d]# drbd-overview 0:mystore/0 Connected Secondary/Secondary Inconsistent/Inconsistent # 使用此命令也可以 [root@primary drbd.d]# drbdadm primary --force mystore # 设置节点1为主节点 [root@primary drbd.d]# cat /proc/drbd version: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00 0: cs:SyncSource ro:Primary/Secondary ds:UpToDate/Inconsistent C r----- ns:1067676 nr:0 dw:0 dr:1069720 al:0 bm:0 lo:0 pe:2 ua:2 ap:0 ep:1 wo:f oos:2074560 [=====&gt;..............] sync'ed: 34.1% (2074560/3140544)K finish: 0:00:52 speed: 39,708 (39,480) K/sec # 显示同步过程，有两种状态，primary和secondary，主和从，左边为自己的状态右边是对方的状态 [root@primary drbd.d]# cat /proc/drbd version: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00 0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r----- ns:3140544 nr:0 dw:0 dr:3141208 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0# 同步完成，这是状态为Primary/Secondary [root@primary drbd.d]# mke2fs -t ext4 /dev/drbd0mke2fs 1.41.12 (17-May-2010)文件系统标签=操作系统:Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks196608 inodes, 785136 blocks39256 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=80530636824 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912正在写入inode表: 完成 Creating journal (16384 blocks): 完成Writing superblocks and filesystem accounting information: 完成This filesystem will be automatically checked every 26 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override.# 在主节点格式化磁盘，从节点也会自动格式化，因为是按位同步的 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162========= node1 =========[root@primary drbd.d]# mount /dev/drbd0 /mnt[root@primary drbd.d]# ls /mntlost+found[root@primary drbd.d]# cd /mnt[root@primary mnt]# cp /etc/issue ./[root@primary mnt]# lsissue lost+found[root@primary mnt]# cd[root@primary ~]# umount /mnt[root@primary ~]# drbdadm secondary mystore# 把自己切换为从节点[root@primary ~]# cat /proc/drbdversion: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00 0: cs:Connected ro:Secondary/Secondary ds:UpToDate/UpToDate C r----- ns:3256316 nr:0 dw:115772 dr:3141925 al:31 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0# 状态都是从节点========= node2 =========[root@secondary drbd.d]# drbdadm primary mystore# 在哪个节点执行此命令就是切换哪个节点的状态，这里将备用节点切换为主节点[root@secondary drbd.d]# cat /proc/drbdversion: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00 0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r----- ns:0 nr:3256316 dw:3256316 dr:664 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0[root@secondary drbd.d]# mount /dev/drbd0 /mnt[root@secondary drbd.d]# ls /mntissue lost+found[root@secondary drbd.d]# vim /mnt/issueabcabc# 加入一些内容[root@secondary drbd.d]# umount /mnt[root@secondary drbd.d]# drbdadm secondary mystore# 一定要切换状态，备用状态是不能被挂载========= node1 =========[root@primary ~]# mount /dev/drbd0 /mntmount: you must specify the filesystem type# 备用状态是不能被挂载的[root@primary ~]# drbdadm primary mystore[root@primary ~]# mount /dev/drbd0 /mnt[root@primary ~]# cat /mnt/issue CentOS release 6.6 (Final)Kernel \r on an \mabcabc# 内容也被改变了[root@primary ~]# service drbd statusdrbd driver loaded OK; device status:version: 8.4.6 (api:1/proto:86-101)GIT-hash: 833d830e0152d1e457fa7856e71e11248ccf3f70 build by phil@Build64R6, 2015-04-09 14:35:00m:res cs ro ds p mounted fstype0:mystore Connected Primary/Secondary UpToDate/UpToDate C /mnt ext4# 查看状态，UpToDate/UpToDate 表示已经同步]]></content>
      <categories>
        <category>Cluster</category>
      </categories>
      <tags>
        <tag>drbd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-语句]]></title>
    <url>%2F2019%2F03%2F26%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[print123456789101112131415161718192021&gt;&gt;&gt; print('Age:', 42)Age: 42# 可同时打印多个表达式，条件是用逗号分隔它们&gt;&gt;&gt; name = 'Gumby'&gt;&gt;&gt; salutation = 'Mr.'&gt;&gt;&gt; greeting = 'Hello,'&gt;&gt;&gt; print(greeting, salutation, name)Hello, Mr. Gumbyprint(greeting + ',', salutation, name)# 如果字符串变量greeting不包含逗号，可使用此方法添加，记得一定要有加号，不然会在greeting与逗号间加入一个空格&gt;&gt;&gt; print("I", "wish", "to", "register", "a", "complaint", sep="_")I_wish_to_register_a_complaint# 自定义分隔符print('Hello,', end='')print('world!')Hello,world!# 还可自定义结束字符串，以替换默认的换行符。上面将结束字符串指定为空字符串，所以Hello和world会打印在一行。 import12345678910111213141516171819import somemodulefrom somemodule import somefunctionfrom somemodule import somefunction, anotherfunction, yetanotherfunctionfrom somemodule import *# 从模块导入。仅当你确定要导入模块中的一切时，采用使用最后一种方式module1.open(...)module2.open(...)# 有两个模块，它们都包含函数open，可使用第一种方式导入这两个模块，使用此种方式调用open函数&gt;&gt;&gt; import math as foobar&gt;&gt;&gt; foobar.sqrt(4)2.0# 导入整个模块并在语句末尾添加as子句指定别名。&gt;&gt;&gt; from math import sqrt as foobar&gt;&gt;&gt; foobar(4)2.0# 导入特定函数并给它指定别名，这是给sqrt起的别名叫foobar 赋值序列解包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&gt;&gt;&gt; x, y, z = 1, 2, 3&gt;&gt;&gt; print(x, y, z)1 2 3# 同时(并行)给多个变量赋值&gt;&gt;&gt; x, y = y, x&gt;&gt;&gt; print(x, y, z)2 1 3# 这种方式还可交换多个变量的值&gt;&gt;&gt; values = 1, 2, 3&gt;&gt;&gt; values(1, 2, 3)&gt;&gt;&gt; x, y, z = values&gt;&gt;&gt; x1# 这里执行的操作称为序列解包(或可迭代对象解包)：将一个序列(或任何可迭代对象)解包，并将得到的值存储到一系列变量中。&gt;&gt;&gt; scoundrel = &#123;'name': 'Robin', 'girlfriend': 'Marion'&#125;&gt;&gt;&gt; key, value = scoundrel.popitem()&gt;&gt;&gt; key'girlfriend'&gt;&gt;&gt; value'Marion'# 从字典中随便获取(或删除)一个键值对，可使用方法popitem，它随便获取一个键值对并以元组的方式返回。接下来，可直接将返回的元组解包到两个变量中。&gt;&gt;&gt; x, y, z = 1, 2Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: need more than 2 values to unpack&gt;&gt;&gt; x, y, z = 1, 2, 3, 4Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: too many values to unpack# 要解包的序列包含的元素个数必须与你在等号左边列出的目标个数相同&gt;&gt;&gt; a, b, *rest = [1, 2, 3, 4]&gt;&gt;&gt; rest[3, 4]# 可使用星号运算符(*)来收集多余的值，这样无需确保值和变量的个数相同&gt;&gt;&gt; name = "Albus Percival Wulfric Brian Dumbledore"&gt;&gt;&gt; first, *middle, last = name.split()&gt;&gt;&gt; middle['Percival', 'Wulfric', 'Brian']# 还可将带星号的变量放在其他位置。&gt;&gt;&gt; a, *b, c = "abc"&gt;&gt;&gt; a, b, c('a', ['b'], 'c')# 赋值语句的右边可以是任何类型的序列，但带星号的变量最终包含的总是一个列表。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-字典]]></title>
    <url>%2F2019%2F03%2F26%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[概念字典，也称映射(mapping)是一种可通过名称来访问其各个值的数据结构。字典是Python中唯一的内置映射类型，其中的值不按顺序排列，而是存储在键下。键可能是数、字符串或元组。字典是key-value键值对的数据的集合，它是可变的、无序的、key不重复。字典中的item指的就是kv对 字典(日常生活中的字典和Python字典)旨在让你能够轻松地找到特定的单词(键)，以获悉其定义(值) 。 Python字典的用途： 表示棋盘的状态，其中每个键都是由坐标组成的元组； 存储文件修改时间，其中的键为文件名； 数字电话/地址簿。 不要用值来找，要用key来找。如果需要用值来找就不要用此种方法 12345&gt;&gt;&gt; names = ['Alice', 'Beth', 'Cecil', 'Dee-Dee', 'Earl']&gt;&gt;&gt; numbers = ['2341', '9102', '3158', '0142', '5551']&gt;&gt;&gt; numbers[names.index('Cecil')]'3158'# 这可行，但不太实用。 基本的字典操作12345678910len(d)# 返回字典d 包含的项(键值对)数。d[k]# 返回与键k相关联的值。d[k] = v# 将值v关联到键k。del d[k]# 删除键为k的项。k in d# 检查字典d 是否包含键为k的项。 字典dict定义，初始化 d = dict() 或者 d = {} dict(**kwargs) 使用name = value对初始化一个字典 dict(iterable,**kwarg) 使用可迭代对象和name = value对构造字典，不过可迭代对象的元素必须是一个二元结构 d = dict(((1,’a’),(2,’b’))) 或者 d = dict(([1,’a’],[2,’b’])) dict(mapping,**kwarg) 使用一个字典构建另一个字典 d = {‘a’:10,’b’:20,’c’:None,’d’:[1,2,3]} 类方法 dict.fromkeys(iterable,value) d = dict.fromkeys(range(5)) d = dict.fromkeys(range(5),0) 键的类型：字典中的键可以是整数，但并非必须是整数。字典中的键可以是任何不可变的类型，如浮点数(实数) 、字符串或元组。 自动添加：即便是字典中原本没有的键，也可以给它赋值，这将在字典中创建一个新项。然而，如果不使用append或其他类似的方法，就不能给列表中没有的元素赋值。 成员资格：表达式k in d(其中d 是一个字典)查找的是键而不是值，而表达式v in l(其中l是一个列表)查找的是值而不是索引。这看似不太一致，但你习惯后就会觉得相当自然。毕竟如果字典包含指定的键，检查相应的值就很容易。 相比于检查列表是否包含指定的值，检查字典是否包含指定的键的效率更高。数据结构越大，效率差距就越大。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# 创建与使用phonebook = &#123;'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'&#125;# 字典由键及其相应的值组成，这种键值对称为项(item)。这里键为名字，而值为电话号码。每个键与其值之间都用# 冒号(:)分隔，项之间用逗号分隔，而整个字典放在花括号内。空字典(没有任何项)用两个花括号表示。在字典(以# 及其他映射类型)中，键必须是独一无二的，而字典中的值无需如此。# 创建字典l1 = list(range(5))d = dict(l1)# 这样是不行是，因为l1里都是单值，字典需要两个值。d = dict(enumerate(l1))# enumerate是给值加上索引的，这样也就是两个值了。e = enumerate(l1)print(type(e))# e的类型枚举，是一个可迭代对象，可以使用list、set、tuple来包括这个类型，用什么方法包括这个类型，这个# 类型就生成什么数据类型。也就是封装成什么就返回什么类型for x in e: print(x)# 返回的是二元组，在python命令行中执行要使用Ctrl + 回车d = dict(e)print(d)# 这是一个类似生成器的东西，走到头就不会再走了，所以d返回的是&#123;&#125;。e = enumerate(l1)d = dict(e)print(d)# 这样就生成了一个字典d = &#123;('a',1)&#125;print(d)# 这样是不可以的，因为结果不是key:valuec = dict(((1,'a'),))print(c)# 需要使用这种方式，dict中是一个元组，一般不用这种方式。((1,'a'),)表示一个元组，因为字典# 需要两个值，所以定义成(1,'a')# 使用dict函数创建&gt;&gt;&gt; items = [('name', 'Gumby'), ('age', 42)]&gt;&gt;&gt; d = dict(items)&gt;&gt;&gt; d&#123;'age': 42, 'name': 'Gumby'&#125;&gt;&gt;&gt; d['name']'Gumby'# 使用函数dict从其他映射(如其他字典)或键值对序列创建字典。&gt;&gt;&gt; d = dict(name='Gumby', age=42)&gt;&gt;&gt; d&#123;'age': 42, 'name': 'Gumby'&#125;# 使用关键字实参来调用这个函数# 也可使用一个映射实参来调用它，这将创建一个字典，其中包含指定映射中的所有项。像函数list、tuple和str一# 样，如果调用这个函数时没有提供任何实参，将返回一个空字典。从映射创建字典时，如果该映射也是字典(毕竟字# 典是Python中唯一的内置映射类型)，可不使用函数dict，而是使用字典方法copy。与list、tuple和str一样，# dict其实根本就不是函数，而是一个类。&gt;&gt;&gt; x = []&gt;&gt;&gt; x[42] = 'Foobar'Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in ?IndexError: list assignment index out of range# 将字符串'Foobar'赋给一个空列表中索引为42的元素。这是不可以的，因为没有这样的元素。要让这种操作可行，# 初始化x时，必须使用[None] * 43之类的代码，而不能使用[]。&gt;&gt;&gt; x = &#123;&#125;&gt;&gt;&gt; x[42] = 'Foobar'&gt;&gt;&gt; x&#123;42: 'Foobar'&#125;# 将'Foobar'赋给一个空字典的键42，这样做一点问题都没有people = &#123; 'Alice': &#123; 'phone': '2341', 'addr': 'Foo drive 23' &#125;, 'Beth': &#123; 'phone': '9102', 'addr': 'Bar street 42' &#125;, 'Cecil': &#123; 'phone': '3158', 'addr': 'Baz avenue 90' &#125;&#125;# 一个将人名用作键的字典。每个人都用一个字典表示，字典包含键'phone'和'addr'，它们分别与电# 话号码和地址相关联labels = &#123;'phone': 'phone number','addr': 'address'&#125;# 电话号码和地址的描述性标签，供打印输出时使用name = input('Name: ')request = input('Phone number (p) or address (a)? ')# 要查找电话号码还是地址?if request == 'p': key = 'phone'if request == 'a': key = 'addr'# 判断输入的是电话还是地址，如果是电话，key='phone'；如果是地址，key = 'addr'if name in people: print("&#123;&#125;'s &#123;&#125; is &#123;&#125;.".format(name, labels[key], people[name][key]))# 仅当名字是字典包含的键时才打印信息，打印的格式为某人的电话或地址是什么，format指定三个值# 对应前面的三个中括号，第一个值是用户输入的name；第二个值是key，key可以是phone或addr，# 在labels字典中查找对应的电话号码或地址；第三个值是使用name和key的值在people字典中查找# 对应的值。这个程序的运行情况类似于下面这样:Name: BethPhone number (p) or address (a)? pBeth's phone number is 9102. 类与函数调用123456789101112131415161718192021222324252627l1 = list()print(l1)# 上面定义了l1是一个空列表a = listl2 = atype(l2)# 这样定义后，l2是一个类而不是列表。因为定义了a等于list类l3 = a()print(l3)# l3被定义成了一个空列表，因为a等于list，所以这里l3 = a()就等于l3 = list()# a = list就是a把list的名称拿走了，等于把名称对应的地址拿走了# 函数也是一个对象，对象在内存中有一个地方放。这个地方就是函数的地址。列表放在内存中是一个对象，比如创建# 一个空列表，这是一个对象，我们把空列表赋值给了l3，l3拿的就是这个空列表对象的地址。现在我们给出一个函数# list，函数本身也是对象，一切皆对象。我们把这个对象给了a，就是把a覆盖掉了，这是把对象地址或叫对象引用# 给了a，这时a与list也就是等价的了。如果写成list()就是调用了，只要加了括号就是调用了。也就是说，# a = list是将对象地址给了a，a与list等价。a = list()是调用，将调用list函数的结果给了a，a被定义成了一个空列表l4 = 5()# 这样定义会提示"TypeError: 'int' object is not callable"，这说明int类型是不可以调用的。这就说明# 了加括号是可以调用前面的对象或名称的，但前面的对象或名称需要是可调用的对象。list是一个写好的函数，这个# 函数已经被当前环境加载过了，所以这个名称可以直接拿来用，这个名称指代的是list名称加载到内存中的位置，这# 就是引用类型。真正的引用并不是我们写一个列表，把列表赋值给变量，这才是对它的引用，实际这个函数也是对# 象，它也在内存中，你要引用它，也要通过它的名称才能引用，一加括号意义就变了，这个对象如果是可调用对象的# 话，我们就调用它了。如果函数是一个可调用对象，调用时就会执行函数里的函数体了。之后的类也可以变成一个可# 调用对象，比如把一个类实例化了，它就变成一个对象，这个对象后面也可以加括号，这就是python的技巧 字典元素的访问 d[key] 返回key对应的值value key不存在抛出KeyError异常 get(key[,default]) 返回key对应的值value get方法不会抛异常，如果key不存在，返回缺省值，如果没有设置缺省值就返回None。如果存在，就显示其值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 方法get为访问字典项提供了宽松的环境。通常，如果你试图访问字典中没有的项，将引发错误。&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; print(d['name'])Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in ?KeyError: 'name'# 访问没有的项，报错。&gt;&gt;&gt; print(d.get('name'))None# 使用get方法访问没有的项，不会报错。而是返回None。&gt;&gt;&gt; d.get('name', 'N/A')'N/A'# 可指定“默认”值，这样将返回你指定的值而不是None。&gt;&gt;&gt; d['name'] = 'Eric'&gt;&gt;&gt; d.get('name')'Eric'# 如果字典包含指定的键，get的作用将与普通字典查找相同。people = &#123; 'Alice': &#123; 'phone': '2341', 'addr': 'Foo drive 23' &#125;, 'Beth': &#123; 'phone': '9102', 'addr': 'Bar street 42' &#125;, 'Cecil': &#123; 'phone': '3158', 'addr': 'Baz avenue 90' &#125;&#125;labels = &#123;'phone': 'phone number','addr': 'address'&#125;name = input('Name: ')request = input('Phone number (p) or address (a)? ')key = request if request == 'p': key = 'phone'if request == 'a': key = 'addr'person = people.get(name, &#123;&#125;)label = labels.get(key, key)result = person.get(key, 'not available')print("&#123;&#125;'s &#123;&#125; is &#123;&#125;.".format(name, label, result))# 使用了方法get来访问“数据库”条目下面是这个程序的运行情况。Name: GumbyPhone number (p) or address (a)? batting averageGumby's batting average is not available. setdefault(key[,default]) 返回key对应的值value key不存在，添加kv对，value为default，并返回default，如果default没有设置，缺省为None 1234567891011121314151617181920# 方法setdefault 有点像 get，因为它也获取与指定键相关联的值，但除此之外，setdefault还在字典不包含指定的键时，在字典中添加指定的键值对。&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; d.setdefault('name', 'N/A')'N/A'&gt;&gt;&gt; d&#123;'name': 'N/A'&#125;&gt;&gt;&gt; d['name'] = 'Gumby'&gt;&gt;&gt; d.setdefault('name', 'N/A') # 这里不加'N/A'也可以，N/A是默认值，如果name没有对应值就返回此值'Gumby'&gt;&gt;&gt; d&#123;'name': 'Gumby'&#125;# 指定的键不存在时， setdefault返回指定的值并相应地更新字典。如果指定的键存在，就返回其值，并保持字典# 不变。与get一样，值是可选的；如果没有指定，默认为None。&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; print(d.setdefault('name'))None&gt;&gt;&gt; d&#123;'name': None&#125; 字典增加和修改 d[key] = value 将key对应的值修改为value key不存在添加新的kv对 update([other]) -&gt; None 使用另一个字典的kv对更新本字典 key不存在，就添加 key存在，覆盖已经存在的key对应的值 就地修改 d.update(red=1) d.update(((‘red’,2),)) d.update({‘red’:3}) 123456789101112# 方法update使用一个字典中的项来更新另一个字典。&gt;&gt;&gt; d = &#123;... 'title': 'Python Web Site',... 'url': 'http://www.python.org',... 'changed': 'Mar 14 22:09:15 MET 2016'... &#125;&gt;&gt;&gt; x = &#123;'title': 'Python Language Website'&#125;&gt;&gt;&gt; d.update(x)&gt;&gt;&gt; d&#123;'url': 'http://www.python.org', 'changed':'Mar 14 22:09:15 MET 2016', 'title': 'Python Language Website'&#125;# 对于通过参数提供的字典，将其项添加到当前字典中。如果当前字典包含键相同的项，就替换它。 copy（返回一个新字典） 123456789101112131415161718192021222324# 方法copy返回一个新字典，其包含的键值对与原来的字典相同(这个方法执行的是浅复制，因为值本身是原件，而非副本)。&gt;&gt;&gt; x = &#123;'username': 'admin', 'machines': ['foo', 'bar', 'baz']&#125;&gt;&gt;&gt; y = x.copy()&gt;&gt;&gt; y['username'] = 'mlh'&gt;&gt;&gt; y['machines'].remove('bar')&gt;&gt;&gt; y&#123;'username': 'mlh', 'machines': ['foo', 'baz']&#125;&gt;&gt;&gt; x&#123;'username': 'admin', 'machines': ['foo', 'baz']&#125;# 当替换副本中的值时，原件不受影响。然而，如果修改副本中的值(就地修改而不是替换)，原件也将发生变化，因为# 原件指向的也是被修改的值&gt;&gt;&gt; from copy import deepcopy&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; d['names'] = ['Alfred', 'Bertrand']&gt;&gt;&gt; c = d.copy()&gt;&gt;&gt; dc = deepcopy(d)&gt;&gt;&gt; d['names'].append('Clive')&gt;&gt;&gt; c&#123;'names': ['Alfred', 'Bertrand', 'Clive']&#125;&gt;&gt;&gt; dc&#123;'names': ['Alfred', 'Bertrand']&#125;# 深复制，即同时复制值及其包含的所有值，等等。为此，可使用模块copy中的函数deepcopy。c和dc的值都是从d# 复制过来的，只是c是浅复制，dc是深复制，在d中追加值后，c的值也有变化，dc没有。 fromkeys（创建新字典） 123456789101112# fromkeys创建一个新字典，其中包含指定的键，且每个键对应的值都是None。&gt;&gt;&gt; &#123;&#125;.fromkeys(['name', 'age'])&#123;'age': None, 'name': None&#125;# 首先创建了一个空字典，再对其调用方法fromkeys来创建另一个字典，这显得有点多余。&gt;&gt;&gt; dict.fromkeys(['name', 'age'])&#123;'age': None, 'name': None&#125;# 直接对dict调用方法fromkeys。&gt;&gt;&gt; dict.fromkeys(['name', 'age'], '(unknown)')&#123;'age': '(unknown)', 'name': '(unknown)'&#125;# 不使用默认值None，可提供特定的值。 字典删除 pop(key[,default]) key存在，移除它，并返回它的value key不存在，返回给定的default default未设置，key不存在则抛出KeyError异常 123456# 方法pop可用于获取与指定键相关联的值，并将该键值对从字典中删除。&gt;&gt;&gt; d = &#123;'x': 1, 'y': 2&#125;&gt;&gt;&gt; d.pop('x')1&gt;&gt;&gt; d&#123;'y': 2&#125; popitem() 移除并返回一个任意的键值对 字典为empty，抛出KeyError异常 123456789# 方法popitem类似于list.pop ，但 list.pop弹出列表中的最后一个元素，而popitem随机地弹出一个字典项，# 因为字典项的顺序是不确定的，没有“最后一个元素”的概念。&gt;&gt;&gt; d = &#123;'url': 'http://www.python.org', 'spam': 0, 'title': 'Python Web Site'&#125;&gt;&gt;&gt; d.popitem()('url', 'http://www.python.org')&gt;&gt;&gt; d&#123;'spam': 0, 'title': 'Python Web Site'&#125;# 虽然popitem 类似于列表方法pop，但字典没有与append(它在列表末尾添加一个元素)对应的方法。这是因为字典# 是无序的，类似的方法毫无意义。 clear() 清空字典 就地修改 1234567891011121314151617181920212223242526272829303132# clear（删除所有字典项）&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; d['name'] = 'Gumby'&gt;&gt;&gt; d['age'] = 42&gt;&gt;&gt; d&#123;'age': 42, 'name': 'Gumby'&#125;&gt;&gt;&gt; returned_value = d.clear()&gt;&gt;&gt; d&#123;&#125;&gt;&gt;&gt; print(returned_value)None# 这种操作是就地执行的(就像list.sort一样)，因此什么都不返回(或者说返回None)。&gt;&gt;&gt; x = &#123;&#125;&gt;&gt;&gt; y = x&gt;&gt;&gt; x['key'] = 'value'&gt;&gt;&gt; y&#123;'key': 'value'&#125;&gt;&gt;&gt; x = &#123;&#125;&gt;&gt;&gt; y&#123;'key': 'value'&#125;# x和y最初都指向同一个字典。通过将一个空字典赋给x来“清空”它。这对y没有任何影响，它依然指向原来的字典。&gt;&gt;&gt; x = &#123;&#125;&gt;&gt;&gt; y = x&gt;&gt;&gt; x['key'] = 'value'&gt;&gt;&gt; y&#123;'key': 'value'&#125;&gt;&gt;&gt; x.clear()&gt;&gt;&gt; y&#123;&#125;# 要删除原来字典的所有元素，必须使用clear。如果这样做，y也将是空的 del语句 1234567891011a = Trueb = [6]d = &#123;'a':1,'b':b,'c':[1,3,5]&#125;del adel d['c'] # 删除了'c'键及其值del b[0] # 变成了空列表c = bdel cdel bb = d['b']# del d['c']看着像删除了一个对象，本质上减少了一个对象的引用，del实际上删除的是名称，而不是对象 字典遍历 遍历key，方法keys返回一个字典视图，其中包含指定字典中的键。 1234567Method：for k in d: print(k)for k in d.keys(): print(k)# 下面这种方法较常用 遍历value 1234567891011121314151617181920Method：for k in d: print(d[k])for k in d.keys(): print(d.get(k))for v in d.values(): print(v) # 方法values返回一个由字典中的值组成的字典视图。不同于方法keys，方法values返回的视图可能包含重复的值。&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; d[1] = 1&gt;&gt;&gt; d[2] = 2&gt;&gt;&gt; d[3] = 3&gt;&gt;&gt; d[4] = 1&gt;&gt;&gt; d &#123;1: 1, 2: 2, 3: 3, 4: 4&#125;&gt;&gt;&gt; d.values()dict_values([1, 2, 3, 1]) 遍历item，即kv对 12345678910111213141516171819202122232425262728293031323334353637383940Method:for item in d.items(): print(item)for item in d.items(): print(item[0],item[1])for k,v in d.items(): print(k,v)for k,_ in d.items(): print(k)for _,v in d.items(): print(v)# 方法items返回一个包含所有字典项的列表，其中每个元素都为(key, value)的形式。&gt;&gt;&gt; d = &#123;'title': 'Python Web Site', 'url': 'http://www.python.org', 'spam': 0&#125;&gt;&gt;&gt; d.items()dict_items([('url', 'http://www.python.org'), ('spam', 0), ('title', 'Python Web Site')])# 字典项在列表中的排列顺序不确定。返回值属于一种名为字典视图的特殊类型。字典视图可用于迭代&gt;&gt;&gt; it = d.items()&gt;&gt;&gt; len(it)3&gt;&gt;&gt; ('spam', 0) in itTrue# 还可确定其长度以及对其执行成员资格检查。如下 ：&gt;&gt;&gt; d['spam'] = 1&gt;&gt;&gt; ('spam', 0) in itFalse&gt;&gt;&gt; d['spam'] = 0&gt;&gt;&gt; ('spam', 0) in itTrue# 视图的一个优点是不复制，它们始终是底层字典的反映，即便你修改了底层字典亦如此&gt;&gt;&gt; list(d.items())[('spam', 0), ('title', 'Python Web Site'), ('url', 'http://www.python.org')]# 将字典项复制到列表中 总结 Python3中，keys、values、items方法返回一个类似一个生成器的可迭代对象，不会把函数的返回结果复制到内存中 Dictionary view对象 字典的entry的动态的视图，字典变化，视图将反映出这些变化 Python2中，上面的方法会返回一个新的列表，占据新的内存空间。所以Python2建议使用iterkeys、itervalues、iteritems版本，返回一个迭代器，而不是一个copy 字典遍历和移除 如何在遍历的时候移除元素 123456789101112131415161718错误的做法d = dict(a=1,b=2,c='abc')for k,v in d.items(): d.pop(k) # 异常 while len(d): # 相当于清空，不如直接clear() print(d.popitem())正确的做法d = dict(a=1,b=2,c='abc')keys = []for k,v in d.items(): if isinstance(v,str): keys.append(k) for k in keys: d.pop(k)print(d) 字典的key key的要求和set的元素要求一致 set的元素可以看做key，set可以看做dict的简化版 hashable可哈希才可以作为key，可以使用hash()测试。可hash的类型是不可变的，可变类型是不可hash的 12d = &#123;1:0,2.0:3,"abc":None,('hello','world','python'):"string",b'abc':'135'&#125;# 同理，这里要用&#123;&#125;大括号，不能用dict()，不然会报错。个人还是认为dict()是转换类型的，&#123;&#125;是定义的 defaultdict collections.defaultdict([default_factory[,…]]) 第一个参数是default_factory，缺省是None，它提供一个初始化函数。当key不存在的时候，会调用这个工厂函数来生成key对应的value 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152例：import randomd1 = &#123;&#125;for k in 'abcdef': for i in range(random.randint(1,5)): if k not in d1.keys(): d1[k] = [] d1[k].append(i)print(d1)from collections import defaultdictimport randomd1 = defaultdict(list)for k in 'abcdef': for i in range(random.randint(1,5)): d1[k].append(i)print(d1)# defaultdictfrom collections import defaultdictd1 = &#123;&#125;d2 = defaultdict(list)# list放在这里相当于传了一个工厂方法，要求是一个初始化函数，这就是以后的初始化函数default_factory，初# 始化函数什么时候用，只有在key不存在的时候，会调用这个工厂函数来生成key对应的value，也就是生成一个缺# 省值，用来给这个没有value的key赋值，这样就可以凑上一个kv对，也就可以加入字典当中了。for k in "abcde": # 迭代a到e，这里要创建的是key for v in range(5): # 迭代0到4，这里要生成value if k not in d1.keys(): # d1.keys()开始是空的，第一次的时候找不到上面循环的k是a，只有在每次循环的第一次key不存在时会进入这里 d1[k] = [] # 这里表示，如果上面判断k不存在，就给d1[k]初始化一个空列表 d1[k].append(v) # 这里把0-4依次追加到d1[k]中，第一次d1[a].append[0]，第二次d1[a].append[1]print(d1) # 最后打印出来，这是第一种方式输出：&#123;'a': [0, 1, 2, 3, 4], 'b': [0, 1, 2, 3, 4], 'c': [0, 1, 2, 3, 4], 'd': [0, 1, 2, 3, 4], 'e': [0, 1, 2, 3, 4]&#125; for k in 'mnopq': for v in range(3): # 这里是3是为了说明v与上面的k的数量可以不一样 d2[k].append(v) # 这里不做判断，直接赋值。是为了说明上面的k(key)如果不存在，就调用上面定义的d2 = defaultdict(list)# 中的list，这时就是在做创建空列表的动作，也就是list()，因为上面已经说明了当key不存在时调用工厂函数生# 成key对应的value，并且也定义了d2等于这个工厂函数d2[k]就相当于测试一下这个k是否存在，不存在就调用工# 厂函数。之后也可以自定义函数，并调用。# 这就相当于替换了d1[k] = []中后面的中括号# 个人想，如果将list改成tuple是否可以，也许不行，因为tuple是不可变的，没有append这样的方法，那么改成# set是不是就可以了？测试发现，当使用tuple或set时会提示没有append属性print(d2)输出：defaultdict(&lt;class 'list'&gt;, &#123;'m': [0, 1, 2], 'n': [0, 1, 2], 'o': [0, 1, 2], 'p': [0, 1, 2], 'q': [0, 1, 2]&#125;) OrderedDict collections.OrderedDict([items]) key并不是按照加入的顺序排列，可以使用OrderedDict记录顺序 有序字典可以记录元素插入的顺序，打印的时候也是按照这个顺序输出打印 3.6版本的Python的字典就是记录key插入的顺序（IPython不一定有效果） 应用场景 假如使用字典记录了N个产品，这些产品使用ID由小到大加入到字典中 除了使用字典检索的遍历，有时候需要取出ID，但是希望是按照输入的顺序，因为输入顺序是有序的 否则还需要重新把遍历到的值排序 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from collections import OrderedDictimport randomd = &#123;'banana':3,'apple':4,'pear':1,'orange':2&#125;print(d)keys = list(d.keys())random.shuffle(keys)print(keys)od = OrderedDict()for key in keys: od[key] = d[key]print(od)print(od.keys())# OrderedDict顺序的字典，这里指key要按顺序而不是值输出。key的顺序应该和我们放入的顺序是一样的d = &#123;&#125;d['a'] = 1d['b'] = 2d[1] = 3print(d)# 这里显示的d的值应该是按hash值排列的for k in d: print(k)输出：&#123;'a': 1, 'b': 2, 1: 3&#125;ab1from collections import OrderedDictimport randomd = &#123;'banana':3,'apple':4,'pear':1,'orange':2&#125;print(d)keys = list(d.keys())random.shuffle(keys) # 用shuffle把keys列表打乱od = OrderedDict()for key in keys: od[key] = d[key] # 创建od的kv对，这里就是od['pear'] = 1这样的形式 print(od)print(od.keys())# 这种方法可能在ipython中不再起作用，因为显示的值与输入的顺序是一样的。3.5版本之前是解决不了这个问题# 的。或者是在jupeter中就是可以按顺序显示的？需要在python命令行中再测试一下。视频中测试的3.6.1版本# 时，发现和这里的显示是一样的，按顺序显示。所以最好在python环境中测试，也就是在命令行输入python，之后# 执行上面的命令测试。之前视频中用ipython测试会打乱顺序输出：&#123;'banana': 3, 'apple': 4, 'pear': 1, 'orange': 2&#125;OrderedDict([('banana', 3), ('pear', 1), ('orange', 2), ('apple', 4)])odict_keys(['banana', 'pear', 'orange', 'apple'])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>字典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-使用字符串]]></title>
    <url>%2F2019%2F03%2F25%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[概念​ 字符串是一个个字符组成的有序的序列，是字符的集合。可以使用单引号、双引号、三引号引住的字符序列。字符串是不可变对象。从Python3起，字符串就是Unicode类型。 字符串定义-初始化1234567891011s1 = 'string's2 = "string2"s3 = '''this's a "string"'''s4 = 'hello \n magedu.com's5 = r"hello \n magedu.com"s6 = 'c:\windows\nt's7 = R"c:\windows\\nt"s8 = 'c:\windows\\nt'# 使用\\可以转义为一个\sql = """select * from user where name='tom'"""print(s1,s2,s3,s4,s5,s6,s7,s8,sql) 字符串元素访问-下标12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 字符串支持使用索引访问sql = "select * from user where name='tom'"sql[4] 输出：'c'sql[4] = 'o'输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-6-9056ec11fda5&gt; in &lt;module&gt; 1 sql = "select * from user where name='tom'"----&gt; 2 sql[4] = 'o'TypeError: 'str' object does not support item assignment# 字符串是不可变对象，所以报错# 有序的字符集合，字符序列sql = "select * from user where name='tom'"for c in sql: print(c) print(type(c))输出：s&lt;class 'str'&gt;e&lt;class 'str'&gt;l&lt;class 'str'&gt;e&lt;class 'str'&gt;c&lt;class 'str'&gt;t&lt;class 'str'&gt;# 可迭代sql = "select * from user where name='tom'"lst = list(sql)print(lst)输出：['s', 'e', 'l', 'e', 'c', 't', ' ', '*', ' ', 'f', 'r', 'o', 'm', ' ', 'u', 's', 'e', 'r', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 'n', 'a', 'm', 'e', '=', "'", 't', 'o', 'm', "'"]练习：&gt;&gt;&gt; website = 'http://www.python.org'&gt;&gt;&gt; website[-3:] = 'com'Traceback (most recent call last):File "&lt;pyshell#19&gt;", line 1, in ?website[-3:] = 'com'TypeError: object doesn't support slice assignment# 所有标准序列操作(索引、切片、乘法、成员资格检查、长度、最小值和最大值)都适用于字符串，但字符串是不可变的，因此所有的元素赋值和切片赋值都是非法的。 字符串join连接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# "string".join(iterable) -&gt; str# 将可迭代对象连接起来，使用string作为分隔符# 可迭代对象本身元素都是字符串# 返回一个新字符串lst = ['1','2','3']print("\"".join(lst))输出：1"2"3# 分隔符是双引号。\是转义符print(" ".join(lst))输出：1 2 3print("\n".join(lst))输出：123lst = ['1',['a','b'],'3']print(" ".join(lst))输出：---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-11-d6bdd3c2fbc5&gt; in &lt;module&gt; 1 lst = ['1',['a','b'],'3']----&gt; 2 print(" ".join(lst))TypeError: sequence item 1: expected str instance, list found# 不能对复杂列表用join()函数练习&gt;&gt;&gt; seq = [1, 2, 3, 4, 5]&gt;&gt;&gt; sep = '+'&gt;&gt;&gt; sep.join(seq) # 尝试合并一个数字列表，结果不可以对列表使用join方法Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in ?TypeError: sequence item 0: expected string, int found&gt;&gt;&gt; seq = ['1', '2', '3', '4', '5']&gt;&gt;&gt; sep.join(seq) '1+2+3+4+5'# 合并一个字符串列表&gt;&gt;&gt; dirs = '', 'usr', 'bin', 'env'&gt;&gt;&gt; '/'.join(dirs)'/usr/bin/env'&gt;&gt;&gt; print('C:' + '\\'.join(dirs))C:\usr\bin\env# 这里需要对\转义# 注：所合并序列的元素必须都是字符串。 字符串+连接123# + -&gt; str# 将2个字符串连接在一起# 返回一个新字符串 * 字符串分割123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# 分割字符串的方法分为2类 # split系 # 将字符串按照分隔符分割成若干字符串，并返回列表 # partition系 # 将字符串按照分隔符分割成2段，返回这2段和分隔符的元组 # split(sep=None,maxsplit=-1) -&gt; list of strings # 从左至右 # sep指定分割字符串，缺省的情况下空白字符串作为分隔符 # maxsplit指定分割的次数，-1表示遍历整个字符串 s1 = "I'm \ta super student."s1.split()输出：["I'm", 'a', 'super', 'student.']# 默认以空白为分割符s1.split('s')输出：["I'm \ta ", 'uper ', 'tudent.']# 以s为分割符s1.split('super')输出：["I'm \ta ", ' student.']s1.split('super ') # 这比上面的super多了一个空格输出：["I'm \ta ", 'student.']s1.split(' ')输出：["I'm", '\ta', 'super', 'student.']s1.split(' ',maxsplit=2)输出：["I'm", '\ta', 'super student.']s1.split('\t',maxsplit=2)输出：["I'm ", 'a super student.']练习&gt;&gt;&gt; '1+2+3+4+5'.split('+')['1', '2', '3', '4', '5']&gt;&gt;&gt; '/usr/bin/env'.split('/')['', 'usr', 'bin', 'env']&gt;&gt;&gt; 'Using the default'.split()['Using', 'the', 'default']# split是一个非常重要的字符串方法，其作用与join相反，用于将字符串拆分为序列。如果没有指定分隔符，将默认在单个或多个连续的空白字符(空格、制表符、换行符等)处进行拆分。# splitlines([keepends]) -&gt; list of strings # 按照行来切分字符串 # keepends指的是是否保留行分隔符 # 行分隔符包括\n、\r\n、\r、等'ab c\n\nde fg\rkl\r\n'.splitlines()输出：['ab c', '', 'de fg', 'kl']'ab c\n\nde fg\rkl\r\n'.splitlines(True)输出：['ab c\n', '\n', 'de fg\r', 'kl\r\n']s1 = '''I'm a super student.You're a super teacher.'''print(s1)输出：I'm a super student.You're a super teacher.print(s1.splitlines())输出：["I'm a super student.", "You're a super teacher."]print(s1.splitlines(True))输出：["I'm a super student.\n", "You're a super teacher."]# * partition(sep) -&gt; (head, sep, tail) # 从左至右，遇到分隔符就把字符串分割成两部分，返回头、分隔符、尾三部分的三元组；如果没有找 # 到分隔符，就返回头、2个空元素的三元组 # sep分割字符串，心须指定s1 = "I'm a super student."s1.partition('s')输出：("I'm a ", 's', 'uper student.')s1.partition('stu')输出：("I'm a super ", 'stu', 'dent.')s1.partition('')输出：---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-29-4a93ae92b66c&gt; in &lt;module&gt; 2 s1.partition('s') 3 s1.partition('stu')----&gt; 4 s1.partition('')ValueError: empty separator s1.partition('abc')输出：# rpartition(sep) -&gt; (head, sep, tail) # 从右至左，遇到分隔符就把字符串分割成两部分，返回头、分隔符、尾三部分的三元组；如果没有找到分隔符， # 就返回2个空元素和尾的三元组 字符串大小写12345678910111213141516171819202122# upper() 全大写# lower() 全小写# 大小写，做判断的时候用# swapcase() 交互大小写练习&gt;&gt;&gt; 'Trondheim Hammer Dance'.lower()'trondheim hammer dance'# lower返回字符串的小写版本&gt;&gt;&gt; if 'Gumby' in ['gumby', 'smith', 'jones']: print('Found it!')...&gt;&gt;&gt;# 这样是找不到的。这里的匹配是区分大小写的&gt;&gt;&gt; name = 'Gumby'&gt;&gt;&gt; names = ['gumby', 'smith', 'jones']&gt;&gt;&gt; if name.lower() in names: print('Found it!')...Found it!&gt;&gt;&gt;# 使用lower转换后才可以找到 字符串排版123456789101112131415161718192021222324252627# title() -&gt; str # 标题的每个单词都大写# capitalize() -&gt; str # 首个单词大写# center(width[,fillchar]) -&gt; str # width 打印宽度 # fillchar 填充的字符# zfill(width) -&gt; str # width 打印宽度，居右，左边用0填充# ljust(width[,fillchar]) -&gt; str 左对齐# rjust(width[,fillchar]) -&gt; str 右对齐练习&gt;&gt;&gt; "The Middle by Jimmy Eat World".center(39)' The Middle by Jimmy Eat World '&gt;&gt;&gt; "The Middle by Jimmy Eat World".center(39, "*")'*****The Middle by Jimmy Eat World*****'# center通过在两边添加填充字符(默认为空格)让字符串居中。上面表示总长度是39，不足的地方用星号填充&gt;&gt;&gt; "that's all folks".title()"That'S All, Folks"# title将字符串转换为词首大写，即所有单词的首字母都大写，其他字母都小写。然而，它确定单词边界的方式可能导致结果不合理。&gt;&gt;&gt; import string&gt;&gt;&gt; string.capwords("that's all, folks")That's All, Folks"# 还可以使用模块string中的函数capwords * 字符串修改12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# replace(old,new[,count]) -&gt; str # 字符串中找到匹配替换为新子串，返回新字符串 # count表示替换几次，不指定就是全部替换 'www.magedu.com'.replace('w','p')输出：'ppp.magedu.com''www.magedu.com'.replace('w','p',2)输出：'ppw.magedu.com''www.magedu.com'.replace('w','p',3)输出：'ppp.magedu.com''www.magedu.com'.replace('ww','p',2)输出：'pw.magedu.com''www.magedu.com'.replace('www','python',2)输出：'python.magedu.com'练习&gt;&gt;&gt; 'This is a test'.replace('is', 'eez')'Theez eez a test'# replace将指定子串都替换为另一个字符串，并返回替换后的结果。上面是将is替换为eez# strip([chars]) -&gt; str # 从字符串两端去除指定的字符集chars中的所有字符 # 如果chars没有指定，去除两端的空白字符 s = "\r \n \t Hello Python \n \t"s.strip()输出：'Hello Python'# 没有指定去除的字符串，所以去除的是空白s = " I am very very very sorry "s.strip('Iy')输出：' I am very very very sorry '# 因为前后都有空格，所以输出与原字符串没有区别s = " I am very very very sorry "s.strip('Iy ')输出：'am very very very sorr'# 在strip中加了空格，所以可以去除字符串中前后的空格和与空格挨着的I和y。练习&gt;&gt;&gt; ' internal whitespace is kept '.strip()'internal whitespace is kept'# strip将字符串开头和末尾的空白(但不包括中间的空白)删除，并返回删除后的结果。&gt;&gt;&gt; names = ['gumby', 'smith', 'jones']&gt;&gt;&gt; name = 'gumby '# 这里的gumby后有一个空格&gt;&gt;&gt; if name in names: print('Found it!')...&gt;&gt;&gt; if name.strip() in names: print('Found it!')...Found it!&gt;&gt;&gt;# 需要将输入与存储的值进行比较时，strip很有用。如上面，在用户名后多了一个空格也可以找到&gt;&gt;&gt; '*** SPAM * for * everyone!!! ***'.strip(' *!')'SPAM * for * everyone'# 这个方法可以删除开头或末尾的指定字符，中间的星号不会被删除。# lstrip([chars]) -&gt; str # 从左开始 # rstrip([chars]) -&gt; str # 从右开始 * 字符串查找123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# find(sub[,start[,end]]) -&gt; int # 在指定的区间[start,end]，从左至右，查找子串sub。查询到结果返回索引，没查询到结果返回-1# rfind(sub[,start[,end]]) -&gt; int # 在指定的区间[start,end]，从右至左，查找子串sub。查询到结果返回索引，没查询到结果返回-1 s = "I am very very very sorry"s.find('very')输出：5# 结果表示从索引5开始，找到了verys = "I am very very very sorry"s.find('very', 5)输出：5s = "I am very very very sorry"s.find('very', 6, 13)输出：-1# 这表示没有找到，区间是从索引6到12，这也是前包后不包。如果将13改成14，就能找到了s = "I am very very very sorry"s.rfind('very', 10)输出：15s = "I am very very very sorry"s.rfind('very', 10, 15)输出：10s = "I am very very very sorry"s.rfind('very',-10,-1)输出：15练习&gt;&gt;&gt; 'With a moo-moo here, and a moo-moo there'.find('moo')7&gt;&gt;&gt; title = "Monty Python's Flying Circus"&gt;&gt;&gt; title.find('Monty')0&gt;&gt;&gt; title.find('Python')6&gt;&gt;&gt; title.find('Flying')15&gt;&gt;&gt; title.find('Zirquss')-1# find在字符串中查找子串。如果找到，就返回子串的第一个字符的索引，否则返回-1。&gt;&gt;&gt; subject = '$$$ Get rich now!!! $$$'&gt;&gt;&gt; subject.find('$$$')0# 使用find查找在subject字符串中的$$$，字符串方法find返回的并非布尔值。如果find像这样返回0，就意味着它在索引0处找到了指定的子串。&gt;&gt;&gt; subject = '$$$ Get rich now!!! $$$'&gt;&gt;&gt; subject.find('$$$')0&gt;&gt;&gt; subject.find('$$$', 1) 20# 只指定了起点&gt;&gt;&gt; subject.find('!!!')16&gt;&gt;&gt; subject.find('!!!', 0, 16) -1# 同时指定了起点和终点# 起点和终点值(第二个和第三个参数)指定的搜索范围包含起点，但不包含终点。前包后不包# index(sub[, start[, end]]) -&gt; int # 在指定的区间[start, end)，从左至右，查找子串sub。找到返回索引，没找到抛出异常ValueError# rindex(sub[, start[, end]]) -&gt; int # 在指定的区间[start, end)，从左至右，查找子串sub。找到返回索引，没找到抛出异常ValueError# 这两个函数与上面两个不同之处就是会抛出异常。s = "I am very very very sorry"s.index('very')输出：5s = "I am very very very sorry"s.index('very', 5)输出：5s = "I am very very very sorry"s.index('very', 6, 13)输出：---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-19-2b0e56ce0749&gt; in &lt;module&gt; 1 s = "I am very very very sorry"----&gt; 2 s.index('very', 6, 13)ValueError: substring not founds = "I am very very very sorry"s.rindex('very', 10)输出：15s = "I am very very very sorry"s.rindex('very', 10, 15)输出：10s = "I am very very very sorry"s.rindex('very',-10,-1)输出：15# 时间复杂度 # index和count方法都是O(n) # 随着列表数据规模的增大,而效率下降# len(string) # 返回字符串的长度,即字符的个数# count(sub[, start[, end]]) -&gt; int # 在指定的区间[start, end),从左至右,统计子串sub出现的次数s = "I am very very very sorry"s.count('very')输出：3s = "I am very very very sorry"s.count('very', 5)输出：3s = "I am very very very sorry"s.count('very', 10, 14)输出：1 * 字符串判断12345678910111213141516171819202122232425262728293031323334# endswith(suffix[, start[, end]]) -&gt; bool # 在指定的区间[start, end)，字符串是否是suffix结尾# startswith(prefix[, start[, end]]) -&gt; bool # 在指定的区间[start, end)，字符串是否是prefix开头s = "I am very very very sorry"s.startswith('very')输出：Falses = "I am very very very sorry"s.startswith('very', 5)输出：Trues = "I am very very very sorry"s.startswith('very', 5, 9)输出：Trues = "I am very very very sorry"s.endswith('very', 5, 9)输出：True# 因为第一个very是从索引5到索引8，所以上面的命令涵盖了这个区间，所以无论是startswith还是# endswith都返回Trues = "I am very very very sorry"s.endswith('sorry', 5)输出：Trues = "I am very very very sorry"s.endswith('sorry', 5, -1)输出：False# 因为是前包后不包，所以索引是-1是不行的，就不能从尾部找到sorry了。s = "I am very very very sorry"s.endswith('sorry', 5, 100)输出：True 字符串判断 is系列12345678# isalnum() -&gt; bool 是否是字母和数字组成# isalpha() 是否是字母# isdecimal() 是否只包含十进制数字# isdigit() 是否全部数字(0~9)# isidentifier() 是不是字母和下划线开头,其他都是字母、数字、下划线# islower() 是否都是小写# isupper() 是否全部大写# isspace() 是否只包含空白字符 *** 字符串格式化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280# 字符串的格式化是一种拼接字符串输出样式的手段，更灵活方便 # join拼接只能使用分隔符，且要求被拼接的是可迭代对象 # + 拼接字符串还算方便，但是非字符串需要先转换为字符串才能拼接# 在2.5版本之前，只能使用printf style风格的print输出 # printf-style formatting，来自于C语言的printf函数 # 格式要求 # 占位符:使用%和格式字符组成，例如%s、%d等 # s调用str()，r会调用repr()。所有对象都可以被这两个转换。 # 占位符中还可以插入修饰字符，例如%03d表示打印3个位置，不够前面补零 # format % values，格式字符串和被格式的值之间使用%分隔 # values只能是一个对象，或是一个和格式字符串占位符数目相等的元组，或一个字典# printf-style formatting 举例"I am %03d" % (20,)输出：'I am 020''I like %s.' % 'Python'输出：'I like Python.''%3.2f%% , 0x%x, 0X%02X' % (89.7654, 10, 15)输出：'89.77% , 0xa, 0X0F'"I am %-5d" % (20,)输出：'I am 20 '# format函数格式字符串语法——Python鼓励使用 # "&#123;&#125; &#123;xxx&#125;".format(*args, **kwargs) -&gt; str # args是位置参数,是一个元组 # kwargs是关键字参数,是一个字典 # 花括号表示占位符 # &#123;&#125;表示按照顺序匹配位置参数,&#123;n&#125;表示取位置参数索引为n的值 # &#123;xxx&#125;表示在关键字参数中搜索名称一致的 # &#123;&#123;&#125;&#125; 表示打印花括号 # 位置参数"&#123;&#125;:&#123;&#125;".format('192.168.1.100',8888)输出：192.168.1.100:8888# 这就是按照位置顺序用位置参数替换前面的格式字符串的占位符中# 关键字参数或命名参数"&#123;server&#125; &#123;1&#125;:&#123;0&#125;".format(8888, '192.168.1.100', server='Web Server Info : ') 输出：Web Server Info : 192.168.1.100:8888# 位置参数按照序号匹配，关键字参数按照名词匹配# 访问元素"&#123;0[0]&#125;.&#123;0[1]&#125;".format(('magedu','com'))输出：magedu.com# 对象属性访问from collections import namedtuplePoint = namedtuple('_Point','x y')p = Point(4,5)"&#123;&#123;&#123;0.x&#125;,&#123;0.y&#125;&#125;&#125;".format(p)输出：'&#123;4,5&#125;'# 对齐'&#123;0&#125;*&#123;1&#125;=&#123;2:&lt;2&#125;'.format(3,2,2*3)输出：3*2=6 '&#123;0&#125;*&#123;1&#125;=&#123;2:&lt;02&#125;'.format(3,2,2*3)输出：3*2=60'&#123;0&#125;*&#123;1&#125;=&#123;2:&gt;02&#125;'.format(3,2,2*3)输出：3*2=06'&#123;:^30&#125;'.format('centered')输出： centered '&#123;:*^30&#125;'.format('centered')输出：***********centered***********# 进制"int: &#123;0:d&#125;; hex: &#123;0:x&#125;; oct: &#123;0:o&#125;; bin: &#123;0:b&#125;".format(42)输出：int: 42; hex: 2a; oct: 52; bin: 101010 "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(42)输出：int: 42; hex: 0x2a; oct: 0o52; bin: 0b101010 octets = [192, 168, 0, 1]'&#123;:02X&#125;&#123;:02X&#125;&#123;:02X&#125;&#123;:02X&#125;'.format(*octets)输出：C0A80001# *号表示参数解构，依次将每个元素分解开。X表示转为16进制练习&gt;&gt;&gt; format = "Hello, %s. %s enough for ya?"&gt;&gt;&gt; values = ('world', 'Hot')&gt;&gt;&gt; format % values'Hello, world. Hot enough for ya?'# 在%左边指定一个字符串(格式字符串)，并在右边指定要设置其格式的值。指定要设置其格式的值时，可使用单个值(如字符串或数字)，可使用元组(如果要设置多个值的格式)，还可使用字典，其中最常见的是元组。&gt;&gt;&gt; format = "Hello, %s. %s enough for ya?"&gt;&gt;&gt; values = ('world', 'Hot')&gt;&gt;&gt; format % values'Hello, world. Hot enough for ya?'# 上述格式字符串中的%s称为转换说明符，指出了要将值插入什么地方。s意味着将值视为字符串进行格式设置。如果指定的值不是字符串，将使用str将其转换为字符串。其他说明符将导致其他形式的转换。例如，%.3f将值的格式设置为包含3位小数的浮点数。&gt;&gt;&gt; from string import Template&gt;&gt;&gt; tmpl = Template("Hello, $who! $what enough for ya?")&gt;&gt;&gt; tmpl.substitute(who="Mars", what="Dusty")'Hello, Mars! Dusty enough for ya?'# 包含等号的参数称为关键字参数。在字符串格式设置中，可将关键字参数视为一种向命名替换字段提供值的方式。&gt;&gt;&gt; "&#123;&#125;, &#123;&#125; and &#123;&#125;".format("first", "second", "third")'first, second and third'&gt;&gt;&gt; "&#123;0&#125;, &#123;1&#125; and &#123;2&#125;".format("first", "second", "third")'first, second and third'# 在最简单的情况下，替换字段没有名称或将索引用作名称。&gt;&gt;&gt; "&#123;3&#125; &#123;0&#125; &#123;2&#125; &#123;1&#125; &#123;3&#125; &#123;0&#125;".format("be", "not", "or", "to")'to be or not to be'# 索引无需按顺序排列&gt;&gt;&gt; from math import pi&gt;&gt;&gt; "&#123;name&#125; is approximately &#123;value:.2f&#125;.".format(value=pi, name="π")'π is approximately 3.14.'# 关键字参数的排列顺序无关紧要。在这里，我还指定了格式说明符.2f，并使用冒号将其与字段名隔开。它意味着要使用包含2位小数的浮点数格式。&gt;&gt;&gt; "&#123;name&#125; is approximately &#123;value&#125;.".format(value=pi, name="π")'π is approximately 3.141592653589793.'# 没有指定.2f的结果&gt;&gt;&gt; from math import e&gt;&gt;&gt; f"Euler's constant is roughly &#123;e&#125;.""Euler's constant is roughly 2.718281828459045."# 如果变量与替换字段同名，可使用f字符串——在字符串前面加上f。创建最终的字符串时，将把替换字段e替换为变量e的值。&gt;&gt;&gt; "Euler's constant is roughly &#123;e&#125;.".format(e=e)"Euler's constant is roughly 2.718281828459045."# 此命令与上面的命令效果是一样的。&gt;&gt;&gt; "&#123;&#123;ceci n'est pas une replacement field&#125;&#125;".format()"&#123;ceci n'est pas une replacement field&#125;"# 要在最终结果中包含花括号，可在格式字符串中使用两个花括号(即&#123;&#123;或 &#125;&#125;)来指定。============================================================================================在格式字符串中，最激动人心的部分为替换字段。替换字段由如下部分组成，其中每个部分都是可选的。* 字段名：索引或标识符，指出要设置哪个值的格式并使用结果来替换该字段。除指定值外，还可指定值的特定部分，如列表的元素。* 转换标志：跟在叹号后面的单个字符。当前支持的字符包括r(表示repr) 、s(表示str)和a(表示ascii)。如果你指定了转换标志，将不使用对象本身的格式设置机制，而是使用指定的函数将对象转换为字符串，再做进一步的格式设置。* 格式说明符：跟在冒号后面的表达式(这种表达式是使用微型格式指定语言表示的) 。格式说明符让我们能够详细地指定最终的格式，包括格式类型(如字符串、浮点数或十六进制数)，字段宽度和数的精度，如何显示符号和千位分隔符，以及各种对齐和填充方式。============================================================================================&gt;&gt;&gt; "&#123;foo&#125; &#123;&#125; &#123;bar&#125; &#123;&#125;".format(1, 2, bar=4, foo=3)'3 1 4 2'# 还可通过索引来指定要在哪个字段中使用相应的未命名参数，这样可不按顺序使用未命名参数。&gt;&gt;&gt; "&#123;foo&#125; &#123;1&#125; &#123;bar&#125; &#123;0&#125;".format(1, 2, bar=4, foo=3)'3 2 4 1'# 不能同时使用手工编号和自动编号，因为这样很快会变得混乱不堪。&gt;&gt;&gt; fullname = ["Alfred", "Smoketoomuch"]&gt;&gt;&gt; "Mr &#123;name[1]&#125;".format(name=fullname)'Mr Smoketoomuch'&gt;&gt;&gt; import math&gt;&gt;&gt; tmpl = "The &#123;mod.__name__&#125; module defines the value &#123;mod.pi&#125; for π"&gt;&gt;&gt; tmpl.format(mod=math)'The math module defines the value 3.141592653589793 for π'&gt;&gt;&gt; print("&#123;pi!s&#125; &#123;pi!r&#125; &#123;pi!a&#125;".format(pi="π"))π 'π' '\u03c0'# 上述三个标志(s、r和a)指定分别使用str、repr和ascii进行转换。函数str通常创建外观普通的字符串版本(这里没有对输入字符串做任何处理)。函数 repr 尝试创建给定值的Python表示(这里是一个字符串字面量)。函数 ascii创建只包含ASCII字符的表示&gt;&gt;&gt; "The number is &#123;num&#125;".format(num=42)'The number is 42'&gt;&gt;&gt; "The number is &#123;num:f&#125;".format(num=42)'The number is 42.000000'# 可指定要转换的值是哪种类型，更准确地说，是要将其视为哪种类型。例如，上面命令提供一个整数，但将其作为小数进行处理。为此可在格式说明(即冒号后面)使用字符f(表示定点数) 。&gt;&gt;&gt; "The number is &#123;num:b&#125;".format(num=42)'The number is 101010'# 作为二进制数进行处理============================================================================================类型 含义b 将整数表示为二进制数c 将整数解读为Unicode码点d 将整数视为十进制数进行处理，这是整数默认使用的说明符e 使用科学表示法来表示小数(用e来表示指数)E 与e相同，但使用E来表示指数f 将小数表示为定点数F 与 f相同，但对于特殊值(nan和 inf)，使用大写表示g 自动在定点表示法和科学表示法之间做出选择。这是默认用于小数的说明符，但在默认情况下至少有1位小数G 与 g相同，但使用大写来表示指数和特殊值n 与 g相同，但插入随区域而异的数字分隔符o 将整数表示为八进制数s 保持字符串的格式不变，这是默认用于字符串的说明符x 将整数表示为十六进制数并使用小写字母X 与 x相同，但使用大写字母% 将数表示为百分比值(乘以100，按说明符 f设置格式，再在后面加上%)============================================================================================&gt;&gt;&gt; "&#123;num:10&#125;".format(num=3)' 3'&gt;&gt;&gt; "&#123;name:10&#125;".format(name="Bob")'Bob '# 宽度是使用整数指定的。数和字符串的对齐方式不同。&gt;&gt;&gt; "Pi day is &#123;pi:.2f&#125;".format(pi=pi)'Pi day is 3.14'# 精度也是使用整数指定的，但需要在它前面加上一个表示小数点的句点。这里显式地指定了类型f，因为默认的精度处理方式稍有不同&gt;&gt;&gt; "&#123;pi:10.2f&#125;".format(pi=pi)' 3.14'# 同时指定宽度和精度&gt;&gt;&gt; "&#123;:.5&#125;".format("Guido van Rossum")'Guido'# 对于其他类型也可指定精度，但是这样做的情形不太常见。&gt;&gt;&gt; 'One googol is &#123;:,&#125;'.format(10**100)'One googol is 10,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000'# 使用逗号来指出你要添加千位分隔符&gt;&gt;&gt; '&#123;:010.2f&#125;'.format(pi)'0000003.14'# 在指定宽度和精度的数前面，可添加一个标志。这个标志可以是零、加号、减号或空格，其中零表示使用0来填充数字。# &#123;:010.2f&#125;指定一共有10位，小数点有两位，前面不足的地方用0填充。&gt;&gt;&gt; print('&#123;0:&lt;10.2f&#125;\n&#123;0:^10.2f&#125;\n&#123;0:&gt;10.2f&#125;'.format(pi))3.14 3.14 3.14# 指定左对齐、右对齐和居中，可分别使用&lt;、&gt;和^&gt;&gt;&gt; "&#123;:$^15&#125;".format(" WIN BIG ")'$$$ WIN BIG $$$'# &#123;:$^15&#125;表示一共15位，空格也算，不足的地方用$填充。&gt;&gt;&gt; print('&#123;0:10.2f&#125;\n&#123;1:10.2f&#125;'.format(pi, -pi)) 3.14 -3.14&gt;&gt;&gt; print('&#123;0:10.2f&#125;\n&#123;1:=10.2f&#125;'.format(pi, -pi)) 3.14- 3.14# 指定将填充字符放在符号和数字之间。&#123;1:=10.2f&#125;表示索引为1的元素&gt;&gt;&gt; print('&#123;0:-.2&#125;\n&#123;1:-.2&#125;'.format(pi, -pi)) #默认设置3.1-3.1&gt;&gt;&gt; print('&#123;0:+.2&#125;\n&#123;1:+.2&#125;'.format(pi, -pi))+3.1-3.1&gt;&gt;&gt; print('&#123;0: .2&#125;\n&#123;1: .2&#125;'.format(pi, -pi))3.1-3.1# 要给正数加上符号，可使用说明符+(将其放在对齐说明符后面)，而不是默认的-。如果将符号说明符指定为空格，会在正数前面加上空格而不是+。&gt;&gt;&gt; "&#123;:b&#125;".format(42)'101010'&gt;&gt;&gt; "&#123;:#b&#125;".format(42)'0b101010'# 井号( #)选项，可将其放在符号说明符和宽度之间(如果指定了这两种设置)。这个选项将触发另一种转换方式，转换细节随类型而异。例如，对于二进制、八进制和十六进制转换，将加上一个前缀。&gt;&gt;&gt; "&#123;:g&#125;".format(42)'42'&gt;&gt;&gt; "&#123;:#g&#125;".format(42)'42.0000'# 对于各种十进制数,它要求必须包含小数点(对于类型g,它保留小数点后面的零)。# 根据指定的宽度打印格式良好的价格列表width = int(input('Please enter width: '))price_width = 10item_width = width - price_widthheader_fmt = '&#123;&#123;:&#123;&#125;&#125;&#125;&#123;&#123;:&gt;&#123;&#125;&#125;&#125;'.format(item_width, price_width)fmt = '&#123;&#123;:&#123;&#125;&#125;&#125;&#123;&#123;:&gt;&#123;&#125;.2f&#125;&#125;'.format(item_width, price_width)print('=' * width)print(header_fmt.format('Item', 'Price'))print('-' * width)print(fmt.format('Apples', 0.4))print(fmt.format('Pears', 0.5))print(fmt.format('Cantaloupes', 1.92))print(fmt.format('Dried Apricots (16 oz.)', 8))print(fmt.format('Prunes (4 lbs.)', 12))print('=' * width)这个程序的运行情况类似于下面这样:Please enter width: 35===================================Item Price-----------------------------------Apples 0.40Pears 0.50Cantaloupes 1.92Dried Apricots (16 oz.) 8.00Prunes (4 lbs.) 12.00=================================== string模块12345678910111213string.digits# 包含数字0~9的字符串。string.ascii_letters# 包含所有ASCII字母(大写和小写)的字符串。string.ascii_lowercase# 包含所有小写ASCII字母的字符串。string.printable# 包含所有可打印的ASCII字符的字符串。string.punctuation# 包含所有ASCII标点字符的字符串。string.ascii_uppercase# 包含所有大写ASCII字母的字符串。# 虽然说的是ASCII字符，但值实际上是未解码的Unicode字符串。 translate（替换字符串）12345678910111213# 方法translate与replace一样替换字符串的特定部分，但不同的是它只能进行单字符替换。这个方法的优势在于能够同时替换多个字符，因此效率比replace高。&gt;&gt;&gt; table = str.maketrans('cs', 'kz')# 使用translate前必须创建一个转换表。将cs两个字母转换为kz两个字母，字母是单个匹配的。这个转换表指出了不同Unicode码点之间的转换关系。要创建转换表，可对字符串类型str调用方法maketrans，这个方法接受两个参数：两个长度相同的字符串，它们指定要将第一个字符串中的每个字符都替换为第二个字符串中的相应字符。&gt;&gt;&gt; table&#123;115: 122, 99: 107&#125;# 查看转换表的内容，但你看到的只是Unicode码点之间的映射。&gt;&gt;&gt; 'this is an incredible test'.translate(table)'thiz iz an inkredible tezt'# 创建转换表后，就可将其用作方法translate的参数。&gt;&gt;&gt; table = str.maketrans('cs', 'kz', ' ')&gt;&gt;&gt; 'this is an incredible test'.translate(table)'thizizaninkredibletezt'# 调用方法 maketrans时,还可提供可选的第三个参数，指定要将哪些字母删除。上面是将所有的空格删除。 判断字符串是否满足特定的条件 很多字符串方法都以is打头，如isspace、 isdigit 和isupper，它们判断字符串是否具有特定的性质(如包含的字符全为空白、数字或大写) 。如果字符串具备特定的性质，这些方法就返回True，否则返回False。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>使用字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-列表和元组]]></title>
    <url>%2F2019%2F03%2F21%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84%2F</url>
    <content type="text"><![CDATA[概念数据结构 数据结构是以某种方式(如通过编号)组合起来的数据元素(如数、字符乃至其他数据结构)集合。 序列 在Python中，最基本的数据结构为序列(sequence) 。序列中的每个元素都有编号，即其位置或索引，其中第一个元素的索引为0，第二个元素的索引为1，依此类推。Python内置了多种序列，如列表、元组、字符串。列表和元组的主要不同在于，列表是可以修改的，而元组不可以。 列表1234567891011121314151617181920212223242526272829# 一个队列，一个排列整齐的队伍# 列表内的个体称作元素，由若干元素组成列表# 元素可以是任意对象（数字、字符串、对象、列表等）# 列表内元素有顺序，可以使用索引# 线性的数据结构# 使用[]表示# 列表是可变的# 列表list、链表、queue、stack的差异# 列表不能一开始就定义大小list()# 定义一个空列表list(iterable)# 从可交互项初始化的新列表例lst = list()# list()中需要是一个可迭代序列，如range()。或一个列表，如list([1,2])，不能使用list(2)这样的方法来定义，会提示int是不可迭代的lst = []lst = [2,6,9,'ab']lst = list(range(5))&gt;&gt;&gt; edward = ['Edward Gumby', 42]# 使用列表来表示&gt;&gt;&gt; edward = ['Edward Gumby', 42]&gt;&gt;&gt; john = ['John Smith', 50]&gt;&gt;&gt; database = [edward, john]&gt;&gt;&gt; database[['Edward Gumby', 42], ['John Smith', 50]]# 序列还可包含其他序列，上面是创建一个由数据库中所有人员组成的列表。Python支持一种数据结构的基本概念，名为容器(container)。容器基本上就是可包含其他对象的对象。两种主要的容器是序列(如列表和元组)和映射(如字典) 。在序列中，每个元素都有编号，而在映射中，每个元素都有名称(也叫键)。 数字的处理函数12345678910111213141516171819round()# 这个函数是四舍六入五取偶的floor()# 这个函数是向下取整的ceil()# 这个函数是向上取整的int()# 这个函数是取整数部分的//# 整除且向下取整# python只有长整型，数值没有上限。int也是取整的，如int(1.5)，得1。floor是向下取整的。ceil是向上取整的。round是4舍6入5取偶。 bin是二进制，返回的是字符串。oct是八进制。pi是派。 bin()oct()hex()# 上面三个是进制函数，返回值是字符串math.pi# 派math.e# 自然常数 类型判断1234567891011121314type(a) == str # 这是类型比较的方式type(obj)# 返回类型，而不是字符串isinstance(obj,class_or_tuple)# 返回布尔值例：type(a)type('abc')type(123)isinstance(6,str)isinstance(6,(str,bool,int))type(1+True)type(1+True+2.0) 通用的序列操作索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 索引，也叫下标# 正索引：从左至右，从0开始，为列表中每一个元素编号# 负索引：从右至左，从-1开始# 正负索引不可以超界，否则引发异常IndexError# 为了理解方便，可以认为列表是从左至右排列的，左边是头部，右边是尾部，左边是下界，右边是上界# 列表通过索引访问# list[index]，index就是索引，使用中括号访问&gt;&gt;&gt; greeting = 'Hello'&gt;&gt;&gt; greeting[0]'H'# 字符串就是由字符组成的序列。索引0指向第一个元素,这里为字母H。Python没有专门用于表示字符的类型，因此一个字符就是只包含一个元素的字符串。&gt;&gt;&gt; greeting[-1]'o'# 当你使用负数索引时，Python将从右(即从最后一个元素)开始往左数，因此-1是最后一个元素的位置。对于字符串字面量(以及其他的序列字面量)，可直接对其执行索引操作,无需先将其赋给变量。这与先赋给变量再对变量执行索引操作的效果是一样的。&gt;&gt;&gt; 'Hello'[1]'e'&gt;&gt;&gt; fourth = input('Year: ')[3]Year: 2005&gt;&gt;&gt; fourth'5'# 如果函数调用返回一个序列，可直接对其执行索引操作。例如：如果你只想获取用户输入的年份的第4位months = ['January','February','March','April','May','June','July','August','September','October','November','December']endings = ['st', 'nd', 'rd'] + 17 * ['th'] \+ ['st', 'nd', 'rd'] + 7 * ['th'] \+ ['st']# 这是一个列表的拼接，st,nd,rd表示1,2,3号，4-20使用th，之后只要有1,2,3就要用st,nd,rd表示，其他用th表示year= input('Year: ')month= input('Month (1-12): ')day= input('Day (1-31): ')month_number = int(month)day_number = int(day)month_name = months[month_number-1]ordinal = day + endings[day_number-1]# 将表示月和日的数要减1，这样才能得到正确的索引。因为months是一个列表，其索引是从0开始的，所以要减1。print(month_name + ' ' + ordinal + ', ' + year)上面的程序执行结果如下：Year: 1974Month (1-12): 8Day (1-31): 16August 16th, 1974 切片1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 需要注意：使用切片方法时，切片中指定的第一个索引值是一定会取的，第二个元素不一定取得到。&gt;&gt;&gt; tag = '&lt;a href="http://www.python.org"&gt;Python web site&lt;/a&gt;'&gt;&gt;&gt; tag[9:30]'http://www.python.org'# 这是提取tag变量索引9到29的值&gt;&gt;&gt; tag[32:-4]'Python web site'# 提取tag变量索引32到倒数第5个的值。中括号中的数字是前包后不包的。也就是第一个索引指定的元素包含在切片内，但第二个索引指定的元素不包含在切片内。如下：&gt;&gt;&gt; numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; numbers[3:6] [4, 5, 6]&gt;&gt;&gt; numbers[0:1] [1]&gt;&gt;&gt; numbers[7:10][8, 9, 10]# 首先明确指定从第8个元素开始取值，在这里，索引10指的是第11个元素，它并不存在，但确实是到达最后一个元素后再前进一步所处的位置。&gt;&gt;&gt; numbers[-3:-1][8, 9]# 从倒数第3个元素取到倒数第二个元素&gt;&gt;&gt; numbers[-3:0][]# 如果第二个元素使用0，那么结果是一个空。因为执行切片操作时，如果第一个索引指定的元素位于第二个索引指定的元素后面(在这里，倒数第3个元素位于第1个元素后面) ，结果就为空序列。&gt;&gt;&gt; numbers[-3:][8, 9, 10]# 如果要取到最后一个元素，可以不写第二个索引的值&gt;&gt;&gt; numbers[:3][1, 2, 3]# 同样，如果索引从第一个元素开始取值，也可以不写第一个元素的值&gt;&gt;&gt; numbers[:][1, 2, 3, 4, 5, 6, 7, 8, 9, 10]# 要复制整个序列,可将两个索引都省略。&gt;&gt;&gt; url = input('Please enter the URL:')&gt;&gt;&gt; domain = url[11:-4]&gt;&gt;&gt; print("Domain name: " + domain)Please enter the URL: http://www.python.orgDomain name: python# 从类似于http://www.something.com的URL中提取域名&gt;&gt;&gt; numbers[0:10:1][1, 2, 3, 4, 5, 6, 7, 8, 9, 10]# 执行切片操作时，你显式或隐式地指定起点和终点，但通常省略另一个参数，即步长。在普通切片中，步长为1。这意味着从一个元素移到下一个元素，因此切片包含起点和终点之间的所有元素。&gt;&gt;&gt; numbers[0:10:2][1, 3, 5, 7, 9]&gt;&gt;&gt; numbers[3:6:3][4]&gt;&gt;&gt; numbers[::4][1, 5, 9]# 要从序列中每隔3个元素提取1个，只需提供步长4即可。&gt;&gt;&gt; numbers[8:3:-1][9, 8, 7, 6, 5]&gt;&gt;&gt; numbers[10:0:-2][10, 8, 6, 4, 2]&gt;&gt;&gt; numbers[0:10:-2][]&gt;&gt;&gt; numbers[::-2][10, 8, 6, 4, 2]&gt;&gt;&gt; numbers[5::-2][6, 4, 2]&gt;&gt;&gt; numbers[:5:-2][10, 8]# 步长不能为0，否则无法向前移动，但可以为负数，即从右向左提取元素。步长为负数时，第一个索引必须比第二个索引大。 序列相加123456789101112131415# + -&gt; list# 连接操作，将两个列表连接起来# 产生新的列表，原列表不变# 本质上调用的是__add__()方法&gt;&gt;&gt; [1, 2, 3] + [4, 5, 6][1, 2, 3, 4, 5, 6]&gt;&gt;&gt; 'Hello,' + 'world!''Hello, world!'&gt;&gt;&gt; [1, 2, 3] + 'world!'Traceback (innermost last):File "&lt;pyshell&gt;", line 1, in ?[1, 2, 3] + 'world!'TypeError: can only concatenate list (not "string") to list# 不能拼接列表和字符串，虽然它们都是序列。一般而言，不能拼接不同类型的序列。 乘法123456789101112131415161718192021222324252627282930313233343536373839404142# * -&gt; list# 重复操作，将本列表元素重复n次，返回新的列表。&gt;&gt;&gt; 'python' * 5'pythonpythonpythonpythonpython'&gt;&gt;&gt; [42] * 10[42, 42, 42, 42, 42, 42, 42, 42, 42, 42]# 将序列与数x相乘时，将重复这个序列x次来创建一个新序列&gt;&gt;&gt; sequence = [None] * 10&gt;&gt;&gt; sequence[None, None, None, None, None, None, None, None, None, None]# 空列表是使用不包含任何内容的两个方括号([])表示的。如果要创建一个可包含10个元素的列表，但没有任何有用的内容，可像前面那样使用[42]*10。但更准确的做法是使用[0]*10，这将创建一个包含10个零的列表。然而，在有些情况下，你可能想使用表示“什么都没有”的值，如表示还没有在列表中添加任何内容。在这种情况下，可使用None。在Python中，None表示什么都没有。sentence = input("Sentence: ")# 这里是要求输入要在框中显示的内容的screen_width = 80# screen_width：屏幕宽度text_width = len(sentence)# 文本宽度，len用于取字符串宽度box_width = text_width + 4# 框的宽度，这里加的数需要自行调整，示例中加了6，但测试打印出的内容没有达到效果left_margin = (screen_width - box_width) // 2# 左边缘的宽度，等于屏幕宽度减去框的宽度最后除以2,这是为了使最后的内容居中print()# 打印一个空行print(' ' * left_margin + '+' + '-' * (box_width-2) + '+')# ' ' * left_margin是整个内容左边空出来的距离，然后输出一个加号，之后输出"-"，输出的数量是外框的长度减2,因为两侧都有一个加号所以要减2.最后输出一个加号。print(' ' * left_margin + '| ' + ' ' * text_width + ' |')# 实际打印每一行时只要注意左侧的空格数量就可以了。print(' ' * left_margin + '| ' + sentence + ' |')# 通过'| '和' |'使内容与边缘间多出一个空格print(' ' * left_margin + '| ' + ' ' * text_width + ' |')print(' ' * left_margin + '+' + '-' * (box_width-2) + '+')print()输出结果如下：Sentence: He's a very naughty boy! +---------------------------------+ | | | He's a very naughty boy! | | | +---------------------------------+ 成员资格12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 要检查特定的值是否包含在序列中，可使用运算符in。这个运算符与前面讨论的运算符(如乘法或加法运算符)稍有不同。它检查是否满足指定的条件，并返回相应的值:满足时返回True，不满足时返回False。这样的运算符称为布尔运算符，而前述真值称为布尔值。&gt;&gt;&gt; permissions = 'rw'&gt;&gt;&gt; 'w' in permissionsTrue&gt;&gt;&gt; 'x' in permissionsFalse# 使用成员资格测试分别检查'w'和'x'是否包含在字符串变量permissions中&gt;&gt;&gt; users = ['mlh', 'foo', 'bar']&gt;&gt;&gt; input('Enter your user name: ') in usersEnter your user name: mlhTrue# 检查提供的用户名mlh是否包含在用户列表中，这在程序需要执行特定的安全策略时很有用(在这种情况下，可能还需检查密码)。&gt;&gt;&gt; subject = '$$$ Get rich now!!! $$$'&gt;&gt;&gt; '$$$' in subjectTrue# 检查字符串变量subject是否包含字符串'$$$'，这可用于垃圾邮件过滤器中。# 相比于其他示例，检查字符串是否包含'$$$'的示例稍有不同。一般而言，运算符in检查指定的对象是否是序列(或其他集合)的成员(即其中的一个元素)，但对字符串来说，只有它包含的字符才是其成员或元素，因此下面的代码完全合理：&gt;&gt;&gt; 'P' in 'Python' Truedatabase = [['albert', '1234'],['dilbert', '4242'],['smith', '7524'],['jones', '9843']]username = input('User name: ')pin = input('PIN code: ')if [username, pin] in database: print('Access granted')输出结果如下：User name: jonesPIN code: 9843Access granted# 检查用户名和PIN码，程序从用户那里获取一个用户名和一个PIN码，并检查它们组成的列表是否包含在数据库(实际上也是一个列表)中。如果用户名-PIN码对包含在数据库中，就打印字符串'Access granted'&gt;&gt;&gt; numbers = [100, 34, 678]&gt;&gt;&gt; len(numbers)3&gt;&gt;&gt; max(numbers)678&gt;&gt;&gt; min(numbers)34&gt;&gt;&gt; max(2, 3)3&gt;&gt;&gt; min(9, 3, 2, 5)2# 函数len返回序列包含的元素个数，而min和max分别返回序列中最小和最大的元素。# 最后两个表达式调用max和min时指定的实参并不是序列，而直接将数作为实参。 随机数123456789# random模块# randint(a,b)返回[a,b]之间的整数# choice(seq)从非空序列的元素中随机挑选一个元素，比如random.choice(range(10))，从0到9中随机挑选一个整数。random.choice([1,3,5,7])# randrange([start,]stop[,step])从指定范围内，按指定基数递增的集合中获取一个随机数，基数缺省值为1.random.randrange(1,7,2)# random.shuffle(list) -&gt; None，就地打乱列表元素# sample(population,k)从样本空间或总体（序列或者集合类型）中随机取出k个不同的元素，返回一个新的列表import randomrandom.sample(['a','b','c','d'],2)random.sample(['a','a'],2) 列表函数list1234&gt;&gt;&gt; list('Hello')['H', 'e', 'l', 'l', 'o']# 鉴于不能像修改列表那样修改字符串，因此在有些情况下使用字符串来创建列表很有帮助。可将任何序列(而不仅仅是字符串)作为list的参数。# 要将字符列表(如前述代码中的字符列表)转换为字符串。可使用下面的表达式：''.join(somelist)，其中somelist是要转换的列表。 基本的列表操作123456789101112131415161718192021222324252627282930313233343536373839404142434445* 修改列表：给元素赋值list[index] = value# 索引不要超界&gt;&gt;&gt; x = [1, 1, 1]&gt;&gt;&gt; x[1] = 2# 将索引为1的值改为2&gt;&gt;&gt; x[1, 2, 1]# 不能给不存在的元素赋值，因此如果列表的长度为2，就不能给索引为100的元素赋值。要这样做，列表的长度至少为101。* 删除元素&gt;&gt;&gt; names = ['Alice', 'Beth', 'Cecil', 'Dee-Dee', 'Earl']&gt;&gt;&gt; del names[2]&gt;&gt;&gt; names['Alice', 'Beth', 'Dee-Dee', 'Earl']* 给切片赋值&gt;&gt;&gt; name = list('Perl')&gt;&gt;&gt; name['P', 'e', 'r', 'l']&gt;&gt;&gt; name[2:] = list('ar')# 将索引为2到最后的一个元素改为ar，perl就变成了pear&gt;&gt;&gt; name['P', 'e', 'a', 'r']&gt;&gt;&gt; name = list('Perl')&gt;&gt;&gt; name[1:] = list('ython')&gt;&gt;&gt; name['P', 'y', 't', 'h', 'o', 'n']# 通过使用切片赋值，可将切片替换为长度与其不同的序列。&gt;&gt;&gt; numbers = [1, 5]&gt;&gt;&gt; numbers[1:1] = [2, 3, 4]# [1:1] 指在索引为1的地方&gt;&gt;&gt; numbers[1, 2, 3, 4, 5]# 使用切片赋值还可在不替换原有元素的情况下插入新元素。在这里，“替换”了一个空切片，相当于插入了一个序列。&gt;&gt;&gt; numbers[1, 2, 3, 4, 5]&gt;&gt;&gt; numbers[1:4] = []# 将索引1至4的元素值替换为空&gt;&gt;&gt; numbers[1, 5]# 上述代码与del numbers[1:4]等效 列表方法 方法是与对象(列表、数、字符串等)联系紧密的函数。调用方法：object.method(arguments)方法调用与函数调用很像，只是在方法名前加上了对象和句点。列表包含多个可用来查看或修改其内容的方法。 下面的方法中，pop index count copy 这四个方法不会就地修改并返回None；append clear extend insert remove reverse sort 这些方法会就地修改并返回None append12345678910# append(object) -&gt; None# 列表尾部追加元素，返回None# 返回None就意味着没有新的列表产生，就地修改# 时间复杂度是O(1)&gt;&gt;&gt; lst = [1, 2, 3]&gt;&gt;&gt; lst.append(4)&gt;&gt;&gt; lst[1, 2, 3, 4]# 方法append用于将一个对象附加到列表末尾。 append也就地修改列表。它不会返回修改后的新列表，而是直接修改旧列表。 clear12345678# clear() -&gt; None# 清除列表所有元素，剩下一个空列表&gt;&gt;&gt; lst = [1, 2, 3]&gt;&gt;&gt; lst.clear()&gt;&gt;&gt; lst[]# 方法clear就地清空列表的内容。这类似于切片赋值语句lst[:] = []。 copy123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# copy() -&gt; list# shadow copy返回一个新的列表&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; b[1] = 4&gt;&gt;&gt; a[1, 4, 3]# 方法 copy 复制列表。常规复制只是将另一个名称关联到列表。要让a 和b 指向不同的列表，就必须将b关联到a的副本。&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a.copy()&gt;&gt;&gt; b[1] = 4&gt;&gt;&gt; a[1, 2, 3]# 这类似于使用a[:]或list(a)，它们也都复制a。# shadow copy表示影子拷贝，也叫浅拷贝，遇到引用类型，只是复制了一个引用而已# 深浅拷贝测试lst0 = list(range(4))id(lst0)# 查看内存地址hash(lst0)# 列表是不可hash的，所以会报错hash(id(lst0))# 这样才行lst1 = list(range(4))id(lst1)# lst0和lst1在内存中的位置是不一样的。lst0 == lst1# 这里比较的是两个列表的值lst0 is lst1# 这里比较的是两个列表的内存地址。id就是查看内存地址的lst1 = lst0# 这里是将lst0的内存地址给了lst1，这时两个列表都指向了同一个内存地址，所以下面修改lst1的内容时，lst0也会改变lst1[2] = 10lst0lst0 = list(range(4))lst5 = lst0.copy()# 这里只是复制内容，内存地址是不一样的lst5lst5 == lst0# 返回Truelst5 is lst0# 返回Falseid(lst0)id(lst5)# 内存地址不一样lst0 = [1,[2,3,4],5]lst5 = lst0.copy()# 这是一个影子拷贝或叫浅拷贝。当复制的内容比较复杂时，会复制内存地址，如下面的lst0和lst5的复制。lst5 == lst0# 返回Truelst5[2] = 10lst5 == lst0# 返回Falselst0lst5[2] = 5lst5 == lst0# 返回Truelst5[1][1] = 20# 这里修改的是第一个元素中的第一个元素lst5 == lst0# 因为是浅拷贝，所以列表中的列表复制的是内存地址，所以会都改变。返回Truelst0lst5# 两个列表中的值是一样的# 深拷贝# copy模块提供了deepcopyimport copylst0 = [1,[2,3,4],5]lst5 = copy.deepcopy(lst0)lst5[1][1] = 20lst5 == lst0 count1234567891011# count(value)# 返回列表中匹配value的次数&gt;&gt;&gt; ['to', 'be', 'or', 'not', 'to', 'be'].count('to')2&gt;&gt;&gt; x = [[1, 2], 1, 1, [2, 1, [1, 2]]]&gt;&gt;&gt; x.count(1)2&gt;&gt;&gt; x.count([1, 2])1# 方法count计算指定的元素在列表中出现了多少次。 extend1234567891011121314151617181920# extend(iteratable) -&gt; None# 将可迭代对象的元素追加进来，返回None# 就地修改&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = [4, 5, 6]&gt;&gt;&gt; a.extend(b)&gt;&gt;&gt; a[1, 2, 3, 4, 5, 6]# 方法extend让你能够同时将多个值附加到列表末尾，为此可将这些值组成的序列作为参数提供给方法extend。换而言之，你可使用一个列表来扩展另一个列表。# 这可能看起来类似于拼接，但存在一个重要差别，那就是将修改被扩展的序列(这里是a)。在常规拼接中，情况是返回一个全新的序列。&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = [4, 5, 6]&gt;&gt;&gt; a + b[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; a[1, 2, 3]# 拼接出来的列表与前一个示例扩展得到的列表完全相同，但在这里a并没有被修改。鉴于常规拼接必须使用a和b的副本创建一个新列表，因此如果你要获得类似于下面的效果，拼接的效率将比extend低:&gt;&gt;&gt; a = a + b# 拼接操作并非就地执行的，即它不会修改原来的列表。 index12345678910111213141516# index(value,[start,[stop]])# 通过值value，从指定区间查找列表内的元素是否匹配# 匹配第一个就立即返回索引# 匹配不到，抛出异常ValueError&gt;&gt;&gt; knights = ['We', 'are', 'the', 'knights', 'who', 'say', 'ni']&gt;&gt;&gt; knights.index('who')4&gt;&gt;&gt; knights.index('herring')Traceback (innermost last):File "&lt;pyshell&gt;", line 1, in ?knights.index('herring')ValueError: list.index(x): x not in list&gt;&gt;&gt; knights[4]'who'# index在列表中查找指定值第一次出现的索引。搜索单词'who'时，发现它位于索引4处。然而，搜索'herring'时引发了异常，因为根本就没有找到这个单词。 insert1234567891011121314151617# insert(index,object) -&gt; None# 在指定的索引index处插入元素object# 返回None就意味着没有新的列表产生，就地修改# 时间复杂度是O(n)# 索引超越上界，尾部追加# 索引超越下界，头部追加&gt;&gt;&gt; numbers = [1, 2, 3, 5, 6, 7]&gt;&gt;&gt; numbers.insert(3, 'four')&gt;&gt;&gt; numbers[1, 2, 3, 'four', 5, 6, 7]# insert用于将一个对象插入列表。与extend一样，也可使用切片赋值来获得与insert一样的效果。&gt;&gt;&gt; numbers = [1, 2, 3, 5, 6, 7]&gt;&gt;&gt; numbers[3:3] = ['four']&gt;&gt;&gt; numbers[1, 2, 3, 'four', 5, 6, 7]# 这虽巧妙，但可读性根本无法与使用insert媲美。 pop123456789101112131415161718192021222324# pop([index]) -&gt; item# 不指定索引index，就从列表尾部弹出一个元素# 指定索引index，就从索引处弹出一个元素，索引超界抛出IndexError错误&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; x.pop()3# 如果用pop()，会删除最后一个元素&gt;&gt;&gt; x[1, 2]&gt;&gt;&gt; x.pop(0)1&gt;&gt;&gt; x[2]# pop从列表中删除一个元素(末尾为最后一个元素)，并返回这一元素。# pop是唯一既修改列表又返回一个非None值的列表方法。# 使用pop可实现一种常见的数据结构——栈 (stack)。栈就像一叠盘子，你可在上面添加盘子，还可从上面取走盘子。最后加入的盘子最先取走，这被称为后进先出(LIFO)。&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; x.append(x.pop())# 每次弹出的都是3，再将3追加到列表的尾部，就还是[1,2,3]&gt;&gt;&gt; x[1, 2, 3]# 使用append代替push方法，因为python中没有提供push。此将刚弹出的值压入(或附加)后，得到的栈将与原来相同。要创建先进先出(FIFO)的队列，可使用insert(0, ...)代替append。另外，也可继续使用append，但用 pop(0)替代 pop() 。 remove123456789101112131415# remove(value) -&gt; None# 从左至右查找第一个匹配value的值，移除该元素，返回None# 就地修改&gt;&gt;&gt; x = ['to', 'be', 'or', 'not', 'to', 'be']&gt;&gt;&gt; x.remove('be')&gt;&gt;&gt; x['to', 'or', 'not', 'to', 'be']&gt;&gt;&gt; x.remove('bee')Traceback (innermost last):File "&lt;pyshell&gt;", line 1, in ?x.remove('bee')ValueError: list.remove(x): x not in list# remove用于删除第一个为指定值的元素。这只删除了为指定值的第一个元素，无法删除列表中其他为指定值的元素# remove是就地修改且不返回值的方法之一。不同于 pop的是，它修改列表，但不返回任何值。 reverse12345678910111213# reverse() -&gt; None# 将列表元素反转，返回None# 就地修改&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; x.reverse()&gt;&gt;&gt; x[3, 2, 1]# reverse按相反的顺序排列列表中的元素。但不返回任何值(与remove和sort等方法一样) 。# 如果要按相反的顺序迭代序列，可使用函数reversed 。这个函数不返回列表，而是返回一个迭代器 。你可使用list将返回的对象转换为列表。如下：&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; list(reversed(x))[3, 2, 1] sort12345678910111213141516171819202122232425262728293031323334# sort(key=None,reverse=False) -&gt; None# 对列表元素进行排序，就地修改，默认升序# reverse为True，反转，降序# key一个函数，指定key如何排序# lst.sort(key=functionname)&gt;&gt;&gt; x = [4, 6, 2, 1, 7, 9]&gt;&gt;&gt; x.sort()&gt;&gt;&gt; x[1, 2, 4, 6, 7, 9]# sort是修改列表而不返回任何值的方法，sort用于对列表就地排序。就地排序意味着对原来的列表进行修改，使其元素按顺序排列，而不是返回排序后的列表的副本。&gt;&gt;&gt; x = [4, 6, 2, 1, 7, 9]&gt;&gt;&gt; y = x.sort() # Don't do this!&gt;&gt;&gt; print(y)None# 这种方法是错误的，sort修改x后是不返回任何值的，最终的结果是，x是经过排序的，而y包含 None。正确做法如下：&gt;&gt;&gt; x = [4, 6, 2, 1, 7, 9]&gt;&gt;&gt; y = x.copy()&gt;&gt;&gt; y.sort()&gt;&gt;&gt; x[4, 6, 2, 1, 7, 9]&gt;&gt;&gt; y[1, 2, 4, 6, 7, 9]# 只是将x赋给y是不可行的，因为这样x和y将指向同一个列表。&gt;&gt;&gt; x = [4, 6, 2, 1, 7, 9]&gt;&gt;&gt; y = sorted(x)&gt;&gt;&gt; x[4, 6, 2, 1, 7, 9]&gt;&gt;&gt; y[1, 2, 4, 6, 7, 9]# sorted函数可用于任何可迭代的对象，但总是返回一个列表。如下：&gt;&gt;&gt; sorted('Python')['P', 'h', 'n', 'o', 't', 'y'] 高级排序1234567891011&gt;&gt;&gt; x = ['aardvark', 'abalone', 'acme', 'add', 'aerate']&gt;&gt;&gt; x.sort(key=len)&gt;&gt;&gt; x['add', 'acme', 'aerate', 'abalone', 'aardvark']# 方法sort接受两个可选参数：key 和reverse。这两个参数通常是按名称指定的，称为关键字参数，参数 key类似于参数cmp：你将其设置为一个用于排序的函数。然而，不会直接使用这个函数来判断一个元素是否比另一个元素小，而是使用它来为每个元素创建一个键，再根据这些键对元素进行排序。因此，要根据长度对元素进行排序，可将参数 key 设置为函数len。&gt;&gt;&gt; x = [4, 6, 2, 1, 7, 9]&gt;&gt;&gt; x.sort(reverse=True)&gt;&gt;&gt; x[9, 7, 6, 4, 2, 1]# 对于另一个关键字参数reverse，只需将其指定为一个真值（True或False），以指出是否要按相反的顺序对列表进行排序。# 函数sorted也接受参数key和reverse。在很多情况下，将参数key设置为一个自定义函数很有用。 时间复杂度1index和count方法都是O(n)。随着列表数据规模的增大，而效率下降 如何查帮助1234# 官方帮助文档，搜索关键字# IPython中help(keyword)# keyword可以是变量、对象、类名、函数名、方法名 元组 与列表一样，元组也是序列，唯一的差别在于元组是不能修改的。元组语法很简单，只要将一些值用逗号分隔，就能自动创建一个元组。元组就是一个有序的元素组成的集合，使用小括号()表示。元组是不可变对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# index(value,[start,[stop]]) # 通过值value,从指定区间查找列表内的元素是否匹配 # 匹配第一个就立即返回索引 # 匹配不到,抛出异常ValueError# count(value) # 返回列表中匹配value的次数# 时间复杂度 # index和count方法都是O(n) # 随着列表数据规模的增大,而效率下降# len(tuple) # 返回元素的个数# 元组是只读的,所以增、改、删方法都没有&gt;&gt;&gt; 1, 2, 3(1, 2, 3)&gt;&gt;&gt; (1, 2, 3)(1, 2, 3)# 元组还可用圆括号括起(这也是通常采用的做法) 。&gt;&gt;&gt; ()()# 空元组用两个不包含任何内容的圆括号表示。&gt;&gt;&gt; 4242&gt;&gt;&gt; 42,(42,)&gt;&gt;&gt; (42,)(42,)# 表示一个值的元组也必须在它后面加上逗号。最后两个示例创建的元组长度为1，而第一个示例根本没有创建元组。逗号至关重要，仅将值用圆括号括起不管用：(42)与 42完全等效。但仅仅加上一个逗号，就能完全改变表达式的值。如下：&gt;&gt;&gt; 3 * (40 + 2)126&gt;&gt;&gt; 3 * (40 + 2,)(42, 42, 42)&gt;&gt;&gt; tuple([1, 2, 3])(1, 2, 3)&gt;&gt;&gt; tuple('abc')('a', 'b', 'c')&gt;&gt;&gt; tuple((1, 2, 3))(1, 2, 3)# 函数tuple的工作原理与list很像：它将一个序列作为参数，并将其转换为元组。如果参数已经是元组，就原封不动地返回它。&gt;&gt;&gt; x = 1, 2, 3&gt;&gt;&gt; x[1]2&gt;&gt;&gt; x[0:2](1, 2)# 元组的切片也是元组,就像列表的切片也是列表一样。为何要熟悉元组呢?原因有以下两个。# 1. 它们用作映射中的键(以及集合的成员)，而列表不行。# 2. 有些内置函数和方法返回元组，这意味着必须跟它们打交道。只要不尝试修改元组，与元组“打交道”通常意味着像处理列表一样处理它们(需要使用元组没有的index和count等方法时例外)。# 一般而言，使用列表足以满足对序列的需求。 命名元组namedtuple12345678910111213141516171819202122232425262728# 帮助文档中，查阅namedtuple，有使用教程# 语法： # namedtuple(typename,field_names,verbose=False,rename=False) # 命名元组，返回一个元组的子类，并定义了字段 # typename表示此元组的名称 # field_names表示元组中元素的名称，此字段有多种表达方式，可以是空白符或逗号分隔的字段的字符串，可以是字段的列表 # rename表示如果元素名称中含有python的关键字，则必须设置为rename=True # verbose使用默认就可以。from collections import namedtuplePoint = namedtuple('_Point',['x','y'])# Point为返回的类p = Point(11,22)&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Student = namedtuple('Student', ['name', 'age', 'sex', 'email'])&gt;&gt;&gt; s = Student('Jim', 21, 'male', '123@qq.com')&gt;&gt;&gt; s.name'Jim'&gt;&gt;&gt; s.age21# namedtuple 函数这里接收两个参数，第一个参数为要创建类型的名称，第二个参数是一个列表，代表了每一个# 索引的名字。当建立完这个 Student 类之后，就可以使用正常的构造方法来构造新的对象如 s，并且可以直接# 通过访问属性的方式来访问所需要的值。# 此时使用isinstance函数对比内置的tuple：&gt;&gt;&gt; isinstance(s, tuple)True# 可见用namedtuple构造出来的类其本质就是一个tuple元组，所以仍然可以使用下标的方式来访问属性。并且在# 任何要求类型为元组的地方都可以使用这个namedtuple。 冒泡法 属于交换排序 两两比较大小，交换位置。如同水泡咕嘟咕嘟往上冒 结果分为升序和降序排列 升序 n个数从左至右，编号从0开始到n-1，索引0和1的值比较，如果索引0大，则交换两者位置，如果索引1大，则不交换。继续比较索引1和2的值，将大值放在右侧。直至n-2和n-1比较完，第一轮比较完成。第二轮从索引0比较到n-2，因为最右侧n-1位置上已经是最大值了。依次类推，每一轮都会减少最右侧的不参与比较的数，直至剩下最后2个数比较。 降序 和升序相反 图示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 冒泡法代码实现一，简单冒泡实现num_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9]]# 定义一个列表，这个列表中还有两个子列表nums = num_list[1]# 定义nums等于第2个子列表print(nums)# 先打印一次nums列表length = len(nums)# 计算nums列表的长度count_swap = 0# 交换count = 0# 统计次数for i in range(length):# 用length也就是列表长度来循环，length是一共要比较的次数，也就是要用每个数字与所有的数字比较一次，所有数字比较一遍的次数。i表示第几个数字 for j in range(length-i-1):# 这里j是长度减去之前比较的次数后，还要比较的次数。也就是每次每个数字要与列表中数字比较的次数，如第一次从第一个数字比较到最后一个数字，# 那么，第二次比较时就从第一个数字比较到倒数第二个数字了，因为第一次已经将最大的数字放到最后了。最后减1是因为i是从0开始的，所以要多减1. count += 1# 计算比较的次数 if nums[j] &gt; nums[j+1]:# 按循环每次比较，nums列表中的第j个元素是否与j+1个元素大，也就是前面的数字与后面的数字比较，如第一次是第1个和第2个数字比较，下一次就是第2个和第3个比较 tmp = nums[j]# 如果前面的数字大，就将数字给tmp nums[j] = nums[j+1]# 之后将前面的数字向后移 nums[j+1] = tmp# 再把后面的数字放在临时空间中 count_swap += 1# 记录一次交换print(nums, count_swap, count)# 打印列表，交换次数，比较次数# 冒泡法代码实现二，优化实现num_list = [[1,9,8,5,6,7,4,3,2],[1,2,3,4,5,6,7,8,9],[1,2,3,4,5,6,7,9,8]]nums = num_list[2]print(nums)length = len(nums)count_swap = 0count = 0for i in range(length): flag = False# 每次每个数比较之前都加一个标记 for j in range(length-i-1): count += 1 if nums[j] &gt; nums[j+1]: tmp = nums[j] nums[j] = nums[j+1] nums[j+1] = tmp flag = True # 如果前面的数字比后面的大，进行了交换，就将flag改为True count_swap += 1 if not flag: break# 当flag为False时，证明没有交换，也就证明没必要再进行之后的动作，顺序已经排好了。print(nums, count_swap, count) 冒泡法总结 冒泡法需要数据一轮轮比较 可以设定一个标记判断此轮是否有数据交换发生，如果没有发生交换，可以结束排序，如果发生交换，继续下一轮排序 最差的排序情况是，初始顺序与目标顺序完全相反，遍历次数1,…,n-1之和n(n/1)/2 最好的排序情况是，初始顺序与目标顺序完全相同，遍历次数n-1 时间复杂度O(n**2)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>列表和元组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习-基础知识]]></title>
    <url>%2F2019%2F03%2F20%2Fpython%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[概念算法 算法是流程或菜谱的时髦说法，详尽地描述了如何完成某项任务。算法由对象（原料）和语句（操作说明）组成。从本质上说，编写计算机程序就是使用计算机能够理解的语言(如Python)描述一种算法。这种对机器友好的描述被称为程序，主要由表达式和语句组成。 表达式 表达式为程序的一部分，结果为一个值。例如：2 + 2就是一个表达式，结果为4 。简单表达式是使用运算符(如+或% )和函数(如pow)将字面值(如2或”Hello” )组合起来得到的。通过组合简单的表达式，可创建复杂的表达式，如(2 + 2) *(3 - 1)。表达式还可能包含变量。 圆整，是科技术语，通常理解为因满足某种要求而进行的数据修正。按照修正后的数据在数值上是否比原数据大，又可分为向上圆整和向下圆整。 整除符号：//，当结果为整数时向下圆整，如：10 // 3。如果余数为0，就不会向下圆整了，如：9 // 3。 1234567891011121314151617&gt;&gt;&gt; 10 % 31&gt;&gt;&gt; 10 % -3-2&gt;&gt;&gt; -10 % 32&gt;&gt;&gt; -10 % -3-1&gt;&gt;&gt; 10 // 33&gt;&gt;&gt; 10 // -3-4&gt;&gt;&gt; -10 // 3-4&gt;&gt;&gt; -10 // -33# 对于整数运算，结果是向下圆整的。在结果是负数时，圆整后将离0更远。 变量 变量是表示值的名称。通过赋值,可将新值赋给变量,如x = 2。赋值是一种语句。 使用python变量前必须给它赋值，因此python变量没有默认值。在python中，名称（标识符）只能由字母、数字和下划线(_)构成，且不能以数字开头。最好也不要以下划线开头。 语句 语句是让计算机执行特定操作的指示。这种操作可能是修改变量(通过赋值) 、将信息打印到屏幕上(如print(“Hello, world!”))、导入模块或执行众多其他任务。 表达式是一些东西，而语句是一些事情。上面介绍的都是表达式。如表达式：2 2，语句：print(2 2) 语句的特征是执行修改操作。赋值语句可以改变变量，print语句改变屏幕的外观。 1234567&gt;&gt;&gt; x = input("x: ")x: 34&gt;&gt;&gt; y = input("y: ")y: 42&gt;&gt;&gt; print(int(x) * int(y))1428# int可以将字符串转换为整数。 函数 Python函数类似于数学函数，它们可以接受参数，并返回结果。函数犹如小型程序，可用来执行特定的操作。通常将标准函数称为内置函数。使用函数称为调用函数，可以向函数提供实参，之后函数返回一个值。因为函数调用返回一个值，因此它们也是表达式。可以结合使用函数调用和运算符来编写更复杂的表达式。 1234567891011121314&gt;&gt;&gt; 2 ** 38&gt;&gt;&gt; pow(2,3)8# pow函数是计算幂运算的。&gt;&gt;&gt; 10 + pow(2,3*5) / 3.010932.6666666&gt;&gt;&gt; abs(-10)# abs函数计算绝对值&gt;&gt;&gt; round(2 / 3)# round将浮点数圆整为与之最接近的整数。# 整数总是向下圆整，而round圆整到最接近的整数，并在两个整数一样近时圆整到偶数。 模块 模块是扩展，可通过导入它们来扩展Python的功能。例如：模块math包含多个很有用的函数。 123456789101112131415161718192021222324252627282930313233343536&gt;&gt;&gt; import math&gt;&gt;&gt; math.floor(32.9)32# 使用import导入模块，再以module.function的方式使用模块中的函数。floor函数与上面的round函数相反，可以将浮点数向下圆整&gt;&gt;&gt; math.ceil(32.3)33&gt;&gt;&gt; math.ceil(32)32# ceil与floor相反，返回大于或等于给定数的最小整数。&gt;&gt;&gt; from math import sqrt&gt;&gt;&gt; sqrt(9)3.0# sqrt函数用于计算平方根。如果确定不会从不同模块导入多个同名函数，可使用from math import function的方法调用函数，之后就不用再指定模块前缀了。一般还是不使用此种方法，容易出现无法使用常规函数的问题&gt;&gt;&gt; import math&gt;&gt;&gt; foo = math.sqrt&gt;&gt;&gt; foo(4)# 可以将函数赋值给变量，之后变量就有了函数的功能&gt;&gt;&gt; from math import sqrt&gt;&gt;&gt; sqrt(-1)nan# nan具有特殊含义，指的是"非数值"(not a number)。# 如果将值域限定为实数，并使用其近似的浮点数实现，就无法计算负数的平方根。负数的平方根是虚数，而由实部和虚部组成的数为复数&gt;&gt;&gt; import cmath&gt;&gt;&gt; cmath.sqrt(-1)1j# 1j是个虚数，虚数都以j（或J）结尾。复数算术运算都基于如下定义：-1的平方根为1j。&gt;&gt;&gt; (1 + 3j) * (9 + 4j)(-3 + 31j)# python提供了对复数的支持。# python没有专门表示虚数的类型，而将虚数视为实部为零的复数。 字符串 字符串的主要用途是表示一段文本。在Python 3中，所有的字符串都是Unicode字符串。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&gt;&gt;&gt; "Let's go!""Let's go!"# 这里用了一个单引号，因此不能用单引号再将整个字符串括起，否则解释器将报错。如下：&gt;&gt;&gt; 'Let's go!'SyntaxError: invalid syntax&gt;&gt;&gt; '"Hello, world!" she said''"Hello, world!" she said'# 因为字符串包含双引号，因此必须使用单引号将整个字符串括起&gt;&gt;&gt; 'Let\'s go!'"Let's go!"# 可使用反斜杠( \ )对引号进行转义&gt;&gt;&gt; "\"Hello, world!\" she said"'"Hello, world!" she said'&gt;&gt;&gt; "Let's say " '"Hello, world!"''Let\'s say "Hello, world!"'# Python可以自动将字符串拼接起来&gt;&gt;&gt; "Hello, " + "world!"'Hello, world!'&gt;&gt;&gt; x = "Hello, "&gt;&gt;&gt; y = "world!"&gt;&gt;&gt; x + y'Hello, world!'# 拼接字符串的方法&gt;&gt;&gt; print('''This is a very long string. It continues here.And it's not over yet. "Hello, world!"Still here.''')# 表示长字符串时可以使用三个单引号或三个双引号，这让解释器能够识别表示字符串开始和结束位置的引号，因此字符串本身可包含单引号和双引号，无需使用反斜杠进行转义。&gt;&gt;&gt; 1 + 2 + \4 + 512&gt;&gt;&gt; print \('Hello, world')Hello, world# 常规字符串也可横跨多行。只要在行尾加上反斜杠,反斜杠和换行符将被转义,即被忽略。&gt;&gt;&gt; print(r'C:\nowhere')C:\nowhere&gt;&gt;&gt; print(r'C:\Program Files\fnord\foo\bar\baz\frozz\bozz')C:\Program Files\fnord\foo\bar\baz\frozz\bozz# 原始字符串用前缀r表示。看起来可在原始字符串中包含任何字符，这大致是正确的。一个例外是，引号需要像通常那样进行转义，但这意味着用于执行转义的反斜杠也将包含在最终的字符串中。如下：&gt;&gt;&gt; print(r'Let\'s go!')Let\'s go!&gt;&gt;&gt; print(r"This is illegal\")SyntaxError: EOL while scanning string literal# 原始字符串不能以单个反斜杠结尾。除非你对其进行转义(但进行转义时,用于转义的反斜杠也将是字符串的一部分) 。&gt;&gt;&gt; print(r'C:\Program Files\foo\bar' '\\')C:\Program Files\foo\bar\# 可以将反斜杠单独作为一个字符串 函数表 函数 描述 abs(number) 返回指定数的绝对值 bytes(string, encoding[, errors]) 对指定的字符串进行编码，并以指定的方式处理错误 cmath.sqrt(number) 返回平方根；可用于负数 float(object) 将数字转换为浮点数 help([object]) 提供交互式帮助 input(prompt) 以字符串的方式获取用户输入 int(object) 将字符串或数转换为整数 math.ceil(number) 以浮点数的方式返回向上圆整的结果 math.floor(number) 以浮点数的方式返回向下圆整的结果 math.sqrt(number) 返回平方根；不能用于负数 pow(x, y[, z]) 返回x的y次方对z求模的结果 print(object, …) 将提供的实参打印出来,并用空格分隔 repr(object) 返回指定值的字符串表示 round(number[, ndigits]) 四舍五入为指定的精度，正好为5时舍入到偶数 str(object) 将指定的值转换为字符串。用于转换 bytes 时，可指定编码和错误处理方式 len(seq) 返回序列的长度 list(seq) 将序列转换为列表 max(args) 返回序列或一组参数中的最大值 min(args) 返回序列和一组参数中的最小值 reversed(seq) 让你能够反向迭代序列 sorted(seq) 返回一个有序列表，其中包含指定序列中的所有元素 tuple(seq) 将序列转换为元组 string.capwords(s[, sep]) 使用split 根据sep拆分s，将每项的首字母大写，再以空格为分隔符将它们合并起来 ascii(obj) 创建指定对象的ASCII表示 dict(seq) 从键值对、映射或关键字参数创建字典]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建个人博客github-pages]]></title>
    <url>%2F2019%2F03%2F17%2F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2github-pages%2F</url>
    <content type="text"><![CDATA[下载软件 下载安装Node.js，官网地址：https://nodejs.org/en/download/ 下载安装git，官网地址：https://git-scm.com/download/win 下载安装githubDesktop，官网地址：https://desktop.github.com/ 注：实际git与githubDesktop安装一个就可以，只是不习惯使用命令行的人使用githubDesktop更方便。 注册github官方地址：https://github.com/ 注册后登录，创建一个自己的github pages项目，项目名称一般与自己的登录名一致。 Hexo安装1234567891011121314在本地创建一个Hexo目录，并进入目录，右键选择Git Bash Herenpm install hexo-cli -gnpm install hexo-deployer-git --savehexo inithexo generatehexo server访问localhost:4000# 在执行hexo命令时提示：internal/modules/cjs/loader.js:596 throw err; ^Error: Cannot find module 'D:\Git\node_modules\hexo-cli\bin\hexo'之后在C:\Users\r\AppData\Roaming\npm中找到node_modules，将其复制到D:\Git下后，可以正常使用hexo命令 配置SSH密钥123456ssh-keygen -t rsa -C "your_email@example.com"# 这将按照你提供的邮箱地址，创建一对密钥。一直回车就可以完成cat ~/.ssh/id_rsa.pub复制公钥，将公钥放到github页面中的Settings中的SSH and GPG keys中ssh -T git@github.com# 测试密钥是否生效，如果生效会有向用户打招呼的提示 设置用户信息1234git config --global user.name "ryanlijianchang"# 用户名git config --global user.email "liji.anchang@163.com"# 填写自己的邮箱 将本地的Hexo文件更新到Github的库中 登录github 打开自己的项目 点击Clone or download，选择SSH，并复制地址 打开本地创建的Hexo目录，打开_config.yml文件 在配置文件中修改 执行命令 123hexo g -d# 完成远程部署，如果有报错 ERROR Deployer not found: git，可以删除node_modules目录，再重新执行下面的命令npm install hexo-deployer-git --save 访问name.github.io 美化自己博客安装主题 进入https://hexo.io/themes/ 选择自己喜欢的主题，并打开，打开后是一个github的页面，复制git地址 到本地Hexo目录中的themes右键选择Git Hash Here 克隆主题到本地clonelink12345675. 修改Hexo配置文件，将_config.yml文件中的theme后的参数改为自己下载的主题的名字6. 部署主题，本地查看。```shellhexo ghexo s访问localhost:4000 部署到Github上 12hexo cleanhexo g -d 主题设定 打开主题配置文件 1E:\GitHub\ruopu89.github.io\themes\hexo-theme-next\_config.yml 设置 123456# Schemes#scheme: Muse#scheme: Mist#scheme: Piscesscheme: Gemini# 现在有四种风格，使用哪个就去掉其前面的注释 设置语言 打开站点配置文件 12E:\GitHub\ruopu89.github.io\_config.yml# 注意这里一定是在站点配置文件中设置 设置 12language: zh-TW# 在主题配置目录中有一个languages目录，在这里是可以使用的语言的文件。上面设置的语言应该和languages目录中的文件名是一样的。 设置菜单 打开主题配置文件 1E:\GitHub\ruopu89.github.io\themes\hexo-theme-next\_config.yml 设置 1234567891011menu: home: / || home //主页 #about: /about/ || user //关于页面 #tags: /tags/ || tags tags: /tags || tags //标签页 categories: /categories/ || th //分类页 archives: /archives/ || archive //归档页 #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat //公益 404//这里最前面的name:表示在页面中显示的内容；后面是路径；最后的|| name表示显示的图标样式。除了主页与归档页外，其他需要手动创建这个页面 设置侧栏 默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。 打开主题配置文件 1E:\GitHub\ruopu89.github.io\themes\hexo-theme-next\_config.yml 设置位置 123sidebar: position: left# 可以使用的值有left和right 设置侧栏显示的时机 12345678sidebar: display: post//可选项：//post - 默认行为，在文章页面（拥有目录列表）时显示//always - 在所有页面中都显示//hide - 在所有页面中都隐藏（可以手动展开）//remove - 完全移除//已知侧栏在 use motion: false 的情况下不会展示。 影响版本5.0.0及更低版本。 添加标签 新建页面 123在项目目录中右键打开githexo new page tags# 在项目目录中的source创建一个tags目录，如果没有这个目录，在页面上就没法打开这个标签 设置页面类型 1234567在新建的tags目录中会自动生成一个叫index的文件，打开它---title: 标签date: 2014-12-22 12:39:04type: "tags"---# index文件中的内容如上，添加type: "tags" 修改菜单 123456修改主题配置文件menu: home: / archives: /archives tags: /tags# tags一行要取消注释，这样在页面中才能显示tags标签 写作 1234567在新建文章后，在文章头部会有如下内容---hetitle: 搭建个人博客github_pagesdate: 2018-08-30 08:32:00tags: hexo---# 要指定此文章的tags，这样就可以将文章加入上面创建的tags中了，打开页面时在tags标签中会有一个hexo，在hexo中有我们的文章 添加分类页面 新建页面 123在项目目录中右键打开githexo new page categories# 在项目目录中的source创建一个categories目录，如果没有这个目录，在页面上就没法打开这个标签 设置页面类型 1234567在新建的tags目录中会自动生成一个叫index的文件，打开它---title: 标签date: 2014-12-22 12:39:04type: "categories"---# index文件中的内容如上，添加type: "categories" 修改菜单 123456修改主题配置文件menu: home: / archives: /archives categories: /categories# categories一行要取消注释，这样在页面中才能显示categories标签 写作 1234567在新建文章后，在文章头部会有如下内容---hetitle: 搭建个人博客github_pagesdate: 2018-08-30 08:32:00categories: hexo---# 要指定此文章的tags，这样就可以将文章加入上面创建的tags中了，打开页面时在tags标签中会有一个hexo，在hexo中有我们的文章 添加搜索功能123456789101112131415161718cd /home/ruopu/文档/Github/ruopu.github.io# 先到博客的根目录npm install hexo-generator-searchdb --save# 安装搜索插件vim /home/ruopu/文档/Github/ruopu.github.io/_config.ymlsearch: path: search.xml field: post format: html limit: 10000# 在博客的配置文件中添加上述内容vim /home/ruopu/文档/Github/ruopu.github.io/theme/hexo-next/_config.ymllocal_search: enable: true# 配置主题的功能，上面内容默认是flase，改为truehexo ghexo d# 上传后就可以看到搜索功能了。 添加访客人数统计123456789101112131415161718192021vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/layout/_partials/footer.swig# 打开使用的主题下的这个文件&lt;div class="copyright"&gt; ... ... &lt;script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"&gt; &lt;/script&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt; &lt;span id="busuanzi_container_site_pv"&gt; 本站总访问量: &lt;span id="busuanzi_value_site_pv"&gt;&lt;/span&gt;次 &lt;/span&gt;&lt;/div&gt;# 在上方的两个div之间配置上面的代码，script是安装不蒜子的统计脚本，下面的本部总访问量是统计的PV量# pv：单个用户连续点击n篇文章，记录n次访问量# uv：单个用户连续点击n篇文章，只记录1次访客数# 使用uv的方法# &lt;span id="busuanzi_container_site_uv"&gt;# 本站访客数&lt;span id="busuanzi_value_site_uv"&gt;&lt;/span&gt;人次# &lt;/span&gt;# 参考：https://hexo-guide.readthedocs.io/zh_CN/latest/third-service/[%E4%B8%8D%E8%92%9C%E5%AD%90]%E8%AE%BF%E5%AE%A2%E4%BA%BA%E6%95%B0.html 添加文章阅读量统计123456789101112131415161718192021222324方法一vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/_config.yml busuanzi_count: enable: true # 这里默认是false，改为true即可。next主题自带了不蒜子的统计功能 total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: true post_views_icon: eye# 这个方法在进入文章后，可以看到阅读次数方法二vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/layout/_macro/post.swig# 在&#123;# LeanCould PageView #&#125;下添加下面内容&#123;# LeanCould PageView #&#125;&lt;span id="busuanzi_container_page_pv"&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt; &lt;span class="post-meta-item-icon"&gt; &lt;i class="fa fa-eye"&gt;&lt;/i&gt; &lt;/span&gt; 阅读量: &lt;span id="busuanzi_value_page_pv"&gt;&lt;/span&gt;次&lt;/span&gt;# 这个方法在首页就能看到每篇文章的阅读次数# 参考：https://hexo-guide.readthedocs.io/zh_CN/latest/third-service/[%E4%B8%8D%E8%92%9C%E5%AD%90]%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E6%AC%A1%E6%95%B0.html 添加文章评论功能12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758591. 注册github应用，首先登录github，之后在settings-&gt;Developer settings-&gt;OAuth Apps中注册。注意需要输入四项内容，应用名称是自定义的，主页地址是自己的github页面的地址，但要注意，地址前要加https://，不然会报错，应用说明是自定义的，授权回调地址与主页地址一样。注册成功后会得到Client ID和Client Secret2. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/layout/_third-party/comments/gitalk.swig&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"&gt; &lt;script src="https://unpkg.com/gitalk/dist/gitalk.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; var gitalk = new Gitalk(&#123; clientID: '&#123;&#123; theme.gitalk.ClientID &#125;&#125;', clientSecret: '&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;', repo: '&#123;&#123; theme.gitalk.repo &#125;&#125;', owner: '&#123;&#123; theme.gitalk.githubID &#125;&#125;', admin: ['&#123;&#123; theme.gitalk.adminUser &#125;&#125;'], id: location.pathname, distractionFreeMode: '&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;' &#125;) gitalk.render('gitalk-container') &lt;/script&gt;&#123;% endif %&#125;3. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/layout/_partials/comments.swig&#123;% elseif theme.gitalk.enable %&#125; &lt;div id="gitalk-container"&gt;&lt;/div&gt;# 注意，添加的内容与前面的elseif同一级别上即可，但不要加在最后，测试时加在了18行左右的位置4. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/layout/_third-party/comments/index.swig&#123;% include 'gitalk.swig' %&#125;# 在最后一行添加内容5. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/source/css/_common/components/third-party/third-party.styl@import "gitalk";# 在最后一行上添加内容6. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/source/css/_common/components/third-party/gitalk.styl.gt-header a, .gt-comments a, .gt-popup a border-bottom: none;.gt-container .gt-popup .gt-action.is--active:before top: 0.7em;# 新建文件，加入内容7. vim /media/shouyu/C64CC89B4CC8879F/works/GitHub/ruopu89.github.io/themes/hexo-theme-next/_config.yml # Gitalk # Demo: https://gitalk.github.io# Reference: https://asdfv1929.github.io/2018/01/20/gitalk/, https://liujunzhou.top/2018/8/10/gitalk-error/gitalk: enable: true github_id: abc89 # github帐号，不用写邮箱地址 repo: abc # 仓库名称 client_id: # 注册得到的 client_secret: # 注册得到的 admin_user: abc89 # github帐号 distraction_free_mode: true # Facebook-like distraction free mode 8. 问题描述：在文章底部评论框中出现错误信息“Error: Not Found”解决办法：和repo属性有关，换一个新的仓库，比如新建仓库guestbook。# 参考：https://extremegtr.github.io/2017/09/07/Add-Gitment-comment-system-to-hexo-theme-NexT/#%E4%BF%AE%E6%94%B9NexT%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6 高亮显示代码 编辑主题配置文件E:\GitHub\ruopu89.github.io\themes\hexo-theme-next_config.yml 12highlight_theme: night blue# 可选的选择有：normal，night， night blue， night bright， night eighties 编辑站点配置文件E:\GitHub\ruopu89.github.io 1234567highlight: enable: true line_number: true auto_detect: true# 这里默认是false tab_replace: # 设置后，博客中的代码会有高亮显示，但显示的还是有问题。无论是否在代码中加入语言标记。 添加图片 图片默认被保存在主题目录中的source中的images中，如：E:\GitHub\ruopu89.github.io\themes\hexo-theme-next\source\images，我们可以在这个目录下新建目录，与博客名称相同，所有图片都保存在这里使用图片的网络地址也可上传图片。这种方式的问题应该是，当图片的网络地址失效时，这个图片也就看不到了。1![](https://raw.githubusercontent.com/higoge/image/master/basic01/01.png) 1234使用markdown语法添加图片时可以使用下面的语法&lt;img src="/images/image.jpg"/&gt;![](/images/images.jpg)# 上面两种方法都可以添加图片，系统会自动到主题目录中的source中的images中找图片。问题是，在markdown中是看不到图片的。因为提交后，系统会到images中找图片，所以要用这种格式，斜线也要用/。如果输入在windows中的路径，上传后是找不到图片的，所以也无法显示。 问题解决github Desktop提交时提示“Commit failed - exit code 1 received”解决：原因是不能提示的目录中也有.git目录，删除.git目录再上传就正常了。 在另一台ubuntu18.04系统上重新部署hexo12345678910111213141516171819202122* 安装所需软件包apt install -y nodejsapt install -y npmapt install -y gitnpm install hexo-cli -gnpm install hexo-deployer-git --save# 上面安装的nodejs是一个8.10的版本，也可以升级nodejsssh-keygen -t rsa -C "ruopu1989@hotmail.com"# 生成密钥cat .ssh/id_rsa.pub# 获取密钥# 这两步在root和普通用户上都做了一遍。之后将得到的密钥复制到github上ssh -T git@github.com# 在两个帐户上都测试一下连接是否成功。如果成功会有下面的提示，测试发现只在root用户下执行成功，在普通用户上执行也可以通过，但提示github不提供shell访问 Hi ruopu89! You've successfully authenticated, but GitHub does not provide shell access.git config --global user.name "ruopu1989"git config --global user.email "ruopu1989@hotmail.com"cd /media/rp/00E219519546E/MyFile/GitHub/rp.github.iohexo ghexo d# 如果这一步报错，可以尝试使用hexo clean撤消hexo g生成的静态文件，再执行hexo g重新生成再部署。# 测试 github个人博客多电脑使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364apt install nodejsapt install npmnpm install hexo-cli -gnpm install hexo-deployer-git --savecd /home/GitHub/ruopu.github.iossh-keygen -t rsa -C "ruopu19@hotmail.com"# -C后的是一些描述信息cat .ssh/id_rsa.pub# 将密钥复制到github上ssh -T git@github.com# 测试与github连接是否成功git config --global user.name "ruopu1989"git config --global user.email "ruopu1989@hotmail.com"# 自报家门git init# 给源文件目录初始化git，虽然目录中已有内容，但这也不会报错的git remote add origin https://github.com/abc/abc.github.io.git# 与远程的origin分支关联，最后的地址是github上项目的地址。使用git push时如果提示需要输入用户名和密码，可以删除远程地址，再试。命令：git remote remove origin。另外，这里也可以使用git@github.com:abc/abc.github.io.git地址。git checkout -b source# 创建并切换分支，使用-b选择就是为了创建并切换。这与git branch source &amp;&amp; git checkout source两条命令的执行结果是一样的。git branch# 现在本地只有一个source分支，这也就是主分支git add .# 添加所有内容到暂存区git commit -m 'add source'# 提交git push origin source# 将本地的source分支推送到远程的origin分支上在github上将source设置为主分支，这样之后clone的就都是这个source分支上的内容了。** 上传中会有一个问题，就是theme目录中的主题文件上传后可能是灰色的，这是因为获得主题文件时就是从另一个库clone来的，所以主题文件目录中也有.git文件。如果上传了目录，解决方法如下：1. 将主题文件目录剪切到另一个不相干的目录中2. git add .3. git commit -m 'delete theme'4. git push# 以上几步是为了将没有主题文件目录的信息再次提交，之后推送到远程库，也就删除了远程库上的主题文件目录5. 将主题文件目录中的.git、.gitignore、.gitattributes三个文件删除，之后将主题文件目录再剪切回github的theme目录中6. git add .7. git commit -m 'new theme'8. git push# 再次将没有.git文件的主题推送到远程库就没有问题了。==============================================================================================推送时出现问题，原因是想将本地的文件推送到远程，但与远程有很多不同。可以使用下面命令强行推送。但本地的文件可能丢失。推送前将文件备份，推送后将丢失的文再复制到相应目录，再推送就可以了。git push -f origin source==============================================================================================另外还涉及一些常用命令git branch# 查看当前分支git checkout master# 切换分支。加-b选项是创建并切换分支git merge source# 将source分支内容合并到当前分支git add .git commit -m "abc"git push origin sourcegit diffgit statusgit loggit remote add origin https://github.com/abc/rab.github.io.gitgit reset --hard HEAD^# 回退到上一个版本git reflog# 查看提交与回退历史==============================================================================================]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kali使用记录]]></title>
    <url>%2F2019%2F03%2F12%2Fkali%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[软件安装需要安装的包123456789101112131415161718192021222324252627282930sudo apt install -y tmux fping mtr htop net-tools bind9utils gimp axel screenfetch preload okular xarchiver meld jq remmina* smplayer keepnote thunderbird evolution tofrodos ffmpeg obs-studio indicator-china-weather nethogs ethstatus bmon gufw fish audacity ark cherrytree catfish# gimp是作图工具# axel是命令行下载工具# screenfetch是显示系统信息的# preload安装即可，开机时会将数据预加载到内存中。# okular为PDF阅读器，按F6快捷键打开注释功能。参考：https://blog.csdn.net/yangzhongxuan/article/details/8242740# xarchiver为解压缩软件# meld是文件对比软件# jq命令可以将json格式文件格式化# remmina是远程连接软件# smplayer为视频播放软件# keepnote为树状记录软件# thunderbird evolution均为邮件管理软件# 此包安装后有两个命令，todos和fromdos，相当于unix2dos和dos2unix。# ffmpeg obs-studio是视频录制软件及依赖包# indicator-china-weather是优客天气# nethogs可以查看实时进程网络占用，例：nethogs wlan0# ethstatus可以监控实时的网卡带宽占用，例：ethstatus -i wlan0# bmon可以监控网卡状态，例：bmon -p wlan0，输入g控制流量面板的显示和隐藏，输入d控制详情信息的显示和隐藏，输入q退出面板。可以配合nginx部署通过浏览器监控网络# Netspeed是拥有GUI界面实时显示网速的工具，未测试# sudo add-apt-repository ppa:ferramroberto/linuxfreedomlucid &amp;&amp; sudo apt-get update # 添加源：sudo apt-get install netspeed# gufw为ufw防火墙的图形界面。Uncomplicated FireWall，是 debian 系发行版中为了轻量化配置# iptables 而开发的一款工具。使用本机及本机中的虚拟机测试不出防火墙的效果，使用其他主机可以。原因是虚拟# 机使用了NAT联网的方式# fish是一个命令行提示工具，安装后，要运行fish到一个新的shell中才能使用其功能。源：apt-add-repository ppa:fish-shell/release-2# audacity为录音软件# ark为解压缩软件# cherrytree为树状记录软件# catfish为搜索软件 ubuntu18.04 鼠标插入时，自动关闭触摸板1234567sudo add-apt-repository ppa:atareao/atareaosudo apt updatesudo apt install touchpad-indicator# 安装后，可以使用命令行启动touchpad-indicator，启动后可能看不到设置页面，但在屏幕上方可# 以看到一个触摸板的图标，可以左键点击它进行设置，设置页面第一个标签页可以设置快捷键，快捷键# 可以打开或关闭触摸板。第二个标签页第一项是设置插入鼠标就禁用触摸板的，第三个标签页可以设置# 在开机的时候就启动这个小程序 oh-my-zsh及问题解决12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394apt install -y zsh# 安装zshecho $SHELL# 查看当前shellcat /etc/shell# 查看系统安装的shellchsh -s /bin/zsh# 修改用户shell，修改后在/etc/passwd中的用户shell也会变为/bin/zsh重启系统用户shell生效wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh# 安装oh-my-zsh，前提是要先安装过git------------------- oh-my-zsh配置-------------------***下面是安装历史命令提示功能***git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions***语法高亮功能***git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting***history-substring-search 插件***$ git clone https://github.com/zsh-users/zsh-history-substring-search.git $ZSH_CUSTOM/plugins/history-substring-search# 历史命令搜索插件，如果和 zsh-syntax-highlighting 插件共用，要配置到语法高亮插件之后。# 效果是上下键查询历史命令记录，可模糊匹配历史命令记录中任意字符串。vim ~/.zshrcexport ZSH="/home/shouyu/.oh-my-zsh"ZSH_THEME="agnoster"# 修改为这个主题，个人喜欢。主题也可以使用random，每次打开一个终端窗口时都会随机打开一个主题export PATH=/usr/bin:/usr/sbin:/bin:/sbin:/opt/electron-ssr:/usr/local/bin:/usr/local/sbin:/usr/local/jdk1.8/jdk1.8.0_211/bin/:/home/shouyu/anaconda3/binsetopt no_nomatchif [[ -r /usr/local/lib/python2.7/dist-packages/powerline/bindings/zsh/powerline.zsh ]];then source /usr/local/lib/python2.7/dist-packages/powerline/bindings/zsh/powerline.zshfiplugins=(git zsh-autosuggestions zsh-syntax-highlighting z web-search sudo history-substring-search)# z插件可以快速跳转目录# web-search可以在命令行使用百度、必应、google搜索，如：google abc，这表示打开默认浏览器在google中搜索abc# sudo插件可以在使用sudo时按两次ECS# history-substring-search是历史自动补全命令，oh-my-zsh 自带插件export HISTSIZE=10000# 历史纪录条目数量，测试时用echo查看这个变量是50000，不知是在哪儿定义的export SAVEHIST=10000# 注销后保存的历史纪录条目数量export HISTFILE=~/.zhistory# 历史纪录文件，这会在家目录自动生成此文件setopt EXTENDED_HISTORY# 为历史纪录中的命令添加时间戳，在查看.zsh_history和.zhistory时可以看到命令前有时间戳setopt INC_APPEND_HISTORY#以附加的方式写入历史纪录setopt HIST_IGNORE_DUPS# 如果连续输入的命令相同，历史纪录中只保留一个setopt AUTO_PUSHD# 启用 cd 命令的历史纪录，cd -[TAB]进入历史路径setopt PUSHD_IGNORE_DUPS# 相同的历史路径只保留一个HIST_STAMPS="yyyy-mm-dd"# 给history命令的输出添加时间DISABLE_UPDATE_PROMPT=true# 自动更新oh-my-zshsource $ZSH/oh-my-zsh.sh=======================================================================================source .zshrc# 加载文件生效ls ~/.oh-my-zsh# 这是安装后的目录，其中的lib提供了核心功能的脚本库，tools提供安装、升级等功能的快捷工具、plugins自带插件的存放位置，templates是自带的zshrc模板，也就是家目录中的.zshrc文件，temes是主题存放位置，custom是个性化配置目录，自安装的插件和主题存在这里。主题效果查看地址：https://github.com/robbyrussell/oh-my-zsh/wiki/Themeszsh学习地址：https://www.ibm.com/developerworks/cn/linux/shell/z/=============================== 在zsh中使用find命令不能使用星号===============================⚡ root@ruopu64  ~  vim .zshrc setopt no_nomatch# 在使用find / -name *.txt命令时，提示"zsh : no matchs found: *.txt"，在.zshrc文件中加入上面内容就可以在find命令中使用星号了。这是因为默认星号是由zsh解释的，不会传递给find命令。 ===================================== 除kde桌面外，其他桌面环境命令行显示问题=====================================# 原因是没有安装Powerline字体，按下面方法操作后，重启终端即可解决。wget https://raw.githubusercontent.com/powerline/powerline/develop/font/10-powerline-symbols.confwget https://raw.githubusercontent.com/powerline/powerline/develop/font/PowerlineSymbols.otfsudo mkdir /usr/share/fonts/OTFsudo cp 10-powerline-symbols.conf /usr/share/fonts/OTF/sudo mv 10-powerline-symbols.conf /etc/fonts/conf.d/sudo mv PowerlineSymbols.otf /usr/share/fonts/OTF/===================== 手动更新oh-my-zsh=====================upgrade_oh_my_zsh tilix12345678910111213141516171819202122232425262728293031323334apt install -y tilix# 一款不错的linux终端仿真器下载配色方案，https://www.ctolib.com/Gogh.html，这里提供了一个配色方法，大根提供进200种方案，如果选择ALL，表示全部安装，或只输入要安装的方案的编号即可。如果安装全部，可能会比较慢。在https://mayccoll.github.io/Gogh/中有配色方案的样例。bash -c "$(wget -qO- https://git.io/vQgMr)"# 运行此命令即可安装配色方案。个人比较喜欢Mona Lisa这个方案，还有google的，github的，方# 案号有04，05，07，12，51，53，54，56，90，172apt install dconf-cli# 安装配色方案前要安装此包。-------------- 修改默认终端-------------- shouyu@shouyu-pc  ~  sudo update-alternatives --config x-terminal-emulator# 执行命令后会让用户选择默认终端，选择后即可修改。如下： Selection Path Priority Status------------------------------------------------------------------------------------* 0 /usr/bin/gnome-terminal.wrapper 40 auto mode 1 /usr/bin/gnome-terminal.wrapper 40 manual mode 2 /usr/bin/tilix.wrapper 30 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 2update-alternatives: using /usr/bin/tilix.wrapper to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in manual mode--------------------- 配色方案支持的终端---------------------Supported terminals: mintty and deriviates guake iTerm2 elementary terminal (pantheon/elementary) mate-terminal gnome-terminal tili meta-terminal12345678apt install mate-terminal# 这个终端使用起来更好用一些bash -c "$(wget -qO- https://git.io/vQgMr)"# 在选择安装后，可以试着选n来安装使用，这需要尝试，当使用y会有dconf的错误提示的时候可以这样试一下。安装主题后，这个终端是通过新建配置文件来修改终端主题的，安装一个主题后就可以创建一个新的配置文件了。但在设置时还是会有一些混乱的问题，需要反复测试。root@ruopu:~# mv /usr/bin/konsole&#123;,.bak&#125;root@ruopu:~# mv /usr/bin/mate-terminal.wrapper /usr/bin/konsole# 这只是修改默认终端的权宜之计，还没有找到更好的办法。另外，一定要修改mate-terminal.wrapper，如果修改的是mate-terminal是打不开终端的。 远程终端Terminus &amp; Termius1234Terminus下载地址：https://github.com/Eugeny/terminus# 主题已经安装，无需像tilix那样自己再安装主题。可配置性很高。Termius下载地址：https://www.termius.com/# 这个软件可以创建用户并登录，它可以记录用户登录的帐户信息并在其他电脑上同步。 SecureCRT123456789101112131415161718192021222324252627282930313233341. 安装secureCRT7.3.3 vim /etc/apt/sources.list deb http://ftp.de.debian.org/debian jessie main # 因为安装secureCRT7.3.3需要先安装libssl1.0.0，但kalilinux中安装的是1.0.2版本，所以要加入一个源地址。这个源很关键，对于之后安装如google，很有用。 apt update apt install libssl1.0.0 gdebi scrt-7.3.3-779.ubuntu13-64.x86_64.deb # 要用gdebi，用dpkg不能安装 perl securecrt_linux_crack.pl /usr/bin/SecureCRT 2. 启动SecureCRT 3. 将perl命令的执行结果输入到SecureCRT中即可4. options-&gt; session Options -&gt; Terminal -&gt; audio bell （删除勾选）# 关闭SecureCRT输入命令时按Tab的声音=======================================================================================安装SecureCRT8.3.4、SecureFX8.3.4。这里的安装与上面一样，只要注意，在注册软件时，如果.pl文件中的内容与下面的内容不附，请修改.pl文件中的内容与下面内容一致，不然无法注册。安装时主要是SecureFX8.3.4的注册文件有问题。# SecureCRT8.3.4License: Name: xiaobo_l Company: www.boll.me Serial Number: 03-94-294583 License Key: ABJ11G 85V1F9 NENFBK RBWB5W ABH23Q 8XBZAC 324TJJ KXRE5D Issue Date: 04-20-2017# SecureFX8.3.4License: Name: ygeR Company: TEAM ZWT Serial Number: 06-70-001589 License Key: ACUYJV Q1V2QU 1YWRCN NBYCYK ABU767 D4PQHA S1C4NQ GVZDQF Issue Date: 03-10-2017 tmux-powerline并添加天气123456789101112131415161718192021222324252627282930313233shouyu@shouyu-pc  ~  git clone https://github.com/erikw/tmux-powerline.git# 克隆到家目录中shouyu@shouyu-pc  ~  vim .tmux.conf# 创建配置文件并加入下面内容set-option -g status on set-option -g status-interval 2set-option -g status-justify "centre"set-option -g status-left-length 60set-option -g status-right-length 60set-option -g status-left "#(~/tmux-powerline/powerline.sh left)"set-option -g status-right "#(~/tmux-powerline/powerline.sh right)"set-window-option -g window-status-current-format "#[fg=colour235,bg=colour27] #[fg=colour255,bg=colour27] #I #W #[fg=colour27,bg=colour235] "set-window-option -g mouse on# 这一条是设置在所有窗口中启用鼠标滚动shouyu@shouyu-pc  ~  tmux# 测试是否可以看到命令行窗口下面的信息，在ubuntu18.04上按上面方法配置后，发现打开tmux后命# 令行下面只有一个绿色的横条，之后将窗口放大，才能看到绿色的横条变成了一些有用的信息# 添加天气方法shouyu@shouyu-pc  ~  cd ~/tmux-powerline # 到克隆的项目中shouyu@shouyu-pc  ~/tmux-powerline   master ●  ./generate_rc.sh # 执行generate_rc.sh脚本shouyu@shouyu-pc  ~/tmux-powerline   master ●  mv ~/.tmux-powerlinerc.default ~/.tmux-powerlinerc# 把生成的文件改名shouyu@shouyu-pc  ~/tmux-powerline   master ●  vim segments/weather.shTMUX_POWERLINE_SEG_WEATHER_LOCATION="CHXX0008" # 修改TMUX_POWERLINE_SEG_WEATHER_LOCATION为当地的城市代码，因为要使用雅虎的服务，所以# 需要到雅虎的网站查看城市代码，但找到的网页提示已经不再使用之前的域名，所以想直接找城市代码# 有一些麻烦，在百度上找到一个，仅供参考。# 地址：https://wenku.baidu.com/view/35cc2b10cf84b9d529ea7a35.html# 安装后发现只是在右下角显示详细的时间，并没有天气情况 powerline-status1234567891011121314151617181920212223242526272829303132# 官方使用手册：https://powerline.readthedocs.io/en/master/# 在ubuntu18.04上测试成功1. sudo apt install python-pip2. sudo pip install powerline-status# 这里的pip应该使用的pip2版本3. git clone https://github.com/powerline/fonts.git &amp;&amp; cd fonts &amp;&amp; sh ./install.sh# 克隆安装字体，在家目录中运行即可4. 设置vim使用powerlinevim .vimrcset rtp+=/usr/local/lib/python2.7/dist-packages/powerline/bindings/vim/set laststatus=2set t_Co=256 5. github上提供的bash和zsh方法，会使命令行改变显示效果，与oh-my-zsh有冲突，所以在root用户进行此设置。github上提供的下面两个配置文件路径有问题，均提供成了/usr/local/lib/python2.7/site-packages/powerline/bindings/bash/powerline.sh查看发现site-packages目录中没有任何东西========= .bashrc=========root  ~  vim .bashrc if [ -f /usr/local/lib/python2.7/dist-packages/powerline/bindings/bash/powerline.sh ];then source /usr/local/lib/python2.7/dist-packages/powerline/bindings/bash/powerline.shfi========= .zshrc=========if [[ -r /usr/local/lib/python2.7/dist-packages/powerline/bindings/zsh/powerline.zsh ]];then source /usr/local/lib/python2.7/dist-packages/powerline/bindings/zsh/powerline.zshfi6. .tmux.conf的配置，未测试source /usr/local/lib/python2.7/dist-packages/powerline/bindings/tmux/powerline.confset-option -g default-terminal "screen-256color" 截图软件12345apt install flameshot设置&gt;工作区&gt;快捷键&gt;全局快捷键，之后选择加号，然后选择要使用快捷键的程序，命令使用 flameshot gui，在右侧设置此程序的快捷键。⚡ root@ruopu64  ~  apt install deepin-screenshot# 这个软件在xfce4环境下更管用，在xfce4环境中安装上面的软件打不开。 Wunderlist奇妙清单1234下载地址：https://github.com/edipox/wunderlistux/releases/tag/v0.0.9-linux-x64# 可能下载deb，AppImage，和原码包。使用deb包安装即可，桌面图标显示有问题，可以在命令行使# 用wunderlist &amp;运行参考：https://sourcedigit.com/21169-install-wunderlist-app-wunderlistux-ubuntu-16-10-ubuntu-16-04/ apt-fast12345sudo add-apt-repository ppa:apt-fast/stablesudo apt-get install apt-fast# 会弹出一些信息要求选择，按默认选择即可sudo apt-fast upgrade# 没有命令补全，有点不好。 GitKraken1官网：https://www.gitkraken.com/，首页左侧有git客户端下载，安装即可。 linux下载工具motrix1号称是一款全能的下载工具，使用上的确比以往的下载工具好用。下载地址：https://motrix.app/zh-CN/ pycharm1234567891011121314151617将pycharm- 2018.3.4 .tar.gz复制 到所需的安装位置（确保您具有该目录的rw权限）使用以下命令将pycharm- 2018.3.4 .tar.gz文件解压缩到空目录： tar -xzf pycharm- 2018.3.4 .tar.gz# 新的实例必须不超过现有的提取。目标文件夹必须为空。删除pycharm- 2018.3.4 .tar.gz以节省磁盘空间（可选）从bin子目录运行pycharm.sh# pycharm启动器[Desktop Entry]Type = Application Name = PycharmGenericName = PycharmComment = Pycharm:The Python IDEExec = "your_dir/pycharm-2017.3.1/bin/pycharm.sh"Icon = your_dir/pycharm-2017.3.1/bin/pycharm.pngTerminal = pycharmCategories = Pycharm anaconda31下载https://www.anaconda.com/download/，下载后是一个shell脚本，执行即可，回答都是yes或回车。使用root用户安装没有问题，使用其他用户安装时无法连接图形界面。这里有一个问题，就是要安装anaconda3后，python命令会变成anaconda3中bin目录中的python命令，这修改了系统的默认python版本，建议删除anaconda目录中bin目录下的python软链接，bin目录中的jupyter-noteboot打开后，修改第一行的内容，在python后加上3.7，也就是使用anaconda目录中bin目录下的python3.7打开jupyter-notebook，这样就可以使用jupyter-notebook了。 7zip1234567sudo apt install p7zip7z x Windows.iso# 解压iso文件7z l Windows.iso# 查看压缩文件的内容7zr a win10.7z cn_windows_10_multi-***.iso# 创建压缩文件 glances1234567891011121314151617181920212223242526272829303132333435363738394041424344wget -O- https://bit.ly/glances | /bin/bash# 使用此方法安装比较完整。安装过程时间比较长。不可使用apt安装，# 因为安装后会有python的报错。glances -w# 使用此命令后，即可打开网页http://0.0.0.0:61208/查看监控的页面了。# 测试发现，这样在前台运行，在使用浏览器打开时显示没有问题。如果使用nohup在后台运行，# 使用浏览器打开时，显示不了CPU、MEM、SWAP的百分比与代表百分比的线条。在前台运行后，使用# Ctrl+z放到后台，再用bg %1在后台运行显示也没有问题。再次测试，发现如果不使用nohup，只# 使用&amp;在后台运行，显示是没有问题的。glances -t 2# Glances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率=======================================================================================Glances 的选项· a – 对进程自动排序· c – 按 CPU 百分比对进程排序· m – 按内存百分比对进程排序· p – 按进程名字母顺序对进程排序· i – 按读写频率（I/O）对进程排序· d – 显示/隐藏磁盘 I/O 统计信息· f – 显示/隐藏文件系统统计信息· n – 显示/隐藏网络接口统计信息· s – 显示/隐藏传感器统计信息· y – 显示/隐藏硬盘温度统计信息· l – 显示/隐藏日志（log）· b – 切换网络 I/O 单位（Bytes/bits）· w – 删除警告日志· x – 删除警告和严重日志· 1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况· h – 显示/隐藏这个帮助画面· t – 以组合形式浏览网络 I/O· u – 以累计形式浏览网络 I/O· q – 退出（‘ESC‘ 和 ‘Ctrl&amp;C‘ 也可以）Glances 中颜色的含义· 绿色：OK（一切正常）· 蓝色：CAREFUL（需要注意）· 紫色：WARNING（警告）· 红色：CRITICAL（严重）阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。======================================================================================= albert12345678# albert类似mac的alfred。可以搜索包括主机与网络上的信息。1. 下载deb包，也可以添加repo地址下载地址：http://download.opensuse.org/repositories/home:/manuelschneid3r/xUbuntu_16.04/amd64/albert_0.16.1_amd64.deb.mirrorlist，下载包名：albert_0.16.1_amd64.deb。这是opensuse包的下载地址，里面会包含其他发行版的包。# sudo add-apt-repository ppa:nilarimogard/webupd8，此命令显示超时。如果可以使用，之后更新软件库，# 就可以使用apt安装albert了。2. 安装时可能还需要依赖其他包，可以到https://pkgs.org下载。3. 第一次启动时需要设置一下快捷键，另外需要设置一下要搜索的位置 输入法fcitx123456789101112131415161718192021222324apt install fcitx-* -y im-config# 选择fcitx作为默认输入法vim /etc/default/im-config IM_CONFIG_DEFAULT_MODE=fcitx # 原来的值是auto，将其改为fcitx。这一步非常关键。重启后可以使用fcitx输入法，但右上角没有输入法的显示，不明原因。fcitx-config-gtk3# 设置输入法apt install kde-config-fcitx # 安装后就可以执行im-config，如果没有此命令就先下载 vim /etc/X11/xinit/xinputrc run_im fcitx # 这项也一定要改*** 下面可以不用设置vim ~/.bashrc # 在最下方添加export XMODIFIERS=@im=fcitxexport QT_IM_MODULE=ximexport GTK_IM_MODULE=xim#export XMODIFIERS=@im=ibus#export QT_IM_MODULE=ibus#export GTK_IM_MODULE=ibus everynote云笔记123456apt install nixnote2whatever是一款evernote第三方客户端，下载地址：https://sourceforge.net/projects/whatever-evernote-client/files/v1.0.0/Whatever_1.0.0_amd64.deb/download。登录有些慢，功能可以使用，问题还是图片粘贴有问题。tusk是另一款evernote第三方客户端，下载地址：https://github.com/klaussinani/tusk/releases/tag/v0.22.0使用中发现两个问题，一是打开软件需要等待较长时间，才能登录evernote，大概三至五分钟。第二是复制到软件内的图片无法显示，如果单独再复制一次，在网页版的evernote上就会看到两张同样的图片。 启动盘制作软件123456789101112131415161718192021222324252627282930313233官网：https://unetbootin.github.io/linux_download.html下载binary文件chmod +x unetbootin-linux./unetbootin-linux# 在官网上有安装的方法可以查看。执行时可能界面显示有问题sudo add-apt-repository ppa:gezakovacs/ppasudo apt-get updatesudo apt-get install unetbootin# 使用此方法也可以安装sudo QT_X11_NO_MITSHM=1 /usr/bin/unetbootin# 执行软件时会提示必须以root用户执行，并使用上面命令=======================================================================================# 此软件为启动盘制作工具，地址：https://www.balena.io/etcher/。下载相应版本的AppImage版本，# 之后直接执行这个下载的软件即可。另一种安装方法：1. 添加Etcher debian存储库：echo “ deb https://deb.etcher.io stable etcher ” | sudo tee /etc/apt/sources.list.d/balena-etcher.list2. 信任Bintray.com的GPG密钥：sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 379CE192D401AB613. 更新并安装：sudo apt-get updatesudo apt-get install balena-etcher-electron卸载sudo apt-get del balena-etcher-electronsudo rm /etc/apt/sources.list.d/balena-etcher.listsudo apt-get update安装说明地址：https://github.com/balena-io/etcher#debian-and-ubuntu-based-package-repository-gnulinux-x86x64=======================================================================================安装live-usb-install-2.5.12-all.deb下载地址：http://live.learnfree.eu/wp-content/uploads/2017/12/wp-static-html-output-1-lokster/download/ 老版本firefox12345678910# 因为需要连接VPN，且在linux主机上只能安装在老版本的firefox上，所以不得不先安装老版本的firefox首先在https://pkgs.org/download/firefox中找到了一个debian7上安装的firefox-esr_52.8.0esr-1~deb7u1_amd64.deb。安装时还会依赖一些包，也需要从这个网址下载，所需包有libhunspell-1.3-0_1.3.3-3_amd64.deb、libevent-2.0-5_2.0.21-stable-3_amd64.deb、libjsoncpp0_0.6.0_rc2-3.1_amd64.deb、libffi5_3.0.10-3_amd64.deb、libpango1.0-0_1.40.5-1_amd64.deb。 ⚡ root@ruopu64  ~  apt remove firefox-esr # 首先卸载之前安装的firefox ⚡ root@ruopu64  ~  find / -name firefox # 找一下是否还有残留的文件，发现只在用户家目录中有一些缓存文件，都删除即可 ⚡ root@ruopu64  ~  gdebi firefox-esr_52.8.0esr-1\~deb7u1_amd64.deb # 安装老版本的firefox，如果有依赖问题，就先安装依赖包 安装好之后，需要使用root权限打开firefox，在/usr/share/applications/firefox-esr.desktop中的Exec一项中，加入sudo即可。在地址栏输入about:config，找到最下方的xpinstall.signatures.required，双击将此项改为false。这样就可以安装未验证的插件了。 访问https://211.99.15.34:6443下载插件，之后解压，先以root身份到SSLVPNClientLinux目录中执行解压后目录中的install.sh脚本，如果不到SSLVPNClientLinux目录中执行脚本会报错。之后在firefox中选择Add-ons，在页面中上方有一个小齿轮，打开后有一个Install Add-ons From File...，点击后会打开电脑的目录，在其中找到解压后的插件，根据系统，这里要选择安装64位的插件，安装后再重启，这样就可以在VPN登录页面使用帐号登录了，这里一定要注意，不可以选择密码下面的保存配置，如果选择了此项，就无法连接到内网了。登录后就可以访问内网了。 java-jdk8123456789101112131415下载地址：https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html下载前需要先登录cd works/ubuntutool/java-jdk# 进入下载目录tar xf jdk-8u211-linux-x64.tar.gzmv jdk1.8.0_211 /usr/local/jdk1.8# 移动到/usr/local目录下vim /etc/profile.d/java.shexport JAVA_HOME=/usr/local/jdk1.8 export JRE_HOME=$&#123;JAVA_HOME&#125;/jresource /etc/profile$ java -versionjava version "1.8.0_211"Java(TM) SE Runtime Environment (build 1.8.0_211-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode) 微信123wget https://github.com/geeeeeeeeek/electronic-wechat/releases/download/v1.4.0/linux-x64.tar.gztar xf linux-x64.tar.gz./electronic-wechat-linux-x64/electronic-wechat 钉钉123下载地址：https://pan.baidu.com/s/1NznYL5fV8sUWInmUgciXXQ。下载后打开压缩包，是一个dingding.deb文件，使用gdebi命令安装即可。dingding运行时的名称是dtalk，如果关闭了打开的钉钉，无法再打开钉钉，需要使用pkill dtalk杀死钉钉的进程，才能再打开钉钉。 fiddler12341. sudo apt install mono-complete# 安装这个包是为了在linux环境中运行fiddler.exe程序，这个包可以跨平台跑.NET的程序2. mono Fiddler.exe# 运行程序 监控软件netdata123456789apt updateapt install zlib1g-dev uuid-dev libmnl-dev gcc make autoconf autoconf-archive autogen automake pkg-config curl# 安装Netdata的依赖项，其中包括gcc（一个C编译器），GNU Autoconf工具，GUID管理和Netdata内部Web服务器的压缩库。apt install python python-yaml python-mysqldb python-psycopg2 nodejs lm-sensors netcat# 下一组软件包是可选的，但Netdata推荐使用，包括Python，一些Python软件包和Node.JS。与系统包管理器捆绑在一起的稳定版Node.js适用于Netdata的要求。git clone https://github.com/firehol/netdata.git --depth=1 ~/netdatacd ~/netdata./netdata-installer.sh安装时执行回车即可，等待完成。脚本中有一步会使用curl -sSL 命令下载安装包，如果速度太慢，可以到netdata-installer.sh脚本中取消curl的这三个选项。 微软字体1sudo apt install ttf-mscorefonts-installer mac字体123456789101112下载Monaco字体，地址：https://github.com/todylu/monaco.ttf/blob/master/monaco.ttf?raw=truehttps://github.com/cstrap/monaco-fontsudo mkdir /usr/share/fonts/macsudo cp -a MONACO.TTF /usr/share/fonts/maccd /usr/share/fonts/macsudo chmod 744 /usr/share/fonts/custom/Monaco.ttfsudo mkfontscalesudo mkfontdirsudo fc-cache -vf # 刷新系统字体缓存sudo apt install gnome-tweak-toolgnome-tweaks# 使用此工具再设置一下默认字体，将字体大小均改为10更好一些 wine的安装与使用1234567891011121314151617181920212223242526272829303132333435363738394041sudo apt install -y wine64# 安装系统自带的wine64位版本，也有32位版本的==============================================================================================# 也可用使用官方的最新版本wget -nc https://dl.winehq.org/wine-builds/winehq.keysudo apt-key add winehq.keysudo apt-add-repository https://dl.winehq.org/wine-builds/ubuntu/sudo apt-get install --install-recommends winehq-stable==============================================================================================sudo apt install --no-install-recommends winetricks# 安装winetricks（Wine的辅助配置工具，超级便利）。--no-install-recommends选项表示避免安装非必须的文件，# 从而减小镜像的体积winecfg# 初始化wine，也就是在家目录创建一个.wine目录，这个目录就相当于windows系统的C盘。==============================================================================================# 初始化的另一个方法 WINEARCH=win32 WINEPREFIX=~/.win32 winecfg WINEPREFIX=~/.win64 winecfg# 对于64位用户，默认创建的系统目录是64位环境的。若想使用纯32位环境，修改WINEARCH 变量win32为即可： # WINEARCH=win32 winecfg 这样就会生成32位Wine环境。若不设置 WINEARCH 得到的就是64位环境。# 或可以使用初始执行winecfg或wine或winetricks，这三个命令都可以。不必执行上面的命令也可以，这会生成# ~/.wine目录将windows中的\windows\Fonts下的所有字体复制到/opt/wine-stable/share/wine/fonts中，这样可以解决安装的软件有乱码的问题。==============================================================================================因为使用的是ubuntu官方提供的包，所以将字体复制到家目录中的.wine/drive_c/windows/Fonts目录中即可解决乱码问题。winetricks corefonts colorprofilewinetricks fontfix fontsmooth-gray fontsmooth-rgb fontsmooth-bgrwinetricks gdipluswinetricks d3dx9winetricks riched20 riched30winetricks mfc40 mfc42winetricks vcrun6 vb6run vcrun2003 vcrun2005 vcrun2008winetricks msxml3 msxml4 msxml6# 安装依赖库。测试中上面四条命令执行失败了wine uninstaller# 在打开的窗口中可以选择卸载已安装的程序# 安装的软件除了在~/.wine中外，在.local/share/applications中也有wine目录，安装的软件的图标就在这个wine目录中。# 参考：https://blog.csdn.net/buildcourage/article/details/80871141、https://ywnz.com/linuxjc/2553.html# 在使用中发现wine并不好用。不建议使用。 鼠标主题123到https://limitland.gitlab.io/flatbedcursors/下载主题，FlatbedCursors-0.5.tar.bz2 解压主题将解压的目录都放入/usr/share/icons/中 锐捷客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 公司搬家之后需要使用锐捷交换机上网，所以需要安装锐捷客户端才能联网。但使用锐捷客户端无法连接。所以需要使用mentohust包进行连接验证。下面的前两步是下载安装锐捷客户端，可以忽略。1. 下载地址：http://pan.baidu.com/s/1hrhaYrU，包名：RG_SU_For_Linux_1_30_Setup.zip2. 解压unzip RG_SU_For_Linux_1_30_Setup.zip3. 下载mentohust，此包为了可以通过锐捷用户名密码验证，也解决使用锐捷脚本验证时提示"不允许使用的客户端类型"。感觉使用这个包，就不需要锐捷的软件包了。下载地址：https://code.google.com/archive/p/mentohust/。下载包名：mentohust_0.3.4-1_amd64.deb4. 用户名密码验证sudo mentohust -v4.44 -w欢迎使用MentoHUST 版本: 0.3.4Copyright (C) 2009-2010 HustMoon Studio人到华中大，有甜亦有辣。明德厚学地，求是创新家。Bug report to http://code.google.com/p/mentohust/issues/list** 网卡[1]: enp1s0** 网卡[2]: wlp0s20f3** 网卡[5]: bluetooth0** 网卡[6]: nflog** 网卡[7]: nfqueue** 网卡[8]: usbmon1** 网卡[9]: usbmon2?? 请选择网卡[1-9]: 1** 您选择了第[1]块网卡。?? 请输入用户名: guanxiaoman?? 请输入密码: Qc3!Kp89?? 请选择组播地址(0标准 1锐捷私有 2赛尔): 0?? 请选择DHCP方式(0不使用 1二次认证 2认证后 3认证前): 1** 用户名: guanxiaoman** 网卡: enp1s0** 认证超时: 8秒** 心跳间隔: 30秒** 失败等待: 15秒** 允许失败: 8次** 组播地址: 标准** DHCP方式: 二次认证** 通知超时: 5秒** DHCP脚本: dhclient!! 在网卡enp1s0上获取IP失败!!! 在网卡enp1s0上获取子网掩码失败!** 本机MAC: e4:e7:49:3d:34:92** 使用IP: 0.0.0.0** 子网掩码: 255.255.255.255** 认证参数已成功保存到/etc/mentohust.conf.&gt;&gt; 寻找服务器...** 认证MAC: 00:1a:a9:48:2a:b1&gt;&gt; 发送用户名...&gt;&gt; 发送密码...** 客户端版本: 4.44** MD5种子: 23:ed:66:15:a6:f8:dd:93:2e:63:64:a8:97:52:3d:d2!! 缺少8021x.exe信息，客户端校验无法继续！&gt;&gt; 发送用户名...&gt;&gt; 发送密码...** 客户端版本: 4.44** MD5种子: 23:ed:66:15:a6:f8:dd:93:2e:63:64:a8:97:52:3d:d2!! 缺少8021x.exe信息，客户端校验无法继续！&gt;&gt; 认证成功!&gt;&gt; 正在获取IP...RTNETLINK answers: File exists&gt;&gt; 操作结束。!! 在网卡enp1s0上获取IP失败!!! 在网卡enp1s0上获取子网掩码失败!** 本机MAC: e4:e7:49:3d:34:92** 使用IP: 0.0.0.0** 子网掩码: 255.255.255.255&gt;&gt; 寻找服务器...&gt;&gt; 发送用户名...&gt;&gt; 发送密码...** 客户端版本: 4.44** MD5种子: a5:3a:82:3c:58:6a:2a:00:0a:80:a9:0c:de:13:50:86!! 缺少8021x.exe信息，客户端校验无法继续！&gt;&gt; 认证成功!&gt;&gt; 发送心跳包以保持在线...# 上面需要输入和选择一些信息。另外，有一个问题，成功认证后没有分配网关地址。需要手动配置。第一次配置成功后，之后再使用sudo mentohust -v4.44 -w命令连接时就不需要再输入任何信息了，第一次输入的信息会被保存。# 参考：https://blog.csdn.net/tales_/article/details/50533748 测试网速12345678910111213141516171819202122232425262728293031323334# Speedtest.net强大而知名的全球宽带网络速度测试网站，采用Flash载入界面，Alexa世界排名非常高，# Speedtest.net在全球有数百个测试节点，国内有测速节点几十个。作为一款在线并且可视化的网速测试工具。# 使用方法简单，无需下载、安装。Speedtest.net还推出了命令行下测速工具speedtest.py 就能够实时测试网速。shouyu@shouyu-pc  ~  wget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py# 下载工具shouyu@shouyu-pc  ~  chmod +x speedtest.py# 给执行权限shouyu@shouyu-pc  ~  ./speedtest.py # 执行。下面是执行结果：Retrieving speedtest.net configuration...Testing from Beijing Primezone Technologies (211.99.134.28)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Beijing Unicom (Beijing) [1.67 km]: 7.089 msTesting download speed................................................................................Download: 15.14 Mbit/sTesting upload speed................................................................................................Upload: 34.94 Mbit/s shouyu@shouyu-pc  /media/shouyu/C64CC89B4CC8879F/Tools/ubuntutool/网速测试  sudo cp -a speedtest.py /usr/bin # 将脚本入到/usr/bin目录下shouyu@shouyu-pc  ~  source .zshrc # 加载环境变量shouyu@shouyu-pc  ~  speedtest.py Retrieving speedtest.net configuration...Testing from Beijing Primezone Technologies (211.99.134.28)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Beijing Broadband Network (Beijing) [1.67 km]: 4.367 msTesting download speed................................................................................Download: 15.06 Mbit/sTesting upload speed................................................................................................Upload: 34.47 Mbit/s# 这时就可以直接使用此脚本了。最好有线情况测试，无线可能会超时。# 参考：http://www.mamicode.com/info-detail-2329407.html xfce4桌面123apt install xfce4 xfce4-goodies kali-desktop-xfce# xfce4是基础的包，xfce4-goodies是很多插件的包，kali-desktop-xfce安装后才能看到系统托盘中的网络图# 标。但最后还是有一些图标在系统托盘中看不到，原因不明。 KVM安装12345678910111213apt install libvirt-daemon-system libvirt-daemon qemu-kvm qemu virt-manager virt-viewer bridge-utils virtinst# qemu-kvm：QEMU在KVM中主要用于虚拟化IO设备，CPU和内存虚拟化调用KVM内核模块加速实现。# libvirt-daemon-system, libvirt-daemon：libvirt库提供虚拟机操作接口，用于控制和管理各类虚拟机。# 安装virtinst包，提供一整套虚拟机命令行管理工具，包括安装、克隆等命令。如virt-install, virt-clone, virsh# virt-manager,virt-viewer：图形化管理工具systemctl enable libvirtdsystemctl start libvirtdsystemctl status libvirtdsudo virt-manager# 直接运行virt-manager有问题，无法创建虚拟机。如果使用root用户运行virt-manager提示"Unable to init server"，可能是root用户或sudo时执行图形化应用程序时出现，无法连接到X server显示界面，解决方法如下：# export DISPLAY=":0"# xhost +# virt-manager samba图形配置工具123456下载地址：https://packages.ubuntu.com/xenial/system-config-sambasystem-config-samba# 启动时可能会提示: could not open configuration file `/etc/libuser.conf'sudo touch /etc/libuser.conf# 手动添加这个配置文件# 参考：https://www.linuxidc.com/Linux/2018-01/150493.htm 设置方法apt源123456789101112131415161718192021222324252627282930313233vim /etc/apt/sources.list #中科大（加入这一个源即可） deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib #阿里云 #deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib #deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib #清华大学 #deb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free #deb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free #浙大 #deb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free #deb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free #东软大学 deb http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib #deb-src http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib #官方源 #deb http://http.kali.org/kali kali-rolling main non-free contrib #deb-src http://http.kali.org/kali kali-rolling main non-free contrib #重庆大学 #deb http://http.kali.org/kali kali-rolling main non-free contrib #deb-src http://http.kali.org/kali kali-rolling main non-free contrib # 加入上面一行即可 apt update # 这样就可使用源了。 Tmux 启用鼠标滚动12341. 先按ctrl+B2. set -g mouse on# 这时就启用对所有窗口的鼠标滚动了，但不能选中文本进行复制粘贴3. 按住shift再点击鼠标右键，这时就可以看到复制粘贴了，也可以选中文本了 history结果显示操作时间方法1让history命令显示时间，需要在/etc/profile中加入export HISTTIMEFORMAT="[%F %T]"。但在普通用户使用zsh时没有起作用，不明原因。 开启bbr（tcp拥塞控制）1234echo "net.core.default_qdisc=fq" &gt;&gt; /etc/sysctl.confecho "net.ipv4.tcp_congestion_control=bbr" &gt;&gt; /etc/sysctl.confsysctl -p lsmod | grep bbr #检查是否有tcp_bbr vim设置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051在用户家目录中创建的.vimrc文件只对当前用户生效，配置后不用重新加载，立即生效。但/etc下的vimrc配置会失效，所以这个文件中要将需要的功能都写入。vim ~/.vimrcset nocompatible# 不与 Vi 兼容（采用 Vim 自己的操作命令）set nu # 显示行号 set hlsearch# 搜索时，高亮显示匹配结果。set showmatch# 光标遇到圆括号、方括号、大括号时，自动高亮对应的另一个圆括号、方括号和大括号。set history=1000# Vim 需要记住多少次历史操作。syntax on# 打开语法高亮。自动识别代码，使用多种颜色显示。即使加载时报错，也要加入此行set cursorline# 光标所在的当前行高亮。set showcmd# 命令模式下，在底部显示，当前键入的指令。比如，键入的指令是2y3d，那么底部就会显示2y3，当键入d的时候，操作完成，显示消失。set autoindent# 按下回车键后，下一行的缩进会自动跟上一行的缩进保持一致。set expandtab# 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。set wrap# 自动折行，即太长的行分成几行显示。set incsearch# 输入搜索模式时，每输入一个字符，就自动跳到第一个匹配的结果。set ignorecase# 搜索时忽略大小写。colorscheme slate # 即使加载时报错，也要加入此行# 调整配色方案，还有default、blue、darkblue、delek、desert、elflord、evening、industry、koehler、morning、murphy、pablo、peachpuff、ron、shine、slate、torte、zellnerhighlight StatusLine guifg=SlateBlue guibg=Yellow highlight StatusLineNC guifg=Gray guibg=White# 状态行颜色，不使用set tabstop=4 # 制表符为4set softtabstop=4 set shiftwidth=4# 统一缩进为4set rtp+=/usr/local/lib/python2.7/dist-packages/powerline/bindings/vim/set laststatus=2set t_Co=256# 创建.vimrc文件后就可以在命令行中使用鼠标右键了，这是抵消了/etc/vimrc文件中的设置。vim命令粘贴带数字或符号的信息时格式混乱解决使用vim打开文件时，使用:set paste命令关闭缩进功能就可以解决了。如果要开启缩进功能，使用命令:set nopaste。或一种方法是，打开.vimrc文件，加入set pastetoggle=&lt;F9&gt;，之后可以使用F9键来切换缩进功能了。配置文件中的&lt;F9&gt;是按F9键录入的。在vim中，使用%表示全文关闭高亮:nohl 创建启动器1234567891011121314151617181920# Linux 系统中的Desktop Entry 文件以desktop为后缀名。Desktop Entry 文件是 Linux 桌面系统中用于描述程序启动配置信息的文件。wget https://raw.githubusercontent.com/geeeeeeeeek/electronic-wechat/master/assets/icon.png -O electronic-wechat.png# 下载一个微信图标mv electronic-wechat.png works/ubuntutool/electronWechat/electronic-wechat-linux-x64/# 将图标与执行程序放在一起vim /usr/share/applications/electronic-wechat.desktop[Desktop Entry] Name=Electronic WechatName[zh_CN]=微信电脑版Name[zh_TW]=微信电脑版Exec=/root/works/ubuntutool/electronWechat/electronic-wechat-linux-x64/electronic-wechatIcon=/root/works/ubuntutool/electronWechat/electronic-wechat-linux-x64/electronic-wechat.pngTerminal=false# 软件打开时是否启动终端X-MultipleArgs=falseType=ApplicationEncoding=UTF-8Categories=Application;Utility;Network;InstantMessaging;StartupNotify=false编辑完上面的文件，进入/usr/share/applications 目录就可以看到一个叫微信电脑版的图标，可以在图标上右键，将其发送至桌面，之后就可以双击这个图标启动微信了。 设置桥接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 目前有五种方法。因为需要锐捷客户端拨号上网，所以这里只测试通过nm-connection-editor连接成功。或者说，在测试nm-connection-editor才反应过来这里的问题。1. nmcli# 参考：https://www.zcfy.cc/article/how-to-add-network-bridge-with-nmcli-networkmanager-on-linuxnmcli con shownmcli connection show --active# 取当前连接状态nmcli con add ifname br0 type bridge con-name br0 nmcli con add type bridge-slave ifname eno1 master br0 nmcli connection show# 添加新的br0网桥nmcli con down "Wired connection 1"# 先关闭网卡nmcli con up br0# 打开 br0sudo nmcli con modify br0 bridge.stp no # 是不是这里改成yes就开启stp了，stp是生成树协议 nmcli con show nmcli -f bridge con show br0# 禁用 STP2. brctl参考：https://www.cnblogs.com/yinzhengjie/p/7446226.html# 这种方法显得更简单，但连接后br0可以分配到地址，也可以ping通网关。但不能ping能DNS，如114brctl addbr br0 #创建一个名称为"br0"的网卡ifconfig eth0 0 up #将需要桥接的网卡IP清空brctl addif br0 eth0 #在"br0"上添加"eth0"；ifconfig br0 192.168.16.107/24 up #给"br0"配置IP；route add default gw 192.168.16.1 #设置默认的网关地址；brctl stp br0 on # 开启stp服务3. 修改/etc/netplan/50-cloud-init.yamlnetwork: version: 2 ethernets: enp1s0: dhcp4: no dhcp6: no wlp0s20f3: dhcp4: yes dhcp6: yes bridges: br0: interfaces: [enp1s0] dhcp4: yes# yaml文件对缩进很严格，一定要注意缩进netplan --debug apply# 让设置生效，生效后NetworkManager就失效了4. nm-connection-editor 。测试发现，通过路由器直接连接到电脑后，网桥可用。但如果还要经过锐捷播号，就有问题了。- nm-connection-editor # 启动图形界面- 点左下角的加号创建一个网桥 -&gt; 在标签页桥接中点击添加 -&gt; 选择以太网 -&gt; 选择设备为本机的有线网卡，其他默认，保存。-&gt; 这时在桥接标签页中就多了一个添加的以太网，其他默认，IPV4选择与本机网卡相同的配置，如DHCP或静态IP，保存。- 删除原有的以太网卡，重启NetworkManager即可。5. nmtui 设置远程使用root用户登录12345vim /etc/ssh/sshd_config PermitRootLogin yes # PermitRootLogin prohibit-password# 注释一条，写入上面一条即可。systemctl restart ssh 固态硬盘优化123456789101112sudo hdparm -I /dev/sdx | grep "TRIM supported"# 查看固态硬盘是否支持trimvim fstrim.sh #!/bin/sh LOG=/var/log/trim.log echo "*** $(date -R) ***" &gt;&gt; $LOG fstrim -v / &gt;&gt; $LOG fstrim -v /home &gt;&gt; $LOGchmod +x fstrim.shcrontab -e 0 9 * * * /bin/bash /root/sh/fstrim.sh# 每天9点定时执行 修改默认编辑器1sudo update-alternatives --config editor 修改程序默认终端模拟器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950root@ruopu64:~#mv /usr/bin/konsole&#123;,.bak&#125;root@ruopu64:~#ln -sv /usr/bin/tilix.wrapper /usr/bin/konsole# 这样打开终端时就会使用tilix了。# 尝试使用root@ruopu64:~#update-alternatives --config x-terminal-emulator命令修改没有成功# 在设置中的应用程序中修改默认打开的终端也没有成功====================================================gsettings set org.gnome.desktop.default-applications.terminal exec /usr/bin/mate-terminalgsettings set org.gnome.desktop.default-applications.terminal exec-arg "-x"# 上面是设置默认打开的终端命令与选项。但这只可以设置使用Ctrl + Alt + t打开的默认终端。使用鼠标右键打开的终端并不会变。# gsettings的使用为，先使用list-schemas查看有哪些schemas，再通过list-keys查看schemas有哪些key，再通过get可以获取key的值，使用set可以设置key的值。====================================================gsettings命令使用GConf是在基于 GNOME2 的 Linux 操作系统中实现对应用程序的配置及管理功能的工具。我们可以把 GConf 理解为 Linux 操作系统中的注册表。然而，它克服了 Windows 注册表的一些缺点，比如 Windows 注册表遭到破坏，可能会导致操作系统崩溃，而且 GConf 的配置信息存储于纯文本的文件中，可读性很好。在 GNOME3 中，GConf 已经被 DConf/Gsettings 替代，但还是用些应用在使用 GConf。1.dconf-editor 的使用还可以用 dconf 进行操作，明细请通过 man dconf 查看，而 dconf-editor 是 dconf 的一个图形化操作程序。2.使用 gsettings 编辑设置,如下示例在Ubuntu16.04上的效果1.显示系统都安装了哪些不可重定位的schemagsettings list-schemas2.查看org.mate.applications-office都有哪些子schemagsettings list-children org.mate.applications-office3.查看org.mate.applications-office.calendar的schema下都有哪些项(key)gsettings list-keys org.mate.applications-office.calendar4.查看org.mate.applications-office.calendar的schema下所有项的取值gsettings list-recursively org.mate.applications-office.calendar5.查看org.mate.applications-office.calendar的schema下的项needs-term的值gsettings get org.mate.applications-office.calendar needs-term6.查看org.mate.applications-office.calendar的schema下的项needs-term的取值范围gsettings range org.mate.applications-office.calendar needs-term7.修改设置org.mate.media-handling的schema下的项automount-open的值为truegsettings set org.mate.media-handling automount-open falsegsettings get org.mate.media-handling automount-open 8. 恢复org.mate.media-handling的schema下的项automount-open的值为默认值gsettings reset org.mate.media-handling automount-open9. 修改org.mate.media-handling的schema下的多项值后，恢复整个schema的所有项为默认值gsettings list-recursively org.mate.media-handling 连接VPN网络1当宿主机的firefox连接到VPN后，虚拟机使用NAT方式联网，就可以连接到VPN网络内，无需设置。 修改命令提示符显示效果123vim ~/.bashrcexport PS1='\[\e]0;\u@\h: \w\a\]$&#123;debian_chroot:+($debian_chroot)&#125; \[\033[01;31m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\W\[\033[00m\]\$'# 这里就是将最后的小写w改为大写W，这条PS1的命令也是从.bashrc文件内容中的一部分复制过来的 关闭 avahi-daemon 服务1234567avahi-daemon造成过网络异常，用处也不大，停止服务并关闭开机启动：sudo systemctl stop avahi-daemon.socketsudo systemctl stop avahi-daemon.servicesudo /lib/systemd/systemd-sysv-install disable avahi-daemonsudo systemctl disable avahi-daemon.socketsudo systemctl disable avahi-daemon.service 清理家目录中的.cache文件12345678910⚡ root@ruopu64  ~  df -h文件系统 容量 已用 可用 已用% 挂载点udev 7.7G 0 7.7G 0% /devtmpfs 1.6G 9.8M 1.6G 1% /run/dev/mapper/ruopu64--vg-root 53G 48G 2.8G 95% /# root目录增长太大⚡ root@ruopu64  ~  find ~/.cache -size +100M -delete# 清理大于100M的文件⚡ root@ruopu64  ~  find ~/.cache -type f -atime +365# 清理日期大于365天的文件 清理/boot/分区123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 ✘ ⚡ ⚙ root@ruopu64  ~  df -h文件系统 容量 已用 可用 已用% 挂载点udev 7.7G 0 7.7G 0% /devtmpfs 1.6G 9.4M 1.6G 1% /run/dev/mapper/ruopu64--vg-root 53G 49G 2.0G 97% /tmpfs 7.8G 13M 7.7G 1% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.8G 0 7.8G 0% /sys/fs/cgroup/dev/sda1 236M 227M 0 100% /boot# boot分区没有空间了⚡ ⚙ root@ruopu64  ~  dpkg --get-selections|grep linux-imagelinux-image-4.14.0-kali3-amd64 installlinux-image-4.18.0-kali2-amd64 installlinux-image-4.18.0-kali3-amd64 installlinux-image-4.19.0-kali1-amd64 installlinux-image-4.19.0-kali3-amd64 installlinux-image-amd64 install# 查看已安装的内核 ⚡ ⚙ root@ruopu64  ~  uname -aLinux ruopu64 4.19.0-kali3-amd64 #1 SMP Debian 4.19.20-1kali1 (2019-02-14) x86_64 GNU/Linux# 查看正在使用的内核 ⚡ ⚙ root@ruopu64  ~  apt autoremove linux-image-4.14.0-kali3-amd64 # 自动删除不用的内核，这除了删除4.14版本外，4.18版本也会自动删除 ⚡ ⚙ root@ruopu64  ~  dpkg --get-selections|grep linux-image linux-image-4.14.0-kali3-amd64 deinstalllinux-image-4.18.0-kali2-amd64 deinstalllinux-image-4.18.0-kali3-amd64 deinstalllinux-image-4.19.0-kali1-amd64 installlinux-image-4.19.0-kali3-amd64 installlinux-image-amd64 install# 删除后查看，被删除的内核后标有deinstall，这表示有卸载残留⚡ ⚙ root@ruopu64  ~  dpkg -P linux-image-4.14.0-kali3-amd64 linux-image-4.18.0-kali2-amd64 linux-image-4.18.0-kali3-amd64# 清理卸载残留 ⚡ ⚙ root@ruopu64  ~  dpkg --get-selections|grep linux-imagelinux-image-4.19.0-kali1-amd64 installlinux-image-4.19.0-kali3-amd64 installlinux-image-amd64 install# 再次查看就没有了 ⚡ ⚙ root@ruopu64  ~  df -h文件系统 容量 已用 可用 已用% 挂载点udev 7.7G 0 7.7G 0% /devtmpfs 1.6G 9.4M 1.6G 1% /run/dev/mapper/ruopu64--vg-root 53G 47G 3.1G 94% /tmpfs 7.8G 30M 7.7G 1% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.8G 0 7.8G 0% /sys/fs/cgroup/dev/sda1 236M 104M 120M 47% /boot# boot分区也有空间了 命令使用apt使用1apt-get包管理在卸载软件后不要轻易使用apt-get autoremove，否则极容易各种悲剧。如果真想卸载干净，可以用apt-get purge 忽略某个可以升级的包12345⚡ ⚙ root@ruopu64  ~  apt-mark hold firefox-esr firefox-esr 设置为保留。# 使用此命令可以忽略某个可以升级的包，再使用apt upgrade时就不会升级此包了。apt-mark unhold firefox-esr# 此命令可以解除忽略的包 添加用户1234root@ruopu64:~#useradd -m pythonroot@ruopu64:~#passwd pythonroot@ruopu64:~#vim /etc/passwd# 将用户的shell改为/bin/bash，默认是sh，切换到用户后没有自动补全，命令提示符也有问题，改为bash后就正常了。 设置开机启动123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 ⚡ ⚙ root@ruopu64  ~  vim /lib/systemd/system/rc.local.service # SPDX-License-Identifier: LGPL-2.1+## This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.# This unit gets pulled automatically into multi-user.target by# systemd-rc-local-generator if /etc/rc.local is executable.[Unit]Description=/etc/rc.local CompatibilityDocumentation=man:systemd-rc-local-generator(8)ConditionFileIsExecutable=/etc/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.local startTimeoutSec=0RemainAfterExit=yesGuessMainPID=no ⚡ ⚙ root@ruopu64  ~  vim /etc/rc.local #!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will "exit 0" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.electron-ssr/bin/bash /root/sh/Typora.shexit 0# 此文件需要手动创建。服务启动后，将要启动的命令或脚本放入此文件即可。 ⚡ ⚙ root@ruopu64  ~  systemctl start rc-local.service# 启动服务 ⚡ ⚙ root@ruopu64  ~  systemctl status rc-local.service ● rc-local.service - /etc/rc.local Compatibility Loaded: loaded (/lib/systemd/system/rc-local.service; static; vendo Drop-In: /lib/systemd/system/rc-local.service.d └─debian.conf Active: active (exited) since Fri 2019-03-22 08:15:42 CST; 7min ago Docs: man:systemd-rc-local-generator(8) Process: 4063 ExecStart=/etc/rc.local start (code=exited, status=0/S3月 22 08:15:42 ruopu64 systemd[1]: Starting /etc/rc.local Compatibili3月 22 08:15:42 ruopu64 systemd[1]: Started /etc/rc.local Compatibilitlines 1-10/10 (END)# 状态应该是active⚡ ⚙ root@ruopu64  ~  systemctl enable rc-local⚡ ⚙ root@ruopu64  ~  systemctl list-unit-files# 查看开机启动项 重装grub12345grub-install –target=i386-pc /dev/sda # 由于我的系统装在/dev/sda上面，所以这里用的是/dev/sda # –target=i386-pc这个option指的是：只安装BIOS系统的grub。# 我在使用时没有使用--target选项，只是简单地安装grub-mkconfig -o /boot/grub/grub.cfg #安装好之后，将配置文件输出# 参考： https://blog.csdn.net/panglinzhuo/article/details/77599641 dd命令制作启动盘12345sudo umount /dev/sdb*sudo mkfs.vfat /dev/sdb -I# 直接格式化即可sudo dd if=ubuntu-18.04.1-desktop-amd64.iso of=/dev/sdb bs=10M# 直接将镜像写入U盘 命令行操作无线网络123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112# 因更新内核或其他原因，使网络设置的选项在设置中消失了。没有找到好的解决办法。无奈之下，只有使用命令行操作。不过，塞翁失马，焉知非福?1. 查看无线网络名称 ⚡ root@shouyu  ~  iwlist wlan0 scan|grep ESSID# 查找现在可以找到的无线网络的名称 ⚡ root@shouyu  ~  iw dev wlan0 scan|grep SSID# iw命令也可以查看，建议使用此命令2. 生成配置文件 ⚡ root@shouyu  ~  wpa_passphrase ruopu2.4 # 此命令可以输出配置文件信息，如下：network=&#123; ssid="ruopu2.4" #psk="X5kzxctScjn" psk=7f06ac6de165b153ec899b9cc600678e92a68c5e53a044182ba9dcf50ddd153a&#125;3. 保存配置信息 ⚡ root@shouyu  ~  vim ruopu24.conf# 保存的位置是自定义的4. 连接无线网络 ⚡ root@shouyu  ~  wpa_supplicant -i wlan0 -c ruopu24.conf# 用-i指定网卡，-c指定配置文件。连接的过程需要一些时间5. 查看连接状态 ⚡ root@shouyu  ~  iwconfig wlan0wlan0 IEEE 802.11 ESSID:"ruopu24" Mode:Managed Frequency:2.412 GHz Access Point: C0:C1:C0:D9:75:32 Bit Rate=144.4 Mb/s Tx-Power=22 dBm Retry short limit:7 RTS thr:off Fragment thr:off Encryption key:off Power Management:on Link Quality=55/70 Signal level=-55 dBm Rx invalid nwid:0 Rx invalid crypt:0 Rx invalid frag:0 Tx excessive retries:0 Invalid misc:5 Missed beacon:0# 连接后可以看到是否连接成功# 参考：https://www.cnblogs.com/v5captain/p/8724850.html# 参考：https://blog.csdn.net/u010164190/article/details/68942070# 参考：https://pluhuxc.github.io/2018/08/19/use-wpa_supplicant-connect-wifi.html# 参考：http://rickgray.me/2015/08/03/useful-command-tool-for-wifi-connection/6. 查看已连接的wifi信息 ⚡ root@shouyu  ~  cd /etc/NetworkManager/system-connections# 在此目录中有已经连接的无线信息，以文件形式保存，文件中有密码等信息7. 问题解决出现：nl80211: Could not set interface 'p2p-dev-wlan0' UP ⚡ ⚙ root@shouyu  ~  killall wpa_supplicant # 杀死这个进程再重新执行 wpa_supplicant -i wlan0 -c ruopu24.conf命令即可。另一种方法：# 两种方法只能选择一种。1. 创建配置文件 ⚡ root@shouyu  ~  vim /etc/wpa_supplicant/example.confctrl_interface=/run/wpa_supplicant update_config=1# 这样配置是为了后面可以使用 wpa_cli 命令来实时地扫描和配置网络，并能够保存配置信息。2. 初始化网卡 ⚡ root@shouyu  ~  wpa_supplicant -B -D nl80211 -i wlan0 -c /etc/wpa_supplicant/example.confSuccessfully initialized wpa_supplicantctrl_iface exists and seems to be in use - cannot override itDelete '/run/wpa_supplicant/wlan0' manually if it is not used anymoreFailed to initialize control interface '/run/wpa_supplicant'.You may have another wpa_supplicant process already running or the file wasleft by an unclean termination of wpa_supplicant in which case you will needto manually remove this file before starting wpa_supplicant again.# 如果初始化如上面这样，是因为已经使用无线网卡连接了wifi，需要删除/run/wpa_supplicant/wlan0文件 ⚡ root@shouyu  ~  rm -rf /run/wpa_supplicant/wlan0 ⚡ root@shouyu  ~  wpa_supplicant -B -D nl80211 -i wlan0 -c /etc/wpa_supplicant/example.confSuccessfully initialized wpa_supplicantnl80211: Could not set interface 'p2p-dev-wlan0' UPnl80211: deinit ifname=p2p-dev-wlan0 disabled_11b_rates=0p2p-dev-wlan0: Failed to initialize driver interfaceP2P: Failed to enable P2P Device interface# 再将初始化成功，-B参数表示后台运行。如果遇到驱动不支持所插入的无线网卡，可选择wired或者wext等，具体详情可使用 wpa_supplicant -h 进行查看。# 此方法连接无线网络后速度并不理想，不知是否与-D nl80211选项有关。3. 使用交互式命令wpa_cli⚡ root@shouyu  ~  wpa_cli# 进入 wpa_cli 的交互界面后，它会自动地扫描周围的无线网络，你也可以使用 scan 命令进行手动扫描&gt; scanOK&lt;3&gt;CTRL-EVENT-SCAN-STARTED &lt;3&gt;CTRL-EVENT-SCAN-RESULTS &lt;3&gt;WPS-AP-AVAILABLE &lt;3&gt;CTRL-EVENT-NETWORK-NOT-FOUND &gt; scan_results bssid / frequency / signal level / flags / ssid74:05:a5:7a:14:a0 5765 -58 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] TP-LINK_5038e:6d:77:87:b5:8c 5180 -70 [WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][WPS][ESS]ChinaNet-7MRq-5G-Q74:05:a5:7a:14:9e 2412 -53 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] TP-LINK_503d4:ee:07:60:88:00 2427 -53 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] ziroom60280:89:17:5a:9b:4a 2462 -68 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] dingdingdingdingc0:c1:c0:d9:75:32 2412 -52 [WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][WPS][ESS]home28c:6d:77:69:7f:58 2462 -69 [WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][WPS][ESS]ruopu2.4# 使用scan_results搜索到的无线网络4. 创建网络配置信息&gt; add_network# 这条命令会生成一条网络配置信息的编号，从0开始，下面就对这个第0条配置信息进行配置&gt; set_network 1 ssid "ruopu2.4"&gt; set_network 1 psk "12345678"&gt; set_network 1 key_mgmt WPA-PSK# 测试中这里只能这样配置，因为使用WPA2-PSK会提示FAIL。命令最后的Wifi的加密方式可以是WPA-PSK或WPA2-PSK&gt; enable_network 0OK# 执行过此命令后就开始连接了，需要等待一段时间。再使用iwconfig查看是否连接到了目标网络。注意，这里输出的信息并不会停下来。所以直接使用下面的命令即可。&gt; save_configOK# 保存配置信息到/etc/wpa_supplicant/example.conf&gt; status# 查看状态# 参考：http://rickgray.me/2015/08/03/useful-command-tool-for-wifi-connection/ 制作linux启动盘工具1234U盘安装KaliLinux时，用win32diskimager将镜像拷到U盘中，用软碟通拷到U盘后，安装时提示启动失败。 关于双系统启动盘的制作，可以使用WinSetupFromUSB使用方法：https://www.cnblogs.com/zx525/p/7783504.html。官网：http://www.winsetupfromusb.com 设置區域，不然會是英文，即使選了中文安裝123echo LANG="zh_CN.UTF-8" &gt; /etc/default/locale reboot apt update 问题解决1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283841. 系统提示“KDEInit无法启动/usr/bin/systemsettings5”，这时桌面上的图标均不可点，鼠标左右键在桌面上也失灵。需要关闭有问题的程序，之后才会有上面的错误提示。使用中发现是“系统设置”出了问题，需要在系统设置的图标上右键--&gt;属性--&gt;应用程序--&gt;高级选项--&gt;D-Bus注册中要选择“无”。这样就解决问题了。如果其他图标也有此问题，也可按此方法解决。2. 新装系统后，无法安装fcitx输入法，提示有lib的软件版本不对，需要使用apt install命令按要求再装一次lib软件，千万不要使用apt autoremove命令卸载软件，或卸载任何软件，不然会出现其他问题。3. 新装系统后，安装完各种包后，重启无法进入系统，发现是登录页面的左上角的会话中没有了相应的图形环境。需要重新安装。如：apt install kali-defaults kali-root-login desktop-base kde-plasma-desktop，安装完之后重启即可解决。参考： https://www.52os.net/articles/kail-change-desktop-environment.html(kali切换桌面环境)4. 调整LVM后，开机启动有问题，无法正常进入图形界面，注释/etc/fstab文件中有问题的LVM卷自动挂载后正常，进入系统后修复。5. 挂载提示"The disk contains an unclean file system (0, 0).Metadata kept in Windows cache, refused to mount. Falling back to read-only mount because the NTFS partition is in an unsafe state. Please resume and shutdown Windows fully (no hibernation or fast restartin"root@ruopu64:~# ntfsfix /dev/sda4# 修复有问题的分区即可6. 修改命令提示符vim ~/.bashrcexport PS1='\[\e]0;\u@\h: \w\a\]$&#123;debian_chroot:+($debian_chroot)&#125;\[\033[01;31 m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\W\[\033[00m\]\$'# 加入这一行后，提示符只显示当前目录7. 报错"GLib-GIO-Message: 21:55:51.450: Using the 'memory' GSettings backend. Your settings will not be saved or shared with other applications."vim ~/.zshrcexport GIO_EXTRA_MODULES=/usr/lib/x86_64-linux-gnu/gio/modules source ~/.zshrc8. Opera浏览器无法启动解决：右键Opera图标 --&gt; 应用程序 --&gt; 在命令栏中的最后加入--no-sandbox9. 在没有全局代理的情况下让chrome登录google帐号root@shouyu:~# google-chrome-stable %U --proxy-pac-url="http://127.0.0.1:2333/proxy.pac"# 使用此命令启动google浏览器就可以连接到本地的端口10. 安装xfce4桌面后，启动electron-ssr看不到系统托盘中的图标，可以使用Ctrl + Shift + w 调出程序的窗口。11. 在系统托盘中没有网络图标时，可以使用nmtui进入启用连接中连接无线网络。12. 安装xfce4桌面系统后没有声音。apt install alsamixergui# 安装此软件后部分解决声音问题13. vscode显示中文乱码a. 点击右下解的编码模式，一般这时是UTF-8b. 之后软件上方弹出窗口，有两个选择，一个是Reopen with Encoding，一个是Save with Encoding。点击Reopen with Encodingc. 选择第一项Simplified Chinese(GB2312)。这样就解决中文乱码问题了。14. 使用gnome-tweaks工具取消桌面上的磁盘图标15. 系统报错，提示有问题sudo rm/var/crash/* # 删除这些错误报告gksu gedit/etc/default/apportenable=0# 设置0表示禁用Apportw，或者1开启它。把enabled=1改为enabled=0。保存并关闭文件。完成之后你就再也不会看到弹窗报告错误了。很显然，如果我们想重新开启错误报告功能，只要再打开这个文件，把enabled设置为1就可以了。# gksu是linux下图形化的su/sudo工具16. 解决升级内核后无法使用无线网络问题# 问题：现象反映为电脑不停打开关闭飞行模式，无法使用无线网络。在电源中关闭无线后，打开关闭的现象停止了。查找问题原因是最难的，能想到的有两种情况，一种是驱动问题，一种是内核问题。还好是能想到的两种情况中的一种。a. 查看内核列表sudo dpkg --get-selections |grep linux-imageb. 查看当前使用的内核uname -rc. 升级/安装内核sudo apt install linux-image-4.4.0-75-genericd. 删除内核sudo apt-get remove linux-image-4.4.0-75-generic# 卸载内核时，在图形画面要选择否。安装kali的新内核linux-image-5.2版本时有问题，会使无线网络无法使用。e. firmware-iwlwifi# 无线网卡驱动名称。# kde下载的是broadcom-wl-5.100.138.tar.bz2f. http://http.kali.org/kali/pool/main/l/linux/# kali内核下载地址。17. 安装钉钉时提示"/var/lib/dpkg/info/dtalk.postinst:行7: desktop-file-install：未找到命令"，需要安装desktop-file-utils。之后就可以正常安装了。18. linux 命令行 提示符前面多了 (base)(base) shouyu@shouyu-pc:~$ conda deactivate# 是aconda自动加入了命令到 .bashrc中。执行上面的命令可以去掉前面的(base)shouyu@shouyu-pc:~$ 19. 关于electron-ssr打开后看不到图标的解决办法首先，尝试安装libappindicator1应用程序指示器。如果不行，使用下面的快捷键。Control+Shift+W# 使用快捷键切换主窗口显隐，需要在空白桌面上使用上面的快捷键。20. 取消PPA库的方法sudo add-apt-repository --remove ppa:nilarimogard/webupd8 更新软件源时的公钥问题1234567891011121314151617apt update错误提示：W: GPG error: http://mirrordirector.raspbian.org/raspbian stretch InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 9165938D90FDDD2EW: The repository 'http://mirrordirector.raspbian.org/raspbian stretch InRelease' is not signed.N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.N: See apt-secure(8) manpage for repository creation and user configuration details.W: There is no public key available for the following key IDs:9165938D90FDDD2EE: Failed to fetch http://mirrordirector.raspbian.org/raspbian/dists/stretch/main/binary-armhf/Packages.xz Hash Sum mismatchE: Some index files failed to download. They have been ignored, or old ones used instead.# 错误信息大致意思为没有找到对应的公钥，所以软件源地址不被信任。解决办法：apt install software-properties-common dirmngrgpg --keyserver keyserver.ubuntu.com --recv-keys 9165938D90FDDD2E# keyserver.ubuntu.com是key服务器，9165938D90FDDD2E是上面错误提示中提到的，这是公钥签名。gpg --export --armor 9165938D90FDDD2E | sudo apt-key add -# 参考：https://www.cnblogs.com/lanqie/p/8513102.html 网易云音乐无法启动123456789101112直接无法启动，没有反应 vim /usr/share/applications/netease-cloud-music.desktop ... # Exec=netease-cloud-music --no-sandbox %U Exec=sh -c "unset SESSION_MANAGER &amp;&amp; netease-cloud-music %U" ...# 修改上面一行的设置为sh -c ...一行的样子如果上面的设置不起作用，就需要使用sudo启动软件了sudo netease-cloud-music# 启动时提示"Gtk-Message: 10:33:56.116: Failed to load module "canberra-gtk-module""⚙ shouyu@shouyu-pc  ~/下载  sudo apt install libcanberra-gtk-module google-chrome不能启动1234567891011下载chrome：wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb從官網下載瀏覽器，启动時會有報錯，但可以使用google-chrome-stable --no-sandbox啟動。 vim /usr/bin/google-chrome exec -a "$0" "$HERE/chrome" "$@" --user-data-dir --no-sandbox# 无法直接启动谷歌浏览器，要在启动文件中修改上面一行，在配置文件的最后一行 或者 google-chrome --no-sandbox # 用此种方法也可以启动 # 启动chromium浏览器也可用此方法 VMWareVMWare问题解决12345678910111213141516171819202122232425262728293031323334353637* 安装vmware-workstation前一定要先安装build-essential。Built Essential包含对编译Ubuntu二进制安装包所需的所有包的引用。sudo apt install build-essential1. 安装完VMware后，无法启动，提示“GNU C Compiler(gcc)version 7.3 was not found”gcc --version# 现在是8.2版本apt install -y gcc-7# 安装7版本rm /usr/bin/gcc# 删除软连接ln -s /usr/bin/gcc-7 /usr/bin/gcc# 创建新的软链接gcc --version# 这时查看的版本就是7.3了。# 再启动提示linux headers不对apt install linux-headers-$(uname -r)# 安装后重启系统，就可以进入软件了。2. 安装vmware-workstation15，安装完成后启动提示“Kernel Headers for version X.X.XX-XX-XX were not found”解决办法apt install linux-headers-$(uname -r)# 安装这个头文件后，启动就正常了3. 安装VMWare-tools时报错:"there was a problem updating a software component. try again later and if the"，实际是下载有问题手动解决：下载地址：http://softwareupdate.vmware.com/cds/vmw-desktop/ws/15.0.4/12990004/windows/packages/，下载其中的tools-windows.tar，之后将其解压，在虚拟机中加载解压后的iso文件即可手动安装。4. 添加共享文件夹后，在虚拟机的网络中可以查看到，前提是安装了vmware-tools。5. 卸载VMware-Workstationsudo vmware-installer -u vmware-workstation6. vmware或virtualbox无法启动，要求加载vmmon模块，用modprobe。但使用modprobe加载也会报错。可能是电脑开启了安全引导模式，关闭后就可以了。7. vmware使用NAT方式不能连接到网络，提示：Could not connect 'Ethernet0' to virtual network '/dev/vmnet8'. More information can be found in the vmware.log file. Failed to connect virtual device 'Ethernet0'. 将这个虚拟交换机删除，重新创建一个虚拟交换机，选择NAT方式即可解决。8. 挂起是虚拟机的操作本身的休眠功能，关闭即可。如win7的休眠功能 VirtualBox问题解决1231. 启动虚拟机时提示"Kernel driver not installed ... as root ... /sbin/vboxconfig"问题解决时发现自己只做了三件有用的事，但不确定是否是这些问题造成的虚拟机无法启动。一、关闭BIOS的安全启动功能；二、重装VirtualBox；三、启动虚拟机时无法启动，但提示要执行 sudo modprobe vboxdrv。当完成上面三步后，虚拟机可以启动了。 VirtualBox虚拟机安装Ubuntu 16.04.3 LTS后安装增强功能12点击安装增强功能--&gt;bash VBoxLinuxAdditions.run# 实际使用时先安装了autorun.sh，但没有效果。安装VBoxLinuxAdditions.run后需要重启。 VirtualBox安装MacOS方法1234567891011121. 创建MacOS虚拟机，自定义虚拟机名称为MacOS2. 在命令行执行VBoxManage modifyvm "MacOS" --cpuidset 00000001 000106e5 00100800 0098e3fd bfebfbffVBoxManage setextradata "MacOS" "VBoxInternal/Devices/efi/0/Config/DmiSystemProduct" "iMac11,3"VBoxManage setextradata "MacOS" "VBoxInternal/Devices/efi/0/Config/DmiSystemVersion" "1.0"VBoxManage setextradata "MacOS" "VBoxInternal/Devices/efi/0/Config/DmiBoardProduct" "Iloveapple"VBoxManage setextradata "MacOS" "VBoxInternal/Devices/smc/0/Config/DeviceKey" "ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc"VBoxManage setextradata "MacOS" "VBoxInternal/Devices/smc/0/Config/GetKeyFromRealSMC" 1# MacOS为虚拟机名。# VirtualBox原生支持Mac OS X的安装，但是只有在系统环境为Mac的环境下，才能正常引导，因为在非Mac环境下，安装程序会检测出我们的CPU不是已经识别的型号，从而拒绝进一步的安装。为此，我们需要执行以下命令来Hack# 如果VBoxManage没有被加入PATH的话，可能会提示VBoxManage不是可执行的命令。只需要进入VirtualBox的安装目录下Shift+右键在当前目录打开命令行执行即可~# 原理非常简单：利用VBox的命令行工具在虚拟机的DeviceKey中加入Apple的声明即可。 VirtualBox共享文件夹12345因为使用apt安装的VirtualBox在安装增强功能时会有网络问题，无法下载安装，所以采用下载安装包的方法安装，另外，安装6.0版本时会有包依赖问题，所以使用了5.2.20版本下载地址：http://download.virtualbox.org/virtualbox/5.2.20/下载 Oracle_VM_VirtualBox_Extension_Pack-5.2.20-125813.vbox-extpack包，此为增强功能的包，virtualbox-5.2_5.2.20-125813~Ubuntu~bionic_amd64.deb为程序安装包安装好程序包后，打开页面左上解的管理，之后选择全局设定，在其中的扩展中选择添加刚才下载的增强功能包，之后就可以自动安装了。下面需要在已安装操作系统的页面上点击上方设备中的安装增强功能，之后就可以看到虚拟机操作系统中的光驱中挂载了光盘，打开安装后就可以使用VirtualBox的共享文件夹功能了。进入虚拟机后可以在网络中看到共享的文件夹。 VirtualBox虚拟机挂载宿主机U盘1234567891011121. 下载扩展插件，地址：http://download.virtualbox.org/virtualbox/5.2.32/。因为ubuntu18.04默认安装的是5.2.32版本所以下载这个插件Oracle_VM_VirtualBox_Extension_Pack-5.2.20-125813.vbox-extpack。# 6.0使用的插件：Oracle_VM_VirtualBox_Extension_Pack-6.0.0_RC1.vbox-extpack2. 到VirtualBox的全局设置中的扩展中加载这个插件3. 创建usbfs组sudo groupadd usbfs4. 将当前用户加入vboxusers和usbfs组。shouyu@shouyu-pc  ~  sudo vim /etc/groupvboxusers:x:127:shouyu usbfs:x:1001:shouyu 5. 打开虚拟机的设置，在系统中的芯片组选择ICH9，在USB设备中选择USB3.0控制器。启动虚拟机，如果是windows虚拟机，可以使用360驱动大师安装USB的驱动。这一步是必须做的。6. 关闭虚拟机与重启宿主机。7. 再次打开VirtualBox，启动虚拟机，插入U盘。会发现右下角的USB设置已经可以正常识别，勾选U盘的设备。 NAT模式下宿主机与虚拟机通讯1234# 默认情况下，桥接方式支持虚拟机到主机、主机到虚拟机、虚拟机到其他主机、其他主机到虚拟机以及虚拟机之间的通讯。NAT方式只支持虚拟机到主机、虚拟机到其他主机的通讯。如果需要用宿主机与虚拟# 机通讯，就要配置Prot Forwarding。方法是在全局模式下找到Network，在其中创建一个虚拟网卡，之后在网卡中配置地址，如192.168.1.0/24，再点击Prot Forwarding，其中Host IP指宿主# 机的IP，Guest IP指虚拟机的IP，另外，端口要配置成宿主机与虚拟机都没有使用的端口# 这相当于VirtualBox只做了SNAT，但没有做DNAT]]></content>
      <categories>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>kali使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[storm概念]]></title>
    <url>%2F2019%2F03%2F11%2Fstorm%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概念 Storm 是一个分布式的，可靠的，容错的数据流处理系统。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。Storm 集群的输入流由一个被称作 spout 的组件管理，spout 把数据传递给 bolt， bolt 要么把数据保存到某种存储器，要么把数据传递给其它的 bolt。你可以想象一下，一个 Storm 集群就是在一连串的 bolt 之间转换 spout 传过来的数据。 这里用一个简单的例子来说明这个概念。昨晚我在新闻节目里看到主持人在谈论政治人物和他们对于各种政治话题的立场。他们一直重复着不同的名字，而我开始考虑这些名字是否被提到了相同的次数，以及不同次数之间的偏差。 想像播音员读的字幕作为你的数据输入流。你可以用一个 spout 读取一个文件（或者 socket，通过 HTTP，或者别的方法）。文本行被 spout 传给一个 bolt，再被 bolt 按单词切割。单词流又被传给另一个 bolt，在这里每个单词与一张政治人名列表比较。每遇到一个匹配的名字，第二个 bolt 为这个名字在数据库的计数加1。你可以随时查询数据库查看结果， 而且这些计数是随着数据到达实时更新的。 现在想象一下，很容易在整个 Storm 集群定义每个 bolt 和 spout 的并行性级别，因此你可以无限的扩展你的拓扑结构。很神奇，是吗？尽管这是个简单例子，你也可以看到 Storm 的强大。 应用案例 数据处理流 正如上例所展示的，不像其它的流处理系统，Storm 不需要中间队列。 连续计算 连续发送数据到客户端，使它们能够实时更新并显示结果，如网站指标。 分布式远程过程调用 频繁的 CPU 密集型操作并行化。 Storm 组件 Storm 集群由一个主节点(也可称为控制节点)和多个工作节点组成。主节点运行一个名为“Nimbus”的守护进程，工作节点都运行一个名为“Supervisor”的守护进程，两者的协调工作由 ZooKeeper 来完成， ZooKeeper 用于管理集群中的不同组件。 每一个工作节点上运行的 Supervisor 监听分配给它那台机器的工作，根据需要启动 / 关闭工作进程，每一个工作进程执行一个 Topology 的一个子集；一个运行的 Topology 由运行在很多机器上的很多工作进程 Worker 组成。那么Storm 的核心就是主节点（Nimbus）、工作节点（Supervisor）、协调器（ZooKeeper）、工作进程（ Worker）、任务线程（Task）。 在系统底层，Storm 使用了 zeromq(0mq, zeromq(http://www.zeromq.org))。这是一种先进的，可嵌入的网络通讯库，它提供的绝妙功能使 Storm 成为可能。下面列出一些 zeromq 的特性。 一个并发架构的 Socket 库 对于集群产品和超级计算，比 TCP 要快 可通过 inproc（进程内）, IPC（进程间）, TCP 和 multicast(多播协议)通信 异步 I / O 的可扩展的多核消息传递应用程序 利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现 N-N 连接 Storm 只用了 push/pull sockets Nimbus 主节点通常运行一个后台程序——Nimbus，用于响应分布在集群中的节点，分配任务和监测故障，这类似于 Hadoop 中的 JobTracker。Nimbus 进程是快速失败（ fail-fast）和无状态的，所有的状态要么在 ZooKeeper 中，要么在本地磁盘上。可以使用 kill -9 来杀死 Nimbus 进程，然后重启即可继续工作。 Supervisor 工作节点同样会运行一个后台程序——Supervisor，用于收听工作指派并基于要求运行工作进程。每个工作节点都是Topology中一个子集的实现。而Nimbus 和 Supervisor 之间的协调则通过 ZooKeeper 系统。同 样，Supervisor进程也是快速失败（fail-fast）和无状态的， 所有的状态要么在ZooKeeper中，要么在本地磁盘上，用kill -9来杀死Supervisor进程，然后重启就可以继续工作。这个设计使得storm不可思议的稳定。 ZooKeeper ZooKeeper 是完成 Nimbus 和 Supervisor 之间协调的服务。 Storm使用ZooKeeper 协调集群，由于ZooKeeper 并不用于消息传递，所以Storm给ZooKeeper 带来的压力相当低。在大多数情况下，单个节点的 ZooKeeper 集群足够胜任，不过为了确保故障恢复或者部署大规模Storm集群，可能需要更大规模的 ZooKeeper 集群。 worker 运行具体处理组件逻辑的进程。 Topology 拓扑。一个Storm拓扑打包了一个实时处理程序的逻辑。一个Storm拓扑类似一个Hadoop的MapReduce任务(Job)。主要区别是MapReduce任务最终会结束，而拓扑会一直运行（当然直到你杀死它)。一个拓扑是一个通过流分组(stream grouping)把Spout和Bolt连接到一起的拓扑结构。一个拓扑就是一个复杂的多阶段的流计算。 所有Topology任务的提交必须在Storm客户端节点上进行(需要配置~/.storm/storm.yaml文件)，由Nimbus节点分配给其他Supervisor节点进行处理。Nimbus节点首先将提交的Topology进行分片，分成一个个的Task，并将Task和Supervisor相关的信息提交到zookeeper集群上，Supervisor会去zookeeper集群上认领自己的Task，通知自己的Worker进程进行Task的处理。总体的Topology处理流程图为： 每个Topology都由Spout和Bolt组成，在Spout和Bolt传递信息的基本单位叫做Tuple，由Spout发出的连续不断的Tuple及其在相应Bolt上处理的子Tuple连起来称为一个Steam，每个Stream的命名是在其首个Tuple被Spout发出的时候，此时Storm会利用内部的Ackor机制保证每个Tuple可靠的被处理。 而Tuple可以理解成键值对，其中，键就是定义在declareStream方法中的Fields字段，而值就是在emit方法中发送的Values字段。 在运行Topology之前，可以通过一些参数的配置来调节运行时的状态，参数的配置是通过Storm框架部署目录下的conf/storm.yaml文件来完成的。在此文件中可以配置运行时的Storm本地目录路径、运行时Worker的数目等。 在代码中，也可以设置Config的一些参数，但是优先级是不同的，不同位置配置Config参数的优先级顺序为：外部组件的special configuration &gt; 内部组件的special configuration &gt; topology内部的configuration &gt; storm.yaml &gt; default.yaml Spout 一个在Topology中产生源数据流的组件。通常情况下Spout会从外部数据源中读取数据，然后转换为Topology内部的源数据。Spout 是一个主动的角色，其接口中有个nextTuple()函数， Storm框架会不停地调用此函数，用户只要在其中生成源数据即可。 Bolt 一个在Topology中接收由Spout或者其他上游Bolt类发来的Tuple数据然后执行处理的组件。Bolt可以执行过滤、函数操作、合并、写数据库等任何操作。Bolt是一个被动的角色，其接口中有个execute(Tuple input)函数，在接收到消息后会调用此函数，用户可以在其中执行自己想要的操作。 Task Worker中每一个Spout/Bolt的线程称为一个Task。在 Storm 0.8之后，task不再与物理线程对应，同一个Spout/Bolt的Task可能会共享一个物理线程，该线程称为Executor。 Tuple 元组，一次消息传递的基本单元。 Stream 源源不断传递的Tuple就组成了stream。 Stream Grouping 即消息的partition方法。流分组策略告诉Topology如何在两个组件之间发送Tuple。 Storm 中提供若干种实用的grouping方式，包括shuffle, fields hash, all, global, none, direct和localOrShuffle等。 ShuffleGrouping:随机分组，随机分发Stream中的tuple，保证每个Bolt的Task接收Tuple数量大致一致； FieldsGrouping：按照字段分组，保证相同字段的Tuple分配到同一个Task中； AllGrouping：广播发送，每一个Task都会受到所有的Tuple； GlobalGrouping：全局分组，所有的Tuple都发送到同一个Task中，此时一般将当前Component的并发数目设置为1； NonGrouping：不分组，和ShuffleGrouping类似，当前Task的执行会和它的被订阅者在同一个线程中执行； DirectGrouping：直接分组，直接指定由某个Task来执行Tuple的处理，而且，此时必须有emitDirect方法来发送； localOrShuffleGrouping：和ShuffleGrouping类似，若Bolt有多个Task在同一个进程中，Tuple会随机发给这些Task。 Storm 的特性 在所有这些设计思想与决策中，有一些非常棒的特性成就了独一无二的 Storm。 简化编程：如果你曾试着从零开始实现实时处理，你应该明白这是一件多么痛苦的事情。使用 Storm，复杂性被大大降低了。 使用一门基于 JVM 的语言开发会更容易，但是你可以借助一个小的中间件，在 Storm 上使用任何语言开发。有现成的中间件可供选择，当然也可以自己开发中间件。 容错：Storm 集群会关注工作节点状态，如果宕机了必要的时候会重新分配任务。 可扩展：所有你需要为扩展集群所做的工作就是增加机器。Storm 会在新机器就绪时向它们分配任务。 可靠的：所有消息都可保证至少处理一次。如果出错了，消息可能处理不只一次，不过你永远不会丢失消息。 快速：速度是驱动 Storm 设计的一个关键因素 事务性：You can get exactly once messaging semantics for pretty much any computation. 你可以为几乎任何计算得到恰好一次消息语义。 Topology运行流程 Topology的运行可以分为本地模式和分布式模式，模式的设置可以在配置文件中设定，也可以在代码中设置。需要注意的是，在Storm代码编写完成之后，需要打包成jar包放到Nimbus中运行，打包的时候，不需要把依赖的jar都打进去，否则如果把依赖的storm.jar包打进去的话，运行时会出现重复的配置文件错误导致Topology无法运行。因为Topology运行之前，会加载本地的storm.yaml配置文件。 Storm提交后，会把代码首先存放到Nimbus节点的inbox目录下，之后，会把当前Storm运行的配置生成一个stormconf.ser文件放到Nimbus节点的stormdist目录中，在此目录中同时还有序列化之后的Topology代码文件； 在设定Topology所关联的Spouts和Bolts时，可以同时设置当前Spout和Bolt的executor数目和task数目，默认情况下，一个Topology的task的总和是和executor的总和一致的。之后，系统根据worker的数目，尽量平均的分配这些task的执行。worker在哪个supervisor节点上运行是由storm本身决定的； 任务分配好之后，Nimbus节点会将任务的信息提交到zookeeper集群，同时在zookeeper集群中会有workerbeats节点，这里存储了当前Topology的所有worker进程的心跳信息； Supervisor节点会不断的轮询zookeeper集群，在zookeeper的assignments节点中保存了所有Topology的任务分配信息、代码存储目录、任务之间的关联关系等，Supervisor通过轮询此节点的内容，来领取自己的任务，启动worker进程运行； 一个Topology运行之后，就会不断的通过Spouts来发送Stream流，通过Bolts来不断的处理接收到的Stream流，Stream流是无界的。这一步会不间断的执行，除非手动结束Topology。 Topology并行度 worker：每个worker都属于一个特定的Topology，每个Supervisor节点的worker可以有多个，每个worker使用一个单独的端口，它对Topology中的每个component运行一个或者多个executor线程来提供task的运行服务。 executor：executor是产生于worker进程内部的线程，会执行同一个component的一个或者多个task。 task：实际的数据处理由task完成，在Topology的生命周期中，每个组件的task数目是不会发生变化的，而executor的数目却不一定。executor数目小于等于task的数目，默认情况下，二者是相等的。 ​ 在运行一个Topology时，可以根据具体的情况来设置不同数量的worker、task、executor，而设置的位置也可以在多个地方。 worker设置： 可以通过设置yaml中的topology.workers属性 在代码中通过Config的setNumWorkers方法设定 executor设置： 通过在Topology的入口类中setBolt、setSpout方法的最后一个参数指定，不指定的话，默认为1； task设置： 默认情况下，和executor数目一致； 在代码中通过TopologyBuilder的setNumTasks方法设定具体某个组件的task数目； 参考： http://www.cnblogs.com/zlslch/p/5989256.html https://blog.yaodataking.com/2017/03/07/storm-2/ http://www.cnblogs.com/xymqx/p/4366429.html]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>storm概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisord配置使用]]></title>
    <url>%2F2019%2F03%2F11%2Fsupervisor%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍 supervisord是一款linux进程管理工具 组件 supervisord：supervisor的服务端程序。启动supervisor程序自身，启动supervisor管理的子进程，响应来自clients的请求，重启闪退或异常退出的子进程，把子进程的stderr或stdout记录到日志文件中，生成和处理Event supervisorctl：supervisorctl是client端程序。supervisorctl有一个类似shell的命令行界面，我们可以利用它来查看子进程状态，启动/停止/重启子进程，获取running子进程的列表等等。supervisorctl不仅可以连接到本机上的supervisord，还可以连接到远程的supervisord，当然在本机上面是通过UNIX socket连接的，远程是通过TCP socket连接的。supervisorctl和supervisord之间的通信，是通过xml_rpc完成的。 相应的配置在[supervisorctl]块里面 Web Server：主要可以在界面上管理进程，Web Server其实是通过XML_RPC来实现的，可以向supervisor请求数据，也可以控制supervisor及子进程。配置在[inet_http_server]块里面 XML_RPC接口：这个是远程调用的，上面的supervisorctl和Web Server就是它弄的 安装12345[root@webdav ~]# yum install python-setuptools[root@webdav ~]# easy_install supervisor# 安装了python-setuptools后才能使用easy_install命令[root@webdav ~]# echo_supervisord_conf# 测试安装是否成功，这条命令可以输出配置文件 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230[root@webdav ~]# mkdir /etc/supervisor[root@webdav ~]# echo_supervisord_conf &gt; /etc/supervisor/supervisord.conf[root@webdav ~]# vim /etc/supervisor/supervisord.conf; Sample supervisor config file.;; For more information on the config file, please see:; http://supervisord.org/configuration.html;; Notes:; - Shell expansion ("~" or "$HOME") is not supported. Environment; variables can be expanded using this syntax: "%(ENV_HOME)s".; - Quotes around values are not supported, except in the case of; the environment= options as shown below.; - Comments must have a leading space: "a=b ;comment" not "a=b;comment".; - Command will be truncated if it looks like a config file comment, e.g.; "command=bash -c 'foo ; bar'" will truncate to "command=bash -c 'foo ".[unix_http_server]file=/tmp/supervisor.sock ; the path to the socket file# socket文件的路径，supervisorctl用XML_RPC和supervisord通信就是通过它进行的。如果不设置的话，supervisorctl也就不能用了不设置的话，默认为none。 非必须设置 ;chmod=0700 ; socket file mode (default 0700)# 这个简单，就是修改上面的那个socket文件的权限为0700不设置的话，默认为0700。 非必须设置;chown=nobody:nogroup ; socket file uid:gid owner# 这个一样，修改上面的那个socket文件的属组为user.group不设置的话，默认为启动supervisord进程的用户及属组。非必须设置;username=user ; default is no username (open server)# 使用supervisorctl连接的时候，认证的用户不设置的话，默认为不需要用户。 非必须设置;password=123 ; default is no password (open server)# 和上面的用户名对应的密码，可以直接使用明码，也可以使用SHA加密。如：&#123;SHA&#125;82ab876d1387bfafe46cc1c8a2ef074eae50cb1d。默认不设置。非必须设置[inet_http_server] ; inet (TCP) server disabled by default# 侦听在TCP上的socket，Web Server和远程的supervisorctl都要用到他。不设置的话，默认为不开启。非必须设置port=0.0.0.0:9001 ; ip_address:port specifier, *:port for all iface# 这个是侦听的IP和端口，侦听所有IP用 :9001或*:9001。这个必须设置，只要上面的[inet_http_server]开启了，就必须设置它username=user ; default is no username (open server)# 这个和上面的uinx_http_server一个样。非必须设置password=123 ; default is no password (open server)# 密码[supervisord]# 这个主要是定义supervisord这个服务端进程的一些参数的。这个必须设置，不设置，supervisor就不用干活了logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log# 这个是supervisord这个主进程的日志路径，注意和子进程的日志不搭嘎。默认路径$CWD/supervisord.log，$CWD是当前目录。。非必须设置logfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MB# 这个是上面那个日志文件的最大的大小，当超过50M的时候，会生成一个新的日志文件。当设置为0时，表示不限制文件大小。 默认值是50M，非必须设置。 logfile_backups=10 ; # of main logfile backups; 0 means none, default 10# 日志文件保持的数量，上面的日志文件大于50M时，就会生成一个新文件。文件数量大于10时，最初的老文件被新文件覆盖，文件数量将保持为10。当设置为0时，表示不限制文件的数量。默认情况下为10。。。非必须设置loglevel=info ; log level; default info; others: debug,warn,trace# 日志级别，有critical, error, warn, info, debug, trace, or blather等。默认为info。。。非必须设置项pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid# upervisord的pid文件路径。默认为$CWD/supervisord.pid。非必须设置nodaemon=false ; start in foreground if true; default false# 如果是true，supervisord进程将在前台运行。默认为false，也就是后台以守护进程运行。。。非必须设置minfds=1024 ; min. avail startup file descriptors; default 1024# 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动。系统的文件描述符在这里设置cat /proc/sys/fs/file-max。默认情况下为1024。。。非必须设置minprocs=200 ; min. avail process descriptors;default 200# 最小可用的进程描述符，低于这个值supervisor也将不会正常启动。ulimit -u这个命令，可以查看linux下面用户的最大进程数。默认为200。。。非必须设置;umask=022 ; process file creation umask; default 022# 进程创建文件的掩码。默认为022。非必须设置项;user=chrism ; default is current user, required if root# 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。我这里面设置的这个用户，也可以对supervisord进行管理。默认情况是不设置。。。非必须设置项;identifier=supervisor ; supervisord identifier, default is 'supervisor'# 这个参数是supervisord的标识符，主要是给XML_RPC用的。当你有多个supervisor的时候，而且想调用XML_RPC统一管理，就需要为每个supervisor设置不同的标识符了。默认是supervisord。。。非必需设置;directory=/tmp ; default is not to cd during start# 这个参数是当supervisord作为守护进程运行的时候，设置这个参数的话，启动supervisord进程之前，会先切换到这个目录。默认不设置。。。非必须设置;nocleanup=true ; don't clean up tempfiles at start; default false# 这个参数当为false的时候，会在supervisord进程启动的时候，把以前子进程产生的日志文件(路径为AUTO的情况下)清除掉。有时候咱们想要看历史日志，当 然不想日志被清除了。所以可以设置为true。默认是false，有调试需求的同学可以设置为true。。。非必须设置;childlogdir=/tmp ; 'AUTO' child log dir, default $TEMP# 当子进程日志路径为AUTO的时候，子进程日志文件的存放路径。默认路径是这个东西，执行下面的这个命令看看就OK了，处理的东西就默认路径python -c "import tempfile;print tempfile.gettempdir()"。非必须设置;environment=KEY="value" ; key value pairs to add to environment# 这个是用来设置环境变量的，supervisord在linux中启动默认继承了linux的环境变量，在这里可以设置supervisord进程特有的其他环境变量。supervisord启动子进程时，子进程会拷贝父进程的内存空间内容。 所以设置的这些环境变量也会被子进程继承。小例子：environment=name="haha",age="hehe"。默认为不设置。非必须设置;strip_ansi=false ; strip ansi escape codes in logs; def. false# 这个选项如果设置为true，会清除子进程日志中的所有ANSI 序列。什么是ANSI序列呢？就是我们的\n,\t这些东西。默认为false。非必须设置; The rpcinterface:supervisor section must remain in the config file for; RPC (supervisorctl/web interface) to work. Additional interfaces may be; added by defining them in separate [rpcinterface:x] sections.[rpcinterface:supervisor]# 这个选项是给XML_RPC用的，当然你如果想使用supervisord或者web server 这 个选项必须要开启的supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface; The supervisorctl section configures how supervisorctl will connect to; supervisord. configure it match the settings in either the unix_http_server; or inet_http_server section.[supervisorctl]# 这个主要是针对supervisorctl的一些配置serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket# 这个是supervisorctl本地连接supervisord的时候，本地UNIX socket路径，注意这个是和前面的[unix_http_server]对应的。默认值就是unix:///tmp/supervisor.sock。。非必须设置;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket# 这个是supervisorctl远程连接supervisord的时候，用到的TCP socket路径，注意这个和前面的[inet_http_server]对应。默认就是http://127.0.0.1:9001。。。非必须项;username=chris ; should be same as in [*_http_server] if set# 用户名。默认空。非必须设置;password=123 ; should be same as in [*_http_server] if set# 密码。默认空。非必须设置;prompt=mysupervisor ; cmd line prompt (default "supervisor")# 输入用户名密码时候的提示符。默认supervisor。非必须设置;history_file=~/.sc_history ; use readline history if available# 这个参数和shell中的history类似，我们可以用上下键来查找前面执行过的命令。默认是no file的。。所以我们想要有这种功能，必须指定一个文件。非必须设置; The sample program section below shows all possible program subsection values.; Create one or more 'real' program: sections to be able to control them under; supervisor.;[program:theprogramname]# 这个就是咱们要管理的子进程了，":"后面的是名字，最好别乱写和实际进程有点关联最好。这样的program我们可以设置一个或多个，一个program就是要被管理的一个进程;command=/bin/cat ; the program (relative uses PATH, can take args)# 这个就是我们的要启动进程的命令路径了，可以带参数。例子：/home/test.py -a 'hehe'，有一点需要注意的是，我们的command只能是那种在终端运行的进程，不能是守护进程。这个想想也知道了，比如说command=service httpd start。httpd这个进程被linux的service管理了，我们的supervisor再去启动这个命令。这已经不是严格意义的子进程了。这个是个必须设置的项;process_name=%(program_name)s ; process_name expr (default %(program_name)s)# 这个是进程名，如果我们下面的numprocs参数为1的话，就不用管这个参数了，它默认值%(program_name)s也就是上面的那个program冒号后面的名字，但是如果numprocs为多个的话，那就不能这么干了。想想也知道，不可能每个进程都用同一个进程名吧。;numprocs=1 ; number of processes copies to start (def 1)# 启动进程的数目。当不为1时，就是进程池的概念，注意process_name的设置。默认为1 。非必须设置;directory=/tmp ; directory to cwd to before exec (def no cwd)# 进程运行前，会前切换到这个目录。默认不设置。非必须设置;umask=022 ; umask for process (default None)# 进程掩码，默认none，非必须;priority=999 ; the relative start priority (default 999)# 子进程启动关闭优先级，优先级低的，最先启动，关闭的时候最后关闭。默认值为999 。。非必须设置;autostart=true ; start at supervisord start (default: true)# 如果是true的话，子进程将在supervisord启动后被自动启动。默认就是true 。。非必须设置;startsecs=1 ; # of secs prog must stay up to be running (def. 1)# 这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1 。非必须设置;startretries=3 ; max # of serial start failures when starting (default 3)# 当进程启动失败后，最大尝试启动的次数。。当超过3次后，supervisor将把此进程的状态置为FAIL。默认值为3 。非必须设置;autorestart=unexpected ; when to restart if exited after running (def: unexpected)# 这个是设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在下面的exitcodes里面定义的退出码的时候，才会被自动重启。当为true的时候，只要子进程挂掉，将会被无条件的重启;exitcodes=0,2 ; 'expected' exit codes used with autorestart (default 0,2)# 注意和上面的的autorestart=unexpected对应。exitcodes里面的定义的。退出码是expected的。;stopsignal=QUIT ; signal used to kill process (default TERM)# 进程停止信号，可以为TERM, HUP, INT, QUIT, KILL, USR1, or USR2等信号。默认为TERM 。。当用设定的信号去干掉进程，退出码会被认为是expected。非必须设置;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)# 这个是当我们向子进程发送stopsignal信号后，到系统返回信息，给supervisord，所等待的最大时间。 超过这个时间，supervisord会向该子进程发送一个强制kill的信号。默认为10秒。非必须设置;stopasgroup=false ; send stop signal to the UNIX process group (default false)# 这个东西主要用于，supervisord管理的子进程，这个子进程本身还有子进程。那么我们如果仅仅干掉supervisord的子进程的话，子进程的子进程有可能会变成孤儿进程。所以咱们可以设置可个选项，把整个该子进程的整个进程组都干掉。 设置为true的话，一般killasgroup也会被设置为true。需要注意的是，该选项发送的是stop信号。默认为false。非必须设置。;killasgroup=false ; SIGKILL the UNIX process group (def false)# 这个和上面的stopasgroup类似，不过发送的是kill信号;user=chrism ; setuid to this UNIX account to run the program# 如果supervisord是root启动，我们在这里设置这个非root用户，可以用来管理该program。默认不设置。非必须设置项;redirect_stderr=true ; redirect proc stderr to stdout (default false)# 如果为true，则stderr的日志会被写入stdout日志文件中。默认为false，非必须设置;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO# 子进程的stdout的日志路径，可以指定路径，AUTO，none等三个选项。设置为none的话，将没有日志产生。设置为AUTO的话，将随机找一个地方生成日志文件，而且当supervisord重新启动的时候，以前的日志文件会被清空。当 redirect_stderr=true的时候，sterr也会写进这个日志文件;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB)# 日志文件最大大小，和[supervisord]中定义的一样。默认为50;stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10)# 和[supervisord]定义的一样。默认10;stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0)# 这个东西是设定capture管道的大小，当值不为0的时候，子进程可以从stdout发送信息，而supervisor可以根据信息，发送相应的event。默认为0，为0的时候表达关闭管道。非必须项;stdout_events_enabled=false ; emit events on stdout writes (default false)# 当设置为ture的时候，当子进程由stdout向文件描述符中写日志的时候，将触发supervisord发送PROCESS_LOG_STDOUT类型的event。默认为false。。。非必须设置;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO# 这个东西是设置stderr写的日志路径，当redirect_stderr=true。这个就不用设置了，设置了也是白搭。因为它会被写入stdout_logfile的同一个文件中。默认为AUTO，也就是随便找个地存，supervisord重启被清空。。非必须设置;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A="1",B="2" ; process environment additions (def no adds)# 这个是该子进程的环境变量，和别的子进程是不共享的;serverurl=AUTO ; override serverurl computation (childutils); The sample eventlistener section below shows all possible eventlistener; subsection values. Create one or more 'real' eventlistener: sections to be; able to handle event notifications sent by supervisord.;[eventlistener:theeventlistenername]# 这个东西其实和program的地位是一样的，也是suopervisor启动的子进程，不过它干的活是订阅supervisord发送的event。他的名字就叫listener了。;command=/bin/eventlistener ; the program (relative uses PATH, can take args)# 这个和上面的program一样，表示listener的可执行文件的路径;process_name=%(program_name)s ; process_name expr (default %(program_name)s)# 这个也一样，进程名，当下面的numprocs为多个的时候，才需要。否则默认就OK了;numprocs=1 ; number of processes copies to start (def 1)# 相同的listener启动的个数;events=EVENT ; event notif. types to subscribe to (req'd)# event事件的类型，也就是说，只有写在这个地方的事件类型。才会被发送;buffer_size=10 ; event buffer queue size (default 10)# 这个是event队列缓存大小，单位不太清楚，楼主猜测应该是个吧。当buffer超过10的时候，最旧的event将会被清除，并把新的event放进去。默认值为10。非必须选项;directory=/tmp ; directory to cwd to before exec (def no cwd)# 进程执行前，会切换到这个目录下执行。默认为不切换。非必须;umask=022 ; umask for process (default None)# 掩码;priority=-1 ; the relative start priority (default -1)# 启动优先级，默认-1;autostart=true ; start at supervisord start (default: true)# 是否随supervisord启动一起启动，默认true;startsecs=1 ; # of secs prog must stay up to be running (def. 1)# 也是一样，进程启动后跑了几秒钟，才被认定为成功启动，默认1;startretries=3 ; max # of serial start failures when starting (default 3)# 失败最大尝试次数，默认3;autorestart=unexpected ; autorestart if exited after running (def: unexpected)# 是否自动重启，和program一个样，分true,false,unexpected等，注意unexpected和exitcodes的关系;exitcodes=0,2 ; 'expected' exit codes used with autorestart (default 0,2)# 期望或者说预料中的进程退出码;stopsignal=QUIT ; signal used to kill process (default TERM)# 干掉进程的信号，默认为TERM，比如设置为QUIT，那么如果QUIT来干这个进程。那么会被认为是正常维护，退出码也被认为是expected中的;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program# 设置普通用户，可以用来管理该listener进程。默认为空。非必须设置;redirect_stderr=false ; redirect_stderr=true is not allowed for eventlisteners# 为true的话，stderr的log会并入stdout的log里面。默认为false。。。非必须设置;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A="1",B="2" ; process environment additions# 这个是该子进程的环境变量;serverurl=AUTO ; override serverurl computation (childutils); The sample group section below shows all possible group values. Create one; or more 'real' group: sections to create "heterogeneous" process groups.;[group:thegroupname]# 这个东西就是给programs分组，划分到组里面的program。我们可以对组名进行统一的操作。 注意：program被划分到组里面之后，就相当于原来的配置从supervisor的配置文件里消失了。supervisor只会对组进行管理，而不再会对组里面的单个program进行管理了;programs=progname1,progname2 ; each refers to 'x' in [program:x] definitions# 组成员，用逗号分开这个是个必须的设置项;priority=999 ; the relative start priority (default 999)# 优先级，相对于组和组之间说的。默认999。。非必须选项; The [include] section can just contain the "files" setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.;[include]# 当我们要管理的进程很多的时候，写在一个文件里面就有点大了。我们可以把配置信息写到多个文件中，然后include过来;files = relative/directory/*.ini 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227; Sample supervisor config file.;; For more information on the config file, please see:; http://supervisord.org/configuration.html;; Notes:; - Shell expansion ("~" or "$HOME") is not supported. Environment; variables can be expanded using this syntax: "%(ENV_HOME)s".; - Comments must have a leading space: "a=b ;comment" not "a=b;comment".[unix_http_server]file=/tmp/supervisor.sock ; (the path to the socket file);chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; (default is no username (open server));password=123 ; (default is no password (open server))[inet_http_server] ; inet (TCP) server disabled by defaultport=0.0.0.0:9001 ; (ip_address:port specifier, *:port for all iface)username=user ; (default is no username (open server))password=123 ; (default is no password (open server))[supervisord]logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200);umask=022 ; (process file creation umask;default 022);user=chrism ; (default is current user, required if root);identifier=supervisor ; (supervisord identifier, default is 'supervisor');directory=/tmp ; (default is not to cd during start);nocleanup=true ; (don't clean up tempfiles at start;default false);childlogdir=/tmp ; ('AUTO' child log dir, default $TEMP);environment=KEY="value" ; (key value pairs to add to environment);strip_ansi=false ; (strip ansi escape codes in logs; def. false); the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set;prompt=mysupervisor ; cmd line prompt (default "supervisor");history_file=~/.sc_history ; use readline history if available; The below sample program section shows all possible program subsection values,; create one or more 'real' program: sections to be able to control them under; supervisor.;[program:theprogramname];command=/bin/cat ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=999 ; the relative start priority (default 999);autostart=true ; start at supervisord start (default: true);autorestart=unexpected ; whether/when to restart (default: unexpected);startsecs=1 ; number of secs prog must stay running (def. 1);startretries=3 ; max # of serial start failures (default 3);exitcodes=0,2 ; 'expected' exit codes for process (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (default 10);stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (default 10);stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A="1",B="2" ; process environment additions (def no adds);serverurl=AUTO ; override serverurl computation (childutils); The below sample eventlistener section shows all possible; eventlistener subsection values, create one or more 'real'; eventlistener: sections to be able to handle event notifications; sent by supervisor.;[eventlistener:theeventlistenername];command=/bin/eventlistener ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);events=EVENT ; event notif. types to subscribe to (req'd);buffer_size=10 ; event buffer queue size (default 10);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=-1 ; the relative start priority (default -1);autostart=true ; start at supervisord start (default: true);autorestart=unexpected ; whether/when to restart (default: unexpected);startsecs=1 ; number of secs prog must stay running (def. 1);startretries=3 ; max # of serial start failures (default 3);exitcodes=0,2 ; 'expected' exit codes for process (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (default 10);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups ; # of stderr logfile backups (default 10);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A="1",B="2" ; process environment additions;serverurl=AUTO ; override serverurl computation (childutils); The below sample group section shows all possible group values,; create one or more 'real' group: sections to create "heterogeneous"; process groups.;[group:thegroupname];programs=progname1,progname2 ; each refers to 'x' in [program:x] definitions;priority=999 ; the relative start priority (default 999); The [include] section can just contain the "files" setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.;[include];files = relative/directory/*.ini## 下面是管理的zookeeper和storm的模块[program:zookeeper]command=/xor/data0/zookeeper/bin/zkServer.sh start-foregroundautostart=trueautorestart=truestartsecs=1startretries=999user=hadoopredirect_stderr=falsestdout_logfile=/xor/data2/log/storm/zookeeper-outstdout_logfile_maxbytes=10MBstdout_logfile_backups=10stdout_events_enabled=truestderr_logfile=/xor/data2/log/storm/zookeeper-errstderr_logfile_maxbytes=100MBstderr_logfile_backups=10stderr_events_enabled=true[program:storm_nimbus]command=/xor/data0/storm/bin/storm nimbusautostart=trueautorestart=truestartsecs=1startretries=999user=stormredirect_stderr=falsestdout_logfile=/xor/data2/log/storm/storm-nimbus-outstdout_logfile_maxbytes=10MBstdout_logfile_backups=10stdout_events_enabled=truestderr_logfile=/xor/data2/log/storm/storm-nimbus-errstderr_logfile_maxbytes=100MBstderr_logfile_backups=10stderr_events_enabled=true[program:storm_supervisor]command=/xor/data0/storm/bin/storm supervisorautostart=trueautorestart=truestartsecs=1startretries=999user=stormredirect_stderr=falsestdout_logfile=/xor/data2/log/storm/storm-supervisor-outstdout_logfile_maxbytes=10MBstdout_logfile_backups=10stdout_events_enabled=truestderr_logfile=/xor/data2/log/storm/storm-supervisor-errstderr_logfile_maxbytes=100MBstderr_logfile_backups=10stderr_events_enabled=true[program:storm_drpc]command=/xor/data0/storm/bin/storm drpcautostart=trueautorestart=truestartsecs=1startretries=999user=stormredirect_stderr=falsestdout_logfile=/xor/data2/log/storm/storm-drpc-outstdout_logfile_maxbytes=10MBstdout_logfile_backups=10stdout_events_enabled=truestderr_logfile=/xor/data2/log/storm/storm-drpc-errstderr_logfile_maxbytes=100MBstderr_logfile_backups=10stderr_events_enabled=true[program:storm_ui]command=/xor/data0/storm/bin/storm uiautostart=trueautorestart=truestartsecs=1startretries=999user=stormredirect_stderr=falsestdout_logfile=/xor/data2/log/storm/storm-ui-outstdout_logfile_maxbytes=10MBstdout_logfile_backups=10stdout_events_enabled=truestderr_logfile=/xor/data2/log/storm/storm-ui-errstderr_logfile_maxbytes=100MBstderr_logfile_backups=10stderr_events_enabled=true 命令12345678supervisorctl status# 查看所有子进程的状态supervisorctl stop storm1supervisorctl start storm1# 关闭与开启指定子进程supervisorctl stop allsupervisorctl start all# # 关闭与开启全部子进程]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB监控]]></title>
    <url>%2F2019%2F03%2F11%2FMongoDB%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[介绍 在你已经安装部署并允许MongoDB服务后，你必须要了解MongoDB的运行情况，并查看MongoDB的性能。这样在大流量得情况下可以很好的应对并保证MongoDB正常运作。 MongoDB中提供了mongostat 和 mongotop 两个命令来监控MongoDB的运行情况。 mongostat命令123456[root@master ~]# mongostat -u system -p centos --authenticationDatabase admin -h 192.168.251.134:27017insert query update delete getmore command % dirty % used flushes vsize res qr|qw ar|aw netIn netOut conn set repl time *0 *0 *0 *0 0 1|0 0.0 0.0 0 801.0M 52.0M 0|0 0|0 79b 19k 3 hqmongodb PRI 2019-03-11T16:06:14+08:00 *0 *0 *0 *0 0 1|0 0.0 0.0 0 801.0M 52.0M 0|0 0|0 79b 19k 3 hqmongodb PRI 2019-03-11T16:06:15+08:00......# mongostat是mongodb自带的状态检测工具，在命令行下使用。它会间隔固定时间获取mongodb的当前运行状态，并输出。如果你发现数据库突然变慢或者有其他问题的话，你第一手的操作就考虑采用mongostat来查看mongo的状态。 mongotop命令1234567891011121314151617181920[root@master ~]# mongotop -u system -p centos --authenticationDatabase admin -h 192.168.251.134:270172019-03-11T16:08:02.818+0800 connected to: 192.168.251.134:27017 ns total read write 2019-03-11T16:08:03+08:00 local.oplog.rs 1ms 1ms 0ms admin.system.roles 0ms 0ms 0ms admin.system.users 0ms 0ms 0ms admin.system.version 0ms 0ms 0ms local.me 0ms 0ms 0ms local.replset.election 0ms 0ms 0ms local.replset.minvalid 0ms 0ms 0ms local.startup_log 0ms 0ms 0ms local.system.replset 0ms 0ms 0ms runoob.article 0ms 0ms 0ms# mongotop也是mongodb下的一个内置工具，mongotop提供了一个方法，用来跟踪一个MongoDB的实例，查看那些花费在读取和写入数据的大量时间的操作。 mongotop提供每个集合的水平的统计数据。默认情况下，mongotop返回值的每一秒。# ns：包含数据库命名空间，后者结合了数据库名称和集合。# db：包含数据库的名称。名为 . 的数据库针对全局锁定，而非特定数据库。# total：mongod花费的时间工作在这个命名空间提供总额。# read：mongod在此命名空间花费在执行读操作的时间。# write：提供这个命名空间进行写操作的时间。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB备份与恢复]]></title>
    <url>%2F2019%2F03%2F11%2FMongoDB%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[数据备份12345678910111213141516171819202122232425262728293031语法：mongodump -h dbhost -d dbname -o dbdirectory# -h：MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017# -d：需要备份的数据库实例，例如：test# -o：备份的数据存放位置，例如：c:\data\dump，当然该目录需要提前建立，在备份完成后，系统自动在dump目录下建立一个test目录，这个目录里面存放该数据库实例的备份数据。# -u: 指定用户名# -p: 指定密码[root@master ~]# mkdir /tmp/mongodb[root@master ~]# mongodump -h 192.168.251.134:27017 -o /tmp/mongodb/ -u system -p centos2019-03-11T15:40:42.802+0800 writing admin.system.users to 2019-03-11T15:40:42.803+0800 done dumping admin.system.users (2 documents)2019-03-11T15:40:42.803+0800 writing admin.system.version to 2019-03-11T15:40:42.804+0800 done dumping admin.system.version (1 document)2019-03-11T15:40:42.804+0800 writing runoob.collection to 2019-03-11T15:40:42.805+0800 writing runoob.col to 2019-03-11T15:40:42.805+0800 writing runoob.test to 2019-03-11T15:40:42.805+0800 writing runoob.runoob to 2019-03-11T15:40:42.806+0800 done dumping runoob.collection (3 documents)2019-03-11T15:40:42.806+0800 writing runoob.mycol to 2019-03-11T15:40:42.807+0800 done dumping runoob.col (3 documents)2019-03-11T15:40:42.807+0800 writing runoob.values to 2019-03-11T15:40:42.807+0800 done dumping runoob.mycol (0 documents)2019-03-11T15:40:42.808+0800 writing test.col to 2019-03-11T15:40:42.808+0800 done dumping runoob.values (0 documents)2019-03-11T15:40:42.808+0800 done dumping test.col (0 documents)2019-03-11T15:40:42.841+0800 done dumping runoob.test (1 document)2019-03-11T15:40:42.842+0800 done dumping runoob.runoob (0 documents)# 备份所有库到/tmp/mongodb下[root@master ~]# ls /tmp/mongodb/admin runoob test 数据恢复123456789101112131415161718192021222324[root@master ~]# mongorestore -h 192.168.251.134:27017 -d admin /tmp/mongodb/admin/ -u system -p centos2019-03-11T15:48:44.761+0800 building a list of collections to restore from /tmp/mongodb/admin dir2019-03-11T15:48:44.764+0800 restoring users from /tmp/mongodb/admin/system.users.bson2019-03-11T15:48:44.825+0800 done[root@master ~]# mongorestore -h 192.168.251.134:27017 -d test /tmp/mongodb/test/ -u system -p centos --authenticationDatabase admin，不然会报验证失败的错误。2019-03-11T15:52:39.194+0800 building a list of collections to restore from /tmp/mongodb/test dir2019-03-11T15:52:39.195+0800 reading metadata for test.col from /tmp/mongodb/test/col.metadata.json2019-03-11T15:52:39.196+0800 restoring test.col from /tmp/mongodb/test/col.bson2019-03-11T15:52:39.198+0800 restoring indexes for collection test.col from metadata2019-03-11T15:52:39.200+0800 finished restoring test.col (0 documents)2019-03-11T15:52:39.200+0800 done# 命令中必须加入--authenticationDatabase admin，不然会报验证失败的错误。[root@master ~]# mongorestore -h 192.168.251.134:27017 /tmp/mongodb/ -u system -p centos --authenticationDatabase admin# 恢复所有数据库============================================================================================mongodump与mongoexport的区别：a. mongodump导出的是bson格式，是二进制形式，不过可以使用mongo自带的bsondump命令查看里面的数据，而mongoexport导出的则是文本，可以是csv、json格式。b. JSON可读性强但体积较大，BSON则是二进制文件，体积小但对人类几乎没有可读性。c. 在一些mongodb版本之间，BSON格式可能会随版本不同而有所不同，所以不同版本之间用mongodump/mongorestore可能不会成功，具体要看版本之间的兼容性。当无法使用BSON进行跨版本的数据迁移的时候，使用JSON格式即mongoexport/mongoimport是一个可选项。跨版本的mongodump/mongorestore个人并不推荐，实在要做请先检查文档看两个版本是否兼容（大部分时候是的）。d. JSON虽然具有较好的跨版本通用性，但其只保留了数据部分，不保留索引，账户等其他基础信息。使用时应该注意。============================================================================================ 恢复节点12345678910111. 将复制集中要恢复的节点移除rs.remove("10.10.17.26:27000")2. 运行mongorestore --oplogReplay命令mongorestore --host 10.10.17.26 --port 27000 --oplogReplay /data/mongodbbackup/20150820/3. 创建oploguse local db.createCollection("oplog.rs", &#123;"capped" : true, "size" : 10000000&#125;)4. 恢复oplogmongorestore --host 10.10.17.26 --port 27000 -d local -c oplog.rs /data/mongodbbackup/20150820/oplog.bson5. 将该节点加入到复制集 rs.add("10.10.17.26:27000")]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB备份与恢复</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB方法]]></title>
    <url>%2F2019%2F03%2F11%2FMongoDB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Limit方法1234567891011121314语法：db.COLLECTION_NAME.find().limit(NUMBER)# 如果你需要在MongoDB中读取指定数量的数据记录，可以使用MongoDB的Limit方法，limit()方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数。hqmongodb:PRIMARY&gt; use runoobswitched to db runoobhqmongodb:PRIMARY&gt; db.col.find(&#123;"title":&#123;$type:2&#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;hqmongodb:PRIMARY&gt; db.col.find(&#123;&#125;,&#123;"title":1,_id:0&#125;).limit(2)&#123; "title" : "PHP教程" &#125;&#123; "title" : "JAVA教程" &#125;# Skip方法123456语法：db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)# 使用skip()方法跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数。hqmongodb:PRIMARY&gt; db.col.find(&#123;&#125;,&#123;"title":1,_id:0&#125;).limit(1).skip(1)&#123; "title" : "JAVA教程" &#125;# 只显示第二条文档数据。skip()方法默认参数为 0 。 createIndex方法123456789101112131415161718192021222324252627282930# 索引通常能够极大的提高查询的效率，如果没有索引，MongoDB在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录。这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可能要花费几十秒甚至几分钟，这对网站的性能是非常致命的。索引是特殊的数据结构，索引存储在一个易于遍历读取的数据集合中，索引是对数据库表中一列或多列的值进行排序的一种结构。# MongoDB使用 createIndex() 方法来创建索引。在 3.0.0 版本前创建索引方法为 db.collection.ensureIndex()，之后的版本使用了 db.collection.createIndex() 方法，ensureIndex() 还能用，但只是 createIndex() 的别名。语法：db.collection.createIndex(keys, options)hqmongodb:PRIMARY&gt; db.col.createIndex(&#123;"title":1&#125;)&#123; "createdCollectionAutomatically" : false, "numIndexesBefore" : 1, "numIndexesAfter" : 2, "ok" : 1&#125;# 语法中 Key 值为你要创建的索引字段，1 为指定按升序创建索引，如果你想按降序来创建索引指定为 -1 即可。hqmongodb:PRIMARY&gt; db.col.createIndex(&#123;"title":1,"description":-1&#125;)&#123; "createdCollectionAutomatically" : false, "numIndexesBefore" : 2, "numIndexesAfter" : 3, "ok" : 1&#125;# createIndex() 方法中你也可以设置使用多个字段创建索引（关系型数据库中称作复合索引）hqmongodb:PRIMARY&gt; db.values.createIndex(&#123;open:1,close:1&#125;,&#123;background:true&#125;)&#123; "createdCollectionAutomatically" : true, "numIndexesBefore" : 1, "numIndexesAfter" : 2, "ok" : 1&#125;# 后台创建索引。通过在创建索引时加 background:true 的选项，让创建工作在后台执行 createIndex() 接收可选参数列表 Parameter Type Description background Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 “background” 可选参数。 “background” 默认值为false。 unique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为false. name string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。 dropDups Boolean 3.0+版本已废弃。在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引。默认值为 false. sparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 false. expireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 v index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 weights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。 default_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 language_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的language，默认值为 language. aggregate方法1234567891011121314# MongoDB中聚合(aggregate)主要用于处理数据(诸如统计平均值,求和等)，并返回计算后的数据结果。有点类似sql语句中的 count(*)。# MongoDB中聚合的方法使用aggregate()。语法：db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION)hqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;hqmongodb:PRIMARY&gt; db.col.aggregate([&#123;$group:&#123;_id:"$by",num_tutorial:&#123;$sum:1&#125;&#125;&#125;])&#123; "_id" : "cn", "num_tutorial" : 3 &#125;# 统计每个作者所写的文章数。以上实例类似sql语句：select by, count(*) from col group by by;# 上面的例子中，我们通过字段 by字段对数据进行分组，并计算 by字段相同值的总和。 聚合的表达式 表达式 描述 实例 $sum 计算likes的总和。 db.col.aggregate([{$group : {_id : “$by”, num_tutorial : {$sum : “$likes”}}}]) $avg 计算likes的平均值 db.col.aggregate([{$group : {_id : “$by”, num_tutorial : {$avg : “$likes”}}}]) $min 获取集合中所有文档对应值得最小值。 db.col.aggregate([{$group : {_id : “$by”, num_tutorial : {$min : “$likes”}}}]) $max 获取集合中所有文档对应值得最大值。 db.col.aggregate([{$group : {_id : “$by”, num_tutorial : {$max : “$likes”}}}]) $push 在结果文档中插入值到一个数组中。 db.col.aggregate([{$group : {_id : “$by”, url : {$push: “$url”}}}]) $addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.col.aggregate([{$group : {_id : “$by”, url : {$addToSet : “$url”}}}]) $first 根据资源文档的排序获取第一个文档数据。 db.col.aggregate([{$group : {_id : “$by”, first_url : {$first : “$url”}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.col.aggregate([{$group : {_id : “$by”, last_url : {$last : “$url”}}}]) 管道的概念1234567891011121314151617181920212223242526272829303132# MongoDB的聚合管道将MongoDB文档在一个管道处理完毕后将结果传递给下一个管道处理。管道操作是可以重复的。# 表达式：处理输入文档并输出。表达式是无状态的，只能用于计算当前聚合管道的文档，不能处理其它的文档。# 这里我们介绍一下聚合框架中常用的几个操作：$project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。$match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。$limit：用来限制MongoDB聚合管道返回的文档数。$skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。$unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。$group：将集合中的文档分组，可用于统计结果。$sort：将输入文档排序后输出。$geoNear：输出接近某一地理位置的有序文档。hqmongodb:PRIMARY&gt; db.col.aggregate(&#123; $project:&#123; title:1, by:1, &#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "by" : "cn" &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "by" : "cn" &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "by" : "cn" &#125;# 结果中就只还有_id,tilte和by三个字段了，默认情况下_id字段是被包含的hqmongodb:PRIMARY&gt; db.col.aggregate(&#123; $project:&#123; _id:0,title:1, by:1, &#125;&#125;)&#123; "title" : "PHP教程", "by" : "cn" &#125;&#123; "title" : "JAVA教程", "by" : "cn" &#125;&#123; "title" : "mongodb教程", "by" : "cn" &#125;# 不包含_id字段hqmongodb:PRIMARY&gt; db.col.aggregate([&#123;$match:&#123;likes:&#123;$gt:100,$lte:200&#125;&#125;&#125;,&#123;$group:&#123;_id:null,count:&#123;$sum:1&#125;&#125;&#125;])&#123; "_id" : null, "count" : 2 &#125;# $match用于获取likes大于100小于或等于200的记录，然后将符合条件的记录送到下一阶段$group管道操作符进行处理。hqmongodb:PRIMARY&gt; db.col.aggregate(&#123;$skip:2&#125;)&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;# 经过$skip管道操作符处理后，前两个文档被"过滤"掉。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB条件操作符]]></title>
    <url>%2F2019%2F03%2F11%2FMongoDB%E6%9D%A1%E4%BB%B6%E6%93%8D%E4%BD%9C%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[大于操作符123456789101112131415161718hqmongodb:PRIMARY&gt; db.col.remove(&#123;&#125;)# 清空集合 "col" 的数据。col是自定义的名称，只要在插入数据时插入到自定义的集合名中即可。hqmongodb:PRIMARY&gt; db.col.insert(&#123; title:'PHP教程', description:'PHP是一种脚本语言', by:'cn', url:'http://www.runoob.com', tags:['php'], likes:200 &#125;)WriteResult(&#123; "nInserted" : 1 &#125;)# 向col集合中插入数据hqmongodb:PRIMARY&gt; db.col.insert(&#123; title:'JAVA教程', description:'java是高级语言', by:'cn', url:'http://www.runoob.com', tags:['java'], likes:150 &#125;)WriteResult(&#123; "nInserted" : 1 &#125;)hqmongodb:PRIMARY&gt; db.col.insert(&#123; title:'mongodb教程', description:'mongodb是Nosql', by:'cn', url:'http://www.runoob.com', tags:['mongodb'], likes:100 &#125;)WriteResult(&#123; "nInserted" : 1 &#125;)# 插入三个文档hqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;hqmongodb:PRIMARY&gt; db.col.find(&#123;likes:&#123;$gt:150&#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;# 获取 "col" 集合中 "likes" 大于 150 的数据。类似SQL语句：Select * from col where likes &gt; 150; 大于等于操作符1234hqmongodb:PRIMARY&gt; db.col.find(&#123;likes:&#123;$gte:150&#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;# 获取 "col" 集合中 "likes" 大于等于 150 的数据。类似SQL语句：Select * from col where likes &gt;= 150; 小于操作符123hqmongodb:PRIMARY&gt; db.col.find(&#123;likes:&#123;$lt:150&#125;&#125;)&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;# 获取 "col" 集合中 "likes" 小于 150 的数据。类似SQL语句：Select * from col where likes &lt; 150; 小于等于操作符1234hqmongodb:PRIMARY&gt; db.col.find(&#123;likes:&#123;$lte:150&#125;&#125;)&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;# 获取 "col" 集合中 "likes" 小于等于 150 的数据。类似SQL语句：Select * from col where likes &lt;= 150; 联合使用123hqmongodb:PRIMARY&gt; db.col.find(&#123;likes:&#123;$lt:200,$gt:100&#125;&#125;)&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;# 获取"col"集合中 "likes" 大于100，小于 200 的数据。类似SQL语句：Select * from col where likes&gt;100 AND likes&lt;200; $type操作符123456789101112131415# $type操作符是基于BSON类型来检索集合中匹配的数据类型，并返回结果。# MongoDB中可以使用的类型有：(1)Double、(2)String、(3)Object、(4)Array、(5)Binary data、(7)Object id、(8)Boolean、(9)Date、(10)Null、(11)Regular Expression、(13)JavaScript、(14)Symbol、(15)JavaScript(with scope)、(16)32-bit integer、(17)Timestamp、(18)64-bit integer、(255)Min key、(127)Max keyhqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;hqmongodb:PRIMARY&gt; db.col.find(&#123;"title":&#123;$type:2&#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;# 这里$type指定的是上面说明中类型前面的数字，也可以指定类型名称，如下hqmongodb:PRIMARY&gt; db.col.find(&#123;"title":&#123;$type:'string'&#125;&#125;)&#123; "_id" : ObjectId("5c85f81c95892d355859a619"), "title" : "PHP教程", "description" : "PHP是一种脚本语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "php" ], "likes" : 200 &#125;&#123; "_id" : ObjectId("5c85f8f995892d355859a61a"), "title" : "JAVA教程", "description" : "java是高级语言", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "java" ], "likes" : 150 &#125;&#123; "_id" : ObjectId("5c85f93195892d355859a61b"), "title" : "mongodb教程", "description" : "mongodb是Nosql", "by" : "cn", "url" : "http://www.runoob.com", "tags" : [ "mongodb" ], "likes" : 100 &#125;]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB条件操作符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nginx搭建webdav服务]]></title>
    <url>%2F2019%2F03%2F11%2F%E4%BD%BF%E7%94%A8Nginx%E6%90%AD%E5%BB%BAwebdav%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[介绍 WebDAV 就是通过 Restful API ，实现对服务端文件的 创建 / 删除 / 读取 / 修改，比起其他文件传输协议，它基于 HTTP，不容易被当作不明流量被砍掉。同时能够利用 HTTP 的各种扩展，比如 HTTPS 提供数据加密功能、HTTP 2.0 提供数据流传输、HTTP 范围请求(RFC7233)等。 安装12345[root@webdav ~]# yum install -y nginx httpd-tools[root@webdav ~]# mkdir /webdav# 创建上传目录[root@webdav conf.d]# chmod 777 /webdav/# 要让nginx用户可以将数据写入此目录，所以主要是给其他人加写权限 配置1234567891011121314151617181920212223242526[root@webdav ~]# cd /etc/nginx/conf.d/[root@webdav conf.d]# vim webdav.confserver &#123; listen 8088; error_page 404 /404; error_page 503 /503; client_max_body_size 1000M; location / &#123; root /webdav; autoindex on; # autoindex on是为了通过网页访问时可以直接显示索引 dav_methods PUT DELETE MKCOL COPY MOVE;# dav_ext_methods PROPFIND OPTIONS;# 加入此行，nginx会报错，称不知道dav_ext_methods create_full_put_path on;# create_full_put_path官方的说明为“默认情况下，PUT方法只能在已存在的目录里创建文件。当然了Nginx 必须得有这个目录的修改和写入权限”； dav_access user:rw group:r all:r; auth_basic "Authorized Users Only"; auth_basic_user_file /etc/nginx/.ngxpasswd;# 认证说明与认证文件的路径 &#125;&#125;[root@webdav conf.d]# htpasswd -c -m /etc/nginx/.ngxpasswd test# 创建可以上传的用户名与密码[root@webdav conf.d]# nginx -t[root@webdav conf.d]# systemctl start nginx 测试12345⚡ ⚙ root@ruopu64  ~  curl -u test:centos -T nohup.out 192.168.251.135:8088 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:100 9972 0 0 100 9972 0 4869k --:--:-- --:--:-- --:--:-- 4869k # 测试使用curl命令上传数据。-u选项用来指定用户名和密码，-T表示上传文件，nohup.out是要上传的文件，最后是服务器地址。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginxWebdav</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础命令]]></title>
    <url>%2F2019%2F03%2F08%2FMongoDB%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[创建数据库1234567891011121314151617181920hqmongodb:PRIMARY&gt; use runoobswitched to db runoob# 使用use命令可以创建或进入数据库，当数据库不存在时，就会创建并进行，如果数据库存在，就会进入数据库。hqmongodb:PRIMARY&gt; dbrunoob# 使用db命令可以显示当前所在的库hqmongodb:PRIMARY&gt; show dbsadmin 0.000GBlocal 0.000GB# 使用此命令可以查看所有数据库，但刚创建的库并不在其中，因为库中还没有数据。hqmongodb:PRIMARY&gt; db.runoob.insert(&#123;"name":"test"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)# 向库中插入一个表，并向表中插入数据hqmongodb:PRIMARY&gt; show dbsadmin 0.000GBlocal 0.000GBrunoob 0.000GB# 再次查看时就有这个库了# MongoDB 中默认的数据库为 test，如果你没有创建新的数据库，集合将存放在 test 数据库中。# 在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建。 删除数据库12345hqmongodb:PRIMARY&gt; use runoobswitched to db runoobhqmongodb:PRIMARY&gt; db.dropDatabase()&#123; "dropped" : "runoob", "ok" : 1 &#125;# 删除数据库 创建集合12345678910111213141516171819202122232425262728293031语法：db.createCollection(name, options)# name: 要创建的集合名称；options: 可选参数, 指定有关内存大小及索引的选项# options 可以是如下参数：# capped：布尔值，（可选）如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。当该值为 true 时，必须指定 size 参数。# autoIndexId：布尔值，（可选）如为 true，自动在 _id 字段创建索引。默认为 false。# size：数值，（可选）为固定集合指定一个最大值（以字节计）。如果 capped 为 true，也需要指定该字段。# max：数值，（可选）指定固定集合中包含文档的最大数量。# 在插入文档时，MongoDB 首先检查固定集合的 size 字段，然后检查 max 字段。hqmongodb:PRIMARY&gt; use runoobswitched to db runoobhqmongodb:PRIMARY&gt; db.createCollection("runoob")&#123; "ok" : 1 &#125;# 在runoob库中创建集合runoobhqmongodb:PRIMARY&gt; show collectionsrunoob# 查看集合hqmongodb:PRIMARY&gt; db.createCollection("mycol",&#123;capped:true,autoIndexId:true,size:6142800,max:10000&#125;)&#123; "note" : "the autoIndexId option is deprecated and will be removed in a future release", "ok" : 1&#125;# 创建固定集合 mycol，整个集合空间大小 6142800 KB, 文档最大个数为 10000 个。hqmongodb:PRIMARY&gt; db.mycol2.insert(&#123;"name":"test"&#125;)# 在 MongoDB 中，实际不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合。WriteResult(&#123; "nInserted" : 1 &#125;)hqmongodb:PRIMARY&gt; show collectionsmycolmycol2runoob 删除集合1234567891011121314语法：db.collection.drop()如果成功删除选定集合，则 drop() 方法返回 true，否则返回 false。hqmongodb:PRIMARY&gt; show collectionsmycolmycol2runoobhqmongodb:PRIMARY&gt; db.mycol2.drop()true# 删除mycol2集合hqmongodb:PRIMARY&gt; show collectionsmycolrunoob 插入文档123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869语法：db.COLLECTION_NAME.insert(document)# MongoDB 使用 insert() 或 save() 方法向集合中插入文档3.2 版本后还有以下几种语法可用于插入文档：db.collection.insertOne()# 向指定集合中插入一条文档数据db.collection.insertMany()# 向指定集合中插入多条文档数据 # 文档的数据结构和JSON基本一样。所有存储在集合中的数据都是BSON格式。BSON是一种类json的一种二进制形式的存储格式,简称Binary JSON。hqmongodb:PRIMARY&gt; db.col.insert(&#123;title:'MongoDB教程', description:'MongoDB是一个Nosql数据库', by:'教程', url:'http://www.runoob.com', tags:['mongodb','database','NoSQL'], likes:100&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)# 使用insert()方法插入文档，每对键值间用逗号分隔hqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100 &#125;# 使用find()方法查看hqmongodb:PRIMARY&gt; document=(&#123;title:'MongoDB教程', description:'MongoDB是一个Nosql数据库', by:'教程', url:'http://www.runoob.com', tags:['mongodb','database','NoSQL'], likes:100&#125;)&#123; "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;# 将数据定义在一个变量中hqmongodb:PRIMARY&gt; db.col.insert(document)WriteResult(&#123; "nInserted" : 1 &#125;)# 再插入变量。效果与插入数据是一样的hqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100 &#125;&#123; "_id" : ObjectId("5c822e401fb12ed017cf9363"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100 &#125;# 查看插入了两个数据hqmongodb:PRIMARY&gt; var document = db.collection.insertOne(&#123;"a": 3&#125;)hqmongodb:PRIMARY&gt; document&#123; "acknowledged" : true, "insertedId" : ObjectId("5c8233471fb12ed017cf9364")&#125;# 插入单条数据并查看hqmongodb:PRIMARY&gt; var res = db.collection.insertMany([&#123;"b":3&#125;,&#123;'c':4&#125;])hqmongodb:PRIMARY&gt; res&#123; "acknowledged" : true, "insertedIds" : [ ObjectId("5c8233781fb12ed017cf9365"), ObjectId("5c8233781fb12ed017cf9366") ]&#125;# 插入多条数据并查看------------- 从节点-------------hqmongodb:SECONDARY&gt; use runoobswitched to db runoobhqmongodb:SECONDARY&gt; db.col.find()Error: error: &#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125;hqmongodb:SECONDARY&gt; rs.slaveOk()# 在从节点查看数据要使用此命令，不然会有上面的错误提示hqmongodb:SECONDARY&gt; db.col.find()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100 &#125;&#123; "_id" : ObjectId("5c822e401fb12ed017cf9363"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100 &#125; 更新文档 MongoDB 使用 update() 和 save() 方法来更新集合中的文档。 update() 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105语法：db.collection.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;)# 参数说明：# query：update的查询条件，类似sql update查询内where后面的。# update：update的对象和一些更新的操作符（如$，$inc...）等，也可以理解为sql update查询内set后面的# upsert：可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。# multi : 可选，mongodb 默认是false，只更新找到的第一条记录，如果这个参数为true，就把按条件查出来多条记录全部更新。# writeConcern：可选，抛出异常的级别。hqmongodb:PRIMARY&gt; db.col.insert(&#123; title:'MongoDB教程', description:'MongoDB是一个Nosql数据库', by:'cai', url:'http://www.runoob.com', tags:['mongodb','database','NoSQL'], likes:100 &#125;)WriteResult(&#123; "nInserted" : 1 &#125;)# 插入数据hqmongodb:PRIMARY&gt; db.col.update(&#123;'title':'MongoDB教程'&#125;,&#123;$set:&#123;'title':'MongoDB'&#125;&#125;)WriteResult(&#123; "nMatched" : 1, "nUpserted" : 0, "nModified" : 1 &#125;)hqmongodb:PRIMARY&gt; db.col.find().pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;&#123; "_id" : ObjectId("5c822e401fb12ed017cf9363"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;&#123; "_id" : ObjectId("5c8235aa1fb12ed017cf9367"), "title" : "MongoDB教程", "description" : "MongoDB是一个Nosql数据库", "by" : "cai", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;# 可以看到标题(title)由原来的 "MongoDB 教程" 更新为了 "MongoDB"。# 以上语句只会修改第一条发现的文档，如果你要修改多条相同的文档，则需要设置 multi 参数为 true。如下：hqmongodb:PRIMARY&gt; db.col.update(&#123;'title':'MongoDB教程'&#125;,&#123;$set:&#123;'title':'MongoDB'&#125;&#125;,&#123;multi:true&#125;)WriteResult(&#123; "nMatched" : 2, "nUpserted" : 0, "nModified" : 2 &#125;)hqmongodb:PRIMARY&gt; db.col.find().pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;&#123; "_id" : ObjectId("5c822e401fb12ed017cf9363"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;&#123; "_id" : ObjectId("5c8235aa1fb12ed017cf9367"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "cai", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125; save() 方法 save() 方法通过传入的文档来替换已有文档 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253语法：db.collection.save( &lt;document&gt;, &#123; writeConcern: &lt;document&gt; &#125;)# 参数说明：# document : 文档数据。# writeConcern :可选，抛出异常的级别。hqmongodb:PRIMARY&gt; db.col.save(&#123;... "_id":ObjectId("5c822dfa1fb12ed017cf9362"),... "title":"MongoDB",... "description" : "MongoDB 是一个 Nosql 数据库",... "by" : "Runoob",... "url" : "http://www.runoob.com",... "tags" : [... "mongodb",... "NoSQL"... ],... "likes" : 110... &#125;)WriteResult(&#123; "nMatched" : 1, "nUpserted" : 0, "nModified" : 1 &#125;)hqmongodb:PRIMARY&gt; db.col.find().pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;.......&#125;# 修改后的结果，之前的结果如下：hqmongodb:PRIMARY&gt; db.col.find().pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125; 更多实例123456789101112db.col.update( &#123; "count" : &#123; $gt : 1 &#125; &#125; , &#123; $set : &#123; "test2" : "OK"&#125; &#125; );# 只更新第一条记录db.col.update( &#123; "count" : &#123; $gt : 3 &#125; &#125; , &#123; $set : &#123; "test2" : "OK"&#125; &#125;,false,true );# 全部更新db.col.update( &#123; "count" : &#123; $gt : 4 &#125; &#125; , &#123; $set : &#123; "test5" : "OK"&#125; &#125;,true,false );# 只添加第一条db.col.update( &#123; "count" : &#123; $gt : 5 &#125; &#125; , &#123; $set : &#123; "test5" : "OK"&#125; &#125;,true,true );# 全部添加进去db.col.update( &#123; "count" : &#123; $gt : 15 &#125; &#125; , &#123; $inc : &#123; "count" : 1&#125; &#125;,false,true );# 全部更新db.col.update( &#123; "count" : &#123; $gt : 10 &#125; &#125; , &#123; $inc : &#123; "count" : 1&#125; &#125;,false,false );# 只更新第一条记录 删除文档12345678910111213141516171819202122232425262728293031323334353637383940414243语法：db.collection.remove( &lt;query&gt;, &#123; justOne: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;)# 2.6以后版本的语法# query :（可选）删除的文档的条件。# justOne : （可选）如果设为 true 或 1，则只删除一个文档，如果不设置该参数，或使用默认值 false，则删除所有匹配条件的文档。# writeConcern :（可选）抛出异常的级别。db.inventory.deleteMany(&#123;&#125;)# 官方推荐使用这种语法，使用deleteMany方法或deleteOne方法，分别表示删除所有匹配到的文档或只删除一个文档例：db.inventory.deleteMany(&#123; status : "A" &#125;)# 删除 status 等于 A 的全部文档db.inventory.deleteOne( &#123; status: "D" &#125; )# 删除 status 等于 D 的一个文档hqmongodb:PRIMARY&gt; db.col.insert(&#123;title:'MongoDB教程',... description:'M是一个Nosql',... by:'ruo',... url:'http://www.runoob.com',... tags:['mongodb','database','Nosql'],... likes:100... &#125;)WriteResult(&#123; "nInserted" : 1 &#125;)hqmongodb:PRIMARY&gt; db.col.find()&#123; "_id" : ObjectId("5c85b72b372fdd538ec31fdc"), "title" : "MongoDB教程", "description" : "M是一个Nosql", "by" : "ruo", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "Nosql" ], "likes" : 100 &#125;hqmongodb:PRIMARY&gt; dbtest# 这个文档是在test库中添加的hqmongodb:PRIMARY&gt; db.col.remove(&#123;'title':'MongoDB教程'&#125;)WriteResult(&#123; "nRemoved" : 1 &#125;)# 显示删除了一条文档数据hqmongodb:PRIMARY&gt; db.repairDatabase()&#123; "ok" : 1 &#125;# remove() 方法 并不会真正释放空间。需要继续执行 db.repairDatabase() 来回收磁盘空间。hqmongodb:PRIMARY&gt; db.runCommand(&#123;repairDatabase:1&#125;)&#123; "ok" : 1 &#125;# 使用此方法也可以实现释放空间 查询文档12345678910111213141516171819202122232425262728293031323334353637383940414243语法：db.collection.find(query, projection)# MongoDB 查询文档使用 find() 方法。find() 方法以非结构化的方式来显示所有文档。# query ：可选，使用查询操作符指定查询条件# projection ：可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略）。db.col.find().pretty()# 使用 pretty() 方法以易读的方式来读取数据。pretty() 方法以格式化的方式来显示所有文档。hqmongodb:PRIMARY&gt; use runoobswitched to db runoob# 切换数据库到runoobhqmongodb:PRIMARY&gt; dbrunoobhqmongodb:PRIMARY&gt; db.col.find().pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;......# 查询库中所有文档hqmongodb:PRIMARY&gt; db.col.findOne()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;# findOne() 方法只返回一个文档。 MongoDB 与 RDBMS Where 语句比较 操作 格式 范例 RDBMS中的类似语句 等于 {&lt;key&gt;:&lt;value&gt;} db.col.find({&quot;by&quot;:&quot;菜鸟教程&quot;}).pretty() where by = &#39;菜鸟教程&#39; 小于 {&lt;key&gt;:{$lt:&lt;value&gt;}} db.col.find({&quot;likes&quot;:{$lt:50}}).pretty() where likes &lt; 50 小于或等于 {&lt;key&gt;:{$lte:&lt;value&gt;}} db.col.find({&quot;likes&quot;:{$lte:50}}).pretty() where likes &lt;= 50 大于 {&lt;key&gt;:{$gt:&lt;value&gt;}} db.col.find({&quot;likes&quot;:{$gt:50}}).pretty() where likes &gt; 50 大于或等于 {&lt;key&gt;:{$gte:&lt;value&gt;}} db.col.find({&quot;likes&quot;:{$gte:50}}).pretty() where likes &gt;= 50 不等于 {&lt;key&gt;:{$ne:&lt;value&gt;}} db.col.find({&quot;likes&quot;:{$ne:50}}).pretty() where likes != 50 AND条件1234567891011121314151617181920语法：db.col.find(&#123;key1:value1, key2:value2&#125;).pretty()# find() 方法可以传入多个键(key)，每个键(key)以逗号隔开，即常规 SQL 的 AND 条件。hqmongodb:PRIMARY&gt; db.col.find(&#123;"by":"cai","title":"MongoDB"&#125;).pretty()&#123; "_id" : ObjectId("5c8235aa1fb12ed017cf9367"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "cai", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;# 通过 by 和 title 键来查询。# 实例中类似于 WHERE 语句：WHERE by='cai' AND title='MongoDB' OR条件12345678910111213141516171819202122232425262728293031323334353637语法：db.col.find( &#123; $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125;).pretty()# OR 条件语句使用了关键字 $orhqmongodb:PRIMARY&gt; db.col.find(&#123;$or:[&#123;"likes":110&#125;,&#123;"by":"cai"&#125;]&#125;).pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;&#123; "_id" : ObjectId("5c8235aa1fb12ed017cf9367"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "cai", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;# 条件中的likes键的值是110，110两侧不能加引号，因为110是数字，加引号表示字符串 AND和OR联合使用12345678910111213141516171819202122232425262728293031323334353637383940hqmongodb:PRIMARY&gt; db.col.find(&#123;"likes":&#123;$gt:50&#125;,$or:[&#123;"by":"Runoob"&#125;,&#123;"title":"MongoDB"&#125;]&#125;).pretty()&#123; "_id" : ObjectId("5c822dfa1fb12ed017cf9362"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;&#123; "_id" : ObjectId("5c822e401fb12ed017cf9363"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;&#123; "_id" : ObjectId("5c8235aa1fb12ed017cf9367"), "title" : "MongoDB", "description" : "MongoDB是一个Nosql数据库", "by" : "cai", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;# 常规 SQL 语句为： 'where likes&gt;50 AND (by = '菜鸟教程' OR title = 'MongoDB 教程')' 常用命令1234567891011121314151617181920212223242526272829303132333435363738394041424344451. 连接mongo 10.129.14.6:27017/admin -u xor-admin -p xor-admin# 连接时要使用admin库，因为这个库具有管理权限。# 如果指定username、password，连接并验证登陆指定数据库。若不指定，默认打开 test 数据库。2. 显示所有库show databases# 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。# admin： 从权限的角度来看，这是"root"数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。# local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合# config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。3. 查看版本db.version()4. 切换或创建数据库use admindb.auth("username","password")5. 查看所有表show collectionsshow tables# 这两条命令显示的内容是一样的6. 查看表中的信息db.system.users.find()db.getCollection('system.users').find()# 这两条命令显示的内容是一样的7. 条件查询db.getCollection('system.users').find(&#123;'db':'aquapaas'&#125;)# find中的键值对两侧用单双引号都可以db.getCollection("system.version").find(&#123;"currentVersion":5&#125;)# 查看数字时，数字两侧不能有单双引号8. 模糊查询db.getCollection("system.users").find(&#123;"_id":/aquapaas/&#125;).limit(20)# 使用//的方式模糊匹配，limit指定只显示20条9. 统计条数db.getCollection("system.users").find(&#123;"_id":/aquapaas/&#125;).count()# 用count()统计条数10. 显示当前所在的库db]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB基础命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提取JSON中的指定值]]></title>
    <url>%2F2019%2F03%2F07%2F%E6%8F%90%E5%8F%96JSON%E4%B8%AD%E7%9A%84%E6%8C%87%E5%AE%9A%E5%80%BC%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223有JSON格式文件都在一行中，需要从中提取指定的值，需要从中提取"ChannelName"后的值，如"BTV文艺"，JSON文件内容如下：&#123;"count": 460, "data": [&#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"ADID":"16512_1_102","Advtype":2,"RandomSeq":"dce3db2d-8331-43e8-8dab-fc42d4bdff4b","LocalTime":"2019-02-01 00:00:00","CACardID":"8100103913276261","EventtypeId":"AdvDataCollect","IsLeave":"1","ServiceID":102,"DeviceType":"DVBIP-1004","CollectManufacturer":"inspur","ChannelName":"BTV文艺","SerialNumber":"10081807030091806","ADPositionID":6,"RegionId":"11132"&#125;", "AdvDataCollect": &#123;"ADPositionID": "6", "Advtype": "2", "ServiceID": "102", "ADID": "16512_1_102", "IsLeave": "1", "ChannelName": "BTV文艺", "LocalTime": "2019-02-01 00:00:00.000+0800"&#125;, "RegionId": "11132", "RandomSeq": "dce3db2d-8331-43e8-8dab-fc42d4bdff4b", "DeviceType": "DVBIP-1004", "time": "2019-02-01 00:00:00.000+0800", "EventtypeId": "AdvDataCollect", "_id": "LsulpGgBnh2vjNXwpHy3", "_collect_time": "2019-02-01 00:02:25.064+0800"&#125;, &#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"ADID":"16512_1_102","Advtype":2,"RandomSeq":"653c618f-4282-452a-b680-d4050ec6b567","LocalTime":"2019-02-01 .........23:59:11","CACardID":"8100103913276261","EventtypeId":"LockingDataCollect","DeviceType":"DVBIP-1004","Locked":"true","CollectManufacturer":"inspur","SerialNumber":"10081807030091806","SymbolRate":6875000,"Modulation":"QAM64","Quality":37,"CurrentFrequency":331,"Level":60,"RegionId":"11132"&#125;", "RegionId": "11132", "RandomSeq": "e2c61503-7d9d-47dc-979d-a17cd4db5a30", "DeviceType": "DVBIP-1004", "time": "2019-02-01 23:59:11.000+0800", "EventtypeId": "LockingDataCollect", "_id": "kDTIqWgBNUKkFfMOVTGX", "_collect_time": "2019-02-01 23:58:24.179+0800", "LockingDataCollect": &#123;"Locked": "true", "Level": "60", "Modulation": "QAM64", "SymbolRate": "6875000", "CurrentFrequency": "331", "Quality": "37", "LocalTime": "2019-02-01 23:59:11.000+0800"&#125;&#125;, &#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"DeviceType":"DVBIP-1004","CollectManufacturer":"inspur","RandomSeq":"b7b7896b-c293-425a-ae7c-40675f22252f","SerialNumber":"10081807030091806","LocalTime":"2019-02-01 23:59:11","Idle":91,"SystemRunTime":23475,"RegionId":"11132","FlashRest":4823449,"CACardID":"8100103913276261","EventtypeId":"ResourceDataCollect","RAMRest":638&#125;", "ResourceDataCollect": &#123;"SystemRunTime": 23475.0, "FlashRest": 4823449.0, "Idle": "91", "RAMRest": 638.0, "LocalTime": "2019-02-01 23:59:11.000+0800"&#125;, "RegionId": "11132", "RandomSeq": "b7b7896b-c293-425a-ae7c-40675f22252f", "DeviceType": "DVBIP-1004", "time": "2019-02-01 23:59:11.000+0800", "EventtypeId": "ResourceDataCollect", "_id": "B8TIqWgBnh2vjNXwVauX", "_collect_time": "2019-02-01 23:58:24.602+0800"&#125;], "timed_out": false, "take_time": 5475&#125;root@ruopu64:2019-03-07#cat 8100103913276261_2019-02-01.json | tr "," "\n" | grep "ChannelName"# 使用tr命令将文件中的逗号都转为新行，之后再查找指定值即可。# 这样的JSON文件每天会产生一个root@ruopu64:2019-03-07#cat *.json &gt; all.json# 将所有文件输出到一个文件中root@ruopu64:2019-03-07#cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n &gt; allOK.txt# 再将统计结果输出到一个文件中。通过这两步就可以统计所有频道点播的次数了root@ruopu64:2019-03-07#vim all.sh#!/bin/bash#count=$(cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n)counta=$(cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n|awk '&#123;print $1&#125;')a=0for i in `cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n|awk '&#123;print $1&#125;'`;do let a=$a+$i doneecho $a]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB分片]]></title>
    <url>%2F2019%2F03%2F07%2FMongoDB%E5%88%86%E7%89%87%2F</url>
    <content type="text"><![CDATA[概念 分片技术,可以满足MongoDB数据量大量增长的需求。当MongoDB存储海量的数据时，一台机器可能不足以存储数据，也可能不足以提供可接受的读写吞吐量。这时，我们就可以通过在多台机器上分割数据，使得数据库系统能存储和处理更多的数据。 分片集群特点 复制所有的写入操作到主节点 延迟的敏感数据会在主节点查询 单个副本集限制在12个节点 当请求量巨大时会出现内存不足 解决本地磁盘不足 解决垂直扩展价格昂贵 分片组件 Shard: 用于存储实际的数据块，实际生产环境中一个shard server角色可由几台机器组个一个replica set承担，防止主机单点故障 Config Server: mongod实例，存储了整个 ClusterMetadata，其中包括 chunk信息。 Query Routers: 前端路由，客户端由此接入，且让整个集群看上去像单一数据库，前端应用可以透明使用。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB分片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 复制]]></title>
    <url>%2F2019%2F03%2F06%2FMongoDB-%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[概念 MongoDB复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。复制还允许您从硬件故障和服务中断中恢复数据。 复制可实现保障数据的安全性、数据高可用性(24*7)、灾难恢复、无需停机维护(如备份，重建索引，压缩)、分布式读取数据 Mongodb一共有三种集群搭建的方式： Replica Set（副本集） Sharding（切片） Master-Slaver（主从，目前已不推荐使用了） 其中，Sharding集群也是三种集群中最复杂的。副本集比起主从可以实现故障转移 mongoDB目前已不推荐使用主从模式，取而代之的是副本集模式。副本集是一种互为主从的关系，可理解为主主。副本集指将数据复制，多份保存，不同服务器保存同一份数据，在出现故障时自动切换。对应的是数据冗余、备份、镜像、读写分离、高可用性等关键词； 而分片则指为处理大量数据，将数据分开存储，不同服务器保存不同的数据，它们的数据总和即为整个数据集。追求的是高性能。 在生产环境中，通常是这两种技术结合使用，分片+副本集。 复制原理 mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。 mongodb各个节点常见的搭配方式为：一主一从、一主多从。 在主从结构中，主节点的操作记录成为oplog（operation log）。oplog存储在一个系统数据库local的集合oplog.$main中，这个集合的每个文档都代表主节点上执行的一个操作。从服务器会定期从主服务器中获取oplog记录，然后在本机上执行！对于存储oplog的集合，MongoDB采用的是固定集合，也就是说随着操作过多，新的操作会覆盖旧的操作！ 集群功能： N个节点的集群 任何节点都可作为主节点 所有写入操作都在主节点上 自动故障转移 自动恢复 副本集概念 mongodb不推荐主从复制，推荐建立副本集(Replica Set)来保证一个服务挂了，可以有其他服务顶上，程序正常运行，几个服务的数据都是一样的，后台自动同步。主从复制其实就是一个单副本的应用，没有很好的扩展性和容错性。然而副本集具有多个副本保证了容错性，就算一个副本挂掉了还有很多个副本存在，并且解决了”主节点挂掉后，整个集群内会自动切换”的问题。副本集比传统的Master-Slave主从复制有改进的地方就是它可以进行故障的自动转移，如果我们停掉复制集中的一个成员，那么剩余成员会再自动选举一个成员，作为主库。Replica Set 使用的是 n 个 mongod 节点，构建具备自动的容错功能(auto-failover)，自动恢复的(auto-recovery)的高可用方案。使用 Replica Set 来实现读写分离。通过在连接时指定或者在主库指定 slaveOk，由Secondary 来分担读的压力，Primary 只承担写操作。对于 Replica Set 中的 secondary 节点默认是不可读的。 副本集是一种在多台机器同步数据的进程，副本集提供了数据冗余，扩展了数据可用性。在多台服务器保存数据可以避免因为一台服务器导致的数据丢失。也可以从硬件故障或服务中断解脱出来，利用额外的数据副本，可以从一台机器致力于灾难恢复或者备份。 在一些场景，可以使用副本集来扩展读性能，客户端有能力发送读写操作给不同的服务器。也可以在不同的数据中心获取不同的副本来扩展分布式应用的能力。mongodb副本集是一组拥有相同数据的mongodb实例，主mongodb接受所有的写操作，所有的其他实例可以接受主实例的操作以保持数据同步。主实例接受客户的写操作，副本集只能有一个主实例，因为为了维持数据一致性，只有一个实例可写，主实例的日志保存在oplog。 二级节点复制主节点的oplog然后在自己的数据副本上执行操作，二级节点是主节点数据的反射，如果主节点不可用，会选举一个新的主节点。默认读操作是在主节点进行的，但是可以指定读取首选项参数来指定读操作到副本节点。可以添加一个额外的仲裁节点（不拥有被选举权），使副本集节点保持奇数，确保可以选举出票数不同的主接点。仲裁者并不需要专用的硬件设备。仲裁者节点一直会保存仲裁者身份 副本节点同步直接点操作是异步的，然而会导致副本集无法返回最新的数据给客户端程序。 如果主节点10s以上与其他节点失去通信，其他节点将会选举新的节点作为主节点。拥有大多数选票的副节点会被选举为主节点。副本集提供了一些选项给应用程序，可以做一个成员位于不同数据中心的副本集。也可以指定成员不同的优先级来控制选举。 副本集的结构及原理 MongoDB 的副本集不同于以往的主从模式。在集群Master故障的时候，副本集可以自动投票，选举出新的Master，并引导其余的Slave服务器连接新的Master，而这个过程对于应用是透明的。可以说MongoDB的副本集是自带故障转移功能的主从复制。 传统的主从模式，需要手工指定集群中的 Master。如果 Master 发生故障，一般都是人工介入，指定新的 Master。 这个过程对于应用一般不是透明的，往往伴随着应用重新修改配置文件，重启应用服务器等。而 MongoDB 副本集，集群中的任何节点都可以成为 Master 节点。一旦 Master 节点故障，则会在其余节点中选举出一个新的 Master 节点。 并引导剩余节点连接到新的 Master 节点。这个过程对于应用是透明的。 一个副本集就是服务于同一数据集的多个 MongoDB 实例，其中一个为主节点，其余的都为从节点。主节点上能够完成读写操作，从节点仅能用于读操作。主节点需要记录所有改变数据库状态的操作，这些记录保存在 oplog 中，这个文件存储在 local 数据库，各个从节点通过此 oplog 来复制数据并应用于本地，保持本地的数据与主节点的一致。oplog 具有幂等性，即无论执行几次其结果一致，这个比 mysql 的二进制日志更好用。集群中的各节点还会通过传递心跳信息来检测各自的健康状况。当主节点故障时，多个从节点会触发一次新的选举操作，并选举其中的一个成为新的主节点(通常谁的优先级更高,谁就是新的主节点)，心跳信息默认每 2 秒传递一次。 客户端连接到副本集后，不关心具体哪一台机器是否挂掉。主服务器负责整个副本集的读写，副本集定期同步数据备份。一旦主节点挂掉，副本节点就会选举一个新的主服务器。这一切对于应用服务器不需要关心。 心跳检测整个集群需要保持一定的通信才能知道哪些节点活着哪些节点挂掉。mongodb节点会向副本集中的其他节点每两秒就会发送一次pings包，如果其他节点在10秒钟之内没有返回就标示为不能访问。每个节点内部都会维护一个状态映射表，表明当前每个节点是什么角色、日志时间戳等关键信息。如果是主节点，除了维护映射表外还需要检查自己能否和集群中内大部分节点通讯，如果不能则把自己降级为secondary只读节点。 数据同步副本集同步分为初始化同步和keep复制。初始化同步指全量从主节点同步数据，如果主节点数据量比较大同步时间会比较长。而keep复制指初始化同步过后，节点之间的实时同步一般是增量同步。初始化同步不只是在第一次才会被触发，有以下两种情况会触发： secondary第一次加入，这个是肯定的。 secondary落后的数据量超过了oplog的大小，这样也会被全量复制。 副本集中的副本节点在主节点挂掉后通过心跳机制检测到后，就会在集群内发起主节点的选举机制，自动选举出一位新的主服务器。 副本集包括三种节点:主节点、从节点、仲裁节点。 主节点负责处理客户端请求，读、写数据，记录在其上所有操作的 oplog； 从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。默认情况下，从节点不支持外部读取，但可以设置；副本集的机制在于主节点出现故障的时候，余下的节点会选举出一个新的主节点，从而保证系统可以正常运行。 仲裁节点不复制数据，仅参与投票。由于它没有访问的压力，比较空闲，因此不容易出故障。由于副本集出现故障的时候，存活的节点必须大于副本集节点总数的一半，否则无法选举主节点，或者主节点会自动降级为从节点，整个副本集变为只读。因此，增加一个不容易出故障的仲裁节点，可以增加有效选票，降低整个副本集不可用的风险。仲裁节点可多于一个。也就是说只参与投票，不接收复制的数据，也不能成为活跃节点。 官方推荐MongoDB副本节点最少为3台， 建议副本集成员为奇数，最多12个副本节点，最多7个节点参与选举。限制副本节点的数量，主要是因为一个集群中过多的副本节点，增加了复制的成本，反而拖累了集群的整体性能。 太多的副本节点参与选举，也会增加选举的时间。而官方建议奇数的节点，是为了避免脑裂的发生。 副本集的工作流程 在 MongoDB 副本集中，主节点负责处理客户端的读写请求，备份节点则负责映射主节点的数据。备份节点的工作原理过程可以大致描述为：备份节点定期轮询主节点上的数据操作，然后对自己的数据副本进行这些操作，从而保证跟主节点的数据同步。至于主节点上的所有数据库状态改变的操作都会存放在一张特定的系统表中。备份节点则是根据这些数据进行自己的数据更新。 oplog上面提到的数据库状态改变的操作，称为 oplog(operation log，主节点操作记录)。oplog 存储在 local 数据库的”oplog.rs”表中。副本集中备份节点异步的从主节点同步 oplog，然后重新执行它记录的操作，以此达到了数据同步的作用。关于 oplog 有几个注意的地方: oplog 只记录改变数据库状态的操作 存储在 oplog 中的操作并不是和主节点执行的操作完全一样，例如”$inc”操作就会转化为”$set”操作 oplog 存储在固定集合中(capped collection)，当 oplog 的数量超过 oplogSize，新的操作就会覆盖旧的操作 数据同步在副本集中，有两种数据同步方式： initial sync(初始化)：这个过程发生在当副本集中创建一个新的数据库或其中某个节点刚从宕机中恢复，或者向副本集中添加新的成员的时候。默认的，副本集中的节点会从离它最近的节点复制 oplog 来同步数据，这个最近的节点可以是 primary 也可以是拥有最新 oplog 副本的 secondary 节点。该操作一般会重新初始化备份节点，开销较大。 replication(复制)：在初始化后这个操作会一直持续的进行着，以保持各个 secondary 节点之间的数据同步。 initial sync当遇到无法同步的问题时，只能使用以下两种方式进行 initial sync 了 第一种方式就是停止该节点，然后删除目录中的文件，重新启动该节点。这样，这个节点就会执行 initial sync。通过这种方式，sync 的时间是根据数据量大小的，如果数据量过大，sync 时间就会很长，同时会有很多网络传输，可能会影响其他节点的工作 第二种方式，停止该节点，然后删除目录中的文件，找一个比较新的节点，然后把该节点目录中的文件拷贝到要 sync 的节点目录中。 通过上面两种方式中的一种，都可以重新恢复节点。 副本集管理 1234567891011&gt; 1. 查看oplog的信息，通过"db.printReplicationInfo()"命令可以查看 oplog 的信息&gt; 字段说明:&gt; configured oplog size：oplog 文件大小&gt; log length start to end：oplog 日志的启用时间段&gt; oplog first event time：第一个事务日志的产生时间&gt; oplog last event time：最后一个事务日志的产生时间&gt; now：现在的时间&gt; &gt; 2. 查看 slave 状态，通过"db.printSlaveReplicationInfo()"可以查看 slave 的同步状态&gt; 当插入一条新的数据，然后重新检查 slave 状态时，就会发现 sync 时间更新了&gt; 副本集选举的过程和注意点 Mongodb副本集选举采用的是Bully算法，这是一种协调者(主节点)竞选算法，主要思想是集群的每个成员都可以声明它是主节点并通知其他节点。别的节点可以选择接受这个声明或是拒绝并进入主节点竞争，被其他所有节点接受的节点才能成为主节点。节点按照一些属性来判断谁应该胜出，这个属性可以是一个静态 ID，也可以是更新的度量，比如最近一次事务ID(最新的节点会胜出) 副本集的选举过程大致如下： 得到每个服务器节点的最后操作时间戳。每个 mongodb 都有 oplog 机制会记录本机的操作，方便和主服务器进行对比数据是否同步，还可以用于错误恢复。 如果集群中大部分服务器 down 机了，保留活着的节点都为 secondary 状态并停止，不选举了。 如果集群中选举出来的主节点或者所有从节点最后一次同步时间看起来很旧了，停止选举等待人来操作。 如果上面都没有问题就选择最后操作时间戳最新(保证数据是最新的)的服务器节点作为主节点。 副本集选举的特点：选举还有个前提条件，参与选举的节点数量必须大于副本集总节点数量的一半（建议副本集成员为奇数。最多12个副本节点，最多7个节点参与选举）如果已经小于一半了所有节点保持只读状态。集合中的成员一定要有大部分成员(即超过一半数量)是保持正常在线状态，3个成员的副本集，需要至少2个从属节点是正常状态。如果一个从属节点挂掉，那么当主节点down掉产生故障切换时，由于副本集中只有一个节点是正常的，少于一半，则选举失败。四个成员的副本集，则需要三个成员是正常状态(先关闭一个从属节点，然后再关闭主节点，产生故障切换，此时副本集中只有2个节点正常，则无法成功选举出新主节点)。 副本集数据过程 Primary节点写入数据，Secondary通过读取Primary的oplog得到复制信息，开始复制数据并且将复制信息写入到自己的oplog。如果某个操作失败，则备份节点停止从当前数据源复制数据。如果某个备份节点由于某些原因挂掉了，当重新启动后，就会自动从oplog的最后一个操作开始同步，同步完成后，将信息写入自己的oplog，由于复制操作是先复制数据，复制完成后再写入oplog，有可能相同的操作会同步两份，不过MongoDB在设计之初就考虑到这个问题，将oplog的同一个操作执行多次，与执行一次的效果是一样的。简单的说就是： 当Primary节点完成数据操作后，Secondary会做出一系列的动作保证数据的同步： 检查自己local库的oplog.rs集合找出最近的时间戳。 检查Primary节点local库oplog.rs集合，找出大于此时间戳的记录。 将找到的记录插入到自己的oplog.rs集合中，并执行这些操作。 副本集的同步和主从同步一样，都是异步同步的过程，不同的是副本集有个自动故障转移的功能。其原理是：slave端从primary端获取日志，然后在自己身上完全顺序的执行日志所记录的各种操作（该日志是不记录查询操作的），这个日志就是local数据库中的oplog.rs表，默认在64位机器上这个表是比较大的，占磁盘大小的5%，oplog.rs的大小可以在启动参数中设定：–oplogSize 1000，单位是M。 注意：在副本集的环境中，要是所有的Secondary都宕机了，只剩下Primary。最后Primary会变成Secondary，不能提供服务。 MongoDB 同步延迟问题 当你的用户抱怨修改过的信息不改变，删除掉的数据还在显示，可能是数据库主从不同步。与其他提供数据同步的数据库一样，MongoDB 也会遇到同步延迟的问题，在MongoDB的Replica Sets模式中，同步延迟也经常是困扰使用者的一个大问题。 什么是同步延迟？首先，要出现同步延迟，必然是在有数据同步的场合，在 MongoDB 中，有两种数据冗余方式，一种是Master-Slave 模式，一种是Replica Sets模式。这两个模式本质上都是在一个节点上执行写操作， 另外的节点将主节点上的写操作同步到自己这边再进行执行。在MongoDB中，所有写操作都会产生 oplog，oplog 是每修改一条数据都会生成一条，如果你采用一个批量 update 命令更新了 N 多条数据， 那么抱歉，oplog 会有很多条，而不是一条。所以同步延迟就是写操作在主节点上执行完后，从节点还没有把 oplog 拿过来再执行一次。而这个写操作的量越大，主节点与从节点的差别也就越大，同步延迟也就越大了。 同步延迟带来的问题首先，同步操作通常有两个效果，一是读写分离，将读操作放到从节点上来执行，从而减少主节点的压力。对于大多数场景来说，读多写少是基本特性，所以这一点是很有用的。另一个作用是数据备份，同一个写操作除了在主节点执行之外，在从节点上也同样执行，这样我们就有多份同样的数据，一旦主节点的数据因为各种天灾人祸无法恢复的时候，我们至少还有从节点可以依赖。但是主从延迟问题可能会对上面两个效果都产生不好的影响。 如果主从延迟过大，主节点上会有很多数据更改没有同步到从节点上。这时候如果主节点故障，就有两种情况: 主节点故障并且无法恢复，如果应用上又无法忍受这部分数据的丢失，我们就得想各种办法将这部分数据更改找回来，再写入到从节点中去。可以想象，即使是有可能，那这也绝对是一件非常恶心的活。 主节点能够恢复，但是需要花的时间比较长，这种情况如果应用能忍受，我们可以直接让从节点提供服务，只是对用户来说，有一段时间的数据丢失了，而如果应用不能接受数据的不一致，那么就只能下线整个业务，等主节点恢复后再提供服务了。 如果你只有一个从节点，当主从延迟过大时，由于主节点只保存最近的一部分 oplog，可能会导致从节点青黄不接，不得不进行 resync 操作，全量从主节点同步数据。带来的问题是：当从节点全量同步的时候，实际只有主节点保存了完整的数据，这时候如果主节点故障，很可能全部数据都丢掉了。 测试配置服务1234567891011121314151617181920212223242526272829303132333435363738394041424344===========================================================================================环境：准备两台主机，主节点地址：192.168.251.134；从节点1地址：192.168.251.133；从节点2地址：192.168.251.132；# mongodb安装查看MongoDB安装文档===========================================================================================------------- 主节点-------------[root@master ~]# vim /usr/local/mongodb/conf/mongod1.confport=27017bind_ip = 192.168.251.134# 不同的主机绑定自己的地址dbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/log/mongo.logpidfilepath=/usr/local/mongodb/mongo.pidfork=truelogappend=trueshardsvr=truedirectoryperdb=truereplSet =hqmongodb# 复制集的名称，集群中的服务器的配置文件都需要加入replSet指令，它们都属于一个复制集maxConns=5000# 最大同时连接数，默认2000auth=false# 是否启用身份认证nohttpinterface=truerest=false[root@master mongodb]# scp conf/mongodb.conf 192.168.251.132:/usr/local/mongodb/conf/[root@master mongodb]# scp conf/mongodb.conf 192.168.251.133:/usr/local/mongodb/conf/[root@master mongodb]# mongod -f /usr/local/mongodb/conf/mongodb.conf about to fork child process, waiting until server is ready for connections.forked process: 2908child process started successfully, parent exiting----------------- 从节点1&amp;2-----------------[root@slave1 ~]# vim .bash_profileexport PATH=/usr/local/mongodb/bin:$PATH[root@slave1 ~]# source .bash_profile[root@slave1 ~]# mongod -f /usr/local/mongodb/conf/mongod.conf about to fork child process, waiting until server is ready for connections.forked process: 1267child process started successfully, parent exiting 设置副本集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465------------- 主节点-------------[root@master mongodb]# mongo 192.168.251.134:27017MongoDB shell version: 3.2.8connecting to: testServer has startup warnings: 2019-03-06T17:25:10.076+0800 I CONTROL [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2019-03-06T17:25:10.077+0800 I CONTROL [initandlisten] # 连接数据库，由于配置文件中绑定了ip，所以要用这个绑定的ip登陆&gt; rs.initiate()&#123; "info2" : "no configuration specified. Using a default configuration for the set", "me" : "192.168.251.134:27017", "ok" : 1&#125;# 登入任意一台机器的mongodb执行都可以，因为是全新的复制集，所以可以任意进入一台执行；要是一台有数据，则需要在有数据上执行；要多台有数据则不能初始化。# 也可以使用命令rs.initiate(&#123;_id:'repl1',members:[&#123;_id:1,host:'192.168.251.134:27017'&#125;]&#125;)# 选项意义如下：# _id：复制集名称（第一个_id） # members：复制集服务器列表 # _id：服务器的唯一ID（数组里_id） # host：服务器主机 # 我们操作的是192.168.251.134服务器，其中repl1即是复制集名称，和mongodb.conf中保持一致，初始化复制集的第一个服务器将会成为主复制集hqmongodb:OTHER&gt; rs.conf()&#123; "_id" : "hqmongodb", "version" : 1, "protocolVersion" : NumberLong(1), "members" : [ # 下面是主节点的信息 &#123; "_id" : 0, "host" : "192.168.251.134:27017", "arbiterOnly" : false, "buildIndexes" : true, "hidden" : false, "priority" : 1, "tags" : &#123; &#125;, "slaveDelay" : NumberLong(0), "votes" : 1 &#125; ], "settings" : &#123; "chainingAllowed" : true, "heartbeatIntervalMillis" : 2000, "heartbeatTimeoutSecs" : 10, "electionTimeoutMillis" : 10000, "getLastErrorModes" : &#123; &#125;, "getLastErrorDefaults" : &#123; "w" : 1, "wtimeout" : 0 &#125;, "replicaSetId" : ObjectId("5c80f458aa273710c786c4f1") &#125;&#125;# 通过rs.status()也可以查看复制集状态信息，192.168.251.134:27017已被自动分配为primary主复制集了hqmongodb:PRIMARY&gt; rs.add("192.168.251.133:27017")&#123; "ok" : 1 &#125;hqmongodb:PRIMARY&gt; rs.add("192.168.251.132:27017")&#123; "ok" : 1 &#125;# 增加192.168.251.132和133为从节点，如果有报错，建议关闭防火墙 设置优先级1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889------------ 主节点------------hqmongodb:PRIMARY&gt; cfg = rs.conf()&#123; "_id" : "hqmongodb", "version" : 3, "protocolVersion" : NumberLong(1), "members" : [ &#123; "_id" : 0, "host" : "192.168.251.134:27017", "arbiterOnly" : false, "buildIndexes" : true, "hidden" : false, "priority" : 1, "tags" : &#123; &#125;, "slaveDelay" : NumberLong(0), "votes" : 1 &#125;, &#123; "_id" : 1, "host" : "192.168.251.133:27017", "arbiterOnly" : false, "buildIndexes" : true, "hidden" : false, "priority" : 1, "tags" : &#123; &#125;, "slaveDelay" : NumberLong(0), "votes" : 1 &#125;, &#123; "_id" : 2, "host" : "192.168.251.132:27017", "arbiterOnly" : false, "buildIndexes" : true, "hidden" : false, "priority" : 1, "tags" : &#123; &#125;, "slaveDelay" : NumberLong(0), "votes" : 1 &#125; ], "settings" : &#123; "chainingAllowed" : true, "heartbeatIntervalMillis" : 2000, "heartbeatTimeoutSecs" : 10, "electionTimeoutMillis" : 10000, "getLastErrorModes" : &#123; &#125;, "getLastErrorDefaults" : &#123; "w" : 1, "wtimeout" : 0 &#125;, "replicaSetId" : ObjectId("5c80f458aa273710c786c4f1") &#125;&#125;# 将配置文件赋值给cfg，重启服务后可能对cfg的赋值会失效，所以要重新赋值hqmongodb:PRIMARY&gt; cfg.members[0].priority = 11hqmongodb:PRIMARY&gt; cfg.members[1].priority = 11hqmongodb:PRIMARY&gt; cfg.members[2].priority = 22# 设置_ID 为 2 的节点为主节点。即当当前主节点发生故障时，该节点就会转变为主节点接管服务。但测试发现，设置优先级并使配置生效后，_ID 为 2 的节点就会变为主节点，现在的主节点就变成了从节点hqmongodb:PRIMARY&gt; rs.reconfig(cfg)&#123; "ok" : 1 &#125;# 使配置生效# MongoDB副本集通过设置priority 决定优先级，默认优先级为1，priority值是0到100之间的数字，数字越大优先级越高，priority=0，则此节点永远不能成为主节点 primay。# cfg.members[0].priority =1 参数中括号里的数字是执行rs.conf()查看到的节点顺序， 第一个节点是0，第二个节点是 1，第三个节点是 2，以此类推。优先级最高的那个被设置为主节点。----------------- 从节点1&amp;2-----------------[root@slave1 mongodb]# mongo 192.168.251.133:27017hqmongodb:SECONDARY&gt; db.getMongo().setSlaveOk()# 设置从节点为只读.注意从节点的前缀现在是SECONDARY。# 最后还是将优先级改为了环境中所写的，Master主机的优先级改为了2，从节点的优先级都改为了1。===========================================================================================如果执行命令后出现报错： "errmsg" : "not master and slaveOk=false"，这是正常的，因为SECONDARY是不允许读写的，如果非要解决，方法如下：&gt; rs.slaveOk(); # 执行这个命令然后，再执行其它命令就不会出现这个报错了=========================================================================================== 开启登录验证123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172------------ 主节点------------[root@master ~]# mongo 192.168.251.134:27017hqmongodb:PRIMARY&gt; show dbslocal 0.000GBhqmongodb:PRIMARY&gt; use adminswitched to db admin# mongodb3.0没有admin数据库了，需要手动创建。admin库下添加的账号才是管理员账号hqmongodb:PRIMARY&gt; db.createUser(&#123;user:"system",pwd:"centos",roles:[&#123;role:"root",db:"admin"&#125;]&#125;)Successfully added user: &#123; "user" : "system", "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ]&#125;# 添加系统管理员账号system，用来管理用户hqmongodb:PRIMARY&gt; db.auth('system','centos')1# 添加管理员用户认证，认证之后才能管理所有数据库hqmongodb:PRIMARY&gt; db.createUser(&#123;user:'administrator',pwd:'centos',roles:[&#123;role:"userAdminAnyDatabase",db:"admin"&#125;]&#125;);Successfully added user: &#123; "user" : "administrator", "roles" : [ &#123; "role" : "userAdminAnyDatabase", "db" : "admin" &#125; ]&#125;# 添加数据库管理员,用来管理所有数据库hqmongodb:PRIMARY&gt; db.auth('administrator','centos')1# 添加管理员用户认证，认证之后才能管理所有数据库hqmongodb:PRIMARY&gt; dbadminhqmongodb:PRIMARY&gt; show collectionssystem.userssystem.versionhqmongodb:PRIMARY&gt; db.system.users.find()&#123; "_id" : "admin.system", "user" : "system", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "iDMoK7Qx7M3R4oMvt2rx/Q==", "storedKey" : "jxPOcQQwyd0kVwGX8xD2ohraan4=", "serverKey" : "Bo3fppRn9DaZ8Sjvd+fZiPHlq80=" &#125; &#125;, "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ] &#125;&#123; "_id" : "admin.administrator", "user" : "administrator", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "PjiXSi3vwtiJYDMZiSN80Q==", "storedKey" : "li7NAXV4xWA2htclWqXw/V9QgXI=", "serverKey" : "DFMcKQFJLarvhDjnP5kjK4PWzFs=" &#125; &#125;, "roles" : [ &#123; "role" : "userAdminAnyDatabase", "db" : "admin" &#125; ] &#125;# 查看hqmongodb:PRIMARY&gt; exitbye[root@master ~]# mongo 192.168.251.134:27017 -u system -p centos --authenticationDatabase admin[root@master ~]# mongo 192.168.251.134:27017 -u administrator -p centos --authenticationDatabase admin# 使用新帐号登录测试hqmongodb:PRIMARY&gt; exitbye[root@master ~]# cd /usr/local/mongodb/[root@master mongodb]# openssl rand -base64 21 &gt; keyfile# 创建一个 keyfile(使用 openssl 生成 21 位 base64 加密的字符串)。数字使用了 21，最好是 3 的倍数,否则生成的字符串可能含有非法字符，认证失败。[root@master mongodb]# chmod 600 keyfile [root@master mongodb]# cat keyfile FXXSNrmMnrTb5GgwCaWILKF1B/wZ# 查看刚才生成的字符串,做记录,后面要用到[root@master mongodb]# vim conf/mongodb.conf auth=truekeyFile=/usr/local/mongodb/keyfile# 加入两条信息，三台主机都要改[root@master mongodb]# scp keyfile 192.168.251.133:/usr/local/mongodb/[root@master mongodb]# scp keyfile 192.168.251.132:/usr/local/mongodb/# 将密钥复制到从节点，注意权限一定是600[root@master mongodb]# mongod --shutdown -f conf/mongodb.conf[root@master mongodb]# mongod -f conf/mongodb.conf# 重启服务----------------- 从节点1&amp;2-----------------[root@slave1 mongodb]# vim conf/mongodb.conf auth=truekeyFile=/usr/local/mongodb/keyfile[root@slave1 mongodb]# mongod --shutdown -f conf/mongodb.conf[root@slave1 mongodb]# mongod -f conf/mongodb.conf# 三台主机都要重启服务------------ 主节点------------[root@master mongodb]# mongo 192.168.251.134:27017MongoDB shell version: 3.2.8connecting to: 192.168.251.134:27017/testhqmongodb:PRIMARY&gt; rs.status(... )&#123; "ok" : 0, "errmsg" : "not authorized on admin to execute command &#123; replSetGetStatus: 1.0 &#125;", "code" : 13&#125;# 登录时如果不指定用户名和密码，操作数据库时会有报错。hqmongodb:PRIMARY&gt; exit[root@master mongodb]# mongo 192.168.251.134:27017 -u system -p centos --authenticationDatabase adminMongoDB shell version: 3.2.8connecting to: 192.168.251.134:27017/testServer has startup warnings: 2019-03-08T15:13:49.020+0800 I CONTROL [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2019-03-08T15:13:49.020+0800 I CONTROL [initandlisten] hqmongodb:PRIMARY&gt; hqmongodb:PRIMARY&gt; rs.status()&#123; "set" : "hqmongodb", "date" : ISODate("2019-03-08T07:15:11.774Z"), "myState" : 1, "term" : NumberLong(2), "heartbeatIntervalMillis" : NumberLong(2000), "members" : [ &#123; "_id" : 0, "name" : "192.168.251.134:27017", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 83, "optime" : &#123; "ts" : Timestamp(1552029240, 1), "t" : NumberLong(2) &#125;, "optimeDate" : ISODate("2019-03-08T07:14:00Z"), "electionTime" : Timestamp(1552029239, 1), "electionDate" : ISODate("2019-03-08T07:13:59Z"), "configVersion" : 3, "self" : true &#125;, &#123; "_id" : 1, "name" : "192.168.251.133:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 72, "optime" : &#123; "ts" : Timestamp(1552029240, 1), "t" : NumberLong(2) &#125;, "optimeDate" : ISODate("2019-03-08T07:14:00Z"), "lastHeartbeat" : ISODate("2019-03-08T07:15:11.610Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T07:15:11.347Z"), "pingMs" : NumberLong(0), "syncingTo" : "192.168.251.132:27017", "configVersion" : 3 &#125;, &#123; "_id" : 2, "name" : "192.168.251.132:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 72, "optime" : &#123; "ts" : Timestamp(1552029240, 1), "t" : NumberLong(2) &#125;, "optimeDate" : ISODate("2019-03-08T07:14:00Z"), "lastHeartbeat" : ISODate("2019-03-08T07:15:11.636Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T07:15:11.578Z"), "pingMs" : NumberLong(0), "syncingTo" : "192.168.251.134:27017", "configVersion" : 3 &#125; ], "ok" : 1&#125;# 使用用户名和密码登录后操作就没问题了# 注意上面命令结果中的state,如果这个值为 1,说明是主控节点(master);如果是2，说明是从属节点slave。在上面显示的当前主节点写入数据，到从节点上查看发现数据会同步。# 日志查看1234567891011121314151617181920hqmongodb:PRIMARY&gt; use localswitched to db localhqmongodb:PRIMARY&gt; db.oplog.rs.find()&#123; "ts" : Timestamp(1552028565, 1), "h" : NumberLong("4391722300525823791"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "initiating set" &#125; &#125;&#123; "ts" : Timestamp(1552028566, 1), "t" : NumberLong(1), "h" : NumberLong("8449179963384189305"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "new primary" &#125; &#125;&#123; "ts" : Timestamp(1552028609, 1), "t" : NumberLong(1), "h" : NumberLong("-8014254993634545405"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "Reconfig set", "version" : 2 &#125; &#125;&#123; "ts" : Timestamp(1552028614, 1), "t" : NumberLong(1), "h" : NumberLong("1448067838065630949"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "Reconfig set", "version" : 3 &#125; &#125;&#123; "ts" : Timestamp(1552028878, 1), "t" : NumberLong(1), "h" : NumberLong("7482679933079682833"), "v" : 2, "op" : "c", "ns" : "admin.$cmd", "o" : &#123; "create" : "system.version" &#125; &#125;&#123; "ts" : Timestamp(1552028878, 2), "t" : NumberLong(1), "h" : NumberLong("-4363891485786841171"), "v" : 2, "op" : "i", "ns" : "admin.system.version", "o" : &#123; "_id" : "authSchema", "currentVersion" : 5 &#125; &#125;&#123; "ts" : Timestamp(1552028878, 3), "t" : NumberLong(1), "h" : NumberLong("6832610854355231587"), "v" : 2, "op" : "c", "ns" : "admin.$cmd", "o" : &#123; "create" : "system.users" &#125; &#125;&#123; "ts" : Timestamp(1552028878, 4), "t" : NumberLong(1), "h" : NumberLong("5754891887687461455"), "v" : 2, "op" : "i", "ns" : "admin.system.users", "o" : &#123; "_id" : "admin.system", "user" : "system", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "SOJmBhWoRzjsxLFmoRuUUQ==", "storedKey" : "MpRbzaW4wVAuw8zXISVek+VM71E=", "serverKey" : "l/BxWT12M+F3luMwT5bMIfGt8yw=" &#125; &#125;, "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ] &#125; &#125;&#123; "ts" : Timestamp(1552028973, 1), "t" : NumberLong(1), "h" : NumberLong("-7924226021042987469"), "v" : 2, "op" : "i", "ns" : "admin.system.users", "o" : &#123; "_id" : "admin.administrator", "user" : "administrator", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "ptoSffZtwnu47uBhhU9lMA==", "storedKey" : "409n1lhVnzWex3+Ua4Owx7GAanE=", "serverKey" : "jsf8UFDCNxfRDwL7hseh21EehJ8=" &#125; &#125;, "roles" : [ &#123; "role" : "userAdminAnyDatabase", "db" : "admin" &#125; ] &#125; &#125;&#123; "ts" : Timestamp(1552029240, 1), "t" : NumberLong(2), "h" : NumberLong("6978081991940203547"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "new primary" &#125; &#125;# 字段说明:# ts：某个操作的时间戳# op：操作类型，如下:# i：insert# d：delete# u：update# ns：命名空间，也就是操作的 collection name 添加仲裁节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140hqmongodb:SECONDARY&gt; rs.stepDown()2019-03-08T16:05:41.426+0800 E QUERY [thread1] Error: error doing query: failed: network error while attempting to run command 'replSetStepDown' on host '192.168.251.133:27017' :DB.prototype.runCommand@src/mongo/shell/db.js:135:1DB.prototype.adminCommand@src/mongo/shell/db.js:153:16rs.stepDown@src/mongo/shell/utils.js:1182:12@(shell):1:12019-03-08T16:05:41.428+0800 I NETWORK [thread1] trying reconnect to 192.168.251.133:27017 (192.168.251.133) failed2019-03-08T16:05:41.429+0800 I NETWORK [thread1] reconnect 192.168.251.133:27017 (192.168.251.133) ok# 人为让主节点关闭，成为从节点，如果括号中有数字，就表示多久不能成为主节点。这时三个节点都会是从节点，如果哪个从节点进行了操作，就会成为主节点。hqmongodb:SECONDARY&gt; rs.status()&#123; "set" : "hqmongodb", "date" : ISODate("2019-03-08T08:05:46.805Z"), "myState" : 2, "term" : NumberLong(4), "heartbeatIntervalMillis" : NumberLong(2000), "members" : [ &#123; "_id" : 0, "name" : "192.168.251.134:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 3110, "optime" : &#123; "ts" : Timestamp(1552032275, 1), "t" : NumberLong(4) &#125;, "optimeDate" : ISODate("2019-03-08T08:04:35Z"), "lastHeartbeat" : ISODate("2019-03-08T08:05:42.774Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T08:05:46.630Z"), "pingMs" : NumberLong(0), "configVersion" : 3 &#125;, &#123; "_id" : 1, "name" : "192.168.251.133:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 3111, "optime" : &#123; "ts" : Timestamp(1552032275, 1), "t" : NumberLong(4) &#125;, "optimeDate" : ISODate("2019-03-08T08:04:35Z"), "infoMessage" : "could not find member to sync from", "configVersion" : 3, "self" : true &#125;, &#123; "_id" : 2, "name" : "192.168.251.132:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 3105, "optime" : &#123; "ts" : Timestamp(1552032275, 1), "t" : NumberLong(4) &#125;, "optimeDate" : ISODate("2019-03-08T08:04:35Z"), "lastHeartbeat" : ISODate("2019-03-08T08:05:42.774Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T08:05:46.406Z"), "pingMs" : NumberLong(0), "configVersion" : 3 &#125; ], "ok" : 1&#125;------------- 主节点-------------hqmongodb:PRIMARY&gt; rs.remove("192.168.251.132:27017")&#123; "ok" : 1 &#125;# 删除一个从节点hqmongodb:PRIMARY&gt; rs.addArb("192.168.251.132:27017")&#123; "ok" : 1 &#125;# 将删除的从节点添加为仲裁节点hqmongodb:PRIMARY&gt; rs.status()&#123; "set" : "hqmongodb", "date" : ISODate("2019-03-08T08:12:35.701Z"), "myState" : 1, "term" : NumberLong(5), "heartbeatIntervalMillis" : NumberLong(2000), "members" : [ &#123; "_id" : 0, "name" : "192.168.251.134:27017", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 3527, "optime" : &#123; "ts" : Timestamp(1552032749, 1), "t" : NumberLong(5) &#125;, "optimeDate" : ISODate("2019-03-08T08:12:29Z"), "electionTime" : Timestamp(1552032350, 1), "electionDate" : ISODate("2019-03-08T08:05:50Z"), "configVersion" : 5, "self" : true &#125;, &#123; "_id" : 1, "name" : "192.168.251.133:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 3516, "optime" : &#123; "ts" : Timestamp(1552032749, 1), "t" : NumberLong(5) &#125;, "optimeDate" : ISODate("2019-03-08T08:12:29Z"), "lastHeartbeat" : ISODate("2019-03-08T08:12:33.719Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T08:12:34.787Z"), "pingMs" : NumberLong(2), "syncingTo" : "192.168.251.134:27017", "configVersion" : 5 &#125;, &#123; "_id" : 2, "name" : "192.168.251.132:27017", "health" : 1, "state" : 7, "stateStr" : "ARBITER", "uptime" : 3, "lastHeartbeat" : ISODate("2019-03-08T08:12:33.751Z"), "lastHeartbeatRecv" : ISODate("2019-03-08T08:12:30.829Z"), "pingMs" : NumberLong(0), "configVersion" : 5 &#125; ], "ok" : 1&#125;# 查看，_id为2的节点的stateStr变成了ARBITER 测试副本集secondary节点数据复制功能123456789101112131415161718192021222324252627282930313233343536373839404142------------- 主节点-------------repl1:PRIMARY&gt; dbDBCommandCursor( DBExplainQuery( DBPointer( dbrepl1:PRIMARY&gt; dbtestrepl1:PRIMARY&gt; show collectionsrepl1:PRIMARY&gt; for(var i =0; i &lt;4; i ++)&#123;db.user.insert(&#123;userName:'gxt'+i,age:i&#125;)&#125;WriteResult(&#123; "nInserted" : 1 &#125;)repl1:PRIMARY&gt; show collectionsuserrepl1:PRIMARY&gt; db.user.find()&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b7"), "userName" : "gxt0", "age" : 0 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b8"), "userName" : "gxt1", "age" : 1 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b9"), "userName" : "gxt2", "age" : 2 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6ba"), "userName" : "gxt3", "age" : 3 &#125;------------- 从节点-------------repl1:SECONDARY&gt; dbtestrepl1:SECONDARY&gt; show collections2019-03-06T17:51:59.721+0800 E QUERY [thread1] Error: listCollections failed: &#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; :_getErrorWithCode@src/mongo/shell/utils.js:25:13DB.prototype._getCollectionInfosCommand@src/mongo/shell/db.js:773:1DB.prototype.getCollectionInfos@src/mongo/shell/db.js:785:19DB.prototype.getCollectionNames@src/mongo/shell/db.js:796:16shellHelper.show@src/mongo/shell/utils.js:754:9shellHelper@src/mongo/shell/utils.js:651:15@(shellhelp2):1:1repl1:SECONDARY&gt; rs.slaveOk()repl1:SECONDARY&gt; show collectionsuserrepl1:SECONDARY&gt; db.user.find()&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b9"), "userName" : "gxt2", "age" : 2 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6ba"), "userName" : "gxt3", "age" : 3 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b8"), "userName" : "gxt1", "age" : 1 &#125;&#123; "_id" : ObjectId("5c7f94f0dcfc5b45e0a0f6b7"), "userName" : "gxt0", "age" : 0 &#125;# 通过db.user.find()查询到和主复制集上一样的数据，表示数据同步成功！# "errmsg" : "not master and slaveOk=false"错误说明：因为secondary是不允许读写的，如果非要解决，则执行：rs.slaveOk()]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB安装]]></title>
    <url>%2F2019%2F03%2F06%2FMongoDB%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装与启动1234567891011121314151617181920212223242526272829303132333435============================================================================================环境：一台主机，地址：192.168.251.129============================================================================================[root@test ~]# cat &gt;&gt; /etc/rc.local &lt;&lt;'EOF'if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledfiif test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never &gt; /sys/kernel/mm/transparent_hugepage/defragfiEOF# 该方法仅限与CentOS系统使用。Transparent Huge Pages (THP)，通过使用更大的内存页面，可以减少具有大量内存的机器上的缓冲区（TLB）查找的开销。但是，数据库工作负载通常对THP表现不佳，因为它们往往具有稀疏而不是连续的内存访问模式。您应该在Linux机器上禁用THP，以确保MongoDB的最佳性能。[root@test ~]# chmod +x /etc/rc.d/rc.local[root@test ~]# wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.8.tgz[root@test ~]# tar xf mongodb-linux-x86_64-rhel62-3.2.8.tgz[root@test ~]# mv mongodb-linux-x86_64-rhel62-3.2.8 /usr/local/mongodb[root@test ~]# mkdir /usr/local/mongodb/&#123;log,data,conf&#125;[root@test ~]# vim .bash_profileexport PATH=/usr/local/mongodb/bin:$PATH[root@test ~]# source .bash_profile[root@test ~]# mongod --dbpath=/usr/local/mongodb/data/ --logpath=/usr/local/mongodb/log/mongodb.log --port=27017 --logappend --fork# 启动服务。默认的数据库路径是/data/db，如果单独指定数据库路径的话，一定要创建这个数据目录，不然启动会失败，使用mongod就可以直接启动服务。# --dbpath：数据存放路径；--logpath：日志文件路径；--logappend：日志输出方式；--port：启用端口号；--fork：在后台运行；--auth：是否需要验证权限登录(用户名和密码)；--bind_ip：限制访问的ip；--shutdown：关闭数据库；--rest：通过HTTP访问用户界面。默认mongodb监听在27017端口，web页面监听28017端口。about to fork child process, waiting until server is ready for connections.forked process: 5118child process started successfully, parent exiting[root@test ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 *:27017 *:* [root@test ~]# mongod --shutdown --dbpath=/usr/local/mongodb/data/ --logpath=/usr/local/mongodb/log/mongodb.log --port=27017 --logappend --forkkilling process with pid: 5118# 关闭服务 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748========== 普通格式==========[root@test ~]# vim /usr/local/mongodb/conf/mongod1.confport=27017bind_ip = 192.168.251.129 # 这个最好配置成本机的ip地址。否则后面进行副本集初始化的时候可能会失败！ dbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/log/mongo.logpidfilepath=/usr/local/mongodb/mongo.pidfork=truelogappend=trueshardsvr=truedirectoryperdb=true# auth=true# keyFile =/usr/local/mongodb/keyfile# replSet =hqmongodb[root@test ~]# mongod -f /usr/local/mongodb/conf/mongod1.conf about to fork child process, waiting until server is ready for connections.forked process: 5201child process started successfully, parent exiting# 启动[root@test ~]# mongod -f /usr/local/mongodb/conf/mongod1.conf --shutdownkilling process with pid: 5201# 关闭========== YAML格式==========# 3.X 版本官方推荐使用[root@test ~]# vim /usr/local/mongodb/conf/mongod.confsystemLog: destination: file path: "/usr/local/mongodb/log/mongod.log" logAppend: truestorage: journal: enabled: true dbPath: "/usr/local/mongodb/data"processManagement: fork: truenet: port: 27017# 注意有空格的行，都是四个空格或八个空格，不要使用Tab键，启动时可能会报错："Error parsing YAML config file: yaml-cpp: error at line 7, column 2: end of map not found"[root@test ~]# mongod -f /usr/local/mongodb/conf/mongod.conf about to fork child process, waiting until server is ready for connections.forked process: 5250child process started successfully, parent exiting]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS优化]]></title>
    <url>%2F2019%2F03%2F05%2FCentOS%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[文件句柄数1234567891011* 临时调整[root@template ~]# ulimit -n1024[root@template ~]# ulimit -n 65535[root@template ~]# ulimit -n65535* 永久生效[root@template ~]# vim /etc/security/limits.conf* soft nofile 65535* hard nofile 65535 调整历史记录及连接超时123456789[root@template ~]# vim /etc/bashrcHISTFILESIZE=4000HISTSIZE=4000HISTTIMEFORMAT='%F %T 'export HISTTIMEFORMAT# 添加上面四行。HISTFILESIZE定义了.bash_history中保存命令的总数，默认是1000，这里改成了4000，HISTSIZE设置了history命令输出最多的记录总数，HISTTIMEFORMAT定了时间显示格式。#以前的操作记录都会显示更改/etc/bashrc文件的时间，而不是真正的操作时间，只有更改完/etc/bashrc以后的操作记录会显示正确的时间export TMOUT=10# 置连接会话的超时时间 同步时间12345678* 查看时区[root@template ~]# cat /etc/sysconfig/clock ZONE="Asia/Shanghai"* 同步时间[root@template ~]# ntpdate cn.pool.ntp.org[root@template ~]#crontab -e0 10 * * * /usr/sbin/ntpdate cn.pool.ntp.org 调整yum源12cp CentOS-Base.repo&#123;,.$(date +%F)&#125;wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 更改SSH服务端远程登录的配置1234567891011[root@template ~]# cp /etc/ssh/sshd_config&#123;,.bak&#125;[root@template ~]# vim /etc/ssh/sshd_configPort 52113 # ssh连接默认的端口PermitRootLogin no # 禁止root登录PermitEmptyPasswords no # 禁止空密码登录，此项默认就是noUseDNS no # 不使用DNS解析地址[root@template ~]# /etc/init.d/sshd restart 锁定关键系统文件12345678[root@template ~]# chattr +i /etc/passwd /etc/inittab /etc/group /etc/shadow /etc/gshadow# attr命令用于改变文件属性，i选项表示不得任意更动文件或目录。这时创建用户或组的命令执行也会失败。[root@template ~]# ll /etc/gshadow---------- 1 root root 631 1月 18 18:38 /etc/gshadow[root@template ~]# ll /etc/shadow---------- 1 root root 1259 1月 18 18:40 /etc/shadow[root@template ~]# chattr -i /etc/shadow# 使用-i可以解锁]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python概念及语法]]></title>
    <url>%2F2019%2F02%2F15%2Fpython%E6%A6%82%E5%BF%B5%E5%8F%8A%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概念编译器与解释器 编译器是把源程序的每一条语句都编译成机器语言，并保存成二进制文件，这样运行时计算机可以直接以机器语言来运行此程序，速度很快；它把源代码转换成目标机器的CPU指令 而解释器则是只在执行程序时，才一条一条的解释成机器语言给计算机来执行，所以运行速度是不如编译后的程序运行的快的。解释后转换成字节码，运行在虚拟机上，解释器执行中间代码。 这是因为计算机不能直接认识并执行我们写的语句，它只能认识机器语言(是二进制的形式)。 编译型语言与解释型语言 编译型优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。 解释型优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。 缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。 低级语言与高级语言 低级语言 面向机器的语言，包括机器语言、汇编语言 不同的机器不能通用，不同的机器需要不同的机器指令或者汇编程序 高级语言 接近自然语言和数学语言的计算机语言 高级语言首先要书写源程序，通过编译程序把源程序转换成机器指令的程序 人们只需要关心怎么书写源程序，针对不同机器的编译的事交给编译器处理 语言越高级，越接近人类的自然语言和数学语言。语言越低级，越能让机器理解。高级语言和低级语言之间需要一个转换的工具，就是编译器或解释器。 动态语言和静态语言 动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python和Ruby就是一种典型的动态类型语言，其他的各种脚本语言如VBScript也多少属于动态类型语言。 静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++是静态类型语言的典型代表，其他的静态类型语言还有C#、JAVA等。 强类型定义语言和弱类型定义语言 强类型语言：不同类型之间操作，必须先强制类型转换为同一类型。print(‘a’+1) 弱类型语言：不同类型间可以操作，自动隐式转换，JavaScript中console.log(1+’a’) 基础语法 注释：# 标注的文本 数字： 整数，不区分long和int。可使用二进制、十进制、十六进制。bool(布尔)有两个值True和False 浮点数：1.2、3.1415、-0.12、1.46e9等价于1.46*10的9次方 复数：1+2j 字符串： 使用’ “ 单双引号引用的字符的序列 ‘’’和””” 单双三引号，可以跨行、可以在其中自由的使用单双引号 在字符串前面加上r或R前缀，表示该字符串不做特殊的处理 转义序列 \\ \t \r \n \‘ \“ 前缀r，把里面的所有字符当普通字符对待 缩进 未使用C等语言的花括号，而是采用缩进的方式表示层次关系 约定使用4个空格缩进 续行 在行尾使用\ 如果使用各种括号，认为括号内是一个整体，内部跨行不用\ 标识符 一个名字，用来指代一个值 只能字母、下划线和数字 只能以字母或下划线开头 不能是python的关键字，如def、class就不能作为标识符 python是大小写敏感的 约定： 不允许使用中文 不允许使用歧义单词，如class_ 在python中不要随便使用下划线开头的表示符 常量 一旦赋值就不能改变值的标识符 python中无法定义常量 字面常量 一个单独的量，如12、”abc”、’234531.03e-9’ 变量 赋值后，可以改变值的标识符 运算符算数运算符 运算符 描述 实例 + 两个对象相加 a + b输出结果30；a=10, b=20 - 得到负数或是一个数减去另一个数 a - b输出结果-10 * 两个数相乘或是返回一个被重复若干次的字符串 a * b输出结果200 / x除以y b / a输出结果2 % 返回除法的余数 b % a输出结果0 ** 返回x的y次幂 a ** b为10的20次方，输出结果1000000000000000000 // 返回商的整数部分 9 // 2输出结果4，9.0//2.0输出结果4.0 比较运算符 运算符 描述 实例 == 比较两个对象是否相等 (a == b)返回False != 比较两个对象是否不等 (a != b)返回true &lt;&gt; 比较两个对象是否不等 (a &lt;&gt; b)返回true。这个运算符类似!= &gt; 返回x是否大于y，返回一个bool值 (a &gt; b)返回False；4&gt;3&gt;2或4&gt;mynumber&gt;=1是链式比较操作符 &lt; 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。注意，这些变量名的大写。 (a &lt; b)返回true &gt;= 返回x是否大于等于y (a &gt;= b)返回False &lt;= 返回x是否小于等于y (a &lt;= b)返回true 赋值运算符 运算符 描述 实例 = 简单的赋值运算符 c = a+b将a + b的运算结果赋值为c += 加法赋值运算符 c += a等效于c = c + a -= 减法赋值运算符 c -= a等效于c = c - a *= 乘法赋值运算符 c *= a等效于c = c * a /= 除法赋值运算符 c /= a等效于c = c / a %= 取模赋值运算符 c %= a等效于c = c % a **= 幂赋值运算符 c **= a等效于c = c ** a //= 取整除赋值运算符 c //= a等效于c = c // a 逻辑运算符 短路运算符，可以把and当作乘法，把or当作加法，非是取反。and：如果第一个表达式为False，后面就没有必要计算了，这个逻辑表达式一定是False；or：如果第一个表达式为True，后面没有必要计算了，这个逻辑表达式一定是True 运算符 描述 实例 and 布尔“与”，如果x为False，x and y返回False，否则它返回y的计算值 (a and b)返回true or 布尔“或”，如果x是True，它返回True，否则它返回y的计算值 (a or b)返回true not 布尔“非”，如果x为True，返回False。如果x为False，它返回True not(a and b)返回false 成员运算符 运算符 描述 实例 in 如果在指定的序列中找到值返回True，否则返回False x在y序列中，如果x在y序列中返回True not in 如果在指定的序列中没有找到值返回True，否则返回False x不在y序列中，如果x不在y序列中返回True 身份运算符 运算符 描述 实例 is is是判断两个标识符是不是引用自一个对象 x is y，如果id(x)等于id(y)，is返回结果1 is not is not是判断两个标识符是不是引用自不同对象 x is not y，如果id(x)不等于id(y)，is not返回结果1 位运算符 运算符 描述 实例 &amp; 按位与运算符 (a &amp; b)输出结果12，二进制解释：0000 1100。只有1和1相与得1，其他相与都是0 I 按位或运算符 (a I b)输出结果61，二进制解释：0011 1101 ^ 按位异或运算符 (a ^ b)输出结果49，二进制解释：0011 0001 ~ 按位取反运算符 (~a)输出结果-61，二进制解释：1100 0011，在一个有符号二进制数的补码形式 &lt;&lt; 左移动运算符 a &lt;&lt; 2输出结果240，二进制解释：1111 0000 &gt;&gt; 右移动运算符 a &gt;&gt; 2输出结果15，二进制解释：0000 1111 运算符优先级 算数运算符 &gt; 位运算符 &gt; 身份运算符 &gt; 成员运算符 &gt; 逻辑运算符 记不住，就用小括号 长表达式，多用括号，易懂、易读 原码、反码、补码、负数表示法 原码 5 =&gt; 0b101，1 =&gt; 0b1，-1 =&gt; -0b1，bin(-1) 反码 正数的反码与原码相同；负数的反码符号位不变其余按位取反 补码 正数的补码与原码相同；负数的补码符号位不变其余按位取反后+1；补码的补码就是原码 负数表示法 数字电路的CPU中的运算器实现了加法器，但是没有减法器，减法是转换成加法 负数在计算机中使用补码存储，-1的补码为1111 1111 5 - 1 =&gt; 5+(-1)直觉上是0b101-0b1，其实计算机中是0b101+0b11111111，溢出位舍弃 123456789101112131415例：5-1保存为二进制0000 0101 # 5的二进制。原码是人比较习惯的方式，-0b1中的负号表示转换为二进制数字时在最高位是0还是1，1表示负号，0表示正号。-0b1是python中的写法。-0b1也就是原码1111 1111 # -1的二进制，因为计算机中保存的都是补码，而正数的原码与补码一样，所以上面的5不会变。-1的二进制是1000 0001，转换为补码后，除最高位的符号位不变外，还要加1，就是1111 1110 + 1，所以最后就是1111 11111 0000 0100# 这是5和-1的二进制相加后的结果，因为最高位的1溢出了，所以舍弃，最后就变成了0000 0100，也就是4了例：~12为什么是-130000 1100# 这是12的二进制1111 0011# 这是对12的二进制取反后的数，但最高位是1表示负数，并且保存在计算机中的应该是数字的补码，所以要取这个负数的补码1000 1101# 这是对上面二进制数取的补码，因为上面表示负数，所以按照最高位不变最后加1的原则，取出的二进制数就是这个数，转换为十进制数就是-13了。 内存管理 变量无须事先声明，也不需要指定类型 编程中一般无须关心变量的存亡，也不用关心内存的管理 python使用引用 计数记录所有对象的引用数。当对象引用数变为0,它就可以被垃圾回收（GC）了。 计数增加：赋值给其它变量就增加引用计数，例如：x=3;y=x 计数减少：函数运行结束时，局部变量就会被自动销毁，对象引用计数减少。变量被赋值给其它对象。例如：x=3;y=x;x=4 程序控制 顺序 按照先后顺序一条条执行 分支 根据不同的情况判断，条件满足执行某条件下的语句 循环 条件满足就反复执行，不满足就不执行或不再执行 单分支结构1234567891011121314151617181920if语句if condition: 代码块# condition必须是一个bool类型，这个地方有一个隐式转换bool(condition)if 1 &lt; 2: print('1 less than 2')# 代码块：类似于if语句的冒号后面的就是一个语句块 =======================================================================================真值表"" 假"string" 真0 假&gt;=1 真&lt;=-1 真()空元组 假[]空列表 假&#123;&#125;空字典 假None 假======================================================================================= 三目运算123语法：真值if条件else假值x if(x&gt;y) else yprint((x if (x&gt;y) else y) if ((x if (x&gt;y) else y)&gt;z) else z) 多分支结构12345678910111213141516171819if...elif...else语句if condition1: 代码块1elif condition2: 代码块2elif condition3: 代码块3... ...else: 代码块例：a = 5if a &lt; 0: print('negative')elif a == 0: print('zero')else: print('positive') 分支嵌套1234567891011例：score = 80if score &lt; 0: print('wrong')else: if sore == 0: print('egg') elif score &lt;= 100: print('right') else: print('too big') while循环1234567891011while condition: block# 当条件满足即condition为True，进入循环体，执行block例：flag = 10while flag: print(flag) flag -= 1# lag是标记，while flag也就是while为真，flag会递减，等flag等于0时，while就会退出循环了# while true是死循环，因为条件永远为真，不会变成假。如果 改为-10也会是死循环，可以使用return退出死循环 for循环1234567891011121314151617181920212223242526272829303132333435363738for element in iteratable: block# 当可迭代对象中有元素可以迭代，进入循环体，执行block例：for i in range(10): print(i+1)# range()函数类似seq命令，range(10)可以输出从0到9，共10个数字# iteratable表示迭代的，element表示元素。In [1]: range? Init signature: range(self, /, *args, **kwargs)Docstring: range(stop) -&gt; range objectrange(start, stop[, step]) -&gt; range objectReturn an object that produces a sequence of integers from start (inclusive)to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1.start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3.These are exactly the valid indices for a list of 4 elements.When step is given, it specifies the increment (or decrement).Type: typeSubclasses: # range?可以查看帮助In [4]: for i in range(3,5): ...: print(i) ...: 34# 只会输出3和4In [5]: for i in range(2,6,2): ...: print(i) ...: 24# 还可以加上步长 循环continue语句12345678910111213141516171819202122232425262728293031323334中断当前循环的当次执行，继续下一次循环例：In [7]: for i in range(10): ...: if not i%2: ...: print(i) ...: 02468# 这里会打印偶数是因为range中的数字与2取余后，如果是0就表示假，1表示真，但取余前加了not，所以假就变成了真，所以打印的是偶数，如果不加not，那么就会打印所有奇数。In [9]: for i in range(0,10,2): ...: print(i) ...: 02468# 直接使用range()函数就可以打印奇偶数In [10]: for i in range(0,10): ...: if i &amp; 1: ...: continue ...: print(i) ...: 02468# range()函数内的数字和1按位与，如果为真，也就是1，就会中断当前循环，如果为假就会打印i 循环break语句123456789终止当前循环，跳出循环例：计算1000以内的被7整除的前20个数（for循环）count = 0for i in range(0,1000,7): print(i) count += 1 if count == 20: break# range必须从0开始，如果从1开始，那么永远到不了7的整数倍。但这样也会打印0 continue和break语句总结 continue和break是循环的控制语句，只影响当前循环，包括while、for循环 如果循环嵌套，continue和break也只影响语句所在的那一层循环 continue和break不是跳出语句块，所以if cond: break不是跳出if，而是终止if外的break所在的循环 循环else子句12345678910# 如果循环正常的执行结束，就执行else子句；如果使用break终止，else子句不会执行while condition: blockelse: block for element in iteratable: blockelse: block 练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748491. 输入2个数字，输出最大数a = input('&gt;&gt;&gt;')b = input('&gt;&gt;&gt;')while a == b: print('请重新输入') a = input('&gt;&gt;&gt;') b = input('&gt;&gt;&gt;') if a &gt; b: print(a) else: print(b)2. 给定一个不超过5位的正整数，判断其有几位# 使用input函数，例：input函数获取键盘输入，input([prompt])。input()是内建函数，返回的是字符串。下划线在ipython中是一个特殊的字符，表示上一次output的结果。a = int(input('&gt;&gt;&gt;'))if a // 100000: print('6位数')elif a // 10000: print('5位数')elif a // 1000: print('4位数')elif a // 100: print('3位数')elif a // 10: print('2位数')elif a // 1: print('1位数') 3. 给定一个不超过5位的正整数，判断该数的位数，依次打印出个位、十位、百位、千位、万位的数字4. 打印一个连长为n的正方形5. 求100内所有奇数的和(2500)6. 判断学生成绩，成绩等级A~E。其中，90分以上为A，80～89分为B，70～79分为C，60～69分为D，60分以下为E7. 求1到5阶乘之和8. 给一个数，判断它是否是素数（质数）。质数：一个大于1的自然数只能被1和它本身整除9. 打印九九乘法表10. 打印菱形11. 打印100以内的斐波那契数列12. 求斐波那契数列第101项13. 求10万内的所有素数]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[puppet的master&agent认证]]></title>
    <url>%2F2019%2F01%2F31%2Fpuppet%E7%9A%84master-agent%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[mastar&amp;agent手动注册123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233===========================================================================================手动注册是由Agent端先发起证书申请请求，然后由Puppetserver端确认，方可注册成功，这种注册方式安全系数中等，逐一注册（puppet cert --sign certnmame）在节点数量较大的情况下是比较麻烦的，效率也低，批量注册(puppet cert --sign --all)效率很高，一次性便可注册所有的Agent的请求，但是这种方式安全系数较低，因为错误的请求也会被注册上。环境master：192.168.1.70agent1：192.168.1.71agent2：192.168.1.72===========================================================================================------------ master------------[root@puppet ~]# hostnamectl set-hostname master.ruopu.com[root@master ~]# vim /etc/hosts192.168.1.70 master.ruopu.com192.168.1.71 node1.ruopu.com192.168.1.72 node2.ruopu.com[root@master ~]# rsync -e ssh -arvz --progress /etc/hosts 192.168.1.71:/etc[root@master ~]# rsync -e ssh -arvz --progress /etc/hosts 192.168.1.72:/etc# 主机名的修改非常重要，必须做。让三台主机可以互相解析[root@puppet ~]# yum install -y puppt puppet-server facter tree[root@puppet ~]# vim /etc/puppet/puppet.conf[main] logdir = /var/log/puppet # 默认日志存放路径 rundir = /var/run/puppet # pid存放路径 ssldir = $vardir/ssl # 证书存放目录，默认$vardir为/var/lib/puppet[agent] classfile = $vardir/classes.txt localconfig = $vardir/localconfig server = master.ruopu.com # 设置agent认证连接master端的服务器名称，注意这个名字必须能够被节点解析 certname = master.ruopu.com # 设置agent端certname名称[master] certname = master.ruopu.com # 设置puppetmaster认证服务器名[root@puppet ~]# touch /etc/puppet/manifests/site.pp[root@puppet ~]# systemctl start puppetmaster # 启动服务端，自动生成CA证书，并签署。[root@master ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:8140 *:* # 监听在8140端口[root@puppet ~]# tree /var/lib/puppet/ssl//var/lib/puppet/ssl/├── ca│ ├── ca_crl.pem│ ├── ca_crt.pem│ ├── ca_key.pem│ ├── ca_pub.pem│ ├── inventory.txt│ ├── private│ │ └── ca.pass│ ├── requests│ ├── serial│ └── signed│ └── master.ruopu.com.pem# 可以看到，signed中已经有服务端了，证明服务器已被认证[root@puppet ~]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")# 有加号的证明是已被认证的主机[root@puppet ~]# tail -f /var/log/puppet/masterhttp.log# 监听日志--------------- agent1&amp;2---------------[root@puppettest1 ~]# hostnamectl set-hostname node1.ruopu.com[root@puppettest1 ~]# yum install -y puppet facter[root@node1 ~]# vim /etc/puppet/puppet.conf [main] logdir = /var/log/puppet rundir = /var/run/puppet ssldir = $vardir/ssl[agent] classfile = $vardir/classes.txt localconfig = $vardir/localconfig server = master.ruopu.com # 指向puppetmaster端 certname = node1.ruopu.com # 设置自己的certname名 listen = true # 让puppet监听8139端口 [root@node1 ~]# vim /etc/puppet/auth.confpath /runmethod saveauth anyallow master.ruopu.com# 在文件尾部path /的上方加入上面内容[root@puppettest1 ~]# systemctl start puppetagent# 启动客户端------------ master------------[root@master ~]# puppet cert --list --all "node1.ruopu.com" (SHA256) F8:DF:B8:26:AE:92:5D:26:96:D9:21:AE:92:3F:84:40:6F:65:3F:B5:D0:C7:27:AC:12:44:E3:87:09:6B:19:0D+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")# 这时可以看到客户端的请求，没有加号[root@master ~]# puppet cert --sign --allNotice: Signed certificate request for node1.ruopu.comNotice: Removing file Puppet::SSL::CertificateRequest node1.ruopu.com at '/var/lib/puppet/ssl/ca/requests/node1.ruopu.com.pem'# 签署请求[root@master ~]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")+ "node1.ruopu.com" (SHA256) DC:8F:2C:D6:0C:97:6B:F7:1B:A6:48:55:E9:D9:3A:AA:C7:C5:C2:89:86:0E:45:C8:22:68:4B:B7:39:4B:B9:D3# 已被认证--------------- agent1&amp;2---------------[root@node1 ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:8139 *:* # 这时可以看到客户端监听在8139端口了，在认证后需要等待一会儿才会监听地址。------------ master------------[root@master ~]# puppet kick --allWarning: Puppet kick is deprecated. See http://links.puppetlabs.com/puppet-kick-deprecationWarning: Failed to load ruby LDAP library. LDAP functionality will not be availableFinished# 测试推送是否成功[root@master ~]# cd /etc/puppet/modules/[root@master modules]# mkdir -pv &#123;jdk8,tomcat,nginx&#125;/&#123;manifests,files,templates,lib,spec,tests&#125;[root@master modules]# yum install -y nginx tomcat java-1.8.0-openjdk-devel[root@master modules]# vim /etc/nginx/nginx.conf location / &#123; proxy_pass http://192.168.1.72:8080; &#125;[root@master modules]# cp /etc/nginx/nginx.conf /etc/puppet/modules/nginx/files/[root@master modules]# cp /etc/tomcat/server.xml /etc/puppet/modules/tomcat/files/[root@master modules]# vim nginx/manifests/init.ppclass nginx &#123; package&#123;'nginx': name =&gt; 'nginx', ensure =&gt; latest, &#125; file&#123;'nginx.conf': path =&gt; '/etc/nginx/nginx.conf', source =&gt; "puppet:///modules/nginx/nginx.conf", &#125; service&#123;'nginx': ensure =&gt; running, enable =&gt; true, &#125; Package['nginx'] -&gt; File['nginx.conf'] ~&gt; Service['nginx']&#125;[root@master modules]# vim tomcat/manifests/init.ppclass tomcat &#123; package&#123;['tomcat','tomcat-webapps','tomcat-admin-webapps','tomcat-docs-webapp']: # 安装多个包要用这种定义方式 ensure =&gt; latest, &#125; -&gt; file&#123;'server.xml': path =&gt; '/etc/tomcat/server.xml', source =&gt; 'puppet:///modules/tomcat/server.xml', &#125; ~&gt; service&#123;'tomcat': ensure =&gt; running, enable =&gt; true, &#125;&#125;[root@master modules]# vim jdk8/manifests/init.ppclass jdk8 &#123; package&#123;'jdk8': name =&gt; 'java-1.8.0-openjdk-devel', ensure =&gt; latest, &#125; file&#123;'java.sh': path =&gt; '/etc/profile.d/java.sh', source =&gt; "puppet:///modules/jdk8/java.sh", &#125;&#125;[root@master modules]# vim jdk8/files/java.shexport JAVA_HOME=/usr[root@master modules]# cd /etc/puppet/manifests/[root@master manifests]# vim site.pp # 定义主机清单node 'node1.test.com' &#123; include nginx&#125;node 'node2.test.com' &#123; include jdk8 include tomcat&#125;[root@master manifests]# puppet module list/etc/puppet/modules├── jdk8 (???)├── nginx (???)└── tomcat (???)# 查看上面定义的三个模块tomcat、nginx、jdk8是否加载[root@master modules]# puppet kick --allWarning: Puppet kick is deprecated. See http://links.puppetlabs.com/puppet-kick-deprecationWarning: Failed to load ruby LDAP library. LDAP functionality will not be availableFinished# 提醒所有客户端进行同步，如果是单个主机，可以写为客户端的主机名，如node1.ruopu.com，不能写为node1，因为不是主机名，所以推送不过去。也可以写多个主机名，主机名之间用空格分隔。# 这个推送的过程很慢，测试中一起推送非常慢，使用了单个主机的推送------------- agent1-------------[root@node1 ~]# rpm -q nginx# 可以看到安装了nginx[root@node1 ~]# ss -tln# 服务也启动了[root@node1 ~]# vim /etc/nginx/nginx.conf# 配置文件也被修改了。# 这个过程有些慢，需要在服务端推送后等一会儿才会生效。===========================================================================================客户端认证出现问题或推送失败的解决方法------------ master------------[root@puppet ~]# puppet cert --clean node1.ruopu.com# 服务端使用此命令将某个主机的认证清除---------- agent----------[root@puppettest1 ~]# systemctl stop puppetagent# 先停止服务[root@puppettest1 ~]# rm -rf /var/lib/puppet/ssl/*# 清除所有密钥[root@puppettest1 ~]# systemctl start puppetagent# 再启动------------ master------------[root@puppet ~]# puppet cert --list --all[root@puppet ~]# puppet cert --sign --all # 签署认证[root@puppet ~]# tail -f /var/log/puppet/masterhttp.log# 查看日志[root@puppet ~]# tree /var/lib/puppet/ssl/# 查看认证=========================================================================================== 自动注册12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697============================================================================================这种注册方式简单来讲是通过Puppetmaster端的ACL列表进行控制的，安全系统较低，也就是说符合预先定义的ACL列表中的所有节点请求不需要确认都会被自动注册上，也就是说你只需要知道ACL列表要求，其次能和PuppetMaster端通信便可轻易注册成功。当然，它的最大优点就是效率非常高。============================================================================================------------ master------------[root@master modules]# puppet cert --clean node2.ruopu.comNotice: Revoked certificate with serial 5Notice: Removing file Puppet::SSL::Certificate node2.ruopu.com at '/var/lib/puppet/ssl/ca/signed/node2.ruopu.com.pem'Notice: Removing file Puppet::SSL::Certificate node2.ruopu.com at '/var/lib/puppet/ssl/certs/node2.ruopu.com.pem'# 清除PuppetMaster端已经注册的agent2的证书[root@master modules]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")+ "node1.ruopu.com" (SHA256) DC:8F:2C:D6:0C:97:6B:F7:1B:A6:48:55:E9:D9:3A:AA:C7:C5:C2:89:86:0E:45:C8:22:68:4B:B7:39:4B:B9:D3------------- agent2-------------[root@node2 ~]# rm -rf /var/lib/puppet/ssl/*------------ master------------[root@master modules]# vim /etc/puppet/autosign.conf*.ruopu.com# 在Puppetmaster端编写ACL列表[root@master modules]# systemctl restart puppetmaster.service# 重启服务[root@master modules]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")+ "node1.ruopu.com" (SHA256) DC:8F:2C:D6:0C:97:6B:F7:1B:A6:48:55:E9:D9:3A:AA:C7:C5:C2:89:86:0E:45:C8:22:68:4B:B7:39:4B:B9:D3------------- agent2-------------[root@node2 ~]# puppet agent --testInfo: Creating a new SSL key for node2.ruopu.comInfo: Caching certificate for caInfo: csr_attributes file loading from /etc/puppet/csr_attributes.yamlInfo: Creating a new SSL certificate request for node2.ruopu.comInfo: Certificate Request fingerprint (SHA256): 6E:0E:32:71:38:77:41:92:E6:55:B0:90:07:3B:42:BF:87:8A:A7:16:2F:C2:90:25:43:10:B6:8B:DF:0A:65:A8Info: Caching certificate for node2.ruopu.comInfo: Caching certificate_revocation_list for caInfo: Caching certificate for caNotice: Ignoring --listen on onetime runInfo: Retrieving pluginfactsInfo: Retrieving pluginInfo: Caching catalog for node2.ruopu.comWarning: The package type's allow_virtual parameter will be changing its default value from false to true in a future release. If you do not want to allow virtual packages, please explicitly set allow_virtual to false. (at /usr/share/ruby/vendor_ruby/puppet/type.rb:816:in `set_default')Info: Applying configuration version '1548985465'Notice: Finished catalog run in 4.31 seconds# 申请证书------------ master------------[root@master modules]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")+ "node1.ruopu.com" (SHA256) DC:8F:2C:D6:0C:97:6B:F7:1B:A6:48:55:E9:D9:3A:AA:C7:C5:C2:89:86:0E:45:C8:22:68:4B:B7:39:4B:B9:D3+ "node2.ruopu.com" (SHA256) 3F:C1:1E:F7:4B:BA:2B:28:E0:79:49:AF:F3:96:BC:FE:78:A2:D2:F6:A4:9A:76:E6:29:BA:D9:09:29:D4:E0:79# agent2已经自动注册成功[root@master modules]# puppet kick node2.ruopu.com Warning: Puppet kick is deprecated. See http://links.puppetlabs.com/puppet-kick-deprecationWarning: Failed to load ruby LDAP library. LDAP functionality will not be availableTriggering node2.ruopu.comError: Host node2.ruopu.com failed: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [certificate revoked for /CN=node2.ruopu.com]node2.ruopu.com finished with exit code 2Failed: node2.ruopu.com# 这时向agent2推送可能会有问题，需要重启agent2的puppet服务------------- agent2-------------[root@node2 ~]# systemctl restart puppetagent------------ master------------[root@master modules]# vim /root/puppetclient.txtnode1.ruopu.comnode2.ruopu.com[root@master modules]# puppet kick --host `cat /root/puppetclient.txt`Warning: Puppet kick is deprecated. See http://links.puppetlabs.com/puppet-kick-deprecationWarning: Failed to load ruby LDAP library. LDAP functionality will not be availableTriggering node1.ruopu.comGetting statusstatus is successnode1.ruopu.com finished with exit code 0Triggering node2.ruopu.comGetting statusstatus is successnode2.ruopu.com finished with exit code 0Finished# 可以使用此种方法一起推送 预签名注册123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475============================================================================================预签名注册是在agent端未提出申请的情况下，预先在puppetmaster端生成agent端的证书，然后复制到节点对应的目录下即可注册成功，这种方式安全系数最高，但是操作麻烦，需要提前预知所有节点服务器的certname名称，其次需要将生成的证书逐步copy到所有节点上去。不过，如果你的系统中安装了kickstart或者cobbler这样的自动化工具，倒是可以将证书部分转换成脚本集成到统一自动化部署中== 生产环境中建议此方式进行注册，既安全又可靠！ ==============================================================================================------------ master------------[root@master modules]# puppet cert --clean node1.ruopu.comNotice: Revoked certificate with serial 4Notice: Removing file Puppet::SSL::Certificate node1.ruopu.com at '/var/lib/puppet/ssl/ca/signed/node1.ruopu.com.pem'Notice: Removing file Puppet::SSL::Certificate node1.ruopu.com at '/var/lib/puppet/ssl/certs/node1.ruopu.com.pem'[root@master modules]# puppet cert --list --all+ "master.ruopu.com" (SHA256) B5:A8:47:D4:FE:4E:FE:AC:5E:48:A2:C0:CF:7E:CB:1D:B9:03:26:8F:1F:66:6B:9A:29:E3:C7:39:E0:5E:D6:E0 (alt names: "DNS:master.ruopu.com", "DNS:puppet", "DNS:puppet.ruopu.com")+ "node2.ruopu.com" (SHA256) 3F:C1:1E:F7:4B:BA:2B:28:E0:79:49:AF:F3:96:BC:FE:78:A2:D2:F6:A4:9A:76:E6:29:BA:D9:09:29:D4:E0:79[root@master modules]# mv /etc/puppet/autosign.conf&#123;,.bak&#125;# 删除自动注册ACL列表------------- agent1-------------[root@puppettest1 ~]# rm -rf /var/lib/puppet/*------------ master------------[root@master modules]# puppet ca generate node1.ruopu.comNotice: node1.ruopu.com has a waiting certificate requestNotice: Signed certificate request for node1.ruopu.comNotice: Removing file Puppet::SSL::CertificateRequest node1.ruopu.com at '/var/lib/puppet/ssl/ca/requests/node1.ruopu.com.pem'Notice: Removing file Puppet::SSL::CertificateRequest node1.ruopu.com at '/var/lib/puppet/ssl/certificate_requests/node1.ruopu.com.pem'"-----BEGIN CERTIFICATE-----\nM...# puppetserver端预先生成agent1证书============================================================================================[root@master modules]# puppet --version3.6.2[root@master modules]# puppet help# 3.6.2版本中的命令与网上的一些教程已有很多不同，可以通过此命令查看帮助信息[root@master modules]# puppet help ca# 这是查看ca模块的帮助命令============================================================================================------------- agent1-------------[root@puppettest1 ~]# puppet agent --test --server=master.ruopu.com# 节点生成目录结构，最后是服务端的主机名------------ master------------[root@master modules]# scp /var/lib/puppet/ssl/private_keys/node1.ruopu.com.pem node1.ruopu.com:/var/lib/puppet/ssl/private_keys/[root@master modules]# scp /var/lib/puppet/ssl/certs/node1.ruopu.com.pem node1.ruopu.com:/var/lib/puppet/ssl/certs/[root@master modules]# scp /var/lib/puppet/ssl/certs/ca.pem node1.ruopu.com:/var/lib/puppet/ssl/certs/# 复制密钥到客户端------------- agent1-------------[root@puppettest1 ~]# puppet agent --testNotice: Ignoring --listen on onetime run# 测试。实际发现，在服务端生成客户端密钥时就已经完成客户端的认证了。------------ master------------[root@master modules]# puppet kick node1.ruopu.com Warning: Puppet kick is deprecated. See http://links.puppetlabs.com/puppet-kick-deprecationWarning: Failed to load ruby LDAP library. LDAP functionality will not be availableTriggering node1.ruopu.comGetting statusstatus is runningHost node1.ruopu.com is already runningnode1.ruopu.com finished with exit code 3Failed: node1.ruopu.com# 提示错误的原因是agent1节点每5秒与服务器同步一次，比较频繁，所以有此提示。如果将更新时间改为默认的1800秒，再次推送就不会有此提示了。 客户端定时更新1234567891011121314151617181920------------- agent2-------------[root@node2 ~]# puppet agent --configprint runinterval1800# Puppet客户端定时更新时间默认为30分钟[root@node2 modules]# vim /etc/puppet/puppet.conf[agent] runinterval = 5# 在agent段中加入上述内容，表示设置agent端5秒去同步。修改即可，无需重启服务[root@node2 ~]# puppet agent --configprint runinterval5------------ master------------[root@puppet ~]# tail -f /var/log/puppet/masterhttp.log# 查看日志会频繁变动# runinterval=0，并不表示从来不运行，而是表示继续运行；如果想要puppet agent从不运行，应该使用--no-client选项来启动；如：puppet agent --no-client# 使用--no-client选项，会启动守护进程但不检测配置，除非它被puppet kick触发。而且只有当puppet.conf配置listen=true或启动时有带--listen选项时，它才生效；]]></content>
      <categories>
        <category>编排工具</category>
      </categories>
      <tags>
        <tag>puppet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看用户登录信息]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%9F%A5%E7%9C%8B%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[w1234567891011121314151617181920212223==============================================================================================查看当前登入系统的用户信息及用户当前的进程（而who命令只能看用户不能看进程）。该命令能查看的信息包括系统当前时间，系统运行时间，登陆系统用户总数及系统1、5、15分钟内的平均负载信息。后面的信息是用户，终端，登录源，login time，idle time，JCPU，PCPU，当前执行的进程等。w的信息来自两个文件：用户登录信息来自/var/run/utmp，进程信息来自/proc/。参数-h：不显示标题。-u：列出当前进程和CPU时间时忽略用户名。这主要是用于执行su命令后的情况。-s：使用短模式。不显示登录时间、JCPU(终端机阶段作业)和PCPU（程序消耗）时间。-f：切换显示FROM项，也就是远程主机名项。默认值是不显示远程主机名-V：显示版本信息。==============================================================================================[root@haproxy ~]# w 18:33:57 up 11:19, 2 users, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot tty1 15:17 3:15m 0.07s 0.07s -bashroot pts/0 192.168.1.9 12:18 5.00s 0.70s 0.00s w# User：登录用户名 # TTY：登录后系统分配的终端号 # From：远程主机名，即从哪登录的 # login@：何时登录 # IDLE：用户空闲时间。这是个计时器，一旦用户执行任何操作，改计时器就会被重置。 # JCPU：和终端连接的所有进程占用时间。包括当前正在运行的后台作业占用时间 # PCPU：当前进程所占用时间 # WHAT：当前正在运行进程的命令行 who123456==============================================================================================查看当前登入系统的用户信息。其中who -m等效于whoami。==============================================================================================[root@haproxy ~]# whoroot tty1 2019-01-29 15:17root pts/0 2019-01-29 12:18 (192.168.1.9) last12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364==============================================================================================列出当前和曾经登入系统的用户信息，它默认读取的是/var/log/wtmp文件的信息。输出的内容包括：用户名、终端位置（pts/0伪终端，意味着从SSH或telnet等工具远程连接的用户，图形界面终端归于此类。tty0直接连接到计算机或本地连接的用户。后面的数字代表连接编号）、登录源信息、开始时间、结束时间（still login in尚未退出，down直到正常关机，crash直到强制关机）、持续时间。注意最后一行输出的是wtmp文件起始记录的时间。当然也可以通过last -f参数指定读取文件，可以是/var/log/btmp、/var/run/utmp参数-R 不显示登录系统或终端的主机名称或IP-a 将登录系统或终端的主机名过IP地址显示在最后一行-d 将IP地址转成主机名称-I 显示特定IP登录情况。-o 读取有linux-libc5应用编写的旧类型wtmp文件-x 显示系统关闭、用户登录和退出的历史-F 显示登录的完整时间-w 在输出中显示完整的用户名或域名==============================================================================================[root@haproxy ~]# lastroot pts/0 192.168.1.9 Tue Jan 29 12:18 still logged in root pts/0 192.168.1.9 Tue Jan 29 15:22 - 12:18 (-3:-3) root tty1 Tue Jan 29 15:17 still logged in reboot system boot 3.10.0-693.el7.x Tue Jan 29 15:13 - 18:41 (03:27) root tty1 Wed Oct 24 05:42 - 05:50 (00:07) reboot system boot 3.10.0-693.el7.x Wed Oct 24 05:42 - 05:50 (00:07) wtmp begins Wed Oct 24 05:42:31 2018[root@haproxy ~]# last -f /var/log/btmp btmp begins Wed Oct 24 05:42:34 2018[root@haproxy ~]# last -f /var/run/utmp root pts/0 192.168.1.9 Tue Jan 29 12:18 still logged in root tty1 Tue Jan 29 15:17 still logged in reboot system boot 3.10.0-693.el7.x Tue Jan 29 15:13 - 18:43 (03:29) utmp begins Tue Jan 29 15:13:55 2019[root@haproxy ~]# last rootroot pts/0 192.168.1.9 Tue Jan 29 12:18 still logged in root pts/0 192.168.1.9 Tue Jan 29 15:22 - 12:18 (-3:-3) root tty1 Tue Jan 29 15:17 still logged in root tty1 Wed Oct 24 05:42 - 05:50 (00:07)# 指定用户[root@haproxy ~]# last -n 1root pts/0 192.168.1.9 Tue Jan 29 12:18 still logged in wtmp begins Wed Oct 24 05:42:31 2018# 指定输出记录的条数[root@haproxy ~]# last -10 -t 20190129000000root tty1 Wed Oct 24 05:42 - 05:50 (00:07) reboot system boot 3.10.0-693.el7.x Wed Oct 24 05:42 - 05:50 (00:07) wtmp begins Wed Oct 24 05:42:31 2018# 显示指定时间之前的记录[root@haproxy ~]# last -10 -droot pts/0 192.168.1.9 Tue Jan 29 12:18 still logged in root pts/0 192.168.1.9 Tue Jan 29 15:22 - 12:18 (-3:-3) root tty1 0.0.0.0 Tue Jan 29 15:17 still logged in reboot system boot 0.0.0.0 Tue Jan 29 15:13 - 18:56 (03:42) root tty1 0.0.0.0 Wed Oct 24 05:42 - 05:50 (00:07) reboot system boot 0.0.0.0 Wed Oct 24 05:42 - 05:50 (00:07) wtmp begins Wed Oct 24 05:42:31 2018# 将IP 地址转换为主机地址 lastlog1234567891011121314151617181920212223242526==============================================================================================列出所有用户最近登录的信息，或者指定用户的最近登录信息。lastlog引用的是/var/log/lastlog文件中的信息，包括login-name、port、last login time==============================================================================================[root@haproxy ~]# lastlog Username Port From Latestroot pts/0 192.168.1.9 Tue Jan 29 12:18:32 +0800 2019bin **Never logged in**daemon **Never logged in**adm **Never logged in**lp **Never logged in**sync **Never logged in**shutdown **Never logged in**halt **Never logged in**mail **Never logged in**operator **Never logged in**games **Never logged in**ftp **Never logged in**nobody **Never logged in**systemd-network **Never logged in**dbus **Never logged in**polkitd **Never logged in**[root@haproxy ~]# lastlog -u 0Username Port From Latestroot pts/0 192.168.1.9 Tue Jan 29 12:18:32 +0800 2019# 通过用户的UID查看指定用户的登录信息 lastb1234567==============================================================================================列出失败尝试的登录信息，和last命令功能完全相同，只不过它默认读取的是/var/log/btmp文件的信息。当然也可以通过last -f参数指定读取文件，可以是/var/log/btmp、/var/run/utmp==============================================================================================[root@haproxy ~]# lastbroot ssh:notty 192.168.1.9 Tue Jan 29 19:05 - 19:05 (00:00) btmp begins Tue Jan 29 19:05:21 2019 登录日志12341. /var/run/utmp：记录当前正在登录系统的用户信息，默认由who和w记录当前登录用户的信息，uptime记录系统启动时间；2. /var/log/wtmp：记录当前正在登录和历史登录系统的用户信息，默认由last命令查看；3. /var/log/btmp：记录失败的登录尝试信息，默认由lastb命令查看。4. /var/log/lastlog：记录每个用户最后的登入信息 清除登录日志123456789[root@haproxy ~]# echo &gt; /var/log/wtmp [root@haproxy ~]# echo &gt; /var/log/btmp [root@haproxy ~]# echo &gt; /var/log/lastlog[root@haproxy ~]# history -r# 导入当前用户家目录中的.bash_history[root@haproxy ~]# history -c# 清除当前会话的历史记录[root@haproxy ~]# echo &gt; ~/.bash_history# 清除所有历史记录]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>用户登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[puppet配置与使用]]></title>
    <url>%2F2019%2F01%2F29%2Fpuppet%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念资源 group：定义组 user：定义用户 file：定义配置文件 service：定义服务 exec：执行命令 package：管理程序包 cron：周期性任务计划 notify：主要用于输出puppet的辅助提示信息,在puppet的执行过程中通过这些辅助信息了解执行的过程,它并不会改变任何操作状态. 资源中的参数 name：指定要创建或显示的信息 system：是否为系统的，true为是，false表示非； ensure：描述状态的。present表示必须创建，adsent表示不创建。latest表示安装最新版本，installed也表示安装最新版本，如果不想安装最新版本，要指定版本号，用present也可以安装。running表示处理启动状态。file表示是配置文件。directory表示定义为目录； enable：表示开机是否自启动，如true require：表示依赖哪个属性； before：表示先于上面的哪个资源执行 subscribe：订阅前面的资源，如果前面发生改变就通知后面的资源，服务会重启。notify和subscribe是通知相关的其它资源进行“刷新”操作 -&gt;表示某资源要在另一个资源之前执行。-&gt;不能写在下面的资源后，如果要用这个符号，就要写在优先于的资源的上面。 ~&gt;表示通知某资源 path：在exec资源中使用时一定要给定命令路径，如’/bin:/sbin:/usr/bin:/usr/sbin’,，如果在exec中没有给路径的情况下。 recurse：表示递归复制整个目录，可用true。 creates：只有在此目录不存在时才执行。对于目录或文件路径类的操作资源来讲，可以用creates来判断，如果不存在才创建 command：要执行的命令 unless：表示其指定的命令执行失败了才执行上面的创建用户命令 refreshonly：refreshonly为true表示触发时才执行命令，如程序包安装了才创建用户，如果没有程序包，就不会创建。如果没有refreshonly时，即使没有事件通知它，exec也会执行。如果加上refreshonly时，exec仅在其他资源用notify或subscribe事件通知时才会执行。refreshonly作用是让exec只在通知时执行，如果被通知多次就执行多次。 refresh：如果有其他资源调用exec的时候，exec会执行好几次，加上refresh后就只会执行一次了，refresh作用就是不管有通知没通知，有多少次通知，都只执行一次。 provider：定义用什么方式安装，如rpm owner：表示文件属主 group：表示文件属组 mode：表示文件权限 message：输出描述信息 withpath：是否显示完整对象路径。 puppet单机模型安装12345678910111213141516171819202122232425==============================================================================================环境node1：192.168.1.70==============================================================================================------------ node1------------ [root@puppet ~]# yum install -y epel-release[root@puppet ~]# yum install -y puppet facter# facter是一个非常有用的系统盘点工具，自定义时可以让节点增加更多的标签。这个工具可以通过一些预先设定好变量定位一台主机，比如可以通过变量lsbdistrelease便可以知道当前系统的版本号，通过osfamily便可以知道系统是RedHat还是SLES，还有其他等等。[root@puppet ~]# puppet describe -lThese are the types known to puppet:augeas - Apply a change or an array of changes to the ...computer - Computer object management using DirectorySer ...cron - Installs and manages cron jobsexec - Executes external commandsfile - Manages files, including their content, owner ...filebucket - A repository for storing and retrieving file ...group - Manage groups...# 查看资源类型[root@puppet ~]# puppet describe group# 查看组类型[root@puppet ~]# mkdir manifests[root@puppet ~]# cd manifests 资源组创建1234567891011121314151617181920212223[root@puppet manifests]# vim first.pp# puppet资源清单要以.pp结尾group&#123;'nginx': # 如果组中没有空白可以不用引号，这里组名就叫nignx，之后用冒号隔开 name =&gt; 'nginx',# 第一个属性name，用=&gt;表示赋值，也叫nginx，最后用逗号隔开。如果不写name，那么就用上面的title当默认的name，也就是上面的nginx gid =&gt; 900, # 指定组id，一定要指定组id，如果不加组id，创建系统组会失败。如果已经有要创建的组了，可以通过这里修改组id system =&gt; true,# system表示系统组，这里的true不能加引号，因为true是布尔型的值。如果创建普通组，可以去掉system项&#125;[root@puppet manifests]# puppet apply --verbose --noop first.pp Notice: Compiled catalog for puppet in environment production in 0.07 secondsInfo: Applying configuration version '1548897081'Info: Creating state file /var/lib/puppet/state/state.yamlNotice: Finished catalog run in 0.01 seconds# apply表示跑一次，--verbose表示查看详细信息，--noop表示干跑。显示结果是绿色表示没有问题[root@puppet manifests]# puppet apply -v first.pp Notice: Compiled catalog for puppet in environment production in 0.06 secondsInfo: Applying configuration version '1548897756'Notice: /Stage[main]/Main/Group[nginx]/ensure: createdNotice: Finished catalog run in 0.04 seconds[root@puppet manifests]# cat /etc/group|grep nginx nginx:x:900:# 创建成功 创建组和用户资源1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@puppet manifests]# vim second.ppgroup&#123;'memcached': ensure =&gt; present,# ensure是描述状态的，present表示必须创建出来。定义系统组时必须有此项(CentOS6上500以内为系统用户和组，500开始为普通用户和组。CentOS7上是1000以内)，但最好何时都加上 name =&gt; 'memcached', system =&gt; true,&#125;[root@puppet manifests]# puppet apply -v --noop second.pp Notice: Compiled catalog for puppet in environment production in 0.06 secondsInfo: Applying configuration version '1548898738'Notice: /Stage[main]/Main/Group[memcached]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.03 seconds[root@puppet manifests]# puppet apply -v second.pp Notice: Compiled catalog for puppet in environment production in 0.07 secondsInfo: Applying configuration version '1548898802'Notice: /Stage[main]/Main/Group[memcached]/ensure: createdNotice: Finished catalog run in 0.04 seconds[root@puppet manifests]# grep -i 'memcached' /etc/groupmemcached:x:899:# 这次在second.pp中不加组id也可以创建系统组了。但还是建议加入组id[root@puppet manifests]# vim user1.ppuser&#123;'nginx': uid =&gt; 444, gid =&gt; 'nginx', system =&gt; true, ensure =&gt; present,&#125;[root@puppet manifests]# puppet apply -v --noop --debug user1.pp Notice: Compiled catalog for puppet in environment production in 0.11 seconds# 基本组要事先存在才能创建用户，--debug可以输出更加详细的信息[root@puppet manifests]# vim user1.pp group&#123;'nginx': system =&gt; true, ensure =&gt; present,&#125;user&#123;'nginx': uid =&gt; 444, gid =&gt; 'nginx', system =&gt; true, ensure =&gt; present,&#125;[root@puppet manifests]# puppet apply -v --debug --noop user1.pp[root@puppet manifests]# puppet apply -v --debug user1.pp # 这样就能创建了，同一个定义执行多遍，其结果是一样的。这叫幂等性。如果没有幂等性，要让其拥有[root@puppet manifests]# vim user2.ppuser&#123;'redis': gid =&gt; 'redis', ensure =&gt; present,&#125;group&#123;'redis': ensure =&gt; present,&#125;[root@puppet manifests]# puppet apply -v --noop --debug user2.pp# 可以执行，会先创建组再创建用户，反着写也可以。只要是在同一文件中就没问题[root@puppet manifests]# vim user2.pp user&#123;'redis': gid =&gt; 'redis', ensure =&gt; present, require =&gt; Group['redis'],# require表示依赖哪个属性，Group这个属性的第一个字母必须大写，后面用['']的方式写明title。这样定义后，执行时就必须先执行下面的命令&#125;group&#123;'redis': ensure =&gt; present, before =&gt; User['redis'],# 这表示先于上面的user执行，格式与上面的require一样，这两种方法都可以使group先执行&#125;[root@puppet manifests]# puppet describe package# 查看管理程序包的 创建程序包资源1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@puppet manifests]# vim pkg1.pppackage&#123;'redis': ensure =&gt; latest,&#125;[root@puppet manifests]# rpm -q redispackage redis is not installed[root@puppet manifests]# puppet apply -v pkg1.pp Notice: Compiled catalog for puppet in environment production in 0.21 secondsWarning: The package type's allow_virtual parameter will be changing its default value from false to true in a future release. If you do not want to allow virtual packages, please explicitly set allow_virtual to false. (at /usr/share/ruby/vendor_ruby/puppet/type.rb:816:in `set_default')Info: Applying configuration version '1548900655'Notice: /Stage[main]/Main/Package[redis]/ensure: createdNotice: Finished catalog run in 11.39 seconds# 这里会有一个Warning: 提示，可以在文件中加入allow_virtual =&gt; false，就不会提示了[root@puppet manifests]# rpm -q redisredis-3.2.12-2.el7.x86_64# 安装成功了下载jdk-8u201-linux-x64.rpm到root目录[root@puppet manifests]# vim pkg2.pppackage&#123;'jdk': ensure =&gt; installed, source =&gt; '/root/jdk-8u201-linux-x64.rpm', provider =&gt; rpm, allow_virtual =&gt; false, # 不加入此项，还会有警告提示&#125;[root@puppet manifests]# puppet apply -v --noop pkg2.pp Notice: Compiled catalog for puppet in environment production in 0.22 secondsInfo: Applying configuration version '1548905011'Notice: /Stage[main]/Main/Package[jdk]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.11 seconds[root@puppet manifests]# puppet apply -v pkg2.pp Notice: Compiled catalog for puppet in environment production in 0.22 secondsInfo: Applying configuration version '1548905065'Notice: /Stage[main]/Main/Package[jdk]/ensure: createdNotice: Finished catalog run in 7.13 seconds[root@puppet manifests]# java -versionjava version "1.8.0_201"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)# 安装成功[root@puppet manifests]# ls /usr/java/default jdk1.8.0_201-amd64 latest[root@puppet manifests]# rpm -q jdk1.8-2000:1.8.0_201-fcs.x86_64jdk1.8-1.8.0_201-fcs.x86_64 服务与配置文件基本配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@puppet manifests]# vim service1.ppservice&#123;'redis': ensure =&gt; running, # 确保处于启动状态 enable =&gt; true, # 是否开机自启动&#125;[root@puppet manifests]# puppet apply -v --noop service1.pp Notice: Compiled catalog for puppet in environment production in 0.08 secondsInfo: Applying configuration version '1548905408'Notice: /Stage[main]/Main/Service[redis]/ensure: current_value stopped, should be running (noop)Info: /Stage[main]/Main/Service[redis]: Unscheduling refresh on Service[redis]Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.03 seconds[root@puppet manifests]# puppet apply -v service1.pp Notice: Compiled catalog for puppet in environment production in 0.08 secondsInfo: Applying configuration version '1548905419'Notice: /Stage[main]/Main/Service[redis]/ensure: ensure changed 'stopped' to 'running'Info: /Stage[main]/Main/Service[redis]: Unscheduling refresh on Service[redis]Notice: Finished catalog run in 0.10 seconds[root@puppet manifests]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:6379 *:* # 可以看到redis启动了# 服务要依赖程序包，要先安装程序包，才能启动服务[root@puppet manifests]# vim service1.pp package&#123;'redis': ensure =&gt; present,&#125;service&#123;'redis': ensure =&gt; running, enable =&gt; true, require =&gt; Package['redis']&#125;[root@puppet manifests]# cp /etc/redis.conf ./[root@puppet manifests]# vim redis.confbind 0.0.0.0requirepass centos[root@puppet manifests]# vim file1.ppfile&#123;'/etc/redis.conf': # 如果只写名字，后面一定要有path。否则就要给目标主机上配置文件的全路径 ensure =&gt; file, source =&gt; '/root/manifests/redis.conf', owner =&gt; 'redis', # 文件属主 group =&gt; 'root', # 文件属组 mode =&gt; '0644', # 文件权限&#125;[root@puppet manifests]# puppet apply -v --noop file1.pp Notice: Compiled catalog for puppet in environment production in 0.07 secondsInfo: Applying configuration version '1548905958'Notice: /Stage[main]/Main/File[/etc/redis.conf]/content: current_value &#123;md5&#125;d98629fded012cd2a25b9db0599a9251, should be &#123;md5&#125;1a1a5828970c05c20bb80d5930c66f12 (noop)Notice: /Stage[main]/Main/File[/etc/redis.conf]/mode: current_value 0640, should be 0644 (noop)Notice: Class[Main]: Would have triggered 'refresh' from 2 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.04 seconds[root@puppet manifests]# puppet apply -v --debug file1.pp# 这样只会改变文件，但服务不会重启[root@puppet manifests]# grep -E -v "^$|^#" /etc/redis.conf bind 0.0.0.0requirepass centos# 可以看到本机的redis配置文件已被修改了 通知&amp;订阅1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798* 方法一[root@puppet manifests]# vim service1.pp package&#123;'redis': ensure =&gt; present,&#125;file&#123;'/etc/redis.conf': ensure =&gt; file, source =&gt; '/root/manifests/redis.conf', require =&gt; Package['redis'], owner =&gt; 'redis', group =&gt; 'root',&#125;service&#123;'redis': ensure =&gt; running, enable =&gt; true, require =&gt; Package['redis'], subscribe =&gt; File['/etc/redis.conf'],# 订阅前面的资源，如果前面发生改变就通知后面的资源，服务会重启。notify和subscribe是通知相关的其它资源进行“刷新”操作&#125;[root@puppet manifests]# vim redis.confrequirepass 123456# 改一下模板的密码[root@puppet manifests]# puppet apply -v service1.pp Notice: Compiled catalog for puppet in environment production in 0.41 secondsWarning: The package type's allow_virtual parameter will be changing its default value from false to true in a future release. If you do not want to allow virtual packages, please explicitly set allow_virtual to false. (at /usr/share/ruby/vendor_ruby/puppet/type.rb:816:in `set_default')Info: Applying configuration version '1548906366'Info: /Stage[main]/Main/File[/etc/redis.conf]: Filebucketed /etc/redis.conf to puppet with sum 1a1a5828970c05c20bb80d5930c66f12Notice: /Stage[main]/Main/File[/etc/redis.conf]/content: content changed '&#123;md5&#125;1a1a5828970c05c20bb80d5930c66f12' to '&#123;md5&#125;3a3222440b0c68afc02b378da96a22b7'Notice: /Stage[main]/Main/File[/etc/redis.conf]/mode: mode changed '0644' to '0640'Info: /Stage[main]/Main/File[/etc/redis.conf]: Scheduling refresh of Service[redis]Info: /Stage[main]/Main/File[/etc/redis.conf]: Scheduling refresh of Service[redis]Notice: /Stage[main]/Main/Service[redis]: Triggered 'refresh' from 2 eventsNotice: Finished catalog run in 0.25 seconds# 提示会刷新服务，对服务来说刷新就是重启[root@puppet manifests]# grep -E -v "^$|^#" /etc/redis.conf bind 0.0.0.0requirepass 123456# 密码变了[root@puppet manifests]# redis-cli 127.0.0.1:6379&gt; AUTH 123456OK# 密码生效了，说明服务重启了[root@puppet manifests]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:6379 *:* # 监听地址也改变了* 方法二[root@puppet manifests]# vim service1.pppackage&#123;'redis': ensure =&gt; present, allow_virtual =&gt; false, &#125; -&gt; # 表示package在file之前执行file&#123;'/etc/redis.conf': ensure =&gt; file, source =&gt; '/root/manifests/redis.conf', owner =&gt; 'redis', group =&gt; 'root',&#125; ~&gt; # 表示通知后面的serviceservice&#123;'redis': ensure =&gt; running, enable =&gt; true,&#125;* 方法三[root@puppet manifests]# vim service1.pp package&#123;'redis': ensure =&gt; present, allow_virtual =&gt; false,&#125; file&#123;'/etc/redis.conf': ensure =&gt; file, source =&gt; '/root/manifests/redis.conf', owner =&gt; 'redis', group =&gt; 'root',&#125;# 从源文件路径中将文件复制到file指定的目标路径service&#123;'redis': ensure =&gt; running, enable =&gt; true,&#125;Package['redis'] -&gt; File['/etc/redis.conf'] ~&gt; Service['redis']# 也可以在最下面单独定义通知和依赖关系，感觉这种方法使逻辑更清晰[root@puppet manifests]# vim redis.confbind 127.0.0.1[root@puppet manifests]# puppet apply -v service1.pp Notice: Compiled catalog for puppet in environment production in 0.38 secondsInfo: Applying configuration version '1548907154'Info: /Stage[main]/Main/File[/etc/redis.conf]: Filebucketed /etc/redis.conf to puppet with sum 3a3222440b0c68afc02b378da96a22b7Notice: /Stage[main]/Main/File[/etc/redis.conf]/content: content changed '&#123;md5&#125;3a3222440b0c68afc02b378da96a22b7' to '&#123;md5&#125;632baae21fab969118a56acd6b389543'Info: /Stage[main]/Main/File[/etc/redis.conf]: Scheduling refresh of Service[redis]Notice: /Stage[main]/Main/Service[redis]: Triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.22 seconds[root@puppet manifests]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:6379 *:* # 可以看到服务重启了。但有些服务是不能重启的，如nginx。要在定义资源时写restart为nginx -s reload，改restart命令，不让其重启 生成指定信息的文件123456789101112[root@puppet manifests]# vim file2.ppfile&#123;'/tmp/test.txt': # 生成/tmp/test.txt文件 ensure =&gt; file, # 这里也可以用persent content =&gt; 'Hello there', # 文件还可以基于content生成，用/n可换行&#125;# 使用content生成文件信息，写入到file指定的目标文件中[root@puppet manifests]# puppet apply file2.pp Notice: Compiled catalog for puppet in environment production in 0.07 secondsNotice: /Stage[main]/Main/File[/tmp/test.txt]/ensure: defined content as '&#123;md5&#125;e8ea7a8d1e93e8764a84a0f3df4644de'Notice: Finished catalog run in 0.04 seconds[root@puppet manifests]# cat /tmp/test.txt Hello there 生成软链接1234567891011[root@puppet manifests]# vim file3.ppfile&#123;'/tmp/test.txt.link': # 生成链接文件 ensure =&gt; link, # 链接文件类型 target =&gt; '/tmp/test.txt', # 指定源文件路径&#125;[root@puppet manifests]# puppet apply file3.pp Notice: Compiled catalog for puppet in environment production in 0.07 secondsNotice: /Stage[main]/Main/File[/tmp/test.txt.link]/ensure: createdNotice: Finished catalog run in 0.03 seconds[root@puppet manifests]# ll /tmplrwxrwxrwx 1 root root 13 Jan 31 12:09 test.txt.link -&gt; /tmp/test.txt 复制目录1234567891011[root@puppet manifests]# vim file4.ppfile&#123;'/tmp/pam.d': ensure =&gt; directory, source =&gt; '/etc/pam.d', recurse =&gt; true, # 表示递归复制整个目录&#125;# 如果不用source和recurse，那么就会创建一个空目录。测试不用recurse也会创建一个pam.d的空目录。[root@puppet manifests]# puppet apply file4.pp[root@puppet manifests]# ll /tmp/pam.d/total 108# 可以看到目录被复制了 执行命令基本执行12345678910111213141516[root@puppet manifests]# vim exec1.ppexec&#123;'mkdir': # mkdir不能当命令用，如果要当，要加路径 command =&gt; 'mkdir /tmp/testdir', path =&gt; '/bin:/sbin:/usr/bin:/usr/sbin', # 一定要给定命令路径 creates =&gt; '/tmp/testdir', # 只有在此目录不存在时才执行。对于目录或文件路径类的操作资源来讲，可以用creates来判断，如果不存在才创建&#125;[root@puppet manifests]# puppet apply -v exec1.pp Notice: Compiled catalog for puppet in environment production in 0.02 secondsInfo: Applying configuration version '1548908746'Notice: /Stage[main]/Main/Exec[mkdir]/returns: executed successfullyNotice: Finished catalog run in 0.06 seconds[root@puppet manifests]# ls /tmp/testdir# 命令执行了# 如果文件中不加creates一项，执行时会报错，因为已经有目录了，这个命令是不幂等的。如果有creates一项，就不会报错了 判断执行123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@puppet manifests]# vim exec2.pp exec&#123;'adduser': command =&gt; 'useradd -r mogilefs', path =&gt; '/bin:/sbin:/usr/bin:/usr/sbin', unless =&gt; 'id mogilefs', # unless表示其指定的命令执行失败了才执行上面的创建用户命令&#125;[root@puppet manifests]# puppet apply exec2.pp Notice: Compiled catalog for puppet in environment production in 0.02 secondsNotice: /Stage[main]/Main/Exec[adduser]/returns: executed successfullyNotice: Finished catalog run in 0.08 seconds[root@puppet manifests]# id mogilefsuid=442(mogilefs) gid=442(mogilefs) groups=442(mogilefs)# 命令执行成功了[root@puppet manifests]# puppet apply exec2.pp Notice: Compiled catalog for puppet in environment production in 0.02 secondsNotice: Finished catalog run in 0.06 seconds# 再次执行时，就不会再执行文件中的命令了[root@puppet manifests]# vim exec2.pppackage&#123;'mogilefs': ensure =&gt; latest,&#125;exec&#123;'adduser': command =&gt; 'useradd -r mogilefs', path =&gt; '/bin:/sbin:/usr/bin:/usr/sbin', unless =&gt; 'id mogilefs', refreshonly =&gt; true,# refreshonly作用是让exec仅在其他资源用notify或subscribe事件通知时才会执行，如果被通知多次就执行多次。 subscribe =&gt; Package['mogilefs'],# 定义何时执行，Package表示其指定的包安装后才执行&#125;[root@puppet manifests]# userdel -r mogilefs[root@puppet manifests]# puppet apply -v exec2.pp Notice: Compiled catalog for puppet in environment production in 0.27 secondsInfo: Applying configuration version '1548909636'Error: Could not update: Execution of '/usr/bin/yum -d 0 -e 0 -y list mogilefs' returned 1: Error: No matching Packages to listWrapped exception:Execution of '/usr/bin/yum -d 0 -e 0 -y list mogilefs' returned 1: Error: No matching Packages to listError: /Stage[main]/Main/Package[mogilefs]/ensure: change from absent to latest failed: Could not update: Execution of '/usr/bin/yum -d 0 -e 0 -y list mogilefs' returned 1: Error: No matching Packages to listNotice: /Stage[main]/Main/Exec[adduser]: Dependency Package[mogilefs] has failures: trueWarning: /Stage[main]/Main/Exec[adduser]: Skipping because of failed dependenciesNotice: Finished catalog run in 4.67 seconds# 提示没有程序包，不能执行[root@puppet manifests]# id mogilefsid: mogilefs: no such user 定时任务1234567891011121314151617[root@puppet manifests]# vim cron1.ppcron&#123;'synctime': command =&gt; '/usr/sbin/ntpdate ntp.ubuntu.com &amp;&gt; /dev/null', # 要执行的命令 name =&gt; 'synctime from ntp server', minute =&gt; '*/3', # 每3分钟执行一次# 上面三个是必须给的属性，不给定用户，就是给当前用户的定时任务 ensure =&gt; present, # absent表示删除，persent表示添加&#125;[root@puppet manifests]# puppet apply -v cron1.pp Notice: Compiled catalog for puppet in environment production in 0.03 secondsInfo: Applying configuration version '1548910460'Notice: /Stage[main]/Main/Cron[synctime]/ensure: createdNotice: Finished catalog run in 0.09 seconds[root@puppet manifests]# crontab -l*/3 * * * * /usr/sbin/ntpdate ntp.ubuntu.com &amp;&gt; /dev/null# 添加了定时任务# 如果将上面改为ensure =&gt; absent，再执行一次puppet就会删除定时任务。 显示提示信息123456789101112[root@puppet manifests]# vim notify1.ppnotify&#123;'sayhi': message =&gt; 'How old are you', name =&gt; 'sayhi',&#125;# notify是显示提示信息的，信息会发送到日志中[root@puppet manifests]# puppet apply notify1.pp Notice: Compiled catalog for puppet in environment production in 0.01 secondsNotice: How old are youNotice: /Stage[main]/Main/Notify[sayhi]/message: defined 'message' as 'How old are you'Notice: Finished catalog run in 0.04 seconds# 结果中有Notify:后是message定义的信息 变量12345678910111213141516171819202122232425262728293031323334==============================================================================================定义变量：以$开头，如：$system、$flag赋值：= ，如：$one = "first one"引用变量：有三种方法如下$var = "Hello World!"notice "1.$var"notice "2.$&#123;var&#125;"notice "3.$::var"==============================================================================================[root@puppet manifests]# facter -p# 收集打印当前系统上的所有变量，这些变量会传递给puppet主机[root@puppet manifests]# vim user3.pp[root@puppet manifests]# vim user3.pp $username = "test"group&#123;"$username": # 在使用变量时要用双引号引用 ensure =&gt; present, system =&gt; true,&#125; -&gt;user&#123;"$username": ensure =&gt; present, gid =&gt; "$username",&#125;[root@puppet manifests]# puppet apply -v user3.ppNotice: Compiled catalog for puppet in environment production in 0.12 secondsInfo: Applying configuration version '1548913706'Notice: /Stage[main]/Main/Group[test]/ensure: createdNotice: /Stage[main]/Main/User[test]/ensure: createdNotice: Finished catalog run in 0.08 seconds.[root@puppet manifests]# id testuid=1000(test) gid=896(test) groups=896(test)[root@puppet manifests]# grep test /etc/grouptest:x:896: 正则表达式123456789101112131415语法结构：/(?&lt;ENABLED OPTION&gt;:&lt;SUBPATTERN&gt;)//(?-&lt;DISABLED OPTION&gt;:&lt;SUBPATTERN&gt;)/OPTION：i: 忽略字符大小写m: 把点号当换行符使用x：忽略模式中的空白字符和注释惯常用法：(?i-mx:PATTERN)$webpackage=$operatingsystem? &#123; /(?i-mx:ubuntu|debian)/ =&gt; ‘apache2‘, /(?i-mx:fedora|redhat|centos)/ =&gt; ‘httpd‘,&#125; 判断语句if判断12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667==============================================================================================语法一if 条件 &#123;语句&#125;条件：是true执行语句，是false则跳过语句语法二if CONDITION &#123;...&#125; else &#123;...&#125;语法三if CONDITION &#123;...&#125; elsif CONDITION &#123;...&#125;...else &#123;...&#125;例if $operatingsystem =~ /^(?i-mx:(Ubuntu|RedHat))/ &#123; notice("Welcome to $1 linux distribution.")&#125; else &#123; notice("Welcome to unkown world.")&#125;==============================================================================================[root@puppet manifests]# vim if.ppif $operatingsystem == 'CentOS' &#123; package&#123;'nginx': ensure =&gt; present, allow_virtual =&gt; false, &#125;&#125;[root@puppet manifests]# puppet apply -v --noop if.pp Notice: Compiled catalog for puppet in environment production in 0.22 secondsInfo: Applying configuration version '1548914166'Notice: /Stage[main]/Main/Package[nginx]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.13 seconds[root@puppet manifests]# vim if.ppif $operatingsystem == 'Fedora' &#123; package&#123;'nginx': ensure =&gt; present, allow_virtual =&gt; false, &#125;&#125; else &#123; notify&#123;'goaway': message =&gt; 'allien', &#125;&#125;[root@puppet manifests]# puppet apply -v --noop if.pp Notice: Compiled catalog for puppet in environment production in 0.01 secondsInfo: Applying configuration version '1548914282'Notice: /Stage[main]/Main/Notify[goaway]/message: current_value absent, should be allien (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.04 seconds# 执行了message unless判断123456789101112==============================================================================================语法unless 条件 &#123;语句&#125;条件：当false时，执行语句。当true时跳过。==============================================================================================例$varless = 100unless $varless &gt; 1000 &#123; notice "$varless &gt; 1000 is false"&#125; case判断1234567891011121314151617181920212223242526==============================================================================================语法case 变量/表达式 &#123;值1 : &#123;语句1&#125;值2,值3 : &#123;语句2&#125;default : &#123;不是上面的值时，执行这条语句&#125;&#125;==============================================================================================[root@puppet manifests]# vim case.ppcase $operatingsystem &#123; RedHat,CentOS,Fedora: &#123; $webserver = 'httpd' &#125; /(?i-mx:debian|ubuntu)/: &#123; $webserver = "apache2" &#125; default: &#123; $webserver = 'httpd' &#125;# 如果是RedHat等，就定义webserver变量为httpd，如果是debian等，就为apache2，否则就为httpd&#125;package&#123;"$webserver": ensure =&gt; latest, allow_virtual =&gt; false,&#125;[root@puppet manifests]# puppet apply -v case.pp Notice: Compiled catalog for puppet in environment production in 0.23 secondsInfo: Applying configuration version '1548915048'Notice: /Stage[main]/Main/Package[httpd]/ensure: createdNotice: Finished catalog run in 8.68 seconds[root@puppet manifests]# rpm -q httpdhttpd-2.4.6-88.el7.centos.x86_64 selector判断123456789101112131415161718192021222324252627==============================================================================================语法未知变量 = 可知变量 ? &#123;值1 =&gt; 赋值1,值2 =&gt; 赋值2,default =&gt; 赋值3,&#125;==============================================================================================[root@puppet manifests]# vim selector.pp$webserver = $operatingsystem ? &#123; /(ubuntu|debian)/ =&gt; 'apache2', /(?i-mx:centos|redhat|fedora)/ =&gt; 'httpd',# default =&gt; 'httpd',&#125;package&#123;"$webserver": ensure =&gt; present, allow_virtual =&gt; false,&#125;# 用这种方法也可以判断，判断operatingsystem是什么，然后赋值给webserver。[root@puppet manifests]# yum remove httpd -y[root@puppet manifests]# puppet apply selector.pp Notice: Compiled catalog for puppet in environment production in 0.23 secondsNotice: /Stage[main]/Main/Package[httpd]/ensure: createdNotice: Finished catalog run in 9.19 seconds[root@puppet manifests]# rpm -q httpdhttpd-2.4.6-88.el7.centos.x86_64 类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859==============================================================================================语法class name &#123;... puppet code ...&#125;# 定义过的类只有被调用(声明)才会执行；# 类名可以包含小写字母、数字和下划线，但只能小写字母开头；# 类会引入新的变量作用域；==============================================================================================[root@puppet manifests]# vim class1.ppclass nginx &#123; package&#123;'nginx': ensure =&gt; latest, allow_virtual =&gt; false, &#125; -&gt; service&#123;'nginx': ensure =&gt; running, enable =&gt; true, &#125;&#125;include nginx# 一定要使用include来调用，不然是不能执行的[root@puppet manifests]# puppet apply -v --noop class1.pp Notice: Compiled catalog for puppet in environment production in 0.33 secondsInfo: Applying configuration version '1548917037'Notice: /Stage[main]/Nginx/Package[nginx]/ensure: current_value absent, should be latest (noop)Notice: /Stage[main]/Nginx/Service[nginx]/ensure: current_value stopped, should be running (noop)Info: /Stage[main]/Nginx/Service[nginx]: Unscheduling refresh on Service[nginx]Notice: Class[Nginx]: Would have triggered 'refresh' from 2 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.19 seconds[root@puppet manifests]# vim class2.ppclass dbserver ($pkgname='mariadb-server') &#123;# 类有一个参数是$pkgname，mariadb-server是它的默认值。如果传递值给pkgname，就用传递的值，如果没传，就用默认值 package&#123;"$pkgname": ensure =&gt; latest, allow_virtual =&gt; false, &#125; service&#123;'mariadb.service':# 这里要写成mariadb.service，不然会无法启动。测试中，将这里写成mariadb，并在下面加上name =&gt; 'mariadb.service'也是不行的，系统还是会提示service中的mariadb启动。会提示找不到。 ensure =&gt; running, enable =&gt; true, &#125;&#125;# 如果没有定义pkgname的默认值并调用dbserver类，它会不知道包名是什么。如果定义了默认值，在CentOS7上就可以执行了if $operatingsystem == "CentOS" &#123; $dbpkg = $operatingsystemmajrelease ? &#123; 7 =&gt; 'mariadb-server', default =&gt; 'mysqld-server', &#125;&#125;# 判断，如果操作系统是CentOS，并且嵌套判断，如果是7版本，就返回mariadb-server给$dbpkg，否则，就返回mysqld-serverclass&#123;'dbserver': # 给dbserver类的参数传值 pkgname =&gt; $dbpkg, # 这里也可以是一个具体的值，用单引号引起&#125;# 使用class&#123;'dbserver':传递值也是调用类的一种方法# 如果类的参数没有默认值，也可以用这种方法给参数传递值# 这样都定义完才能实现根据不同系统安装不同名称的程序包 类的继承12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@puppet manifests]# cp class1.pp class3.pp[root@puppet manifests]# vim class3.ppclass nginx &#123; package&#123;'nginx': ensure =&gt; latest, allow_virtual =&gt; false, &#125; -&gt; service&#123;'nginx': ensure =&gt; running, enable =&gt; true, require =&gt; Package['nginx'], &#125;&#125;class nginx::web inherits nginx &#123; file&#123;'nginx.conf': # 提供配置文件 path =&gt; '/etc/nginx/nginx.conf', source =&gt; '/root/manifests/nginx.conf', &#125; Package['nginx'] -&gt; File['nignx.conf'] ~&gt; Service['nginx']# 定义Package要先于File资源，最后要通知Service资源&#125;# nginx::web是子类的名称，inherits表示继承，最后是父类的名称。这样定义后，子类就能使用父类中定义的内容了class nginx::webproxy inherits nginx &#123; file&#123;'nginx.conf': path =&gt; '/etc/nginx/nginx.conf', source =&gt; '/root/manifests/nginx-webproxy.conf', &#125; Service['nginx']&#123; enable =&gt; false,# 修改父类中属性的值，要先引用属性，再写修改的值。修改的项如果有值，就修改其值，如果没有此项，就新增此项。 require +&gt; File['nginx.conf'] # +&gt;，表示新增一个参数，但不会修改原值，这里表示依赖File属性 &#125; Package['nginx'] -&gt; File['nginx.conf'] ~&gt; Service['nginx']&#125;class nginx::mysqlproxy inherits nginx &#123;&#125;include nginx::webproxy# 这里只能引用一个子类，因为如果定义了多个，在本机上就没法确定用哪个子类了[root@puppet manifests]# yum install -y nginx[root@puppet manifests]# cp /etc/nginx/nginx.conf /root/manifests[root@puppet manifests]# cp nginx.conf nginx-webproxy.conf[root@puppet manifests]# vim nginx-webproxy.conf location / &#123; proxy_pass http://192.168.1.71; &#125;[root@puppet manifests]# yum remove -y nginx[root@puppet manifests]# puppet apply -v class3.pp-------------------- 192.168.1.71--------------------[root@puppettest1 ~]# yum install nginx -y[root@puppettest1 ~]# vim /usr/share/nginx/html/test.html192.168.1.71[root@puppettest1 ~]# systemctl start nginx访问http://192.168.1.70/test.html，可以看到页面上显示192.168.1.71了。 puppet模板1234567891011121314151617[root@puppet manifests]# vim template.pppackage&#123;'nginx': ensure =&gt; latest,&#125;file&#123;'nginx.conf': path =&gt; '/etc/nginx/nginx.conf', content =&gt; template('/root/manifests/nginx.conf.erb'),# content表示直接生成内容，template是内建的函数，用它去加载一个指定的模板&#125;[root@puppet manifests]# cp nginx.conf nginx.conf.erb[root@puppet manifests]# vim nginx.conf.erb worker_processes &lt;%= @processorcount %&gt;;# processorcount是变量名称，变量是内建的，与auto相同，通过facter -p processorcount命令可以查看到信息。等号是变量替换[root@puppet manifests]# puppet apply -v template.pp[root@puppet manifests]# less /etc/nginx/nginx.conf worker_processes 2;# 使用模板后，这里变为了2 模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150[root@puppet manifests]# vim /etc/puppet/puppet.conf# 配置文件中的[main]表示全局配置段，[agent]表示只用于agent程序[root@puppet manifests]# puppet help config# 查看配置文件帮助信息[root@puppet manifests]# puppet config print# 打印puppet配置信息。其中的modulepath是模块的路径[root@puppet manifests]# puppet config print modulepath/etc/puppet/modules:/usr/share/puppet/modules# 只显示modulepath一项[root@puppet manifests]# puppet help module# 查看模块配置帮助[root@puppet manifests]# puppet module list/etc/puppet/modules (no modules installed)/usr/share/puppet/modules (no modules installed)# 查看模块信息[root@puppet manifests]# puppet module search nginxNotice: Searching https://forgeapi.puppetlabs.com ...# 到互联网搜索与nginx相关的模块[root@puppet manifests]# puppet module install oris-nginxNotice: Preparing to install into /etc/puppet/modules ...Notice: Downloading from https://forgeapi.puppetlabs.com ...Notice: Installing -- do not interrupt .../etc/puppet/modules└─┬ oris-nginx (v1.3.0) ├─┬ puppetlabs-apt (v6.3.0) │ └── puppetlabs-translate (v1.2.0) └── puppetlabs-stdlib (v5.2.0)# 安装模块oris-nginx[root@puppet ~]# mkdir modules[root@puppet ~]# cd modules/[root@puppet modules]# mkdir -pv chrony/&#123;manifests,files,templates,lib,spec,tests&#125;[root@puppet modules]# cd chrony/manifests/[root@puppet manifests]# vim init.pp # 创建清单，名字不能变，都要叫init.ppclass chrony &#123; # 这个清单中必须有一个与模块名相同的类的名字。模块名就是module目录中的目录的名字 package&#123;'chrony': ensure =&gt; latest, &#125; -&gt; file&#123;'chrony.conf': path =&gt; '/etc/chrony.conf', source =&gt; 'puppet:///modules/chrony/chrony.conf',# 这是源路径，表示/etc/puppet/modules/chrony/files目录，只是files目录是不用写，可以自动找到 &#125; ~&gt; service&#123;'chronyd': ensure =&gt; running, enable =&gt; true, &#125;&#125;[root@puppet manifests]# cp /etc/chrony.conf /root/modules/chrony/files/[root@puppet modules]# vim chrony/files/chrony.conf#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 注释三行[root@puppet modules]# cp -a /root/modules/chrony/ /etc/puppet/modules/# 配置好模块后，要将整个目录都复制到puppet的模块目录。上面创建的modules目录只是为了临时编辑用的，编辑好后是要复制到指定目录的，指定目录是通过puppet config print modulepath命令查看到的两个目录都可以[root@puppet modules]# puppet module list/etc/puppet/modules├── chrony (???)├── oris-nginx (v1.3.0)├── puppetlabs-apt (v6.3.0)├── puppetlabs-stdlib (v5.2.0)└── puppetlabs-translate (v1.2.0)/usr/share/puppet/modules (no modules installed)# 现在就能看到chrony模块了[root@puppet modules]# puppet apply -v -d --noop -e 'include chrony'# 使用-e调用模块[root@puppet modules]# puppet apply -v -e 'include chrony'[root@puppet modules]# cat /etc/chrony.conf # Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 可以看到配置文件已被修改[root@puppet modules]# mv /etc/puppet/modules/nginx/ /root# 移走上面安装的nginx模块[root@puppet modules]# mkdir -pv nginx/&#123;manifests,files,templates,spec,lib,tests&#125;[root@puppet modules]# vim nginx/manifests/init.pp # 定义一个基类class nginx &#123; package&#123;'nginx': ensure =&gt; latest, &#125; service&#123;'nginx': ensure =&gt; running, enable =&gt; true, &#125;&#125;[root@puppet modules]# vim nginx/manifests/webproxy.pp# 定义子类。如果代码较多，可以定义多个子类，但一定要有一个与清单名一样的类名称。参考官方文档，3.8版本以后的版本中，资源清单文件的文件名要与子类名一样class nginx::webproxy inherits nginx &#123; file&#123;'nginx.conf': path =&gt; '/etc/nginx/nginx.conf', source =&gt; 'puppet:///modules/nginx/nginx-webproxy.conf', &#125; Package['nginx'] -&gt; File['nginx.conf'] ~&gt; Service['nginx']&#125;[root@puppet modules]# cp /root/manifests/nginx-webproxy.conf nginx/files/[root@puppet modules]# cp -a nginx/ /etc/puppet/modules/[root@puppet modules]# puppet module list/etc/puppet/modules├── chrony (???)├── nginx (???)[root@puppet manifests]# puppet apply -v -d --noop -e 'include nginx::webproxy'==============================================================================================注意：1. puppet 3.8及以后的版本中，资源清单文件的文件名要与文件听类名保持一致，例如某子类名为“base_class::child_class”，其文件名应该为child_class.pp；2. 无需再资源清单文件中使用import语句；3. manifests目录下可存在多个清单文件，每个清单文件包含一个类，其文件名同类名；==============================================================================================[root@puppet manifests]# pwd/etc/puppet/modules/nginx/manifests[root@puppet manifests]# vim web.ppclass nginx::web inherits nginx &#123; file&#123;'nginx.conf': path =&gt; '/etc/nginx/nginx.conf', content =&gt; 'template('nginx/nginx.conf.erb')',# 这里应该是一个相对路径，也就是/etc/puppet/modules下的nginx目录，这里可以省略nginx目录中的template目录，直接写template目录中的nginx.conf.erb即可。 &#125; Package['nginx'] -&gt; File['nginx.conf'] ~&gt; Service['nginx']&#125;[root@puppet manifests]# cp /root/manifests/nginx.conf.erb ../templates/[root@puppet manifests]# puppet apply -v -d --noop -e 'include nginx::web'[root@puppet manifests]# cd /root/modules/[root@puppet modules]# mkdir -pv redis/&#123;manifests,files,templates,spec,lib,tests&#125;下载一个redis-3.2.8-1.el7.x86_64.rpm到 /root/modules/redis/tests目录中[root@puppet modules]# vim redis/manifests/init.ppclass redis &#123; $redispkg='redis-3.2.8-1.el7.x86_64.rpm' package&#123;'redis': ensure =&gt; installed, provider =&gt; yum, source =&gt; "puppet:///modules/redis/$redispkg", &#125; service&#123;'redis': ensure =&gt; running, enable =&gt; true, &#125;&#125;[root@puppet modules]# cp -a redis/ /etc/puppet/modules/[root@puppet modules]# puppet module list/etc/puppet/modules├── chrony (???)├── nginx (???)├── puppetlabs-apt (v6.3.0)├── puppetlabs-stdlib (v5.2.0)├── puppetlabs-translate (v1.2.0)└── redis (???)[root@puppet modules]# puppet apply -v -d --noop -e 'include redis']]></content>
      <categories>
        <category>编排工具</category>
      </categories>
      <tags>
        <tag>puppet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy部署]]></title>
    <url>%2F2019%2F01%2F29%2Fhaproxy%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178==============================================================================================haproxy配置段分为两段，一为全局配置段，一为代理配置段。代理配置段又分为三段，第一段是frontend，用来定义接收以及从何处接收请求。第二段是backend，定义接收到请求后代理至哪些主机，以及如何进行代理。第三段是listen，定义直接匹配的前端和后端，没有分开定义。这三段如果使用同一个值，用defaults定义。==============================================================================================#---------------------------------------------------------------------# Example configuration for a possible web application. See the# full configuration options online.## http://haproxy.1wt.eu/download/1.4/doc/configuration.txt##---------------------------------------------------------------------#---------------------------------------------------------------------# Global settings#---------------------------------------------------------------------global # 全局配置段 # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2# 定义全局日志配置，日志级别为info。127.0.0.1是定义日志输出的地址，local2是日志设备。也就是使用127上的rsyslog来记录日志。这样定义，日志会输出到messages中 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid# pid存放路径 maxconn 4000# haproxy的最大头连接数，与linux的最大打开的文件数有关。一般小于最大打开文件数 user haproxy group haproxy nbproc 1# haproxy启动时创建的进程数，不要超时CPU的核数 daemon# 做守护进程 # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the 'listen' and 'backend' sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http# haproxy实例的运行模式，一般是tcp或http。http就表示工作在七层 log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3# 连接后端服务器失败重试的次数，如果超过这个值就标记为不可用 timeout http-request 10s timeout queue 1m timeout connect 10s# 成功连接服务器的最长等待时间，没有单位是毫秒 timeout client 1m# 客户端发送数据最长等待时间 timeout server 1m# 服务器端回应客户端的最长等待时间 timeout http-keep-alive 10s timeout check 10s# 设置检查后端服务器的超时时间，如果超过这个值就标记不可用 maxconn 3000#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------frontend main *:5000# main是名称，可自定义名称。*:5000表示监听在所有地址的5000端口 mode http# 指定负载均衡的工作模式 option httplog# 设置haproxy记录http请求的日志记录。建议打开 option forwardfor# 让后端服务器获取客户端的真实地址 option httpclose# 客户端与服务器完成一次连接后，服务器主动关闭这个连接 log global# 引用全局的日志配置 acl url_static path_beg -i /static /images /javascript /stylesheets# 以-i后定义的内容开头的信息的名称为url_static acl url_static path_end -i .jpg .gif .png .css .js# 以-i后定义的内容结尾的信息的名称为url_static use_backend static if url_static# 如果是acl中定义了url_static条件的话，就给后端的static池中定义的主机 default_backend app# 默认给app池中定义的主机，也就是不符合给static池的请求都给app#---------------------------------------------------------------------# static backend for serving up images, stylesheets and such#---------------------------------------------------------------------backend static# 定义一组后端服务器，static是自取名 mode http option redispatch# 用于会话保持 option abortonclose# 自动结束处理较长的连接 balance roundrobin# 设置调度算法 cookie SERVERID# 指定cookie的ID值，表示允许向cookie插入一个serverID。serverID在下面配置。如果是source算法，就不用设置 cookie。因为使用cookie就是为了会话保持 option httpchk GET /index.jsp# 探测后端服务器状态，健康检测，如果长时间无效应，会将后端服务器剔除。haproxy会访问下面sever中定义的每一个后端主机的IP/index.jsp来探测主机是否正常 server static 127.0.0.1:4331 cookie server1 weight 6 check inter 2000 rise 2 fall 3# static是主机名，自定义的。之后是地址和端口。cookie server1就是定义上面的cookie SERVERID的。每个server的SERVERID是不一样的。weight是权重。check表示启用对后端服务器的检查，inter是检查的时间间隔，默认单位是毫秒，rise表示连续检查几次标记为正常，fall表示连续检查几次标记为失败#---------------------------------------------------------------------# round robin balancing between the various backends#---------------------------------------------------------------------backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check listen admin_stats# listen可以同时拥前端和后端，将前端与后端绑定在一起。主要配置与监控相关的信息。admin_stats是自定义名称 bind 0.0.0.0:9188# 设置状态页地址和端口 mode http log 127.0.0.1 local0 err stats refresh 20s# 刷新的时间间隔 stats uri /haproxy-status# 状态页的地址 stats realm welcome login\ Haproxy# 欢迎信息 status auth admin:admin123# 验证信息，用户名:密码 stats hide-version# 隐藏版本号 stats admin if TRUE# 开启管理后端服务器功能==============================================================================================算法1. roundrobin：Each server is used in turns, according to their weights.# 设置高度算法为轮询，这里的轮询是加权轮询，这取决于下面的server中是否设定了权重。roundrobin是动态算法，支持权重的运行时调整，调整完不用重启服务。另外支持慢启动，慢启动指当后端加入一台新服务器时，调度器会将请求慢慢地分配到新加入的服务器上，如果马上全部分配到新加入的服务器上，对服务器的压力很大。roundrobin对后端主机的数量是有限制的。最多支持4095个。# server options： weight #2. static-rr# 静态算法：不支持权重的运行时调整及慢启动；后端主机数量无上限；3. leastconn# 加权最少连接，最少连接的接收请求，这个算法也是动态的。建议使用在支持长连接的会话中。例如MySQL、LDAP等；4. first：# 根据服务器在列表中的位置，自上而下进行调度；前面服务器的连接数达到上限，新请求才会分配给下一台服务。如果后端有三台服务器，这个算法会依次将后端服务器请求打满，第一台打满后再给第二台服务器5. source# 源地址hash，相当于nginx中的IPhash，LVS的HS。如果hash取决于hast-type，如果是map-based就是取模法，取模法就是把所有服务器按权重虚拟成节点，如果是权重是2就虚拟成两个节点。对数组元素数量取模，等于几就映射给索引为几的服务器，但服务器变动，hash值会影响全局。如果是consistent就是一致性hash6. uri# 将请求同一个uri的主机代理到后端同一台主机，取决与hash-type# 对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器；# &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt;# 左半部分：/&lt;path&gt;;&lt;params&gt;# 整个uri：/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt;7. url_param# 调度时以某个特定的值调度到后端同一主机，用处不大。动态还是静态取决于hash-type# 对用户请求的uri&lt;params&gt;部分中的参数的值作hash计算，并由服务器总权重相除以后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server；8. hdr(&lt;name&gt;)# 请求报文的首部，对对应首部的值做hash，一样的就给同一主机。可以对浏览器调度# 对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算； 并由服务器总权重相除以后派发至某挑出的服务器；没有有效值的会被轮询调度；根据HTTP请求头来锁定每一次HTTP请求 9. rdp-cookie(&lt;name&gt;)# 远程桌面协议# 表示根据cookie(name)来锁定并哈希第一次TCP请求# uri向下的四种算法为七层算法，用的不多常用的负载均衡算法1.轮询算法：roundrobin2. 根据请求源IP算法：source3. 最少连接者先处理算法：leastconn============================================================================================== 测试轮询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283==============================================================================================环境准备三台主机haproxy：外网地址：192.168.1.25；内网地址：172.16.106.143httpd1：内网地址：172.16.106.145httpd2：内网地址：172.16.106.144==============================================================================================--------------- httpd1&amp;2---------------[root@httpd1 ~]# yum install -y httpd[root@httpd1 ~]# systemctl start chronyd[root@httpd1 ~]# systemctl enable chronyd[root@httpd1 ~]# chronycchrony version 3.1Copyright (C) 1997-2003, 2007, 2009-2017 Richard P. Curnow and otherschrony comes with ABSOLUTELY NO WARRANTY. This is free software, andyou are welcome to redistribute it under certain conditions. See theGNU General Public License version 2 for details.chronyc&gt; waitsync try: 1, refid: 771CCEC1, correction: 0.000001078, skew: 32.010# 同步时间[root@httpd1 ~]# vim /var/www/html/index.htmlBackend Server 1# 给两台服务器提供一个主面，另一台服务器的内容是Backend Server 2[root@httpd1 ~]# systemctl start httpd[root@httpd2 ~]# curl 172.16.106.144Backend Server 2[root@httpd2 ~]# curl 172.16.106.145Backend Server 1-------------- haproxy--------------[root@haproxy haproxy]# vim /etc/rsyslog.conf$ModLoad imudp # 基于UDP收集日志$UDPServerRun 514 # 监听端口local2.* /var/log/haproxy.log# 加入此行，设置haproxy的日志路径[root@haproxy haproxy]# systemctl restart rsyslog[root@haproxy ~]# cd /etc/haproxy/[root@haproxy haproxy]# cp haproxy.cfg&#123;,.bak&#125;[root@haproxy haproxy]# vim haproxy.cfgglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend myweb # 定义前端主机，取名叫myweb bind *:80 # 定义haproxy的监听端口 default_backend websrvs # 定义默认使用的后端主机是websrvsbackend websrvs # 定义后端主机组叫websrvs balance roundrobin # 使用轮询的方式 server srv1 172.16.106.145:80 check server srv2 172.16.106.144:80 check# 后端主机信息，使用server定义，srv1是haproxy内部引用的ID号，自定义的。它是服务器在haproxy上的内部名称；出现在日志及警告信息；check是对主机的健康检测，如果不加，那么会被认为是始终在线的。这是四层检测，发TCP请求，如果响应就表示在线[root@haproxy haproxy]# systemctl start haproxy[root@haproxy haproxy]# for i in `seq 10`;do curl 192.168.1.25;doneBackend Server 1Backend Server 2 first算法12345678910111213141516171819202122==============================================================================================根据服务器在列表中的位置，自上而下进行调度；前面服务器的连接数达到上限，新请求才会分配给下一台服务；==============================================================================================-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 default_backend websrvsbackend websrvs balance first server srv1 172.16.106.145:80 check maxconn 3 # maxconn指定最大并发连接数 server srv2 172.16.106.144:80 check[root@haproxy haproxy]# systemctl restart haproxy.service [root@haproxy haproxy]# yum install -y httpd-tools[root@haproxy haproxy]# ab -n 100000 -c 10 http://192.168.1.25/index.html------------ httpd2------------[root@httpd2 ~]# tail -f /var/log/httpd/access_log # 在第二台web服务器上查看日志，如果有请求日志，就说明第一台web服务器打满了 uri算法1234567891011121314151617181920212223242526==============================================================================================对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器；只要访问的是同一页面，不管是哪台主机，都发往同一台服务器==============================================================================================-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 default_backend websrvsbackend websrvs balance uri server srv1 172.16.106.145:80 check maxconn 3 # maxconn指定最大并发连接数 server srv2 172.16.106.144:80 check[root@haproxy haproxy]# systemctl restart haproxy.service --------------- httpd1&amp;2---------------[root@httpd2 ~]# for i in &#123;1..10&#125;;do echo "Test Page $i @BES 1" &gt; /var/www/html/test$i.html;done# 在两台主机上分别添加主页-------------- haproxy--------------[root@haproxy haproxy]# for i in `seq 10`;do curl http://192.168.1.25/test1.html;done# 这时显示的内容是一样的，因为请求被发到了同一台主机。另外可以换其他主机再访问，结果应该和这里一样，因为访问的都是同一页面 hdr算法1234567891011121314151617==============================================================================================hdr(&lt;name&gt;)：对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算，并由服务器总权重相除以后派发至某挑出的服务器，没有有效值的会被轮询调度。==============================================================================================-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 default_backend websrvsbackend websrvs balance hdr(User-Agent)# 对客户端浏览器进行hash计算并调度，如果浏览器一样就发往后端同一主机 server srv1 172.16.106.145:80 check maxconn 3 # maxconn指定最大并发连接数 server srv2 172.16.106.144:80 check[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]# for i in `seq 10`;do curl http://192.168.1.25/test1.html;done# 这时不管访问哪个页面，都会被发到同一台服务器处理，到哪台后端服务器是不能预测的 压缩测试1234567891011121314151617181920212223-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check maxconn 3 server srv2 172.16.106.144:80 check[root@haproxy haproxy]# systemctl restart haproxy.service------------ httpd1------------[root@httpd1 ~]# cp /var/log/httpd/access_log /var/www/html/log.txt# 找一个大一些的文件做压缩测试[root@httpd1 ~]# rsync -e ssh -arzv --progress /var/www/html/log.txt 172.16.106.144:/var/www/html/# 将文件复制到另一台web服务器上用firefox访问192.168.1.77/log.txt，按F12，这时Response headers(响应头)中会有Content-Encoding gzip的显示 备用主机1234567891011121314151617181920212223242526272829303132333435-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check server srv2 172.16.106.144:80 check backup# backup指备用主机，也就是sorryserver.[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]# for i in `seq 10`;do curl http://192.168.1.25/index.html;doneBackend Server 1# 这时请求只会发到第一台web服务器上------------ httpd1------------[root@httpd1 ~]# systemctl stop httpd# 停止web服务-------------- haproxy--------------[root@haproxy haproxy]# for i in `seq 10`;do curl http://192.168.1.25/index.html;doneBackend Server 2------------ httpd1------------[root@httpd1 ~]# systemctl start httpd# 启动web服务后，所有的请求又都会发到httpd1上了 七层反向代理12345678910111213141516171819202122232425262728293031323334353637383940414243-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin option httpchk server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service# 反向代理在四层还是七层取决于mode设置的是tcp还是http------------ httpd1------------[root@httpd1 ~]# tail -f /var/log/httpd/access_log# 这时这里会不停显示"172.16.106.143 - - [29/Jan/2019:09:54:16 +0800] "OPTIONS / HTTP/1.0" 200 - "-" "-""，这表示haproxy发出的健康检测请求，但这会产生大量无效日志-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin option httpchk GET /index.html HTTP/1.0# 指定使用GET方法，对/index.html检测，协议是HTTP/1.0 server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2# inter是每隔多久检测一次，单位是毫秒；rise是检测几次就上线，fall检测几次就下线 server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service------------ httpd1------------[root@httpd1 ~]# tail -f /var/log/httpd/access_log172.16.106.143 - - [29/Jan/2019:09:57:45 +0800] "GET /index.html HTTP/1.0" 200 17 "-" "-" 重定向1234567891011121314151617-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin option httpchk GET /index.html HTTP/1.0# 指定使用GET方法，对/index.html检测，协议是HTTP/1.0 server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 redir http://www.baidu.com# redir &lt;prefix&gt;：将发往此server的所有GET和HEAD类的请求重定向至指定的URL server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service访问192.168.1.25时会被转到百度首页 权重123456789101112131415161718-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2# 使用weight定义权重 server srv2 172.16.106.144:80 check weight 1[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]# for i in `seq 10`;do curl http://192.168.1.25/index.html;doneBackend Server 1Backend Server 1Backend Server 2 状态页12345678910111213141516-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 stats enable compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service访问192.168.1.25/haproxy?stats，如果设置中没有用stats uri指定页面地址，/haproxy?stats是默认的页面。页面中会用颜色标记后端主机，配置文件中的第二个server是backup，不同状态主机用不同颜色标识。停掉第一台web服务器的服务，颜色也会改变 自定义状态页uri1234567891011121314151617-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 stats enable stats uri /myproxy?admin # 自定义状态页uri compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service访问http://192.168.1.25/myproxy?admin 登录状态页认证1234567891011121314151617181920-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 stats enable stats uri /myproxy?admin # 自定义状态页uri stats realm "HAProxy Stats Page" # 设置登录认证时弹出的信息。测试中此项未起作用 stats auth admin:centos # 设置认证的用户名和密码 stats admin if TRUE # 启用页面的管理功能，if TRUE表示一直为真，总是可以访问，生产中不能这样使用 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 server srv2 172.16.106.144:80 check backup[root@haproxy haproxy]# systemctl restart haproxy.service访问http://192.168.1.25/myproxy?admin，打开页面的管理功能后，可以页面进行一些简单操作 自定义状态页面的端口1234567891011121314151617181920212223-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 server srv2 172.16.106.144:80 check weight 1listen stats # listen可以同时拥前端和后端，将前端与后端绑定在一起。主要配置与监控相关的信息。 bind *:9099 stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUE# 在这里定义listen，名字叫stats，之后用bind指定状态页的端口，打开相应功能。与上面一样实现了状态页功能，只是这里又定义了状态页的端口[root@haproxy haproxy]# systemctl restart haproxy.service访问http://192.168.1.25:9099/myproxy?admin 代理ssh1234567891011121314151617181920212223242526272829-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 server srv2 172.16.106.144:80 check weight 1listen stats bind *:9099 stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUElisten sshsrvs mode tcp bind *:22322 balance leastconn server sshsrv1 172.16.106.145:22 check server sshsrv2 172.16.106.144:22 check# 再添加一个listen，用mode指定在tcp层(四层)实现代理。监听在22322端口，leastconn算法表示加权最少连接，最少连接的接收请求，建议使用在支持长连接的会话中。这个算法也是动态的[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]#ssh 192.168.1.25 -p 22322# 连接了两次，分别连接到了两台httpd上 cookie粘性绑定123456789101112131415161718192021222324252627282930-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript default_backend websrvsbackend websrvs cookie SRV insert indirect nocache balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 cookie srv1 server srv2 172.16.106.144:80 check weight 1 cookie srv1# 加入cookie的键名，server最后的cookie是其值，cookie的值最好和server的名字一致。当用户访问时，如果被调度到第一台web服务器上，用户的cookie中会加入cookie的键和值在开头，这里就是SRV=srv1，当用户再次访问时，这个cookie的键和值也会到haproxy服务器，这时haproxy就知道上次这个用户的请求被调度到哪台服务器上，这次还会调度到同一台服务器上。insert表示信息数据的插入方式，上面表示仅对indirect和nocache这样的数据拷入cookielisten stats bind *:9099 stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUElisten sshsrvs mode tcp bind *:22322 balance leastconn server sshsrv1 172.16.106.145:22 check server sshsrv2 172.16.106.144:22 check[root@haproxy haproxy]# systemctl restart haproxy.service用浏览器访问192.168.1.25，访问多次也不会有变化 让后端主机收到的请求地址是源地址123456789101112131415161718-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgdefaults option forwardfor except 127.0.0.0/8 if-none# 此项是原本就有的，forwardfor表示对请求加入一个首部，得到后端服务器真正的请求地址。except表示除了，这里表示除了本机127地址发出的请求，其他请求都加入首部。if-none表示如果没有首部才添加------------ httpd1------------[root@httpd1 ~]# vim /etc/httpd/conf/httpd.confLogFormat "%&#123;X-Forwarded-For&#125;i %h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combined# 将%h改为%&#123;X-Forwarded-For&#125;i，X-Forwarded-For是haproxy中forwardfor默认的格式[root@httpd1 ~]# systemctl restart httpd[root@httpd1 ~]# tail -f /var/log/httpd/access_log# 再次访问192.168.1.25时，查看web服务器日志，可以看到客户端的请求IP地址，而不再是haproxy的内网地址了。 添加首部12345678910111213141516171819202122232425262728293031323334353637383940414243444546-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript reqadd X-Proxy-By:\ HAProxy# 添加请求报文首部，\是转义符，转义后面的空格。X-Proxy-By:\ HAProxy都是自定义的名称，表示这个服务器是由Haproxy代理的 rspadd X-Proxy-By:\ HAProxy-1.5# 添加响应首部 rspidel ^Server:.*# 删除响应报文中Server开头的所有内容 default_backend websrvsbackend websrvs cookie SRV insert indirect nocache balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 cookie srv1 server srv2 172.16.106.144:80 check weight 1 cookie srv1listen stats bind *:9099 stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUElisten sshsrvs mode tcp bind *:22322 balance leastconn server sshsrv1 172.16.106.145:22 check server sshsrv2 172.16.106.144:22 check[root@haproxy haproxy]# systemctl restart haproxy.service------------ httpd1------------[root@httpd1 ~]# vim /etc/httpd/conf/httpd.confLogFormat "%&#123;X-Forwarded-For&#125;i %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i %&#123;X-Proxy-By&#125;i\"" combined# 将请求首部加到最后[root@httpd1 ~]# systemctl restart httpd[root@httpd1 ~]# tail -f /var/log/httpd/access_log192.168.1.9 - - [29/Jan/2019:11:13:52 +0800] "GET / HTTP/1.1" 304 - "-" "Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0 HAProxy"访问192.168.1.25，并查看日志，可以看到请求首部HAProxy在浏览器上按F12可以看到响应首部，在Response headers中有X-Proxy-By: HAProxy-1.5 acl访问控制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript reqadd X-Proxy-By:\ HAProxy# 添加请求报文首部，\是转义符，转义后面的空格。X-Proxy-By:\ HAProxy都是自定义的名称，表示这个服务器是由Haproxy代理的 rspadd X-Proxy-By:\ HAProxy-1.5# 添加响应首部 rspidel ^Server:.*# 删除响应报文中Server开头的所有内容 default_backend websrvsbackend websrvs cookie SRV insert indirect nocache balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 cookie srv1 server srv2 172.16.106.144:80 check weight 1 cookie srv1listen stats bind *:9099 acl allowstats src 192.168.1.9# 定义acl名字是allowstats，只允许源地址是192.168.1.64的地址来访问# acl all src 0.0.0.0/0.0.0.0表示设置acl为所有主机地址 block if ! allowstats# 定义除allowstats以外的任何主机不能访问，!是取反的。如果没有!号，表示除了allowstats外的主机都能访问。block是阻塞之意。# http-request allow if allowstats表示允许allowstats的主机访问，这样所有主机都能访问了。# http-request deny if all：不允许除allowstats外的其他主机访问# 先要自定义一个acl，之后用http-request指定，这样可以实现除了allowstats外的其他主机都不能访问============================================================================================== acl allowstats src 192.168.1.9 http-request allow if allowstats errorfile 403 /etc/haproxy/errorfiles/403forbid.http acl all src 0.0.0.0/0.0.0.0 http-request deny if all#上面可以设置为这样，结果是只有192.168.1.9可以访问状态页，其他主机不可访问。要注意acl与http-request要定义在一起，如果将http-request allow放在http-request deny下面，也会使所有主机都不能访问状态页============================================================================================== errorloc 403 http://192.168.1.25:10080/errorloc/403.html# 这里不能定义errorfile，因为上面已经拒绝本机访问了，也就是本机不能访问http://192.168.1.25# 这里也可以使用errorfile 403 /etc/haproxy/errorfiles/403forbid.http，之后创建/etc/haproxy/errorfiles/403forbid.http，当无权访问时，就会提示错误页的内容。# errorfile &lt;code&gt; &lt;file&gt;：在用户请求不存在的页面时，返回一个页面文件给客户端而非由haproxy生成的错误代码；可用于所有段中。&lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504；&lt;file&gt;：指定用于响应的页面文件； stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUElisten sshsrvs mode tcp bind *:22322 balance leastconn server sshsrv1 172.16.106.145:22 check server sshsrv2 172.16.106.144:22 check[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]# yum install -y nginx[root@haproxy haproxy]# vim /etc/nginx/conf.d/errorsrv.confserver &#123; listen 10080; server_name 192.168.1.25; root /data/nginx/html;&#125;[root@haproxy haproxy]# mkdir -pv /data/nginx/html/errorloc[root@haproxy haproxy]# vim /data/nginx/html/errorloc/403.html403 Forbidden from nginx [root@haproxy haproxy]# systemctl start nginx# 使用nginx提供一个haproxy的错误页[root@haproxy haproxy]# curl --basic --user admin:centos http://192.168.1.25:9099/myproxy?admin/# 使用curl命令访问，基于basic认证，用户名和密码用--user指定使用一台新主机访问http://192.168.1.25:9099/myproxy?admin，因为此主机的地址不是192.168.1.9，所以返回nginx提供的错误页内容：403 Forbidden from nginx。 后端主机动静分离123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105==============================================================================================后端两台web服务器，一台配置为两个虚拟主机，支持动态服务。另一台也配置为两台虚拟主机，支持静态服务。静态服务当图片服务器==============================================================================================------------ httpd1------------[root@httpd1 network-scripts]# yum install -y php[root@httpd1 ~]# mkdir -pv /data/web/vhost&#123;1,2&#125;[root@httpd1 ~]# vim /data/web/vhost1/info.php&lt;h1&gt;Application Server 1&lt;/h1&gt; #vhost2中将此处改为Application Server 2&lt;?php phpinfo();?&gt;[root@httpd1 ~]# cp /data/web/vhost&#123;1,2&#125;/info.php# 将vhost1中的info.php复制到vhost2中[root@httpd1 ~]# vim /etc/httpd/conf.d/vhost1.conf&lt;VirtualHost *:80&gt; ServerName www1.test.com DocumentRoot "/data/web/vhost1" &lt;Directory "/data/web/vhost1"&gt; options FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;[root@httpd1 ~]# cp /etc/httpd/conf.d/vhost&#123;1,2&#125;.conf[root@httpd1 ~]# vim /etc/httpd/conf.d/vhost2.confListen 8080&lt;VirtualHost *:8080&gt; ServerName www2.test.com DocumentRoot "/data/web/vhost2" &lt;Directory "/data/web/vhost2"&gt; options FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;[root@httpd1 ~]# httpd -t[root@httpd1 ~]# systemctl restart httpd访问http://172.16.106.145/info.php，http://172.16.106.145:8080/info.php可以看到php页面[root@httpd1 ~]# scp /etc/httpd/conf.d/vhost* 172.16.106.144:/etc/httpd/conf.d/------------ httpd2------------[root@httpd2 ~]# mkdir -pv /data/web/vhost&#123;1,2&#125;[root@httpd2 vhost1]# find /usr/share -iname "*.jpg" -exec cp &#123;&#125; /data/web/vhost1/ \;[root@httpd2 vhost1]# find /usr/share -iname "*.jpg" -exec cp &#123;&#125; /data/web/vhost2/ \;[root@httpd2 ~]# vim /data/web/vhost1/test.txtImage Server 1[root@httpd2 ~]# vim /data/web/vhost2/test.txtImage Server 2[root@httpd2 ~]# systemctl restart httpd# 这里已有从httpd1上复制过来的配置文件访问http://172.16.106.144/test.txt，http://172.16.106.144:8080/test.txt-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 compression algo gzip compression type text/html text/plain application/xml application/javascript acl static path_end .jpg .jpeg .png .gif .txt .html .css .javascript .js# path_end表示以什么结尾的。请求时，一定要写明后缀，如curl 192.168.1.25/index.html，不然请求都会被代理到动态服务器上。因为设置了默认是发给动态服务器，而且动态服务器设置了cookie粘性绑定，信息是不会变的 acl static path_beg /imgs /images /css /javascripts# path_beg定义以什么开头。两个acl可以一起使用 use_backend staticsrvs if static# use_backend表示当符合指定的条件时使用特定的backend。这表示如果访问的内容是以acl中定义的结尾的静态内容，就给后端的staticsrvs主机。否则就给下面default定义的动态主机 default_backend dynsrvs# 默认主机组 reqadd X-Proxy-By:\ HAProxy rspadd X-Proxy-By:\ HAProxy-1.5 rspidel ^Server:.*backend dynsrvs cookie SRV insert indirect nocache balance roundrobin server srv1 172.16.106.145:80 check inter 3000ms rise 1 fall 2 weight 2 cookie dynsrv1 server srv2 172.16.106.145:8080 check weight 1 cookie dynsrv2backend staticsrvs balance roundrobin server srv1 172.16.106.144:80 check server srv2 172.16.106.144:8080 checklisten stats bind *:9099 acl allowstats src 192.168.1.9 block if ! allowstats errorloc 403 http://192.168.1.25:10080/errorloc/403.htm stats enable stats uri /myproxy?admin stats realm "HAProxy Stats Page" stats auth admin:centos stats admin if TRUElisten sshsrvs mode tcp bind *:22322 balance leastconn server sshsrv1 172.16.106.145:22 check server sshsrv2 172.16.106.144:22 check[root@haproxy haproxy]# systemctl restart haproxy.service访问状态页192.168.1.25:9099/myproxy?admin访问192.168.1.25/info.php，因为cookie绑定了，所以内容不会变访问192.168.1.25/test.txt，多次访问会有变化 阻塞curl工具访问12345678910111213-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 acl bad_browsers hdr_reg(User-Agent) .*curl.* block if bad_browsers# 加入上面两条，定义acl，用hdr_reg，直接匹配用户请求报文中的首部，下面使用block拒绝acl设置的客户端访问[root@haproxy haproxy]# systemctl restart haproxy.service[root@haproxy haproxy]# curl http://192.168.1.25&lt;html&gt;&lt;body&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;Request forbidden by administrative rules.&lt;/body&gt;&lt;/html&gt; 阻塞域访问1234567891011121314151617-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend myweb *:80 acl valid_referers hdr_reg(Referer) \.ruopu\.com.*# 用hdr_reg，匹配Referer，匹配来自ruopu.com的任何值 block unless valid_referers# 不是上面定义的值就拒绝[root@haproxy haproxy]# curl -e "http://www.ruopu.com/admin.php" http://192.168.1.25/test2.htmlTest Page 2 @BES 1# 用-e模拟一个Referer，这样就能返回值了[root@haproxy haproxy]# curl http://192.168.1.25/test2.html&lt;html&gt;&lt;body&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;Request forbidden by administrative rules.&lt;/body&gt;&lt;/html&gt;# 直接访问是没有权限的 SSL功能123456789101112131415161718192021222324252627282930313233343536373839404142-------------- haproxy--------------[root@haproxy haproxy]# vim haproxy.cfgfrontend https bind *:443 ssl crt /etc/haproxy/certs/haproxy.pem# 定义用ssl协议，crt指明密钥的路径 acl static path_end .jpg .jpeg .png .gif .txt .html .css .javascript .js acl static path_beg /imgs /images /css /javascripts use_backend staticsrvs if static default_backend dynsrvs# 与上面一样，如果是特定结尾或开头的就转到静态页，不是的就转到动态页frontend http *:80 redirect scheme https if ! &#123; ssl_fc &#125;# redirect即为重定向之意。scheme指协议，ssl_fc指非ssl会话的前端链接。这是定义，如果不是https协议的非前端会话，都转到https443端口上。[root@haproxy certs]# mkdir /etc/haproxy/certs[root@haproxy certs]# cd /etc/pki/CA[root@haproxy certs]# (umask 077;openssl genrsa -out private/cakey.pem 4096)[root@haproxy certs]# openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365[root@haproxy certs]# touch index.txt[root@haproxy certs]# echo 01 &gt; serial[root@haproxy certs]# cd /etc/haproxy/certs/[root@haproxy certs]# openssl genrsa -out haproxy.key 2048[root@haproxy certs]# openssl req -new -key haproxy.key -out haproxy.csr[root@haproxy certs]# openssl ca -in haproxy.csr -out haproxy.crt[root@haproxy certs]# cat haproxy.crt haproxy.key &gt; haproxy.pem# 将两个文件打包成pem文件[root@haproxy certs]# chmod 600 haproxy.pem[root@haproxy certs]# systemctl restart haproxy[root@haproxy certs]# ss -tln# 这时应该有443和8080端口被监听访问https://192.168.1.25/test.txt访问http://192.168.1.25/test.txt，访问会被重定向到https[root@haproxy haproxy]# vim haproxy.cfgfrontend http *:80 redirect location https://192.168.1.25 if ! &#123; ssl_fc &#125;# 设置所有请求都重定向到https://172.16.0.67访问http://192.168.1.25/test.txt，这会重定向到https://172.16.0.67。不论访问什么页面，都会重定向到https://172.16.0.67]]></content>
      <categories>
        <category>balance</category>
      </categories>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS部署]]></title>
    <url>%2F2019%2F01%2F28%2FLVS%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[介绍 LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的官方网是 http://www.linuxvirtualserver.org 现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。LVS 是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。 LVS的基本工作原理 当用户向负载均衡调度器（Director Server）发起请求时，调度器将请求发往至内核空间 PREROUTING链首先会接收到用户请求，判断目标IP确定是本机IP，将数据包发往INPUT链 IPVS是工作在INPUT链上的，当用户请求到达INPUT时，IPVS会将用户请求和自己已定义好的集群服务进行比对，如果用户请求的就是定义的集群服务，那么此时IPVS会强行修改数据包里的目标IP地址及端口，并将新的数据包发往POSTROUTING链 POSTROUTING链接收数据包后发现目标IP地址刚好是自己的后端服务器，那么此时通过选路，将数据包最终发送给后端的服务器 LVS的组成 LVS 由两部分程序组成，包括 ipvs 和 ipvsadm。 ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs，是真正生效实现调度的代码。 ipvsadm：在用户空间，负责为ipvs内核框架编写规则，定义谁是集群服务，而谁是后端真实的服务器(Real Server) LVS相关术语 DS：Director Server。前端负载均衡器节点。 RS：Real Server。后端真实的工作服务器。 VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP：Director Server IP，前端负载均衡器节点上用于和内部主机通讯的IP地址。 RIP：Real Server IP，后端服务器的IP地址。 CIP：Client IP，访问客户端的IP地址。 LVS/NAT原理和特点 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP POSTROUTING链通过选路，将数据包发送给Real Server Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP Director Server在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP LVS-NAT模型的特性 RS应该使用私有地址，RS的网关必须指向DIP DIP和RIP必须在同一个网段内 请求和响应报文都需要经过Director Server，高负载场景中，Director Server易成为性能瓶颈支持端口映射 RS可以使用任意操作系统 缺陷：对Director Server压力会比较大，请求和响应都需经过director server LVS/DR原理和特点 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址 由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。 RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP 响应报文最终送达至客户端 LVS-DR模型的特性 特点 保证前端路由将目标地址为VIP报文统统发给Director Server，而不是RS RS可以使用私有地址；也可以是公网地址，如果使用公网地址，此时可以通过互联网对RIP进行直接访问 RS和Director Server必须在同一个物理网络中 所有的请求报文经由Director Server，但响应报文必须不能经过Director Server 不支持地址转换，也不支持端口映射 RS可以是大多数常见的操作系统 RS的网关绝不允许指向DIP(因为我们不允许他经过director) RS上的lo接口配置VIP的IP地址 缺陷：RS和DS必须在同一机房中 企业中最常用的是 DR 模型 解决 在前端路由器做静态地址路由绑定，将对于VIP的地址仅路由到Director Server。但用户未必有路由操作权限，因为有可能是运营商提供的，所以这个方法未必实用 arptables：在arp的层次上实现在ARP解析时做防火墙规则，过滤RS响应ARP请求。这是由iptables提供的。修改RS上内核参数（arp_ignore和arp_announce），将RS上的VIP配置在lo接口的别名上，并限制其不能响应对VIP地址解析请求。 LVS/Tun原理和特点 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 。 PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 IPVS比对数据包请求的服务是否为集群服务，若是，在请求报文的首部再次封装一层IP报文，封装源IP为为DIP，目标IP为RIP。然后发至POSTROUTING链。 此时源IP为DIP，目标IP为RIP POSTROUTING链根据最新封装的IP报文，将数据包发至RS（因为在外层封装多了一层IP首部，所以可以理解为此时通过隧道传输）。 此时源IP为DIP，目标IP为RIP RS接收到报文后发现是自己的IP地址，就将报文接收下来，拆除掉最外层的IP后，会发现里面还有一层IP首部，而且目标是自己的lo接口VIP，那么此时RS开始处理此请求，处理完成之后，通过lo接口送给eth0网卡，然后向外传递。 此时的源IP地址为VIP，目标IP为CIP 响应报文最终送达至客户端 LVS-Tun模型特性 RIP、VIP、DIP全是公网地址 RS的网关不会也不可能指向DIP 所有的请求报文经由Director Server，但响应报文必须不能进过Director Server 不支持端口映射 RS的系统必须支持隧道 LVS的八种调度算法轮叫调度 rr 这种算法是最简单的，就是依次将请求调度到不同的服务器上，该算法最大的特点就是简单。轮询算法假设所有的服务器处理请求的能力都是一样的，调度器会将所有的请求平均分配给每个真实服务器，不管后端 RS 配置和处理能力，非常均衡地分发下去。 加权轮叫 wrr 这种算法比 rr 的算法多了一个权重的概念，可以给 RS 设置权重，权重越高，那么分发的请求数越多，权重的取值范围 0 – 100。主要是对rr算法的一种优化和补充， LVS 会考虑每台服务器的性能，并给每台服务器添加权值，如果服务器A的权值为1，服务器B的权值为2，则调度到服务器B的请求会是服务器A的2倍。权值越高的服务器，处理的请求越多。 最少链接 lc 这个算法会根据后端 RS 的连接数来决定把请求分发给谁，比如 RS1 连接数比 RS2 连接数少，那么请求就优先发给 RS1 加权最少链接 wlc 这个算法比 lc 多了一个权重的概念。 基于局部性的最少连接调度算法 lblc 这个算法是请求数据包的目标 IP 地址的一种调度算法，该算法先根据请求的目标 IP 地址寻找最近的该目标 IP 地址所有使用的服务器，如果这台服务器依然可用，并且有能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其它可行的服务器 复杂的基于局部性最少的连接算法 lblcr 记录的不是目标 IP 与一台服务器之间的连接记录，而是维护一个目标 IP 到一组服务器之间的映射关系，防止单点服务器负载过高。 #### 目标地址散列调度算法 dh 该算法是根据目标 IP 地址通过散列函数将目标 IP 与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标 IP 的请求会固定发给该服务器。 源地址散列调度算法 sh 与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源。 部署LVS/NAT模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051==============================================================================================环境准备三台主机director：外网地址：192.168.1.26；内网地址：172.16.106.140realServer1：内网地址：172.16.106.142realServer2：内网地址：172.16.106.141==============================================================================================--------------------- realServer1&amp;2---------------------[root@realserver1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33IPADDR=172.16.106.142# realServer2主机的地址为172.16.106.141NETMASK=255.255.255.0GATEWAY=172.16.106.140# 配置两台realServer主机的地址为静态地址，并将网关指向director的内网地址。[root@realserver2 ~]# yum install -y nginx# 两台主机需要安装nginx，可以临时添加dirctor的防火墙规则，iptables -t nat -A POSTROUTING -s 172.16.106.0/24 -j SNAT --to-source 192.168.1.26，并开启路由转发功能，echo 1 &gt; /proc/sys/net/ipv4/ip_forward，最后为realServer配置DNS。这样realServer就可以连接外网了。安装nginx后再取消director的防火墙规则。[root@realserver1 ~]# mkdir /usr/share/nginx/html/test[root@realserver1 ~]# vim /usr/share/nginx/html/test/index.html realServer1# 在两台主机上添加主面测试文件，一个是realServer1，一个是realServer2[root@realserver1 ~]# systemctl start nginx-------------- Director--------------[root@director ~]# yum install -y ipvsadm#!/bin/bash#echo 1 &gt; /proc/sys/net/ipv4/ip_forwardecho 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirects[root@director ~]# ipvsadm -A -t 192.168.1.26:80 -s wrr[root@director ~]# ipvsadm -a -t 192.168.1.26:80 -r 172.16.106.142:80 -m -w 1[root@director ~]# ipvsadm -a -t 192.168.1.26:80 -r 172.16.106.141:80 -m -w 1[root@director ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.1.26:80 wrr -&gt; 172.16.106.141:80 Masq 1 1 0 -&gt; 172.16.106.142:80 Masq 1 1 0 [root@director ~]# ipvsadm -C # 清除所有ipvs规则--------- 本机---------使用IE浏览器访问192.168.1.26/test/，会轮流返回realServer上的页面内容。不能使用realServer访问，访问超时，不会返回结果 部署LVS/DR模型1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950环境准备三台主机，以上面三台主机为基础director：外网地址：192.168.1.26realServer1：内网地址：192.168.1.27realServer2：内网地址：192.168.1.28VIP：192.168.1.260-------------- Director--------------[root@director ~]# ipvsadm -C[root@director ~]# vim lvs_dr.sh#! /bin/bash#echo 1 &gt; /proc/sys/net/ipv4/ip_forwardvip=192.168.1.60rs1=192.168.1.27rs2=192.168.1.28ifconfig ens33:0 downifconfig ens33:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip dev ens33:0[root@director ~]# ipvsadm -A -t 192.168.1.60:80 -s wrr[root@director ~]# ipvsadm -a -t 192.168.1.60:80 -r 192.168.1.27 -g -w 1[root@director ~]# ipvsadm -a -t 192.168.1.60:80 -r 192.168.1.28 -g -w 1[root@director ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.1.60:80 wrr -&gt; 192.168.1.27:80 Route 1 0 0 -&gt; 192.168.1.28:80 Route 1 0 0 --------------------- realServer1&amp;2---------------------[root@realserver1 ~]# vim lvs_dr_rs.sh #! /bin/bash#vip=192.168.1.60ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce--------- 本机---------使用IE浏览器访问192.168.1.26/test/，会轮流返回realServer上的页面内容。不能使用realServer访问，访问超时，不会返回结果 部署keepalived+LVS环境123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105环境准备四台主机，以上面三台主机为基础director1：外网地址：192.168.1.26director2：外网地址：192.168.1.26realServer1：内网地址：192.168.1.27realServer2：内网地址：192.168.1.28VIP：192.168.1.260------------------ Director1&amp;2------------------[root@director keepalived]# ifconfig ens33:0 down# down掉director1上的ens33:0网卡，因为此网卡上有VIP地址。影响下面的keepalived测试[root@realserver2 ~]# yum install -y ipvsadm keeyalived[root@director ~]# cd /etc/keepalived/[root@director keepalived]# cp keepalived.conf&#123;,.bak&#125;[root@director keepalived]# vim keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 # # director2这里要改为node2 vrrp_mcast_group4 224.1.101.12&#125;vrrp_instance VI_1 &#123; state MASTER # director2这里要改为BACKUP interface ens33 virtual_router_id 51 priority 100 # dirctor2这里要改为96 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.60 dev ens33 label ens33:0 &#125;&#125;virtual_server 192.168.1.60 80 &#123; delay_loop 1 lb_algo wrr lb_kind DR protocol TCP real_server 192.168.1.27 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.1.28 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125;[root@director keepalived]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward[root@director keepalived]# systemctl start keepalived# 启动keepalived后，会自动生成ipvs规则[root@director keepalived]# tcpdump -i ens33 -vv -nn host 224.1.101.12#这时可以看到探测信息，这是拥有VIP地址的主机发来的。[root@director keepalived]# ip a# 可以看到VIP在director1上[root@director keepalived]# ipvsadm -ln# 查看是否生成了ipvs规则，如果未生成，可以用下面命令[root@director keepalived]# ipvsadm -A -t 192.168.1.60:80 -s wrr# 生成一个虚拟服务器，用加权轮询算法[root@director keepalived]# ipvsadm -a -t 192.168.1.60:80 -r 192.168.1.27:80 -g -w 1[root@director keepalived]# ipvsadm -a -t 192.168.1.60:80 -r 192.168.1.28:80 -g -w 1# 将realserver加入到虚拟服务器中，-g表示使用DR直接路由，-w指定权重。[root@director keepalived]# ipvsadm -E -t 10.5.5.140:9999 -s wrr# 修改调度算法--------------------- realServer1&amp;2---------------------[root@realserver1 ~]# vim lvs_dr_rs.sh #! /bin/bash#vip=192.168.1.60ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce--------- 本机---------使用IE浏览器访问192.168.1.26/test/，会轮流返回realServer上的页面内容。不能使用realServer访问，访问超时，不会返回结果。使用命令：root@ru:ruopu.gitb#for i in `seq 10000`;do curl 192.168.1.60/test/ &amp;&amp; echo $i;done也会返回两台服务器的页面内容。这时如果停止一台keepalived，VIP地址会转移到另一台上，访问还会继续]]></content>
      <categories>
        <category>balance</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK部署]]></title>
    <url>%2F2019%2F01%2F25%2FELK%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[elk概念 ELK又称为ELK Stack,是 Elasticsearch、Logstash、Kibana 三个开源软件的组合,每个完成不同的功能，官方网站 www.elastic.co elasticsearch概念 Elasticsearch 可实现数据的实时全文搜索、支持分布式可实现高可用、提供API接口，可以处理大规模日志数据，比如Nginx、Tomcat、系统日志等。 logstash概念 Logstash:通过插件实现日志收集，支持日志过滤，支持普通log、自定义json格式的日志解析。 logstash格式 input {} #input 插件收集日志 output {} #output 插件输出日志 kibana概念 kibana：kibana主要是调用elasticsearch的数据，并进行前端数据可视化的展现。 elk部署elk简单部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249======================================================================================收集单个日志======================================================================================准备三台主机，做els集群，配置：双核处理器，2G内存。地址：192.168.1.20，192.168.1.21，192.168.1.22准备一台主机，安装nginx，地址：192.168.1.30准备一台主机，安装kibana，地址：192.168.1.23systemctl stop firewalldsystemctl disable firewalldsed -i ‘/SELINUX/s/enforcing/disabled/’ /etc/selinux/config# 关闭三台主机的防火墙和SELinuxulimit -n# 查看打开文件最大数echo "* soft nofile 65536" &gt;&gt; /etc/security/limits.confecho "* hard nofile 65536" &gt;&gt; /etc/security/limits.conf# 调整打开文件最大数ulimit -n 65535# 临时调整打开文件最大数systemctl start chronydsystemctl enable chronydchronycchronyc&gt; waitsync# 同步三台主机时间yum install jdk-8u201-linux-x64.rpm -y# 安装jdkvim /etc/profile.d/java.sh export JAVA_HOME=/usr. /etc/profile.d/java.sh# 设置java家目录并加载yum install -y elasticsearch-6.5.4.rpm# 三台主机均安装elsvim /etc/elasticsearch/elasticsearch.yml cluster.name: testelk # 集群的名称，名称相同的主机就是处于同一个集群 node.name: node1 # 集群情况下，当前node的名字，每个node应该不一样。要将此文件复制到另两个节点 path.data: /elkdata/data # 数据目录 path.logs: /elkdata/logs # 日志目录 # bootstrap.memory_lock: true # 服务启动时即锁定足够大的内存，提高效率。测试中如果打开此项，启动会失败，提示内存未锁定 network.host: 0.0.0.0 # 监听的地址 http.port: 9200 # 客户端访问端口 discovery.zen.ping.unicast.hosts: ["192.168.1.20", "192.168.1.21", "192.168.1.22"] # 组播范围 discovery.zen.minimum_master_nodes: 2 # 设置此项为了必免脑裂，这里的数字是总节点数除以2加1算出来的。vim /etc/elasticsearch/jvm.options -Xms3g # 初始化的堆内存 -Xmx3g # 最大堆内存，可以改大此值。这两个值要保持一致。或将上面配置文件中的bootstrap.memory_lock的值改为falsemkdir /elkdata/&#123;data,logs&#125; -pv# 创建数据和日志目录chown elasticsearch.elasticsearch /elkdata/ -Rsystemctl start elasticsearchsystemctl enable elasticsearch# 三台服务器启动并查看状态======================================================================================Master的职责：1. 节点状态信息2. 集群状态信息3. 创建索引4. 删除索引5. 分片管理6. 关闭节点Slave节点的职责：1. 同步数据2. 等待机会成为master======================================================================================----------------------------------- node1上安装elasticsearch-head插件-----------------------------------git clone git://github.com/mobz/elasticsearch-head.git# 下载elasticsearch-head插件，这个插件是为了实现简单的集群监控、主机信息显示和管理等功能yum install -y epel-releaseyum install npm -ycd elasticsearch-head/npm install grunt -save# 这里可能会有报错"npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.so.10 with link time reference"，需要安装openssl即可解决。npm installnpm run start &amp;vim /etc/elasticsearch/elasticsearch.yml #---------------------------------- http --------------------------------------- http.cors.enabled: true # 打开http功能 http.cors.allow-origin: "*" # 允许谁访问# 配置elasticsearch允许远程访问systemctl restart elasticsearch* nginxyum install -y gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel openssl openssl-develtar xf nginx-1.12.2.tar.gzcd nginx-1.12.2/./configure --prefix=/usr/local/nginxmake &amp;&amp; make installcd /usr/local/nginx/mkdir html/testecho "nginx test page" &gt;&gt; html/test/index.htmlvim conf/nginx.conf server &#123; location /test &#123; root html; index index.html index.htm; &#125; &#125;/usr/local/nginx/sbin/nginx -t/usr/local/nginx/sbin/nginx# 启动访问http://192.168.1.30/test/测试======================================================================================# 下面在nginx主机上安装logstash======================================================================================yum -y install jdk-8u201-linux-x64.rpmvim /etc/profile.d/java.shexport JAVA_HOME=/usr. /etc/profile.d/java.shyum -y install logstash-6.5.4.rpmsystemctl start logstashsystemctl enable logstash/usr/share/logstash/bin/logstash -e "input&#123;stdin&#123;&#125;&#125; output&#123;stdout&#123; codec =&gt; "rydebug"&#125;&#125;"# 执行此命令并不需要启动logstash服务，执行此命令就是启动服务，Ctrl + c可以关闭服务WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console[WARN ] 2019-06-25 17:14:39.128 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified[INFO ] 2019-06-25 17:14:39.153 [LogStash::Runner] runner - Starting Logstash &#123;"logstash.version"=&gt;"6.5.4"&#125;[INFO ] 2019-06-25 17:14:44.034 [Converge PipelineAction::Create&lt;main&gt;] pipeline - Starting pipeline &#123;:pipeline_id=&gt;"main", "pipeline.workers"=&gt;2, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;50&#125;The stdin plugin is now waiting for input:[INFO ] 2019-06-25 17:14:44.444 [Converge PipelineAction::Create&lt;main&gt;] pipeline - Pipeline started successfully &#123;:pipeline_id=&gt;"main", :thread=&gt;"#&lt;Thread:0x71f559d3 run&gt;"&#125;[INFO ] 2019-06-25 17:14:44.603 [Ruby-0-Thread-1: /usr/share/logstash/lib/bootstrap/environment.rb:6] agent - Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;[INFO ] 2019-06-25 17:14:45.472 [Api Webserver] agent - Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;# 这是一条使用标准输入输出的命令，上面是执行命令后的正常输出。有时会报错，不明白原因，可能是没有调动logstash，可能是没有设置JAVA_HOME环境变量，修改后一定重启logstash。 hello # 输入hello后会有下面信息 &#123; "@timestamp" =&gt; 2019-01-24T08:47:22.515Z, #@timestamp，用来标记当前事件发生的时间 "message" =&gt; "hello", #消息的具体内容 "host" =&gt; "nginx1", #host标记事件发生在哪里 "@version" =&gt; "1" #@version时间版本号，一个事件就是一个ruby对象 &#125;# 测试。这要等待一会儿才会有结果vim /etc/logstash/conf.d/system.conf input &#123; file&#123; type =&gt; "messagelog" path =&gt; "/var/log/messages" start_position =&gt; "beginning" # 首次从头收集 &#125; # 从文件输入，类型是messagelog，写明路径，最后指定从头收集 &#125; output &#123; file &#123; path =&gt; "/tmp/123.txt" &#125; # 输出到一个文件，用file引导，下面写明路径。 elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] # 指定第一台logstash地址即可。 index =&gt; "system-messages-%&#123;+YYYY.MM.dd&#125;" # 索引的命名规则，后面加入日期 &#125; # 输出到elasticsearch，写明地址，索引的名称 &#125;/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system.conf -t# 使用-f指定配置文件，-t表示测试配置文件是否正确chmod 644 /var/log/messages# 让普通用户可以读系统日志systemctl start logstash# 启动logstash。也可以使用/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system.conf在前台启动tail -f /tmp/123.txt# 这时可以看到输出的日志文件了访问192.168.1.20:9100，在其中的数据浏览中修改上方的连接地址为第一台logstash的地址，之后就可以看到一个叫system-messages-2019.01.24的索引了======================================================================================收集多个日志======================================================================================cp /etc/logstash/conf.d/system.conf /etc/logstash/conf.d/nginx.conf -avim /etc/logstash/conf.d/nginx.confinput &#123; file&#123; type =&gt; "messagelog" # type是自定义的，为了下面的if判断使用 path =&gt; "/var/log/messages" start_position =&gt; "beginning" &#125; file &#123; type =&gt; "nginxlog" path =&gt; "/usr/local/nginx/logs/access.log" start_position =&gt; "beginning" &#125;&#125;output &#123; file &#123; path =&gt; "/tmp/123.txt" &#125; elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "system-messages-%&#123;+YYYY.MM.dd&#125;" &#125; if [type] == "nginxlog" &#123; # 使用if判断type是否为输入中定义的nginxlog，如果是就传输到elasticsearch中 elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "nginx-messages-%&#123;+YYYY.MM.dd&#125;" &#125; &#125;&#125;/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx.conf -tsystemctl restart logstash访问192.168.1.20:9100，在概览中可以看到传过来的nginxlog索引了* kibana# 下面安装kibanayum install -y kibana-6.5.4-x86_64.rpmvim /etc/kibana/kibana.yml server.port: 5601 server.host: "0.0.0.0" elasticsearch.url: "http://192.168.1.20:9200" # 调用elasticsearch的接口，写一个就可以systemctl start kibanayum install -y gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel openssl openssl-develtar xf nginx-1.12.2.tar.gzcd nginx-1.12.2/./configure --prefix=/usr/local/nginxmake &amp;&amp; make install# 使用nginx反向代理kibanavim /etc/kibana/kibana.yml server.host: "localhost" # 改为监听本地地址cd /usr/local/nginx/mkdir /usr/local/nginx/conf/conf.dvim /usr/local/nginx/conf/conf.d/kibana.conf server &#123; listen 80; server_name test.kibana.com; location / &#123; proxy_pass http://localhost:5601; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125; &#125;vim /usr/local/nginx/conf/nginx.conf http &#123; ... include /usr/local/nginx/conf/conf.d/*.conf; &#125;/usr/local/nginx/sbin/nginx# 启动设置本机可以解析test.kibana.com kibana简单设置使用访问 这里可以选择使用样本数据，也可以只使用自己的数据。可以通过对样本数据设置的学习，了解kibana的设置方法 设置 选择左侧的Management，之后在右边输入从els中获取的索引的名称，只需要输入前面部分，后面的日期可以使用星号配置，这里在下面也可以看到匹配到的索引，最后点击下一步。之后选择按时间过滤并创建即可。 这后可以在Discover中看到我们添加的索引了，如果无法显示数据，可能是右上方的时间有误 nginx登录认证1234567891011121314151617181920212223* kibana[root@kibana ~]# yum install -y httpd-tools[root@kibana ~]# htpasswd -bc /usr/local/nginx/conf/htpasswd.users kibanauser centosAdding password for user kibanauser# 设置登录用户名和密码[root@kibana ~]# vim /usr/local/nginx/conf/conf.d/kibana.conf server &#123; listen 80; server_name test.kibana.com; auth_basic "Restricted Access"; auth_basic_user_file /usr/local/nginx/conf/htpasswd.users; location / &#123; proxy_pass http://localhost:5601; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125;# 加入认证[root@kibana ~]# /usr/local/nginx/sbin/nginx -s reload再次访问kibana页面时就需要认证了 日志收集123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301======================================================================================* 规划通过在要收集日志的服务器上安装filebeat进行日志收集，之后将收集到的数据写入到redis服务器，再通过logstash服务器取出数据并写入到elasticsearch集群中。也可以通过filebeat收集日志后转发给logstash服务器，再由logstash服务器写入到redis中，再由另一台logstash服务器从redis服务器中取出数据并写入到elasticsearch集群中。* 环境准备三台主机，做els集群，配置：双核处理器，2G内存。地址：192.168.1.20，192.168.1.21，192.168.1.22准备一台主机，安装nginx，地址：192.168.1.30准备一台主机，安装kibana，地址：192.168.1.23准备一台主机，安装redis，地址：192.168.1.24准备一台主机，安装haproxy，地址：192.168.1.31* 软件版本1. 操作系统:CentOS7.4.17082. jdk: jdk-8u201 官方rpm或gz包3. elasticsearch:6.5.4 官方当前最新rpm4. logstash:6.5.4 官方当前最新rpm5. kibana:6.5.4 官方当前最新rpm6. filebeat:6.5.4 官方当前最新rpm7. nginx:1.12.28. redis:5.0.3 官方最新源码包======================================================================================------------- redis-------------[root@redis ~]# yum install -y gcc[root@redis ~]# tar xf redis-5.0.3.tar.gz -C /usr/local/src/[root@redis redis-5.0.3]# cd /usr/local/src/redis-5.0.3/[root@redis redis-5.0.3]# make[root@redis redis-5.0.3]# ln -sv /usr/local/src/redis-5.0.3/ /usr/local/redis‘/usr/local/redis’ -&gt; ‘/usr/local/src/redis-5.0.3/’[root@redis redis-5.0.3]# cp src/redis-server src/redis-cli /usr/bin[root@redis redis-5.0.3]# cd /usr/local/redis/[root@redis redis]# vim redis.conf bind 0.0.0.0 daemonize yes # 让redis以守护进程方式运行 save "" #save 900 1 #save 300 10 #save 60 10000 # 因为不需要持久存储，所以将save ""打开，将下面三行关闭。 requirepass centos logfile "/var/log/redis.log" # 输出日志路径，默认会输出到/dev/null中[root@redis redis]# redis-server /usr/local/redis/redis.conf# 启动redis，启动时指定配置文件[root@redis redis]# ss -tln[root@redis redis]# redis-cli 127.0.0.1:6379&gt; KEYS *(error) NOAUTH Authentication required.127.0.0.1:6379&gt; AUTH centosOK127.0.0.1:6379&gt; KEYS *(empty list or set)------------- haproxy-------------[root@haproxy ~]# yum install jdk-8u201-linux-x64.rpm[root@haproxy ~]# yum install logstash-6.5.4.rpm[root@haproxy ~]# yum install -y haproxy[root@haproxy ~]# vim /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local6 # 这行很重要，local6是haproxy的日志级别，在rsyslog配置文件中也要定义这个级别 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend myweb bind *:80 default_backend websrvsbackend websrvs balance roundrobin server srv1 192.168.1.30:80 check# 这里只简单地将haproxy反代到nginx服务器上，实现访问haproxy就会反代到nginx服务器上[root@haproxy ~]# vim /etc/rsyslog.d/haproxy.conf $ModLoad imudp $UDPServerRun 514 $ModLoad imtcp $InputTCPServerRun 514 local6.* @@192.168.1.31:5140# 接收日志的logstash服务器IP:PORT，local6对应haproxy的日志级别。这里将日志传给了本机的logstash[root@haproxy ~]# vim /etc/logstash/conf.d/syslog.conf input &#123; syslog &#123; type =&gt; "system-rsyslog" port =&gt; "5140" # 从logstash的5140端口输入，实际也是定义logstash监听的端口 &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; data_type =&gt; "list" # redis的数据类型要使用list key =&gt; "system-rsyslog" # 写入redis的键名 host =&gt; "192.168.1.24" # redis地址 port =&gt; "6379" # redis端口 db =&gt; "0" # redis库 password =&gt; "centos" # redis密码 &#125;&#125;[root@haproxy ~]# systemctl restart rsyslog# rsyslog监听在514端口[root@haproxy ~]# systemctl start haproxy [root@haproxy ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/syslog.conf在本机设置hosts文件，解析haproxy地址到www.test.com，访问www.test.com，这时应该显示一些信息，如：&#123; "timestamp" =&gt; "Jan 25 12:53:39", "@timestamp" =&gt; 2019-01-25T04:53:39.000Z, "message" =&gt; "192.168.1.9:33634 [25/Jan/2019:12:53:39.002] myweb websrvs/srv1 0/0/1/1/2 304 175 - - ---- 2/2/0/0/0 0/0 \"GET / HTTP/1.1\"\n", "logsource" =&gt; "localhost", "type" =&gt; "system-rsyslog", "host" =&gt; "192.168.1.31", "priority" =&gt; 182, "facility_label" =&gt; "local6", "severity" =&gt; 6, "program" =&gt; "haproxy", "facility" =&gt; 22, "severity_label" =&gt; "Informational", "pid" =&gt; "3817", "@version" =&gt; "1"&#125;[root@haproxy ~]# ss -tln# 可以看到监听了5140端口[root@haproxy ~]# systemctl start logstash# 在后台启动------------- redis-------------[root@redis redis]# redis-cli -a centos127.0.0.1:6379&gt; SELECT 0OK127.0.0.1:6379&gt; KEYS *1) "system-rsyslog"127.0.0.1:6379&gt; LLEN system-rsyslog(integer) 3127.0.0.1:6379&gt; LPOP system-rsyslog"&#123;\"facility\":22,\"host\":\"192.168.1.31\",\"logsource\":\"localhost\",\"program\":\"haproxy\",\"@version\":\"1\",\"facility_label\":\"local6\",\"message\":\"192.168.1.9:33540 [25/Jan/2019:12:37:37.836] myweb websrvs/srv1 0/0/0/1/1 304 175 - - ---- 2/2/0/1/0 0/0 \\\"GET / HTTP/1.1\\\"\\n\",\"priority\":182,\"pid\":\"3817\",\"timestamp\":\"Jan 25 12:37:37\",\"severity\":6,\"severity_label\":\"Informational\",\"type\":\"system-rsyslog\",\"@timestamp\":\"2019-01-25T04:37:37.000Z\"&#125;"# 可以看到相关数据了------------- haproxy-------------[root@haproxy ~]# vim /etc/logstash/conf.d/syslog.conf input &#123; syslog &#123; type =&gt; "system-rsyslog" port =&gt; "5140" &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; data_type =&gt; "list" key =&gt; "haproxy-log-31" # 改变输出到redis中的键名 host =&gt; "192.168.1.24" port =&gt; "6379" db =&gt; "0" password =&gt; "centos" &#125;&#125;[root@haproxy ~]# systemctl restart logstash------------- redis-------------127.0.0.1:6379&gt; KEYS *1) "haproxy-log-31"2) "system-rsyslog"# 可以看到从logstash传入新的键了======================================================================================下面设置收集TCP/UDP日志======================================================================================------------- haproxy-------------[root@haproxy ~]# vim /etc/logstash/conf.d/tcp.confinput &#123; tcp &#123; port =&gt; "5500" type =&gt; "tcp-syslog" mode =&gt; "server" &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; data_type =&gt; "list" key =&gt; "tcp-syslog" host =&gt; "192.168.1.24" port =&gt; "6379" db =&gt; "0" password =&gt; "centos" &#125;&#125;[root@haproxy ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcp.conf -tWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console[WARN ] 2019-01-25 13:16:45.820 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specifiedConfiguration OK[INFO ] 2019-01-25 13:16:47.307 [LogStash::Runner] runner - Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash# 测试配置文件没有问题[root@haproxy ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcp.conf# logstash启动时还会监听本地的9600端口[root@haproxy ~]# yum install -y nc[root@haproxy ~]# echo "nc test"|nc 192.168.1.31 5500这时logstash会在终端输出内容：&#123; "host" =&gt; "haproxy", "message" =&gt; "nc test", "port" =&gt; 39566, "type" =&gt; "tcp-syslog", "@timestamp" =&gt; 2019-01-25T05:29:16.034Z, "@version" =&gt; "1"&#125;[root@haproxy ~]# nc 192.168.1.31 5500 &lt; /root/anaconda-ks.cfg[root@haproxy ~]# echo "伪设备" &gt; /dev/tcp/192.168.1.31/5500# /dev后面的部分是没有的，要手动输入，在logstash中也会显示------------- redis-------------127.0.0.1:6379&gt; KEYS *1) "tcp-syslog"2) "haproxy-log-31"3) "system-rsyslog"127.0.0.1:6379&gt; LLEN tcp-syslog(integer) 52# redis中也可以看到数据了------------- logstash-------------# 使用nginx主机中的logstash收集redis中的数据[root@nginx1 ~]# vim /etc/logstash/conf.d/tcp.confinput &#123; port =&gt; "6379" key =&gt; "haproxy-log-31" db =&gt; "0" password =&gt; "centos" &#125; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "tcp-syslog" db =&gt; "0" password =&gt; "centos" &#125; &#125; output &#123; if [type] == "tcp-syslog" &#123; elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "tcp-rsyslog-%&#123;+YYYY.MM.dd&#125;" &#125; &#125; if [type] == "system-rsyslog" &#123; # 这里判断的是haproxy服务器的logstash设置中input定义的type elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "haproxy-log-31-%&#123;+YYYY.MM.dd&#125;" &#125; &#125; &#125; # 从redis中取行数据，之后输出到elasticsearch集群中。[root@nginx1 ~]# systemctl start logstash[root@nginx1 ~]# tail -f /var/log/logstash/logstash-plain.log# 可以通过这个日志文件查看logstash运行是否正常，如是否可以连接到redis服务器访问els服务器：192.168.1.20:9200，这时可以看到haproxy-log-31-*这个索引了 filebeat收集日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236======================================================================================* 规划1. 在web端安装filebeat进行对日志的收集，之后将日志发送给logstash。2. 配置一台logstash服务器，将收到的日志转发到redis3. 使用另一台logstash服务器从redis中读取日志，并将处理的结果写入到elasticsearch集群4. 配置地图显示IP访问地址5. 将日志写入数据库持久化保存6. 通过zabbix对elasticsearch集群状态及redis队列长度监控并实现邮件报警* 环境准备三台主机，做els集群，配置：双核处理器，2G内存。地址：192.168.1.20，192.168.1.21，192.168.1.22准备一台主机，安装nginx，地址：192.168.1.30准备一台主机，安装kibana，地址：192.168.1.23准备一台主机，安装redis，地址：192.168.1.24准备一台主机，安装logstash负责将日志转发到redis，地址：192.168.1.30准备一台主机，安装logstash负责从redis中读取数据并写入elasticsearch集群，地址：192.168.1.31。需要从redis中取出数据，所以再配置一台logstash服务器======================================================================================------------------------------------- nginx+tomcat+logstash30-------------------------------------# 下面配置nginx日志格式，filebeat获取nginx与系统日志并转发至本机的logstash[root@nginx1 ~]# mkdir /usr/local/nginx/html/web[root@nginx1 ~]# echo "Nginx WebPage" &gt; /usr/local/nginx/html/web/index.html访问http://192.168.1.30/web/[root@nginx1 ~]# vim /usr/local/nginx/conf/nginx.confhttp &#123; ... log_format access1 '&#123;"@timestamp":"$time_iso8601",' '"host":"$server_addr",' '"clientip":"$remote_addr",' '"size":$body_bytes_sent,' '"responsetime":$request_time,' '"upstreamtime":"$upstream_response_time",' '"upstreamhost":"$upstream_addr",' '"http_host":"$host",' '"url":"$uri",' '"domain":"$host",' '"xff":"$http_x_forwarded_for",' '"referer":"$http_referer",' '"status":"$status"&#125;'; server &#123; ... access_log logs/host.access.log access1; &#125;&#125;# 配置日志格式为Json格式。相对普通日志格式,json易于识别,每个值都有与其相对于的key,易于提取日志内容及方便后续进一步对日志的分析。可以到http://www.kjson.com/上验证Json格式是否正确。[root@nginx1 ~]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@nginx1 ~]# /usr/local/nginx/sbin/nginx -s reload[root@nginx1 ~]# yum install -y filebeat-6.5.4-x86_64.rpm# 安装filebeat，这个软件可以在web端实时收集日志并传递给logstash进一步处理======================================================================================为什么不用logstash在web端收集1. 依赖java环境，一旦java出问题，可能影响到web服务2. 系统资源占用率高，且存在bug风险3. 配置比较复杂，支持匹配过滤4. filebeat挺好的，专注日志收集，语法简单，安装快捷，配置方便======================================================================================[root@nginx1 ~]# vim /etc/filebeat/filebeat.yml#filebeat.inputs:#- type: log# enabled: false# paths:# - /var/log/*.log#output.elasticsearch: # Array of hosts to connect to.# hosts: ["localhost:9200"]filebeat.prospectors:- input_type: log paths: - /var/log/messages include_lines: ["^ERR","^WARN"] # 如果加入此行，filebeat会只发送正则表达式匹配到的日志，其他都不发送。测试中未加此行。 fields: service: system-log-30# filebeat6中需要通过fields: service:这样的方式定义输出的类型，而5版本中的设置是使用 document_type: 定义类型。如果6版本中也按5版本的方法设置，在logstash中是找不到的。output.redis: hosts: ["192.168.1.24:6379"] key: "system-log-30" db: 10 timeout: 5 password: "centos"# 在配置文件最下方加入上面内容，另外需要注释配置文件中的inputs和其他output，不然启动会失败，不能有多个output段。启动失败时日志中会提示如"Exiting: prospectors and inputs used in the configuration file, define only inputs not both"[root@nginx1 ~]# tail -f /var/log/filebeat/filebeat# 查看日志[root@nginx1 ~]# vim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- input_type: log paths: - /var/log/messages fields: service: system-log-30- input_type: log paths: - /usr/local/nginx/logs/access.log fields: service: nginx-accesslog-30 output.logstash: hosts: ["192.168.1.30:5044","192.168.1.30:5045"] enabled: true worker: 1 compression_level: 3 loadbalance: true # 默认为false，全部发送到随机选择的一个，相当于高可用模式[root@nginx1 filebeat]# systemctl restart filebeat [root@nginx1 ~]# vim /etc/logstash/conf.d/beats.conf input &#123; beats &#123; # 这个输入的名称是自定义的 port =&gt; 5044 codec =&gt; "json" &#125; beats &#123; port =&gt; 5045 codec =&gt; "json" &#125; &#125; output &#123; stdout &#123; codec =&gt; "rubydebug" &#125; &#125;[root@nginx1 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/beats.conf[root@nginx1 ~]# vim /etc/logstash/conf.d/beats.conf input &#123; beats &#123; # 此输入插件使Logstash能够从Elastic Beats框架接收事件 port =&gt; 5044 codec =&gt; "json" &#125; beats &#123; port =&gt; 5045 codec =&gt; "json" &#125; &#125; output &#123; if [fields][service] == "system-log-30" &#123; # 这里的[fields][service] 是在filebeat的input中定义的，这是logstash6版本中的使用方法。如果是5版本，需要使用if [type] == ""来匹配数据类型 redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "system-log-30" db =&gt; "15" password =&gt; "centos" &#125; # 收集到的系统日志会因为JSON格式而报错，如"[ERROR] 2019-01-28 00:01:06.861 [defaultEventExecutorGroup-5-1] json - JSON parse error, original data now in message field &#123;:error=&gt;#&lt;LogStash::Json::ParserError: Unrecognized token 'Jan': was expecting ('true', 'false' or 'null')# at [Source: (String)"Jan 28 00:01:01 nginx1 systemd: Started Session 197 of user root."; line: 1, column: 4]&gt;, :data=&gt;"Jan 28 00:01:01 nginx1 systemd: Started Session 197 of user root."&#125;"，但数据还是会被写入到redis中。 &#125; if [fields][service] == "nginx-accesslog-30" &#123; redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "nginx-accesslog-30" db =&gt; "15" password =&gt; "centos" codec =&gt; "json" &#125; &#125; &#125;[root@nginx1 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/beats.conf -t[root@nginx1 ~]# systemctl start logstash[root@nginx1 ~]# lsof -i:5045 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 22018 logstash 111u IPv6 265612 0t0 TCP *:osp (LISTEN)java 22018 logstash 140u IPv6 265052 0t0 TCP nginx1:osp-&gt;nginx1:60146 (ESTABLISHED)filebeat 22162 root 5u IPv4 265051 0t0 TCP nginx1:60146-&gt;nginx1:osp (ESTABLISHED)# 查看是否连接到5044端口[root@nginx1 ~]# netstat -alnp | grep filebeattcp 0 0 192.168.1.30:60146 192.168.1.30:5045 ESTABLISHED 22162/filebea tcp 0 0 192.168.1.30:44502 192.168.1.30:5044 ESTABLISHED 22162/filebea# netstart查看端口------------- redis-------------[root@redis ~]# lsof -i:6379 -n COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-ser 15196 root 6u IPv4 32440 0t0 TCP *:6379 (LISTEN)redis-ser 15196 root 10u IPv4 166066 0t0 TCP 192.168.1.24:6379-&gt;192.168.1.30:48894 (ESTABLISHED)# 可以看到192.168.1.30连到了这台redis上。[root@redis ~]# redis-cli -a centos127.0.0.1:6379&gt; SELECT 5OK127.0.0.1:6379[5]&gt; KEYS *1) "system-log-30"2) "nginx-accesslog-30"# 可以看到redis库中已经有数据了。----------------- logstash31-----------------# 下面配置logstash从redis读取数据[root@haproxy ~]# cd /etc/logstash/conf.d/[root@haproxy conf.d]# vim redis-es.confinput &#123; redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "system-log-30" db =&gt; "5" password =&gt; "centos" &#125; redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "nginx-accesslog-30" db =&gt; "5" password =&gt; "centos" codec =&gt; "json" &#125;&#125;output &#123; if [fields][service]== "system-log-30" &#123; # 这里也要使用这样的判断方法，不能使用if [type] == ""这样的方法 elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "system-log-30-%&#123;+yyyy.MM.dd&#125;" # 这里的%&#123;+yyyy.MM.dd&#125;年和日都要使用小写字母，不能使用大写字母，不然logstash会报错。 &#125; &#125; if [fields][service] == "nginx-accesslog-30" &#123; elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "nginx-accesslog-30-%&#123;+yyyy.MM.dd&#125;" &#125; &#125;&#125;[root@haproxy conf.d]# systemctl start logstash访问http://192.168.1.20:9100/，这时可以看到有日志索引nginx-accesslog-30-****.**.**存在了。 kibana验证nginx访问日志 因为kibana是从本机的nginx反向代理的，所以访问的地址是test.kibana.com，访问时出现错误提示：重定向次数过多，需要清理cookie。重启kibana后正常。原因不明。 在kibana中创建nginx-accesslog-30-*索引后，就可以看到数据信息了 部署tomcat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106------------------------------------- nginx+tomcat+logstash30-------------------------------------# 下面部署tomcat[root@nginx1 ~]# yum install -y tomcat tomcat-admin-webapps tomcat-docs-webapp tomcat-webapps[root@nginx1 ~]# mkdir /usr/share/tomcat/webapps/tomcatweb[root@nginx1 ~]# vim /usr/share/tomcat/webapps/tomcatweb/index.html Tomcat Web Page# 创建一个测试页[root@nginx1 ~]# systemctl start tomcat访问http://192.168.1.30:8080/tomcatweb/[root@nginx1 ~]# systemctl stop tomcat[root@nginx1 ~]# vim /etc/tomcat/server.xml&lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="&#123;&amp;quot;clientip&amp;quot;:&amp;quot;%h&amp;quot;,&amp;quot;ClientUser&amp;quot;:&amp;quot;%l&amp;quot;,&amp;quot;authenticated&amp;quot;:&amp;quot;%u&amp;quot;,&amp;quot;AccessTime&amp;quot;:&amp;quot;%t&amp;quot;,&amp;quot;method&amp;quot;:&amp;quot;%r&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;%s&amp;quot;,&amp;quot;SendBytes&amp;quot;:&amp;quot;%b&amp;quot;,&amp;quot;Query?string&amp;quot;:&amp;quot;%q&amp;quot;,&amp;quot;partner&amp;quot;:&amp;quot;%&#123;Referer&#125;i&amp;quot;,&amp;quot;AgentVersion&amp;quot;:&amp;quot;%&#123;User-Agent&#125;i&amp;quot;&#125;" /&gt;# 需要注意tomcat日志的json格式，使用两个&amp;quot;将字段和变量分隔，标点符号不需要使用[root@nginx1 ~]# rm -rf /var/log/tomcat/*[root@nginx1 ~]# systemctl start tomcat[root@nginx1 ~]# tail /var/log/tomcat/localhost_access_log.2019-01-28.txt&#123;"clientip":"192.168.1.9","ClientUser":"-","authenticated":"-","AccessTime":"[28/Jan/2019:09:58:44 +0800]","method":"GET /tomcatweb/ HTTP/1.1","status":"304","SendBytes":"-","Query?string":"","partner":"-","AgentVersion":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36"&#125;# 验证tomcat日志转json[root@nginx1 ~]# vim /etc/filebeat/filebeat.yml - input_type: log paths: - /var/log/tomcat/localhost_access_log.* fields: service: tomcat-accesslog-30# 加入对tomcat日志的收集[root@nginx1 ~]# systemctl restart filebeat.service[root@nginx1 ~]# vim /etc/logstash/conf.d/beats.confoutput &#123; ... if [fields][service] == "tomcat-accesslog-30" &#123; redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "tomcat-accesslog-30" db =&gt; "5" password =&gt; "centos" codec =&gt; "json" &#125; &#125; &#125;[root@nginx1 ~]# systemctl restart logstash[root@nginx1 ~]# yum install -y httpd-tools[root@nginx1 ~]# ab -n1000 -c10 http://192.168.1.30:8080/tomcatweb/------------- redis-------------[root@redis ~]# redis-cli -a centos127.0.0.1:6379&gt; SELECT 5OK127.0.0.1:6379[5]&gt; KEYS *1) "tomcat-accesslog-30"# 可以看到redis中已经有数据了----------------- logstash31-----------------# 下面配置logstash从redis读取tomcat的数据[root@haproxy conf.d]# vim redis-es.conf input &#123;...redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "tomcat-accesslog-30" db =&gt; "5" password =&gt; "centos" codec =&gt; "json" &#125;&#125;output &#123;...if [fields][service] == "tomcat-accesslog-30" &#123; elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "tomcat-accesslog-30-%&#123;+yyyy.MM.dd&#125;" &#125; &#125;&#125;[root@haproxy conf.d]# systemctl restart logstash最后加入到kibana中-------------------- elasticsearch--------------------[root@els3 ~]# du -sh /elkdata/data/nodes/0/indices/97M /elkdata/data/nodes/0/indices/[root@els3 ~]# du -sh /elkdata/data/nodes/0/indices/*4.0K /elkdata/data/nodes/0/indices/--3-U6GWTSifioos1N2yUQ91M /elkdata/data/nodes/0/indices/6MycbQuEQWmCbg3-A1q5EA120K /elkdata/data/nodes/0/indices/HGUqPJuCQ1iTPJr1EVfxoQ2.0M /elkdata/data/nodes/0/indices/KuBtJ9ztSDaI7dFaiNfeFQ2.9M /elkdata/data/nodes/0/indices/QbkLT5G7RYu5nivgm2uncA1.5M /elkdata/data/nodes/0/indices/_yuF7skcTtWOF4YJl_UaTw# 验证filebeat读取的日志，已经通过logstash写入到elasticsearch的数据目录中 kibana配置地图显示IP访问地址12345678910111213141516171819202122232425262728293031323334353637----------------- logstash31-----------------[root@kibana ~]# wget http://geolite.maxmind.com/download/geoip/database/GeoLite2-City.tar.gz# 在写入elasticsearch的logstash服务器配置[root@haproxy ~]# gunzip GeoLite2-City.tar.gz[root@haproxy ~]# tar xf GeoLite2-City.tar[root@haproxy ~]# cd GeoLite2-City_20190122/[root@haproxy GeoLite2-City_20190122]# cp GeoLite2-City.mmdb /etc/logstash/ -a[root@haproxy ~]# vim /etc/logstash/conf.d/redis-es.confinput &#123;&#125;filter &#123; filter &#123; if [fields][service] == "nginx-accesslog-30" &#123; geoip &#123; source =&gt; "clientip" target =&gt; "geoip" database =&gt; "/etc/logstash/GeoLite2-City.mmdb" add_field =&gt; ["[geoip][coordinates]","%&#123;[geoip][longitude]&#125;"] add_field =&gt; ["[geoip][coordinates]","%&#123;[geoip][latitude]&#125;"] &#125; mutate &#123; convert =&gt; ["[geoip][coordinates]","float"] &#125; &#125;&#125;output &#123; ... if [fields][service] == "nginx-accesslog-30" &#123; elasticsearch &#123; hosts =&gt; ["192.168.1.20:9200"] index =&gt; "logstash-nginx-accesslog-30-%&#123;+yyyy.MM.dd&#125;" &#125; &#125;# 这里输出到els中的index名称必须以logstash开头，不然在kibana中创建地图选择Field时会有错误提示"No Compatible Fields: The "nginx-accesslog-30-*" index pattern does not contain any of the following field types: geo_point"&#125;[root@haproxy ~]# systemctl restart logstash kibana创建地图 删除旧的索引，重新创建新索引 查看字段，会有以geoip开头的字段加入 12345------------------------------------- nginx+tomcat+logstash30-------------------------------------[root@nginx1 ~]# echo '&#123;"@timestamp":"2019-01-27T19:27:57+08:00","host":"192.168.1.30","clientip":"106.38.38.83","size":0,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"192.168.1.30","url":"/index.html","domain":"192.168.1.30","xff":"-","referer":"-","status":"304"&#125;' &gt;&gt; /usr/local/nginx/logs/host.access.log.# 加入一条假数据到日志文件中，clientip改为公网地址 创建地图，选择logstash-nginx-accesslog-30-* 在Buckets中的Aggregation选择Geohash，Field选择geoip.location，最后点击上方的三角按钮，这时就可以在地图上看到标记了 将日志写入数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485=======================================================================================规划1. 安装数据库并授权2. 创建表3. 配置logstash将数据写入数据库4. 测试环境准备一台主机，安装mariadb，地址：192.168.1.25logstash地址：192.168.1.30=======================================================================================-------------- mariadb--------------[root@mysql ~]# yum install -y mariadb-server[root@mysql ~]# systemctl start mariadb[root@mysql ~]# mysql_secure_installation[root@mysql ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; CREATE DATABASE elk CHARACTER SET utf8 COLLATE utf8_bin;MariaDB [(none)]&gt; GRANT ALL privileges ON elk.* TO elk@"%" identified by "centos";MariaDB [(none)]&gt; FLUSH PRIVILEGES;# 创建数据库并授权[root@els3 ~]# mysql -h192.168.1.25 -uelk -pcentos# 在其他主机验证远程登录数据库-------------- logstash--------------[root@nginx1 ~]# yum install -y ruby# 需要安装ruby后才可以使用gem命令[root@nginx1 ~]# gem sources --add http://gems.ruby-china.com --remove https://rubygems.org/# Gem是一个管理Ruby库和程序的标准包，它通过Ruby Gem（如 http://rubygems.org/ ）源来查找、安装、升级和卸载软件包，非常的便捷。# taobao Gems 源已停止维护，现由 ruby-china 提供镜像服务，所以将国内源改为http://gems.ruby-china.com[root@nginx1 ~]# mkdir -pv /usr/share/logstash/vendor/jar/jdbc[root@nginx1 ~]# unzip mysql-connector-java-8.0.14.zip[root@nginx1 ~]# cp mysql-connector-java-8.0.14/mysql-connector-java-8.0.14.jar /usr/share/logstash/vendor/jar/jdbc/[root@nginx1 ~]# chown -R logstash.logstash /usr/share/logstash/vendor/jar/[root@nginx1 ~]# /usr/share/logstash/bin/logstash-plugin install logstash-output-jdbc[root@nginx1 ~]# /usr/share/logstash/bin/logstash-plugin list|grep jdbclogstash-filter-jdbc_staticlogstash-filter-jdbc_streaminglogstash-input-jdbclogstash-output-jdb-------------- mariadb--------------[root@mysql ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; use elkMariaDB [elk]&gt; CREATE TABLE elklog (id int(11) NOT NULL AUTO_INCREMENT,host VARCHAR(255),clientip VARCHAR(255),url VARCHAR(255),status INT(16),time timestamp,PRIMARY KEY (id));-------------- logstash--------------[root@nginx1 filebeat]# vim /etc/logstash/conf.d/beats.confif [fields][service] == "nginx-accesslog-30" &#123; redis &#123; data_type =&gt; "list" host =&gt; "192.168.1.24" port =&gt; "6379" key =&gt; "nginx-accesslog-30" db =&gt; "5" password =&gt; "centos" codec =&gt; "json" &#125; jdbc &#123; driver_jar_path =&gt; "/usr/share/logstash/vendor/jar/jdbc/mysql-connector-java-8.0.14.jar" # 插件路径 connection_string =&gt; "jdbc:mysql://192.168.1.25:3306/elk?user=elk&amp;password=centos&amp;useUnicode=true&amp;characterEncoding=UTF8"# 数据库地址、端口、用户名、密码等信息 statement =&gt; ["INSERT INTO elklog(host,clientip,url,status) VALUES(?,?,?,?)","http_host","clientip","url","status"]# 最后四个引号("http_host","clientip","url","status")中的名称是从logstash中取得的字段名称，这四个引号是传入的变量 &#125; &#125;# 设置输出到数据库中-------------- mariadb--------------[root@mysql ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; use elkMariaDB [elk]&gt; select * from elklog;| 6000 | &#123;"containerized":true,"id":"3e6f1f53c66e409f81bc71d9331832af","architecture":"x86_64","os":&#123;"codename":"Core","family":"redhat","platform":"centos","version":"7 (Core)"&#125;,"name":"nginx1"&#125; | 192.168.1.30 | /test/index.html | NULL | 2019-01-28 21:28:35 |# 这里保存的host有问题，需要将logstash中的statement最后的引号中的host改为http_host即可取得服务器地址了 删除els中索引的脚本12345678910111213#!/bin/bash#DATE=`date -d "0 days ago" +%Y.%m.%d`# 获取今天的日期，如果想获取一个月前的日期，就使用30 days agoLOG_NAME="nginx-accesslog-30"FILE_NAME=$LOG_NAME-$DATEcurl -XDELETE http://192.168.1.20:9200/$FILE_NAMEif [ $? -eq 0 ];then echo "$&#123;FILE_NAME&#125; delete success."else echo "$&#123;FILE_NAME&#125; delete error."fi# 不可直接从/elkdata/data/nodes/0/indices/目录中删除索引，会使els服务器运行出错]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper&kafka部署]]></title>
    <url>%2F2019%2F01%2F21%2Fzookeeper-kafka%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[kafka配置文件說明Broker配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# broker的全局唯一编号，不能重复broker.id=0# 用来监听链接的端口，producer或consumer将在此端口建立连接port=9092# 处理网络请求的线程数量，也就是接收消息的线程数。接收线程会将接收到的消息放到内存中，然后再从内存中写入磁盘。num.network.threads=3# 消息从内存中写入磁盘时使用的线程数量。用来处理磁盘IO的线程数量num.io.threads=8# 发送套接字的缓冲区大小socket.send.buffer.bytes=102400# 接受套接字的缓冲区大小socket.receive.buffer.bytes=102400# 请求套接字的缓冲区大小socket.request.max.bytes=104857600# kafka运行日志存放的路径log.dirs=/export/servers/logs/kafka# topic在当前broker上的分片个数。每個partition的備份個數，默認為1，建議根據實際條件選擇；如果這個值較大，意味著消息在各個server上同步時需要的延遲較高num.partitions=2# 我们知道segment文件默认会被保留7天的时间，超时的话就会被清理，那么清理这件事情就需要有一些线程来做。这里就是用来设置恢复和清理data下数据的线程数量num.recovery.threads.per.data.dir=1# segment文件保留的最长时间，默认保留7天（168小时），超时将被删除，也就是说7天之前的数据将被清理掉。log.retention.hours=168# 滚动生成新的segment文件的最大时间log.roll.hours=168# 日志文件中每个segment的大小，默认为1Glog.segment.bytes=1073741824#上面的参数设置了每一个segment文件的大小是1G，那么就需要有一个东西去定期检查segment文件有没有达到1G，多长时间去检查一次，就需要设置一个周期性检查文件大小的时间（单位是毫秒）。log.retention.check.interval.ms=300000# 日志清理是否打开log.cleaner.enable=true# broker需要使用zookeeper保存meta数据，因此broker為zk client；此處為zookeeper集群的connectString，後面可以跟上path，比如hostname:port/chroot/kafka。不過需要注意，path的全路徑需要由自己來創建（使用zookeeper腳本工具）zookeeper.connect=zk01:2181,zk02:2181,zk03:2181# zookeeper链接超时时间zookeeper.connection.timeout.ms=6000# 上面我们说过接收线程会将接收到的消息放到内存中，然后再从内存写到磁盘上，那么什么时候将消息从内存中写入磁盘，就有一个时间限制（时间阈值）和一个数量限制（数量阈值），这里设置的是数量阈值，下一个参数设置的则是时间阈值。# 为了减少磁盘写入的次数，broker会将消息暂时buffer起来，当消息的个数达到一定阀值或者过了一定的时间间隔时，再flush到磁盘，这样减少了磁盘IO调用的次数。log.flush.interval.messages=10000# 消息buffer的时间，达到阈值，将触发将消息从内存flush到磁盘，单位是毫秒。log.flush.interval.ms=3000# 删除topic需要server.properties中设置delete.topic.enable=true否则只是标记删除delete.topic.enable=true# 此处的host.name为本机IP(重要),如果不改,则客户端会抛出：Producer connection to localhost:9092 unsuccessful 错误！指定broker實例綁定的網絡接口地址host.name=kafka01# partition leader等待follower同步消息的最大時間，如果超時，leader將follower移除同步列表replica.lag.time.max.ms=10000# 允許follower落後的最大消息條數，如果達到閾值，將follower移除同步列表#replica.lag.max.message=4000# 消息的備份的個數，默認為1num.replica.fetchers=1advertised.host.name=192.168.239.128 Consumer主要配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 消费者集群通过连接Zookeeper来找到broker。# zookeeper连接服务器地址# consumer作為zookeeper client，需要通過zk保存一些meta信息，此處為zk connectStringzookeeper.connect=zk01:2181,zk02:2181,zk03:2181# zookeeper的session过期时间，默认5000ms，用于检测消费者是否挂掉zookeeper.session.timeout.ms=5000# 当消费者挂掉，其他消费者要等该指定时间才能检查到并且触发重新负载均衡zookeeper.connection.timeout.ms=10000# 这是一个时间阈值。指定多久消费者更新offset到zookeeper中。注意offset更新时基于time而不是每次获得的消息。一旦在更新zookeeper发生异常并重启，将可能拿到已拿到过的消息zookeeper.sync.time.ms=2000# 當前消費者的group名稱，需要指定group.id=xxxxx# 这是一个数量阈值，经测试是500条。当consumer消费一定量的消息之后,将会自动向zookeeper提交offset信息。注意offset信息并不是每消费一次消息就向zk提交一次,而是现在本地保存(内存),并定期提交,默认为trueauto.commit.enable=true# 自动更新时间。默认60 * 1000auto.commit.interval.ms=60*1000# 当前consumer的标识,可以设定,也可以有系统生成，主要用来跟踪消息消费情况，便于观察conusmer.id=xxx# 消费者客户端编号，用于区分不同客户端，默认客户端程序自动产生client.id=xxxx# 最大取多少块缓存到消费者(默认10)queued.max.message.chunks=50# 当有新的consumer加入到group时,将会reblance，此后将会有partitions的消费端迁移到新的consumer上，如果一个consumer获得了某个partition的消费权限，那么它将会向zk注册 "Partition Owner registry"节点信息，但是有可能此时旧的consumer尚没有释放此节点，此值用于控制，注册节点的重试次数。rebalance.max.retries=5# 每拉取一批消息的最大字节数。获取消息的最大尺寸，broker不会像consumer输出大于此值的消息chunk每次feth将得到多条消息，此值为总大小，提升此值,将会消耗更多的consumer端内存fetch.min.bytes=6553600# 当消息的尺寸不足时，server阻塞的时间，如果超时，消息将立即发送给consumer。数据一批一批到达，如果每一批是10条消息，如果某一批还不到10条，但是超时了，也会立即发送给consumer。fetch.wait.max.ms=5000socket.receive.buffer.bytes=655360# 如果zookeeper没有offset值或offset值超出范围。那么就给个初始的offset。有smallest、largest、anything可选，分别表示给当前最小的offset、当前最大的offset、抛异常。默认largestauto.offset.reset=smallest# 指定序列化处理类derializer.class=kafka.serializer.DefaultDecoder# 獲取消息的最大尺寸，broker不會像consumer輸出大於此值的消息chunk。每次fetch將得到多條消息，此值為總大小fetch.messages.max.bytes=1024*1024 Producer主要配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# 指定kafka节点列表，用于获取metadata，不必全部指定#需要kafka的服务器地址，来获取每一个topic的分片数等元数据信息。#對於開發者而言，需要通過broker.list指定當前producer需要關注的broker列表，producer通過和每個broker連接，並獲取partitions，如果某個broker連接失敗，將導致此上的partitions無法繼續發佈消息。格式：host1:port,host2:port，其中host:port需要參考broker配置文件。對於producer而言沒有使用zookeeper自動發現broker列表，非常奇怪。metadata.broker.list=kafka01:9092,kafka02:9092,kafka03:9092#生产者生产的消息被发送到哪个block，需要一个分组策略。#指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区#partitions路由類，消息在發送時將根據此實例的方法獲得partition索引號#partitioner.class=kafka.producer.DefaultPartitioner#生产者生产的消息可以通过一定的压缩策略（或者说压缩算法）来压缩。消息被压缩后发送到broker集群，#而broker集群是不会进行解压缩的，broker集群只会把消息发送到消费者集群，然后由消费者来解压缩。#是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。#压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。#文本数据会以1比10或者更高的压缩比进行压缩。compression.codec=none#指定序列化处理类，消息在网络上传输就需要序列化，它有String、数组等许多种实现。將消息實體轉換成byte[]serializer.class=kafka.serializer.DefaultEncoderkey.serializer.class=$&#123;serializer.class&#125;#如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。#如果上面启用了压缩，那么这里就需要设置#compressed.topics= #这是消息的确认机制，默认值是0。在面试中常被问到。#producer有个ack参数，有三个值，分别代表：#（1）不在乎是否写入成功；#（2）写入leader成功；#（3）写入leader和所有副本都成功；#要求非常可靠的话可以牺牲性能设置成最后一种。#为了保证消息不丢失，至少要设置为1，也就#是说至少保证leader将消息保存成功。#设置发送数据是否需要服务端的反馈,有三个值0,1,2，分别代表3种状态：#0: producer不会等待broker发送ack。生产者只要把消息发送给broker之后，就认为发送成功了，这是第1种情况；#1: 当leader接收到消息之后发送ack。生产者把消息发送到broker之后，并且消息被写入到本地文件，才认为发送成功，这是第二种情况；#2: 当所有的follower都同步消息成功后发送ack。不仅是主的分区将消息保存成功了，而且其所有的分区的副本数也都同步好了，才会被认为发动成功，这是第3种情况。request.required.acks=0#broker必须在该时间范围之内给出反馈，否则失败。#在向producer发送ack之前,broker允许等待的最大时间 ，如果超时,#broker将会向producer发送一个error ACK.意味着上一次消息因为某种原因#未能成功(比如follower未能同步成功)request.timeout.ms=10000#生产者将消息发送到broker，有两种方式，一种是同步，表示生产者发送一条，broker就接收一条；#还有一种是异步，表示生产者积累到一批的消息，装到一个池子里面缓存起来，再发送给broker，#这个池子不会无限缓存消息，在下面，它分别有一个时间限制（时间阈值）和一个数量限制（数量阈值）的参数供我们来设置。#一般我们会选择异步。#同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,#也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息producer.type=sync#在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,#默认为5000ms#此值和batch.num.messages协同工作.queue.buffering.max.ms = 5000#异步情况下，缓存中允许存放消息数量的大小。#在async模式下,producer端允许buffer的最大消息量#无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积#此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000条消息。queue.buffering.max.messages=20000#如果是异步，指定每次批量发送数据量，默认为200#消息在producer端buffer的條數，僅在producer.type=async下有效batch.num.messages=500#在生产端的缓冲池中，消息发送出去之后，在没有收到确认之前，该缓冲池中的消息是不能被删除的，#但是生产者一直在生产消息，这个时候缓冲池可能会被撑爆，所以这就需要有一个处理的策略。#有两种处理方式，一种是让生产者先别生产那么快，阻塞一下，等会再生产；另一种是将缓冲池中的消息清空。#当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后阻塞一定时间后,#队列仍然没有enqueue(producer仍然没有发送出任何消息)#此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间#-1: 不限制阻塞超时时间，让produce一直阻塞,这个时候消息就不会被抛弃#0: 立即清空队列,消息被抛弃queue.enqueue.timeout.ms=-1#当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数#因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失)#有可能导致broker接收到重复的消息,默认值为3.message.send.max.retries=3#producer刷新topic metada的时间间隔,producer需要知道partition leader#的位置,以及当前topic的情况#因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,#将会立即刷新#(比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置#额外的刷新机制，默认值600000topic.metadata.refresh.interval.ms=60000 以上是关于kafka一些基础说明，在其中我们知道如果要kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生产者和消费者都无法正常的工作 zookeeper集群部署 zookeeper是一个为分布式应用提供一致性服务的软件，它是开源的Hadoop项目的一个子项目，并根据google发表的一篇论文来实现的。zookeeper为分布式系统提供了高效且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。zookeeper接口简单，我们不必过多地纠结在分布式系统编程难于处理的同步和一致性问题上，你可以使用zookeeper提供的现成(off-the-shelf)服务来实现分布式系统额配置管理，组管理，Leader选举等功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566準備三台主機，主機名分別為kafka1(10.5.5.19)、kafka2(10.5.5.24)、kafka3(10.5.5.155)。* kafka1到http://zookeeper.apache.org/releases.html去下载zookeeperyum install java-1.8.0-openjdk-deve# zookeeper依賴javatar -zxvf zookeeper-3.4.9.tar.gz -C /usr/local# 解壓安裝cd /usr/localln -sv zookeeper-3.4.9 zookeepercd zookeeper/confcp zoo_sample.cfg zoo.cfgvim zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/usr/local/zookeeper/data dataLogDir=/usr/local/zookeeper/logs clientPort=2181 server.1=10.5.5.19:2888:3888 server.2=10.5.5.24:2888:3888 server.3=10.5.5.155:2888:3888# tickTime：这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。# dataDir：顾名思义就是 Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。# clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。# initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒# syncLimit：这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是5*2000=10 秒# server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号# 注意：dataDir,dataLogDir中的wwb是当前登录用户名，data，logs目录开始是不存在，需要使用mkdir命令创建相应的目录。并且在该目录下创建文件myid。serve1,server2,server3该文件内容分别为1,2,3。cd /usr/local/zookeepermkdir &#123;data,logs&#125;cd dataecho 1 &gt; myidcdscp zookeeper-3.4.9.tar.gz 10.5.5.24:/rootscp zookeeper-3.4.9.tar.gz 10.5.5.155:/rootvim /etc/profile.d/java.sh export JAVA_HOME=/usrchmod +x /etc/profile.d/java.sh. /etc/profile.d/java.shjava -versionscp /etc/profile.d/java.sh 10.5.5.24:/etc/profile.dscp /etc/profile.d/java.sh 10.5.5.155:/etc/profile.d* kafka2&amp;kafka3yum install java-1.8.0-openjdk-devecd /roottar xf zookeeper-3.4.9.tar.gz -C /usr/local/cd /usr/local/ln -sv zookeeper-3.4.9 zookeepercd zookeepermkdir &#123;data,logs&#125;cd data/echo 2 &gt; myid# kafka3這裡改為echo 3 &gt; myid. /etc/profile.d/java.shjava -version* 三台主機cd /usr/local/zookeeper/bin./zkServer.sh start# 啟動zookeeperss -tln# 這時只有leader節點會監聽2888端口，另外兩台是不監聽的。三台主機都會監聽2181和3888端口./zkCli.sh -server 10.5.5.19:2181# 這裡如果連接的是本機的zookeeper可以不用參數和地址，連接集群中其他zookeeper需要。 kafka集群部署12345678910111213141516171819202122232425262728293031使用生產環境kafka包，版本：kafka_2.12-0.10.2.0。三台主機的操作相同cd /roottar xf kafka_2.12-0.10.2.0.tgz -C /usr/localcd /usr/localln -sv kafka_2.12-0.10.2.0 kafkacd kafka/config/vim server.properties broker.id=1# 三台主機這裡的id是不台一樣的，分別為1、2、3 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 log.dirs=/usr/local/kafka/logs# 這裡改了日誌地址 num.partitions=1 num.recovery.threads.per.data.dir=1 log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 zookeeper.connect=10.5.5.19:2181,10.5.5.24:2181,10.5.5.155:2181# zookeeper集群內的所有地址都寫入 zookeeper.connection.timeout.ms=6000# 配置文件基本使用默認配置，之後會再查看配置文件詳細設置mkdir /usr/local/kafka/logscd /usr/local/kafka/binnohup ./kafka-server-start.sh ../config/server.properties &amp;ss -tln# 這時應該監聽了默認端口9092 zookeeper命令123456789101112131415161718192021222324252627282930313233./zkServer.sh start# 啟動zookeeper./zkServer.sh status# 查看當前zookeeper是leader還是follower./zkServer.sh stop# 停止zookeeper./zkCli.sh# zookeeper客戶端，連接當前主機上的zookeeper./zkCli.sh -server IP:port# 连接远端服务[root@kafka3 zookeeper]# bin/zkCli.sh Connecting to localhost:2181[zk: localhost:2181(CONNECTED) 0] ls /[cluster, controller, controller_epoch, brokers, zookeeper, admin, isr_change_notification, consumers, config][zk: localhost:2181(CONNECTED) 1] ls /brokers[ids, topics, seqid][zk: localhost:2181(CONNECTED) 2] ls /brokers/topics[test][zk: localhost:2181(CONNECTED) 3] ls /brokers/ids [0, 1, 2][zk: localhost:2181(CONNECTED) 7] get /brokers/ids/0&#123;"listener_security_protocol_map":&#123;"PLAINTEXT":"PLAINTEXT"&#125;,"endpoints":["PLAINTEXT://192.168.1.14:9092"],"jmx_port":-1,"host":"192.168.1.14","timestamp":"1548120711670","port":9092,"version":4&#125;cZxid = 0x10000001cctime = Tue Jan 22 09:31:51 CST 2019mZxid = 0x10000001cmtime = Tue Jan 22 09:31:51 CST 2019pZxid = 0x10000001ccversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x2687326f51f0000dataLength = 194numChildren = 0 kafka命令創建topic12345678910[root@kafka1 bin]# ./kafka-topics.sh --create --zookeeper 192.168.1.14:2181 --replication-factor 1 --partitions 3 --topic testCreated topic "test".# 創建topic，--create表示創建，--zookeeper指明zookeeper地址，--topic指定topic名稱，--replication-factor指定副本的數量，--partitions指定分區的數量。--if-not-exists表示如果topic不存在就創建。創建的副本的數量不能大於broker，不然會有錯誤提示“Error while executing topic command : replication factor: 4 larger than available brokers: 2”[root@kafka3 kafka]# ls logs/cleaner-offset-checkpoint log-cleaner.log server.log.2019-01-22-09controller.log meta.properties state-change.logkafka-authorizer.log recovery-point-offset-checkpoint test-0kafka-request.log replication-offset-checkpoint test-3kafkaServer-gc.log server.log# 在创建topic后，可以在/usr/local/kafka/logs目录查看到分区的目录 查看topic123456789101112131415[root@kafka1 bin]# ./kafka-topics.sh --list --zookeeper localhost:2181test# 查看所有的topic[root@kafka1 bin]# ./kafka-topics.sh --describe --zookeeper 192.168.1.15:2181 --topic testTopic:test PartitionCount:3 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 2 Replicas: 2 Isr: 2 Topic: test Partition: 1 Leader: 0 Replicas: 0 Isr: 0 Topic: test Partition: 2 Leader: 1 Replicas: 1 Isr: 1# 查看指定topic情況。列出了lx_test_topic的parition数量、replica因子以及每个partition的leader、replica信息# PartitionCount：topic对应的partition的个数# ReplicationFactor：topic对应的副本因子，说白就是副本个数# Partition：partition编号，从0开始递增# Leader：当前partition起作用的breaker.id# Replicas: 当前副本数据坐在的breaker.id，是一个列表，排在最前面的起作用# Isr：当前kakfa集群中可用的breaker.id列表 增加topic分區1234[root@kafka1 bin]# ./kafka-topics.sh --zookeeper localhost:2181 --alter --topic test --partitions 4WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affectedAdding partitions succeeded!# 給現有的topic添加分區，使用--alter選項，在命令中不能加--replication-factor選項，不然會報錯。另外，分区的数量只能增加 創建生產者123[root@kafka1 bin]# ./kafka-console-producer.sh --broker-list 192.168.1.15:9092,192.168.1.13:9092 --topic testabc# 創建生產者，這時終端會等待用戶輸入信息 創建消費者1234[root@kafka2 bin]# ./kafka-console-consumer.sh --zookeeper 192.168.1.14:2181 --topic test --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].abc# 創建消費者，創建後終端會等待生產者生產消息。在生產者終端輸入信息後，消費者終端會顯示生產者輸入的消息，這表示消費者消費了。如果有多個地址，地址間要用逗號隔開。 查看消費者列表1234567891011121314查看consumer group列表有新、旧两种命令，分别查看新版(信息保存在broker中)consumer列表和老版(信息保存在zookeeper中)consumer列表，因而需要区分指定bootstrap--server和zookeeper参数：[root@kafka3 bin]# ./kafka-consumer-groups.sh --new-consumer --bootstrap-server 127.0.0.1:9092 --listNote: This will only show information about consumers that use the Java consumer API (non-ZooKeeper-based consumers).[root@kafka3 bin]# ./kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --listNote: This will only show information about consumers that use ZooKeeper (not those using the Java consumer API).console-consumer-6777--------------------------------------------bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --broker-info --group inbound --topic inboundMsg --zookeeper 192.168.2.182:2181# 结果中的Lag是待消费的数量watch '/usr/local/kafka/bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 192.168.2.182:9092 --group inbound --describe'# 如果是多个分区，用此命令--------------------------------------------# 查看特定consumer group 详情，使用--group与--describe参数 查看kafka日誌1234567./kafka-run-class.sh kafka.tools.DumpLogSegments# 我们可以看到都需要哪些参数，根据不同的需求我们可以选择不同的参数。[root@kafka3 bin]# ./kafka-run-class.sh kafka.tools.DumpLogSegments --files /usr/local/kafka/logs/test-0/00000000000000000000.log --print-data-logDumping /usr/local/kafka/logs/test-0/00000000000000000000.logStarting offset: 0offset: 0 position: 0 CreateTime: 1548121485387 isvalid: true payloadsize: 3 magic: 1 compresscodec: NONE crc: 3938834414 payload: abc# 这里--print-data-log 是表示查看消息内容的，不加此项是查看不到详细的消息内容。如果要查看多个log文件可以用逗号分隔。 刪除topic12345678vim server.properties delete.topic.enable=truekill -9 kafkazkServer.sh restart# 修改配置文件後要重啟zookeeper和kafkazkCli.shrmr /brokers/topic/topic-name# 進入zookeeper中再刪除topic kafka测试123456789101112131415* 测试生产者[root@kafka1 kafka]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --topic test-rep-one --partitions 6 --replication-factor 1 Created topic "test-rep-one".# 创建一个六分区一个副本的topic[root@kafka1 kafka]# bin/kafka-producer-perf-test.sh --num-records 500000 --throughput 100000 --record-size 3000 --topic testtest-rep-one --producer-props bootstrap.servers=192.168.1.14:9092,192.168.1.15:9092,192.168.1.13:9092...51490 records sent, 10298.0 records/sec (29.46 MB/sec), 997.3 ms avg latency, 1031.0 max latency.52075 records sent, 10415.0 records/sec (29.80 MB/sec), 982.8 ms avg latency, 1019.0 max latency.500000 records sent, 10366.131774 records/sec (29.66 MB/sec), 971.63 ms avg latency, 1033.00 ms max latency, 988 ms 50th, 1014 ms 95th, 1022 ms 99th, 1028 ms 99.9th.# --num-records：要生成的消息数# --throughput：将最大消息吞吐量限制为*大约*吞吐量消息/秒，也就是每秒发送多少条数据# --record-size：消息大小（字节）。注意，您必须只提供一个--record-size或--payload文件。# --topic：指定主题# --producer-props：kafka生产者相关的配置属性，如bootstrap。 servers，client.id等。这些配置优先于通过--producer.config传递的配置。# bootstrap.servers：指定kafka地址与端口 附錄1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Kafka is a distributed,partitioned,replicated commit logservice卡夫卡是一个分布式的，分区的，复制提交的日志服务distributed[dɪ'strɪbjʊtɪd] adj. 分布式的，分散式的partitioned adj. 分割的；分区的；分段的replicated 重复的topic n. 主题（等于theme）；题目；partition n. 划分，分开；[数] 分割；隔墙；隔离物append 添加；附加offset 偏移anatomy of a topic解剖一个主题anatomy[ə'nætəmɪ] n. 解剖；解剖学；剖析；骨骼consumer n. 消费者；用户，顾客producer[prə'djuːsə] n. 制作人，制片人；生产者；发生器replica['replɪkə] n. 复制品，复制物queue[kjuː] n. 队列；长队；辫子guarantee[,ɡærən'ti] n. 保证；担保；保证人；保证书；抵押品replication factor 複製因子factor['fæktə] n. 因素；要素；[物] 因数；代理人Websit activity tracking 網絡活動追蹤activity[ækˈtɪvətɪ] n. 活动；行动；活跃Log Aggregation 日誌收集aggregation[,æɡrɪ'ɡeɪʃən] n. [地质][数] 聚合，聚集；聚集体，集合体fetch[fetʃ] vi. 拿；取物；push[pʊʃ] n. 推pull[pʊl] n. 拉batch fetch 批量獲取batch[bætʃ] n. 一批provider[prə'vaɪdə] n. 供应者；养家者exactly once 恰一次exactly[ɪɡ'zæktli] adv. 恰好地；正是；精确地；正确地at most once 最多一次at least once 至少一次up to date 最新的log entry 日誌條目entry[ˈentrɪ] n. 进入；入口；条目；登记；报关手续；对土地的侵占segment['segm(ə)nt] n. 段；部分chunk[tʃʌŋk] 數據塊copy on write 寫入時複製meta['metə] 元Broker node registry Broker節點註冊registry['redʒɪstrɪ] n. 注册；登记处；挂号处；船舶的国籍stream[striːm] n. 溪流；流动；潮流；光线balance['bæl(ə)ns] n. 平衡；余额；匀称off the shelf 現成的shelf[ʃelf] n. 架子；搁板；搁板状物；暗礁chubby['tʃʌbɪ] adj. 圆胖的，丰满的 [ 比较级 chubbier 最高级 chubbiest ]election[ɪ'lekʃ(ə)n] n. 选举；当选；选择权；上帝的选拔discovery[dɪ'skʌv(ə)rɪ] n. 发现，发觉；被发现的事物broadcast['brɔːdkɑːst] n. 广播；播音；广播节目random['rændəm] adj. [数] 随机的；任意的；胡乱的controller[kən'trəʊlə] n. 控制器；管理员proposal[prəˈpəuzəl] n. 提议;建议; 求婚; 〈美〉投标;epoch[ˈi:pɔk] n. 纪元;时期;新时代;世;failover[feɪl'əʊvər] n.[电脑][数据库]失效备援 （为系统备援能力的一种，当系统中其中一项设备失效而无法运作时，另一项设备即可自动接手原失效系统所执行的工作）persist[pəˈsist] v. 坚持; 固执; 存留; 继续存在; ephemeral[ɪˈfemərəl] adj. 短暂的，瞬息的; 朝露; 一年生; 朝生暮死;sequence[ˈsi:kwəns] n. [数]数列，序列; 顺序; 连续; 片断插曲; split brain[split][brein] 脑裂split n. 划分; 分歧; 裂缝; 劈叉; brain n. 脑; 智慧; 聪明的人; （群体中）最聪明的人;]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>zookeeper&amp;kafka部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka概念]]></title>
    <url>%2F2019%2F01%2F21%2Fkafka%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[介紹 Kafka is a distributed，partitioned，replicated commit logservice。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者稱为Producer，消息接受者稱为Consumer，此外kafka集群由多个kafka实例组成，每个实例(server)稱为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性，zookeeper集群保存一些meta(元數據)信息。 概念消息队列（Message Queue） 消息 Message网络中的两台计算机或者两个通讯设备之间传递的数据。例如说：文本、音乐、视频等内容。 队列 Queue一种特殊的线性表（数据元素首尾相接），特殊之处在于只允许在首部删除元素和在尾部追加元素。入队、出队。 消息队列 MQ消息+队列，保存消息的队列。消息的传输过程中的容器；主要提供生产、消费接口供外部调用做数据的存储和获取。 MQ分类 MQ主要分为两类：点对点(p2p)、发布订阅(Pub/Sub) 共同点：消息生产者生产消息发送到queue中，然后消息消费者从queue中读取并且消费消息。 不同点：p2p模型包括：消息队列(Queue)、发送者(Sender)、接收者(Receiver)一个生产者生产的消息只有一个消费者(Consumer)(即一旦被消费，消息就不在消息队列中)。比如说打电话。 Pub/Sub包含：消息队列(Queue)、主题(Topic)、发布者(Publisher)、订阅者(Subscriber)每个消息可以有多个消费者，彼此互不影响。比如我发布一个微博：关注我的人都能够看到。那么在大数据领域呢，为了满足日益增长的数据量，也有一款可以满足百万级别消息的生成和消费，分布式、持久稳定的产品——Kafka。 Kafka组件 Topic：主题，Kafka处理的消息的不同分类。 Broker：消息代理，Kafka集群中的一个kafka服务节点称为一个broker，主要存储消息数据。存在硬盘中。每个topic都是有分区的。 Partition：Topic物理上的分组，一个topic在broker中被分为1个或者多个partition，分区在创建topic的时候指定。 Message：消息，是通信的基本单位，每个消息都属于一个partition Producer：消息和数据的生产者，向Kafka的一个topic发布消息。 Consumer：消息和数据的消费者，定于topic并处理其发布的消息。 Zookeeper：协调kafka的正常运行。 Topics/logs 一个Topic可以认为是一类消息，每个topic将被分成多个partition(分区)，每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量），offset为一个long型数字，它唯一的标记一条消息。kafka并没有提供其他额外的索引机制来存储offset，因为在kafka中几乎不允许对消息进行“随机读写”。 kafka和JMS（Java Message Service）实现(activeMQ)不同的是：即使消息被消费,消息仍然不会被立即删除。日志文件将会根据broker中的配置要求，保留一定的时间之后删除；比如log文件保留2天，那么两天后,文件会被清除，无论其中的消息是否被消费。kafka通过这种简单的手段，来释放磁盘空间，以及减少消息消费之后对文件内容改动的磁盘IO开支。 对于consumer而言，它需要保存消费消息的offset，对于offset的保存和使用，由consumer来控制；当consumer正常消费消息时，offset将会”线性”的向前驱动，即消息将依次顺序被消费。事实上consumer可以使用任意顺序消费消息，它只需要将offset重置为任意值。(offset将会保存在zookeeper中) kafka集群几乎不需要维护任何consumer和producer状态信息，这些信息由zookeeper保存；因此producer和consumer的客户端实现非常轻量级，它们可以随意离开，而不会对集群造成额外的影响。 partitions的设计目的有多个。最根本原因是kafka基于文件存储。通过分区，可以将日志内容分散到多个server上，来避免文件尺寸达到单机磁盘的上限，每个partiton都会被当前server(kafka实例)保存；可以将一个topic切分為任意多个partitions，来提高消息保存/消费的效率。此外越多的partitions意味着可以容纳更多的consumer，有效提升并发消费的能力。 Distribution 一个Topic的多个partitions，被分布在kafka集群中的多个server上；每个server(kafka实例)负责partitions中消息的读写操作；此外kafka还可以配置partitions需要备份的个数(replicas)，每个partition将会被备份到多台机器上，以提高可用性。 基于replicated方案，那么就意味着需要对多个备份进行调度；每个partition都有一个server为”leader”；leader负责所有的读写操作，如果leader失效，那么将会有其他follower来接管(成为新的leader)；follower只是单调的和leader跟进，同步消息即可。由此可见作为leader的server承载了全部的请求压力，因此从集群的整体考虑，有多少个partitions就意味着有多少个”leader”，kafka会将”leader”均衡的分散在每个实例上，来确保整体的性能稳定。 Producers Producer将消息发布到指定的Topic中，同时Producer也能决定将此消息归属于哪个partition；比如基于”round-robin”方式或者通过其他的一些算法等。 Consumers 本质上kafka只支持Topic。每个consumer属于一个consumer group；反过来说，每个group中可以有多个consumer。发送到Topic的消息，只会被订阅此Topic的每个group中的一个consumer消费。 如果所有的consumer都具有相同的group，这种情况和queue模式很像；消息将会在consumers之间负载均衡。 如果所有的consumer都具有不同的group，那这就是”发布-订阅”；消息将会广播给所有的消费者。 在kafka中，一个partition中的消息只会被group中的一个consumer消费；每个group中consumer消息消费互相独立；我们可以认为一个group是一个”订阅”者，因為一个Topic中的每个partions，只会被一个”订阅者”中的一个consumer消费，不过一个consumer可以消费多个partitions中的消息。kafka只能保证一个partition中的消息被某个consumer消费时，消息是顺序的。事实上，从Topic角度来说，消息仍不是有序的。 kafka的设计原理决定，对于一个topic，同一个group中不能有多于partitions个数的consumer同时消费，否则将意味着某些consumer将无法得到消息。partition與consumer的數量最好相等。 Guarantees 发送到partitions中的消息将会按照它接收的顺序追加到日志中 对于消费者而言，它们消费消息的顺序和日志中消息顺序一致。 如果Topic的“replication factor”为N,那么允许N-1个kafka实例失效。 使用场景 Messaging对于一些常规的消息系统，kafka是个不错的选择；partitons/replication和容错，可以使kafka具有良好的扩展性和性能优势。不过到目前为止，我们应该很清楚认识到，kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性；kafka只能使用作为”常规”的消息系统，在一定程度上，尚未确保消息的发送与接收绝对可靠(比如消息重发，消息发送丢失等) Websit activity trackingkafka可以作为”网站活動跟踪”的最佳工具；可以将网页/用户操作等信息发送到kafka中。并实时监控，或者离线统计分析等 Log Aggregationkafka的特性决定它非常适合作为”日志收集中心”；application可以将操作日志”批量””异步”的发送到kafka集群中，而不是保存在本地或者DB中；kafka可以批量提交消息/压缩消息等，这对producer端而言，几乎感觉不到性能的开支。此时consumer端可以使用hadoop等其他系统化的存储和分析系统。 设计原理 kafka的设计初衷是希望作为一个统一的信息收集平台，能够实时的收集反馈信息，并需要能够支撑较大的数据量，且具备良好的容错能力。 持久性 kafka使用文件存储消息，这就直接决定kafka在性能上严重依赖文件系统的本身特性。且无论任何OS下，对文件系统本身的优化几乎没有可能。文件缓存/直接内存映射等是常用的手段。因为kafka是对日志文件进行append操作，因此磁盘检索的开支是较小的；同时为了减少磁盘写入的次数，broker会将消息暂时buffer起来，当消息的个数(或尺寸)达到一定閾值时，再flush到磁盘，这样减少了磁盘IO调用的次数。 性能 需要考虑的影响性能点很多，除磁盘IO之外，我们还需要考虑网络IO，这直接关系到kafka的吞吐量问题。kafka并没有提供太多高超的技巧；对于producer端，可以将消息buffer起来，当消息的条数达到一定閾值时，批量发送给broker；对于consumer端也是一样，批量fetch多条消息。不过消息量的大小可以通过配置文件来指定。对于kafka broker端，似乎有个sendfile系统调用[^註釋]可以潜在的提升网络IO的性能。将文件的数据映射到系统内存中，socket直接读取相应的内存区域即可，而无需进程再次copy和交换。 其实对于producer/consumer/broker三者而言，CPU的开支应该都不大，因此启用消息压缩机制是一个良好的策略；压缩需要消耗少量的CPU资源，不过对于kafka而言，网络IO更应该需要考虑。可以将任何在网络上传输的消息都经过压缩。kafka支持gzip/snappy等多种压缩方式。 生產者 负载均衡：producer将会和Topic下所有partition leader保持socket连接；消息由producer直接通过socket发送到broker，中间不会经过任何”路由层”。事实上，消息被路由到哪个partition上，由producer客户端决定。比如可以采用”random””key-hash””轮询”等方式，如果一个topic中有多个partitions，那么在producer端实现”消息均衡分发”是必要的。 其中partition leader的位置(host:port)注册在zookeeper中，producer作为zookeeper client，已经注册了watch用来监听partition leader的变更事件。 异步发送：将多条消息暂且在客户端buffer起来，并将他们批量的发送到broker，小数据IO太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。不过这也有一定的隐患，比如说当producer失效时，那些尚未发送的消息将会丢失。 消費者 consumer端向broker发送”fetch”请求，并告知其获取消息的offset；此后consumer将会获得一定条数的消息；consumer端也可以重置offset来重新消费消息。 在JMS实现中，Topic模型基于push方式，即broker将消息推送给consumer端。不过在kafka中，采用了pull方式，即consumer在和broker建立连接之后，主动去pull(或者说fetch)消息；这種模式有些优点，首先consumer端可以根据自己的消费能力适时的去fetch消息并处理，且可以控制消息消费的进度(offset)；此外，消费者可以良好的控制消息消费的数量，batch fetch（批量獲取）. 其他JMS实现，消息消费的位置是由provider保留，以便避免重复发送消息或者将没有消费成功的消息重发等，同时还要控制消息的状态。这就要求JMS broker需要太多额外的工作。在kafka中，partition中的消息只有一个consumer在消费，且不存在消息状态的控制，也没有复杂的消息确认机制，可见kafka broker端是相当轻量级的。当消息被consumer接收之后，consumer可以在本地保存最后消費的offset，并间歇性的向zookeeper注册offset。由此可见，consumer客户端也很轻量级。 消息傳送機制 对于JMS实现，消息传输担保非常直接，有且只有一次(exactly once)。在kafka中稍有不同： at most once：最多一次，这个和JMS中”非持久化”消息类似。发送一次，无论成败，将不会重发。 at least once：消息至少发送一次，如果消息未能接受成功，可能会重发，直到接收成功。 exactly once：消息只会发送一次。 at most once：消费者fetch消息，然后保存offset，然后处理消息；当client保存offset之后，但是在消息处理过程中出现了异常，导致部分消息未能继续处理。那么此后”未处理”的消息将不能被fetch到，这就是”at most once”。 at least once：消费者fetch消息，然后处理消息，然后保存offset。如果消息处理成功之后，但是在保存offset阶段zookeeper异常导致保存操作未能执行成功，这就导致接下来再次fetch时可能获得上次已经处理过的消息，这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态。 exactly once：kafka中并没有严格的去实现(基于2阶段提交,事务)，我们认为这种策略在kafka中是没有必要的。 通常情况下”at-least-once”是我们首选(相比at most once而言，重复接收数据总比丢失数据要好)。 複製備份 kafka将每个partition数据复制到多个server上，任何一个partition都有一个leader和多个follower(可以没有)；备份的个数可以通过broker配置文件来设定。leader处理所有的read-write请求，follower需要和leader保持同步。Follower和consumer一样，消费消息并保存在本地日志中；leader负责跟踪所有的follower状态，如果follower”落后”太多或者失效，leader将会把它从replicas同步列表中删除。当所有的follower都将一条消息保存成功，此消息才被认为是”committed”，那么此时consumer才能消费它。即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收，只要zookeeper集群存活即可。(不同于其他分布式存储，比如hbase需要”多数派”存活才行)当leader失效时，需在followers中选取出新的leader，可能此时follower落后于leader，因此需要选择一个”up-to-date”的follower。选择follower时需要兼顾一个问题，就是新leaderserver上已经承载的partition leader的个数，如果一个server上有过多的partition leader，意味着此server将承受着更多的IO压力。在选举新leader，需要考虑到”负载均衡”。 日誌 如果一个topic的名称为”my_topic”，它有2个partitions，那么日志将会保存在my_topic_0和my_topic_1两个目录中；日志文件中保存了一序列”log entries”(日志条目)，每个log entry格式为”4个字节的数字，N表示消息的长度” + “N个字节的消息内容”；每个日志都有一个offset来唯一的标记一条消息，offset的值为8个字节的数字，表示此消息在此partition中所处的起始位置。**每个partition在物理存储层面有多个log file组成(称为segment)。segmentfile的命名为”最小offset”.kafka(log)。例如”00000000000.kafka(log)”；其中”最小offset”表示此segment中起始消息的offset。 其中每个partiton中所持有的segments列表信息会存储在zookeeper中。 当segment文件尺寸达到一定閾值时(可以通过配置文件设定，默认1G)，将会创建一个新的文件；当buffer中消息的条数达到閾值时将会触发日志信息flush到日志文件中，同时如果”距离最近一次flush的时间差”达到閾值时，也会触发flush到日志文件。如果broker失效，极有可能会丢失那些尚未flush到文件的消息。因为server意外仍然会导致log文件格式的破坏(文件尾部)，那么就要求当server启動時需要检测最后一个segment的文件结构是否合法并进行必要的修复。 获取消息时，需要指定offset和最大chunk尺寸，offset用来表示消息的起始位置，chunk size用来表示最大获取消息的总长度(间接的表示消息的条数)。根据offset，可以找到此消息所在segment文件，然后根据segment的最小offset取差值，得到它在file中的相对位置，直接读取输出即可。 日志文件的删除策略非常简单，启动一个后台线程定期扫描log file列表，把保存时间超过閾值的文件直接删除(根据文件的创建时间)。为了避免删除文件时仍然有read操作(consumer消费)，采取copy-on-write方式。 分配 kafka使用zookeeper来存储一些meta信息，并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效，触发负载均衡等) Broker node registry：当一个kafkabroker启动后，首先会向zookeeper注册自己的节点信息(临时znode)，同时当broker和zookeeper断开连接时，此znode也会被删除。 格式： /broker/ids/[0…N] –&gt;host:port，其中[0..N]表示broker id，每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复)，znode的值为此broker的host:port信息。 Broker Topic Registry：当一个broker启动时，会向zookeeper注册自己持有的topic和partitions信息，仍然是一个临时znode。 格式： /broker/topics/[topic]/[0…N]，其中[0..N]表示partition索引号。 Consumer and Consumer group：每个consumer客户端被创建时，会向zookeeper注册自己的信息，此作用主要是为了”负载均衡”。 一个group中的多个consumer可以交错的消费一个topic的所有partitions；简而言之，保证此topic的所有partitions都能被此group所消费，且消费时为了性能考虑，让partition相对均衡的分散到每个consumer上。 Consumer id Registry： 每个consumer都有一个唯一的ID(host:uuid，可以通过配置文件指定，也可以由系统生成)，此id用来标记消费者信息。 格式：/consumers/[group_id]/ids/[consumer_id] 仍然是一个临时的znode，此节点的值为{“topic_name”:#streams…}，即表示此consumer目前所消费的topic + partitions列表。 Consumer offset Tracking：用来跟踪每个consumer目前所消费的partition中最大的offset。 格式：/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value 此znode为持久节点，可以看出offset跟group_id有关，以表明当group中一个消费者失效，其他consumer可以继续消费。 Partition Owner registry：用来标记partition被哪个consumer消费。临时znode 格式：/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id 当consumer启动时，所触发的操作：A. 首先进行”Consumer id Registry”；B. 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”；只要此znode path下节点列表变更，都会触发此group下consumer的负载均衡。(比如一个consumer失效，那么其他consumer接管partitions)。C. 在”Broker id registry”节点下，注册一个watch用来监听broker的存活情况；如果broker列表变更，将会触发所有的groups下的consumer重新balance（在consumer間再平衡，重新分配？）。 Producer端使用zookeeper用来”发现”broker列表，以及和Topic下每个partition leader建立socket连接并发送消息。 Broker端使用zookeeper用来注册broker信息，以监测partitionleader存活性。 Consumer端使用zookeeper用来注册consumer信息，其中包括consumer消费的partition列表等，同时也用来发现broker列表，并和partition leader建立socket连接，并获取消息。]]></content>
      <categories>
        <category>zookeeper&amp;kafka</category>
      </categories>
      <tags>
        <tag>kafka概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper概念]]></title>
    <url>%2F2019%2F01%2F18%2Fzookeeper%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概念分布式系統 只要不是工作在同一節點的工作系統和應用，就可稱為分佈式系統。是一个硬件或软件组件分布在网络中的不同的计算机之上，彼此间仅通过消息传递进行通信和协作的系统。 分佈式系統特征 分布性、对等性、并发性、缺乏全局时钟、故障必然会发生 分佈式系統典型问题 通信异常、网络分区、三态(成功、失败、超时)、节点故障 CAP Consistency 一致性 Availability 可用性(指的是快速获取数据) Tolerance of network Partition 分区容错性(分布式) BASE 基本可用（Basically Available）：用户都有一种愚蠢的期望，就是当他们把浏览器指向一个网页时，就会有某些信息出现。这是你期望发生的，即便系统的某些部分宕机了也一样。这听上去微不足道，事实却并非如此；有很多系统只要一台服务器宕了，整个系统就宕了。 可伸缩（Scalable/Soft-state ）：添加更多的服务器使得服务更多的客户成为可能。不是创建一个巨大的怪物服务器，而是添加更多的服务器，这更具有前瞻性，而且也通常更便宜。重申一下，这是用户的期望之一：信息不仅仅是出现，而且还要快速地出现。（注意这项用户期望不仅要求伸缩性，还同时要求性能。） 最终一致性（Eventually Consistent）：如果数据最终在所有副本出现的地方变为可用，这就足够了（如上一点所述，你可以有很多副本）。这里的期望是，信息要快速出现才会显得及时。 当你在Craigslist上发布一个广告，它不会马上出现在列表和搜索结果中，这不是太大的问题；但如果一个广告需要几天才出现，就没有人会去用那个网站了。 BASE模型與ACID模型完全不同，牺牲高一致性，获得可用性或可靠性： Basically Available基本可用。支持分区失败(e.g. sharding碎片划分数据库) 。Soft state软状态，状态可以有一段时间不同步，异步。 Eventually consistent最终一致，最终数据是一致的就可以了，而不是實时一致。BASE思想的主要实现有：1.按功能划分数据库；2.sharding碎片。BASE思想主要强调基本的可用性，如果你需要高可用性，也就是纯粹的高性能，那么就要以一致性或容错性为牺牲，BASE思想的方案在性能上还是有潜力可挖的。 保证分布式系统的一致性多种协议 2PC：2 Phase-Commit（兩段式提交），请求和执行，所有節點的請求都到達了才會進入第二段提交 3PC：3 Phase-Commit（三段式提交）， CanCommit（發出請求）–&gt; PreCommit（預提交）–&gt; DoCommit（提交） Paxos（帕克索斯）：Leslie Lamport，1990年提出 分布式鎖服務 Google Chubby，分布式锁服务[^1]，GFS/BigTable都用到了chubby 提供分布式协作、元数据存储、Master选举等功能 分布式鎖服務的作用是允許各客戶端可以通過chubby進行同步彼此的操作，有一個公共的存儲或服務，各節點與這個公共存儲或服務通信，各節點按固定週期將自己的數據同步到這個公共存儲，在公共存儲上有數據節點，一個數據節點對應一個節點，如果節點故障，公共存儲上的數據節點也隨之移除，其他節點取不到這個節點的數據時，就認為這個節點不存在了。公共存儲還提供主節點選舉功能，為必免公共存儲故障，所以公共存儲也要高可用，另外公共存儲的高可用也會自己為自己提供所謂的分佈式協作服務。 HDFS/HBase, Zookeeper zookeeper是一个开源的分布式协调服务，由知名互联网公司Yahoo创建，它是Chubby的开源实现；换句话讲，zk是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于它实现数据的发布/订阅、负载均衡、名称服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列； Zookeeper基本概念 Zookeeper是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。这一切的基础，都是Zookeeper提供了一个类似于Linux文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。 Zookeeper架构角色 Zookeeper集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种 Leader：一个Zookeeper集群同一时间只会有一个实际工作的Leader，它会发起并维护与各Follwer及Observer间的心跳。所有的写操作必须要通过Leader完成再由Leader将写操作广播给其它服务器。 Follower：一个Zookeeper集群可能同时存在多个Follower，它会响应Leader的心跳。Follower可直接处理并返回客户端的读请求，同时会将写请求转发给Leader处理，并且负责在Leader处理写请求时对请求进行投票。 Observer 角色与Follower类似，但是无投票权。 原子广播（ZAB） 为了保证写操作的一致性与可用性，Zookeeper专门设计了一种名为原子广播（ZAB）的支持崩溃恢复的一致性协议。基于该协议，Zookeeper实现了一种主从模式的系统架构来保持集群中各个副本之间的数据一致性。 根据ZAB协议，所有的写操作都必须通过Leader完成，Leader写入本地日志后再复制到所有的Follower节点。 一旦Leader节点无法工作，ZAB协议能够自动从Follower节点中重新选出一个合适的替代者，即新的Leader，该过程即为领导选举。该领导选举过程，是ZAB协议中最为重要和复杂的过程。 写操作写Leader 通过Leader进行写操作流程如下图所示 由上图可见，通过Leader进行写操作，主要分为五步： 客户端向Leader发起写请求 Leader将写请求以Proposal(建议;提议;)的形式发给所有Follower并等待ACK Follower收到Leader的Proposal后返回ACK Leader得到过半数的ACK（Leader对自己默认有一个ACK）后向所有的Follower和Observer发送Commmit Leader将处理结果返回给客户端 这里要注意 Leader并不需要得到Observer的ACK，即Observer无投票权 Leader不需要得到所有Follower的ACK，只要收到过半的ACK即可，同时Leader本身对自己有一个ACK。上图中有4个Follower，只需其中两个返回ACK即可，因为(2+1) / (4+1) &gt; 1/2 Observer虽然无投票权，但仍须同步Leader的数据从而在处理读请求时可以返回尽可能新的数据 写Follower/Observer 通过Follower/Observer进行写操作流程如下图所示： 从上图可见 Follower/Observer均可接受写请求，但不能直接处理，而需要将写请求转发给Leader处理 除了多了一步请求转发，其它流程与直接写Leader无任何区别 读操作 Leader/Follower/Observer都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。 由于处理读请求不需要服务器之间的交互，Follower/Observer越多，整体可处理的读请求量越大，也即读性能越好。 FastLeaderElection(快速领袖选举)原理术语myid 每个Zookeeper服务器，都需要在数据文件夹下创建一个名为myid的文件，该文件包含整个Zookeeper集群唯一的ID（整数）。例如某Zookeeper集群包含三台服务器，hostname分别为zoo1、zoo2和zoo3，其myid分别为1、2和3，则在配置文件中其ID与hostname必须一一对应，如下所示。在该配置文件中，server.后面的数据即为myid 123server.1=zoo1:2888:3888server.2=zoo2:2888:3888server.3=zoo3:2888:3888 zxid(事务ID) 类似于RDBMS中的事务ID，用于标识一次更新操作的Proposal ID。为了保证顺序性，该zxid必须单调递增^2。因此Zookeeper使用一个64位的数来表示，高32位是Leader的epoch，从1开始，每次选出新的Leader，epoch加一。低32位为该epoch内的序号，每次epoch变化，都将低32位的序号重置。这样保证了zxid的全局递增性。 支持的领导选举算法 可通过electionAlg配置项设置Zookeeper用于领导选举的算法。 到3.4.10版本为止，可选项有 0：基于UDP的LeaderElection 1：基于UDP的FastLeaderElection 2：基于UDP和认证的FastLeaderElection 3：基于TCP的FastLeaderElection 在3.4.10版本中，默认值为3，也即基于TCP的FastLeaderElection。另外三种算法已经被弃用，并且有计划在之后的版本中将它们彻底删除而不再支持。 FastLeaderElection FastLeaderElection选举算法是标准的Fast Paxos算法实现，可解决LeaderElection选举算法收敛速度慢的问题。 服务器状态 LOOKING 不确定Leader状态。该状态下的服务器认为当前集群中没有Leader，会发起Leader选举 FOLLOWING 跟随者状态。表明当前服务器角色是Follower，并且它知道Leader是谁 LEADING 领导者状态。表明当前服务器角色是Leader，它会维护与Follower间的心跳 OBSERVING 观察者状态。表明当前服务器角色是Observer，与Follower唯一的不同在于不参与选举，也不参与集群写操作时的投票 选票数据结构 每个服务器在进行领导选举时，会发送如下关键信息 logicClock 每个服务器会维护一个自增的整数，名为logicClock，它表示这是该服务器发起的第多少轮投票 state 当前服务器的状态 self_id 当前服务器的myid self_zxid 当前服务器上所保存的数据的最大zxid vote_id 被推举的服务器的myid vote_zxid 被推举的服务器上所保存的数据的最大zxid 投票流程自增选举轮次 Zookeeper规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的logicClock进行自增操作。 初始化选票 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器2投票给服务器3，服务器3投票给服务器1，则服务器1的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。 发送初始化选票 每个服务器最开始都是通过广播把票投给自己。 接收外部投票 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。 判断选举轮次 收到外部投票后，首先会根据投票信息中所包含的logicClock来进行不同处理 外部投票的logicClock大于自己的logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的logicClock更新为收到的logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。 外部投票的logicClock小于自己的logicClock。当前服务器直接忽略该投票，继续处理下一个投票。 外部投票的logickClock与自己的相等。当时进行选票PK。 选票PK 选票PK是基于(self_id, self_zxid)与(vote_id, vote_zxid)的对比 外部投票的logicClock大于自己的logicClock，则将自己的logicClock及自己的选票的logicClock变更为收到的logicClock 若logicClock一致，则对比二者的vote_zxid，若外部投票的vote_zxid比较大，则将自己的票中的vote_zxid与vote_myid更新为收到的票中的vote_zxid与vote_myid并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖 若二者vote_zxid一致，则比较二者的vote_myid，若外部投票的vote_myid比较大，则将自己的票中的vote_myid更新为收到的票中的vote_myid并广播出去，另外将收到的票及自己更新后的票放入自己的票箱 统计选票 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。 更新服务器状态 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为LEADING，否则将自己的状态更新为FOLLOWING 几种领导选举场景集群启动领导选举初始投票给自己 集群刚启动时，所有服务器的logicClock都为1，zxid都为0。 各服务器初始化后，都投票给自己，并将自己的一票存入自己的票箱，如下图所示。 在上图中，(1, 1, 0)第一位数代表投出该选票的服务器的logicClock，第二位数代表被推荐的服务器的myid，第三位代表被推荐的服务器的最大的zxid。由于该步骤中所有选票都投给自己，所以第二位的myid即是自己的myid，第三位的zxid即是自己的zxid。 此时各自的票箱中只有自己投给自己的一票。 更新选票 服务器收到外部投票后，进行选票PK，相应更新自己的选票并广播出去，并将合适的选票存入自己的票箱，如下图所示。 服务器1收到服务器2的选票（1, 2, 0）和服务器3的选票（1, 3, 0）后，由于所有的logicClock都相等，所有的zxid都相等，因此根据myid判断应该将自己的选票按照服务器3的选票更新为（1, 3, 0），并将自己的票箱全部清空，再将服务器3的选票与自己的选票存入自己的票箱，接着将自己更新后的选票广播出去。此时服务器1票箱内的选票为(1, 3)，(3, 3)。 同理，服务器2收到服务器3的选票后也将自己的选票更新为（1, 3, 0）并存入票箱然后广播。此时服务器2票箱内的选票为(2, 3)，(3, 3)。 服务器3根据上述规则，无须更新选票，自身的票箱内选票仍为（3, 3）。 服务器1与服务器2更新后的选票广播出去后，由于三个服务器最新选票都相同，最后三者的票箱内都包含三张投给服务器3的选票。 根据选票确定角色 根据上述选票，三个服务器一致认为此时服务器3应该是Leader。因此服务器1和2都进入FOLLOWING状态，而服务器3进入LEADING状态。之后Leader发起并维护与Follower间的心跳。 Follower重启Follower重启投票给自己 Follower重启，或者发生网络分区后找不到Leader，会进入LOOKING状态并发起新的一轮投票。 发现已有Leader后成为Follower 服务器3收到服务器1的投票后，将自己的状态LEADING以及选票返回给服务器1。服务器2收到服务器1的投票后，将自己的状态FOLLOWING及选票返回给服务器1。此时服务器1知道服务器3是Leader，并且通过服务器2与服务器3的选票可以确定服务器3确实得到了超过半数的选票。因此服务器1进入FOLLOWING状态。 Leader重启Follower发起新投票 Leader（服务器3）宕机后，Follower（服务器1和2）发现Leader不工作了，因此进入LOOKING状态并发起新的一轮投票，并且都将票投给自己。 广播更新选票 服务器1和2根据外部投票确定是否要更新自身的选票。这里有两种情况 服务器1和2的zxid相同。例如在服务器3宕机前服务器1与2完全与之同步。此时选票的更新主要取决于myid的大小 服务器1和2的zxid不同。在旧Leader宕机之前，其所主导的写操作，只需过半服务器确认即可，而不需所有服务器确认。换句话说，服务器1和2可能一个与旧Leader同步（即zxid与之相同）另一个不同步（即zxid比之小）。此时选票的更新主要取决于谁的zxid较大 在上图中，服务器1的zxid为11，而服务器2的zxid为10，因此服务器2将自身选票更新为（3, 1, 11），如下图所示。 选出新Leader 经过上一步选票更新后，服务器1与服务器2均将选票投给服务器1，因此服务器2成为Follower，而服务器1成为新的Leader并维护与服务器2的心跳。 旧Leader恢复后发起选举 旧的Leader恢复后，进入LOOKING状态并发起新一轮领导选举，并将选票投给自己。此时服务器1会将自己的LEADING状态及选票（3, 1, 11）返回给服务器3，而服务器2将自己的FOLLOWING状态及选票（3, 1, 11）返回给服务器3。如下图所示。 旧Leader成为Follower 服务器3了解到Leader为服务器1，且根据选票了解到服务器1确实得到过半服务器的选票，因此自己进入FOLLOWING状态。 一致性保证 ZAB协议保证了在Leader选举的过程中，已经被Commit的数据不会丢失，未被Commit的数据对客户端不可见。 Commit过的数据不丢失Failover前状态 为更好演示Leader Failover过程，本例中共使用5个Zookeeper服务器。A作为Leader，共收到P1、P2、P3三条消息，并且Commit了1和2，且总体顺序为P1、P2、C1、P3、C2。根据顺序性原则，其它Follower收到的消息的顺序肯定与之相同。其中B与A完全同步，C收到P1、P2、C1，D收到P1、P2，E收到P1，如下图所示。 这里要注意 由于A没有C3，意味着收到P3的服务器的总个数不会超过一半，也即包含A在内最多只有两台服务器收到P3。在这里A和B收到P3，其它服务器均未收到P3 由于A已写入C1、C2，说明它已经Commit了P1、P2，因此整个集群有超过一半的服务器，即最少三个服务器收到P1、P2。在这里所有服务器都收到了P1，除E外其它服务器也都收到了P2 选出新Leader 旧Leader也即A宕机后，其它服务器根据上述FastLeaderElection算法选出B作为新的Leader。C、D和E成为Follower且以B为Leader后，会主动将自己最大的zxid发送给B，B会将Follower的zxid与自身zxid间的所有被Commit过的消息同步给Follower，如下图所示。 在上图中 P1和P2都被A Commit，因此B会通过同步保证P1、P2、C1与C2都存在于C、D和E中 P3由于未被A Commit，同时幸存的所有服务器中P3未存在于大多数据服务器中，因此它不会被同步到其它Follower 通知Follower可对外服务 同步完数据后，B会向D、C和E发送NEWLEADER命令并等待大多数服务器的ACK（下图中D和E已返回ACK，加上B自身，已经占集群的大多数），然后向所有服务器广播UPTODATE命令。收到该命令后的服务器即可对外提供服务。 未Commit过的消息对客户端不可见 在上例中，P3未被A Commit过，同时因为没有过半的服务器收到P3，因此B也未Commit P3（如果有过半服务器收到P3，即使A未Commit P3，B会主动Commit P3，即C3），所以它不会将P3广播出去。 具体做法是，B在成为Leader后，先判断自身未Commit的消息（本例中即P3）是否存在于大多数服务器中从而决定是否要将其Commit。然后B可得出自身所包含的被Commit过的消息中的最小zxid（记为min_zxid）与最大zxid（记为max_zxid）。C、D和E向B发送自身Commit过的最大消息zxid（记为max_zxid）以及未被Commit过的所有消息（记为zxid_set）。B根据这些信息作出如下操作 如果Follower的max_zxid与Leader的max_zxid相等，说明该Follower与Leader完全同步，无须同步任何数据 如果Follower的max_zxid在Leader的(min_zxid，max_zxid)范围内，Leader会通过TRUNC命令通知Follower将其zxid_set中大于Follower的max_zxid（如果有）的所有消息全部删除 上述操作保证了未被Commit过的消息不会被Commit从而对外不可见。 上述例子中Follower上并不存在未被Commit的消息。但可考虑这种情况，如果将上述例子中的服务器数量从五增加到七，服务器F包含P1、P2、C1、P3，服务器G包含P1、P2。此时服务器F、A和B都包含P3，但是因为票数未过半，因此B作为Leader不会Commit P3，而会通过TRUNC命令通知F删除P3。如下图所示。 总结 由于使用主从复制模式，所有的写操作都要由Leader主导完成，而读操作可通过任意节点完成，因此Zookeeper读性能远好于写性能，更适合读多写少的场景 虽然使用主从复制模式，同一时间只有一个Leader，但是Failover机制保证了集群不存在单点失败（SPOF）的问题 ZAB协议保证了Failover过程中的数据一致性 服务器收到数据后先写本地文件再进行处理，保证了数据的持久性 Zookeeper特点Zookeeper节点类型 如上文《Zookeeper架构及FastLeaderElection机制》所述，Zookeeper 提供了一个类似于 Linux 文件系统的树形结构。该树形结构中每个节点被称为 znode ，可按如下两个维度分类 Persist vs. Ephemeral (表示永久节点与临时节点) Persist节点，一旦被创建，便不会意外丢失，即使服务器全部重启也依然存在。每个 Persist 节点即可包含数据，也可包含子节点 Ephemeral节点，在创建它的客户端与服务器间的 Session 结束时自动被删除。服务器重启会导致 Session 结束，因此 Ephemeral 类型的 znode 此时也会自动删除 Sequence vs. Non-sequence （序列化与非序列化） Non-sequence节点，多个客户端同时创建同一 Non-sequence 节点时，只有一个可创建成功，其它匀失败。并且创建出的节点名称与创建时指定的节点名完全一样 Sequence节点，创建出的节点名在指定的名称之后带有10位10进制数的序号。多个客户端创建同一名称的节点时，都能创建成功，只是序号不同 Zookeeper语义保证 Zookeeper 简单高效，同时提供如下语义保证，从而使得我们可以利用这些特性提供复杂的服务。 顺序性 客户端发起的更新会按发送顺序被应用到 Zookeeper 上 原子性 更新操作要么成功要么失败，不会出现中间状态 单一系统镜像 一个客户端无论连接到哪一个服务器都能看到完全一样的系统镜像（即完全一样的树形结构）。注：根据上文《Zookeeper架构及FastLeaderElection机制》介绍的 ZAB 协议，写操作并不保证更新被所有的 Follower 立即确认，因此通过部分 Follower 读取数据并不能保证读到最新的数据，而部分 Follwer 及 Leader 可读到最新数据。如果一定要保证单一系统镜像，可在读操作前使用 sync 方法。 可靠性 一个更新操作一旦被接受即不会意外丢失，除非被其它更新操作覆盖 最终一致性 写操作最终（而非立即）会对客户端可见 Zookeeper Watch机制 所有对 Zookeeper 的读操作，都可附带一个 Watch 。一旦相应的数据有变化，该 Watch 即被触发。Watch 有如下特点 主动推送 Watch被触发时，由 Zookeeper 服务器主动将更新推送给客户端，而不需要客户端轮询。 一次性 数据变化时，Watch 只会被触发一次。如果客户端想得到后续更新的通知，必须要在 Watch 被触发后重新注册一个 Watch。 可见性 如果一个客户端在读请求中附带 Watch，Watch 被触发的同时再次读取数据，客户端在得到 Watch 消息之前肯定不可能看到更新后的数据。换句话说，更新通知先于更新结果。也就是先收到通知，才能看到结果。 顺序性 如果多个更新触发了多个 Watch ，那 Watch 被触发的顺序与更新顺序一致。 分布式锁与领导选举关键点最多一个获取锁 / 成为Leader 对于分布式锁（这里特指排它锁）而言，任意时刻，最多只有一个进程（对于单进程内的锁而言是单线程）可以获得锁。 对于领导选举而言，任意时间，最多只有一个成功当选为Leader。否则即出现脑裂（Split brain） 锁重入 / 确认自己是Leader 对于分布式锁，需要保证获得锁的进程在释放锁之前可再次获得锁，即锁的可重入性。 对于领导选举，Leader需要能够确认自己已经获得领导权，即确认自己是Leader。 释放锁 / 放弃领导权 锁的获得者应该能够正确释放已经获得的锁，并且当获得锁的进程宕机时，锁应该自动释放，从而使得其它竞争方可以获得该锁，从而避免出现死锁的状态。 领导应该可以主动放弃领导权，并且当领导所在进程宕机时，领导权应该自动释放，从而使得其它参与者可重新竞争领导而避免进入无主状态。 感知锁释放 / 领导权的放弃 当获得锁的一方释放锁时，其它对于锁的竞争方需要能够感知到锁的释放，并再次尝试获取锁。 原来的Leader放弃领导权时，其它参与方应该能够感知该事件，并重新发起选举流程。 非公平领导选举 从上面几个方面可见，分布式锁与领导选举的技术要点非常相似，实际上其实现机制也相近。本章就以领导选举为例来说明二者的实现原理，分布式锁的实现原理也几乎一致。 选主过程 假设有三个Zookeeper的客户端，如下图所示，同时竞争Leader。这三个客户端同时向Zookeeper集群注册Ephemeral且Non-sequence类型的节点，路径都为/zkroot/leader（工程实践中，路径名可自定义）。 如上图所示，由于是Non-sequence节点，这三个客户端只会有一个创建成功，其它节点均创建失败。此时，创建成功的客户端（即上图中的Client 1）即成功竞选为 Leader 。其它客户端（即上图中的Client 2和Client 3）此时匀为 Follower。 放弃领导权 如果 Leader 打算主动放弃领导权，直接删除/zkroot/leader节点即可。 如果 Leader 进程意外宕机，其与 Zookeeper 间的 Session 也结束，该节点由于是Ephemeral类型的节点，因此也会自动被删除。 此时/zkroot/leader节点不复存在，对于其它参与竞选的客户端而言，之前的 Leader 已经放弃了领导权。 感知领导权的放弃 由上图可见，创建节点失败的节点，除了成为 Follower 以外，还会向/zkroot/leader注册一个 Watch ，一旦 Leader 放弃领导权，也即该节点被删除，所有的 Follower 会收到通知。 重新选举 感知到旧 Leader 放弃领导权后，所有的 Follower 可以再次发起新一轮的领导选举，如下图所示。 从上图中可见 新一轮的领导选举方法与最初的领导选举方法完全一样，都是发起节点创建请求，创建成功即为 Leader，否则为 Follower ，且 Follower 会 Watch 该节点 新一轮的选举结果，无法预测，与它们在第一轮选举中的顺序无关。这也是该方案被称为非公平模式的原因 非公平模式总结 非公平模式实现简单，每一轮选举方法都完全一样 竞争参与方不多的情况下，效率高。每个 Follower 通过 Watch 感知到节点被删除的时间不完全一样，只要有一个 Follower 得到通知即发起竞选，即可保证当时有新的 Leader 被选出 给Zookeeper 集群造成的负载大，因此扩展性差。如果有上万个客户端都参与竞选，意味着同时会有上万个写请求发送给 Zookeper。如《Zookeeper架构》一文所述，Zookeeper 存在单点写的问题，写性能不高。同时一旦 Leader 放弃领导权，Zookeeper 需要同时通知上万个 Follower，负载较大。 公平领导选举选主过程 如下图所示，公平领导选举中，各客户端均创建/zkroot/leader节点，且其类型为Ephemeral与Sequence。 由于是Sequence类型节点，故上图中三个客户端均创建成功，只是序号不一样。此时，每个客户端都会判断自己创建成功的节点的序号是不是当前最小的。如果是，则该客户端为 Leader，否则即为 Follower。 在上图中，Client 1创建的节点序号为 1 ，Client 2创建的节点序号为 2，Client 3创建的节点序号为3。由于最小序号为 1 ，且该节点由Client 1创建，故Client 1为 Leader 。 放弃领导权 Leader 如果主动放弃领导权，直接删除其创建的节点即可。 如果 Leader 所在进程意外宕机，其与 Zookeeper 间的 Session 结束，由于其创建的节点为Ephemeral类型，故该节点自动被删除。 感知领导权的放弃 与非公平模式不同，每个 Follower 并非都 Watch 由 Leader 创建出来的节点，而是 Watch 序号刚好比自己序号小的节点。 在上图中，总共有 1、2、3 共三个节点，因此Client 2 Watch /zkroot/leader1，Client 3 Watch /zkroot/leader2。（注：序号应该是10位数字，而非一位数字，这里为了方便，以一位数字代替） 一旦 Leader 宕机，/zkroot/leader1被删除，Client 2可得到通知。此时Client 3由于 Watch 的是/zkroot/leader2，故不会得到通知。 重新选举 Client 2得到/zkroot/leader1被删除的通知后，不会立即成为新的 Leader 。而是先判断自己的序号 2 是不是当前最小的序号。在该场景下，其序号确为最小。因此Client 2成为新的 Leader 。 这里要注意，如果在Client 1放弃领导权之前，Client 2就宕机了，Client 3会收到通知。此时Client 3不会立即成为Leader，而是要先判断自己的序号 3 是否为当前最小序号。很显然，由于Client 1创建的/zkroot/leader1还在，因此Client 3不会成为新的 Leader ，并向Client 2序号 2 前面的序号，也即 1 创建 Watch。该过程如下图所示。 公平模式总结 实现相对复杂 扩展性好，每个客户端都只 Watch 一个节点且每次节点被删除只须通知一个客户端 旧 Leader 放弃领导权时，其它客户端根据竞选的先后顺序（也即节点序号）成为新 Leader，这也是公平模式的由来 延迟相对非公平模式要高，因为它必须等待特定节点得到通知才能选出新的 Leader 总结 基于 Zookeeper 的领导选举或者分布式锁的实现均基于 Zookeeper 节点的特性及通知机制。充分利用这些特性，还可以开发出适用于其它场景的分布式应用。 集群角色 Leader：选举产生，读/写； Follower：参与选举，可被选举，读服务； Observer：参与选举，不可被选举，提供读服务；一般不需要Observer 会话 ZK中，客户端要長期與服务端保持連接，使用TCP长连接；分佈式系統利用zk來進行協調，這個分佈式系統也可能是一個集群，如果想知道分佈式系統中其他節點的狀態，可以到zk上請求相應的信息。zk中的數據管理模型是倒置的樹狀結構。是在zk的內存中存放的樹狀文件系統，一個分佈式系統可以註冊使用一個樹狀文件系統的子節點。 数据节点(ZNode) 即zk数据模型中的数据单元；zk的数据都存储于内存中，数据模型为树状结构(ZNode Tree)；每个ZNode都会保存自己的数据于内存中；znode有兩類： 持久节点：仅显式删除才消失 临时节点：会话中止即自动消失 版本（version）：ZK会为每个ZNode维护一个称之为Stat的数据结构，记录了当前ZNode的三个数据版本 version：当前版本 cversion：当前znode的子节点的版本 aversion：当前znode的ACL的版本 ACL：ZK使用ACL机制进行权限控制 CREATE， READ，WRITE，DELETE，ADMIN 事件监听器(Watcher) ZK上，由用户指定的触发机制，在某些事件产生时，ZK能够将通知發给相关的客户端； ZAB协议 Zookeeper Atomic Broadcast，ZK原子广播协议；用來支持崩潰恢復機制，保證在leader進程崩潰時重新選舉出新的leader，并且保證數據完整性，這指的是zk自己的leader分区，也包含基於zk所註冊的leader分區，如果不強調，就專指zk自己的。 根据ZAB协议，所有的写操作都必须通过Leader完成，Leader写入本地日志后再复制到所有的Follower节点。 一旦Leader节点无法工作，ZAB协议能够自动从Follower节点中重新选出一个合适的替代者，即新的Leader，该过程即为领导选举。该领导选举过程，是ZAB协议中最为重要和复杂的过程。 zk中所有事務請求都是由leader來處理的。當一個節點要寫某一數據時，寫操作是發給zk的leader的，leader要把這個寫請求轉為一個提案，向當前的zk集群中進行廣播，意思是我現在要改一個數據，大家是否同意，如果有一個follower同意，這就超過半數了(集群中有三個節點)，如果過半數，數據便會被寫進內存了，並更新到元數據，并且結果會通知到沒來參加選舉的節點。所有事務都要由leader來接收和處理，所以客戶端無論連接哪個zk節點上，如果它不是一個leader的話，它應該把信息轉給leader，leader會把每個客戶端的請求轉為一個提案，向當前的集群中進行廣播，在收到過半數的Follower同意之後，將會確認此操作並將結果廣播給其他的Follower而後完成提交 ZAB协议中存在三种状态 Looking, 每個zk節點剛啟動時，它應該先去找leader，所謂找組織，或選舉leader的狀態 Following，Follower所處的狀態就是Following狀態，表示已經有leader了 Leading，Leader所處的狀態就是Leading狀態 zk啟動時，所有節點都處於Looking狀態，這時集群會嘗試選舉出一個Leader，被選舉出的Leader將狀態切換為Leading，其他的切換為Following狀態，當節點其他主機發現已經選舉出了Leader，如後來加入的主機，將自動從Looking轉為Following狀態，嘗試與Leader保持同步數據，當Follower與Leader節點失去聯繫時，Follower會再切換到Looking狀態並開啟新一輪選舉。zk集群中的主機會在這三個狀態之間轉換。選舉出Leader節點後，ZAB協議將進入原子廣播階段，這時Leader會與自己同步的每一個Follower節點創建一個操作序列，因為Follower與Leader的數據不一樣，所以Leader要將自己所有的數據打包，同步給每一個Follower節點。Leader與Follower節點還必須使用心跳檢測機制，去檢測每一個Follower是否處於正常狀態。這種檢測機制就相當於Follower在不斷地在集群中的某個數據節點更新自己的數據版本或時間戳，如果更新了，那麼Leader就認為Follower是正常的，否則一旦在一個超出指令時間的範圍當中，一個Follower沒有更新自己的心跳信息，這個Follower就被認為失去了連接狀態，如果是Leader失去連接，那麼所有節點就轉為Looking狀態，再進行選舉。 四个阶段 选举:election 发现：discovery 同步：sync 广播：Broadcast FAQ 启动zookeeper后，会在/root目录下生成一个zookeeper.out文件，这个文件会非常大，需要使用echo &quot;&quot; &gt; zookeeper.out命令清空此文件，如果删除此文件，磁盘空间不会立即释放，还需要重启zookeeper服务。 [^註釋]: 在传统的文件传输里面（read/write方式），在实现上其实是比较复杂的，需要经过多次上下文的切换，当需要对一个文件进行传输的时候，其具体流程细节如下：调用read函数，文件数据被copy到内核缓冲区read函数返回，文件数据从内核缓冲区copy到用户缓冲区write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。数据从socket缓冲区copy到相关协议引擎。以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次copy操作：硬盘—&gt;内核buf—&gt;用户buf—&gt;socket相关缓冲区—&gt;协议引擎。而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。Sendfile系统调用是在2.1版本内核时引进的：sendfile(socket, file, len)运行流程如下：sendfile系统调用，文件数据被copy至内核缓冲区再从内核缓冲区copy至内核中socket相关的缓冲区，最后再從socket相关的缓冲区copy到协议引擎。相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，sendfile实现了更简单的方式，系统调用方式仍然一样，细节与2.1版本的不同之处在于，当文件数据被复制到内核缓冲区时，不再将所有数据copy到socket相关的缓冲区，而是仅仅将记录数据位置和长度相关的数据保存到socket相关的缓存，而实际数据将由DMA模块直接发送到协议引擎，再次减少了一次copy操作。 [^1]: 分布式锁，是单机锁的一种扩展，主要是为了锁住分布式系统中不同机器代码的物理块或逻辑块。以此保证不同机器之间的逻辑一致性。1. 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。2. 这把锁要是一把可重入锁（避免死锁）. 3. 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）4. 有高可用的获取锁和释放锁功能. 5. 获取锁和释放锁的性能要好]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>zookeeper概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat部署]]></title>
    <url>%2F2019%2F01%2F17%2Ftomcat%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[概念 tomcat最外层为Server，表示一个实例；一个Server内部可以容纳多个Service，Service的目地主要是把Connetor和engine建立关联关系，一个engine可以有多个Connetor，但一个Connetor只能属于一个engine，Connector是对服务地址和端口的定义，还可以定义最大并发连接数等功能。engine是真正的窗口类组件，就是能够存放webapp并可以解析以后响应给用户的组件，这些组件有engine、host、context。它们被定义在server.xml这个主配置文件中。一般不用tomcat面向客户请求，而是用反代。可以用nginx、 httpd反代。用nt或at表示。在后端也不会只用tomcat，还会在tomcat前加一个nginx或httpd处理静态服务，另外，这个前端的nginx服务器还会将动态内容反代到其后面的tomcat处理。也就是nnt或nat。因为给动态服务器处理的内容中有一些如js、css等格式的内容 对tomcat来讲，一个主机上的实例叫一个server，或说每个tomcat进程叫一个server，一台主机上可以有多个server。一般一个主机上只运行一个server。tomcat运行在java的虚拟机（JVM）上，java虚拟机有一个特点，就是单进程使用内存不能超过32G。server可以监听在某个套接字上，用来管理。像vanish监听在6082上进行管理一样，但tomcat的管理默认没有认证功能，所有只能监听在127.0.0.1上，甚至最好不要监听。server只代表是一个进程而已，与web无关。为了表示tomcat自己的组件，需要运行一个叫容器的组件，就是在server中的engine，它是用来让用户能够存储java代码，也就是jsp代码，并把代码加载后运行生成结果的组件。它像是一个JVM的实例，就是一个java虚拟机进程。server只是一个环境，engine才是运行代码的引擎或叫jsp容器。用户请求的动态资源都应该由引擎来运行，请求到达主机后要能交给引擎组件才行。引擎要能通过套接字与其他主机联系，但引擎不能监听端口，所以在server中还要有一个到多个连接器connector。一个server内部可以存在多个引擎，连接器与引擎之间只能一一对应，请求到连接器后，这个请求属于哪个引擎，请求就会被路由到哪个引擎。但连接器是不能直接与引擎建立连接关系的。在server内部还有service，service可以有多个，它的作用主要在于把一个或多个连接器与特定的引擎关联起来。实际是在一个service中可以有一个引擎和多个连接器。一个连接器只能属于一个service，因此，属于service的连接器，也就属于了service中的引擎。一个引擎内可以有多个虚拟主机（Host），一般tomcat只使用基于主机名的虚拟主机。每一个应用叫一个context，context可以出现多个。valve用来过滤日志、用户请求等。（布署进，除了布署应用本身，还要布署应用依赖的环境被满足）。后端的tomcat只处理动态内容，静态内容由nginx处理，所以请求的如果是静态内容，就由nginx处理，如果是动态内容，就由nginx反代到tomcat上，处理后返回给nginx。这是一个nt的组合 网站的基本组织框架：第一层接入层、第二层缓存层、第三层应用程序服务器层、第四层存储层 测试安装与配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@test ~]# yum install -y java-1.8.0-openjdk-devel# 安装openjdk[root@test ~]# java -version# 查看版本，参数是一个横杠[root@test ~]# vim /etc/profile.d/java.shexport JAVA_HOME=/usr[root@test ~]# . /etc/profile.d/[root@test ~]# echo $JAVA_HOME /usr# java程序会依赖这个变量找java的安装环境[root@test ~]# yum install -y tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp# tomcat-jsp-2.2-api和tomcat-servlet-3.0-api是类库。tomcat-webapps提供的是测试页；admin-webapps提供的是Manager App和Host Manager，访问是要认证的；tomcat-docs-webapp提供的是页面中的Documentation[root@test ~]# systemctl start tomcat[root@test ~]# ss -tln# tomcat默认监听在8080上访问http://192.168.1.14:8080/[root@test ~]# cd /etc/tomcat/[root@test tomcat]# cp server.xml&#123;,.bak&#125;# rpm包主配置文件在/etc/tomcat/server.xml，如果是解压安装的tomcat，主配置文件在/usr/local/tomcat/conf下[root@test tomcat]# vim server.xml&lt;Server port="8005" shutdown="SHUTDOWN"&gt;# Server是tomcat的管理端，这表示server监听在哪个端口，并接受SHUTDOWN命令，可以关闭。这个功能是不安全的，将port改为-1或在shutdown后添加一个随机字符串就可使关闭功能失效 &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt;# Listener表示侦听器，作用是查看对应的某个类是否被加载，如果加载了就启用起来，以便侦听某些类的资源 &lt;GlobalNamingResources&gt; # 这是定义全局命名资源的，对主机和用户的名称解析 &lt;Service name="Catalina"&gt; # Service只有一个名称叫Catalina，Service把连接器和engine关联起来的 &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;# Connector对服务端口进行定义。指明连接器的端口和协议，连接超时时间，最后是一旦超时，重定向到哪个端口。这些定义的都是类的属性 &lt;Engine name="Catalina" defaultHost="localhost"&gt;# 同一个Service中的Connector都属于同一个Engine，定义名称为Catalina，defaultHost表示当用户访问的主机与tomcat中的主机没有一个匹配时，就用这个默认的主机来响应 &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt;# 用Host定义虚拟主机，appBase表示网页根文档在哪，rpm包安装的tomcat的网页根目录在/var/lib/tomcat/webapps的ROOT下，unpackWARs自动展开，autoDeploy自动布署[root@test tomcat]# yum install -y nc[root@test tomcat]# nc -nv 127.0.0.1 8005Ncat: Version 7.50 ( https://nmap.org/ncat )Ncat: Connected to 127.0.0.1:8005.SHUTDOWN# 连接管理端口，输入SHUTDOWN命令后就可以关闭tomcat了[root@test tomcat]# ss -tln# 端口关闭了[root@test tomcat]# mkdir -pv test/&#123;WEB-INF,META-INF,lib,classes&#125;[root@test tomcat]# vim test/index.jsp&lt;%@ page language="java" %&gt; # 定义当前网站使用的默认语言是java&lt;%@ page import="java.util.*" %&gt; # 导入java.util下面的所有类 &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello world"); # out.println是java的输出命令 %&gt; &lt;/body&gt; &lt;/html&gt;[root@test tomcat]# cp -a test/ /var/lib/tomcat/webapps/# 将网页目录放到根下，因为文件少，所以没有打包网页目录。因为配置文件中定义了自动布署，所以可以自动导入java.util下面的所有类。如果是war文件，也会自动展开的。因为配置文件中定义了自动展开[root@test tomcat]# systemctl start tomcat访问http://192.168.1.14:8080/test/index.jsp[root@test tomcat]# ls /var/cache/tomcat/workCatalina# 编译后的页面在/var/cache/tomcat/work中叫Catalina 调整tomcat使用jvm内存123456789101112131415161718* 源码安装[root@jenkins local]# vim /usr/local/tomcat/bin/catalina.sh JAVA_OPTS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"# 调整tomcat使用jvm内存[root@jenkins tomcat]# /usr/local/tomcat/bin/startup.sh[root@jenkins tomcat]# tail -f /usr/local/tomcat/logs/catalina.out# 查看启动过程[root@jenkins local]# ps aux|grep tomcatroot 3101 33.7 38.4 3704844 717556 pts/0 Sl 13:02 0:17 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start* rpm包安装[root@jenkins ~]# vim /etc/sysconfig/jenkinsJENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"# 调整jenkins的使用内存，默认此项是-Djava.awt.headless=true# -Xms：初始堆内存Heap大小，使用的最小内存，cpu性能高时此值应设的大一些# -Xmx：初始堆内存heap最大值，使用的最大内存# -XX:MaxPermSize:设定最大内存的永久保存区域# -Xms与-Xmx设置相同的值，需要根据实际情况设置，增大内存可以提高读写性能 页面中的manager12345678[root@test tomcat]# vim /etc/tomcat/tomcat-users.xml.&lt;role rolename="manager-gui"/&gt; # 打开manager-gui功能&lt;user name="tomcat" password="tomcat" roles="manager-gui" /&gt;# 自定义用户名和密码，这里要设置password和roles，roles后的内容要与上面的role中定义的一样[root@test tomcat]# systemctl restart tomcat# 修改后必须重启，因为启动时此文件已装载进内存访问http://192.168.1.14:8080中的Manager App，使用上面的用户名和密码，在这里可以管理站点，在这里也可以热布署 测试热部署12[root@test tomcat]# cp -a test/ /var/lib/tomcat/webapps/test2# 在管理页中的Deploy中的Context Path (required)中输入/test2（视频中去掉了斜线），点Deploy，有错误提示，但也可以在上面的页面管理中看到test2了。在下面还有WAR file to deploy，是热布署war文件的，也是选择好文件，并点击Deploy即可。实际测试中在复制test文件后，在管理页面中就已经可以看到test2的内容了 管理虚拟主机1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@test tomcat]# vim /etc/tomcat/tomcat-users.xml&lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-gui"/&gt;&lt;user name="tomcat" password="tomcat" roles="manager-gui,admin-gui" /&gt;# 页面中的Host Manager是管理虚拟主机的，用户所属的角色是admin-gui，加入即可。[root@test tomcat]# systemctl restart tomcat[root@test tomcat]# mkdir -pv /appdata/ilinux/ROOT[root@test tomcat]# cp -r test/* /appdata/ilinux/ROOT/[root@test tomcat]# vim /appdata/ilinux/ROOT/index.jsp&lt;%@ page language="java" %&gt;&lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;ilinux page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello ilinux"); %&gt; &lt;/body&gt; &lt;/html&gt;访问http://192.168.1.14:8080，进入Host Manager中可以创建删除虚拟主机，定义虚拟主机时要指明Name站点名称，这里用了www.ilinux.io，Aliases站点别名，这里用ilinux.io，App base站点路径，这里用/appdata/ilinux/，下面选项是，AutoDeploy：是否自动布署；DeployOnStartup：是否启动时自动布署；DeployXML：是否基于xml文件来布署；UnpackWARs：是否自动展开WAR文件；Manager App：是否用Manager App来管理，最后添加就行了** 让自己的主机可以解析www.ilinux.io，配置hosts文件访问 www.ilinux.io:8080，不用在访问时写ROOT，tomcat可以自动识别，根文件就在ROOT中。但这种方式是定义在内存中的，如果重启tomcat后，就不存在了。如果要长期有效，还要定义在server.xml中。访问显示hello ilinux[root@test tomcat]# vim server.xml&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" maxThreads="1000" acceptCount="200" /&gt;# 加入，最大并发连接数是1000，等待队列是200。端口如果改为80是启动不了的，因为是普通用户&lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Host name="www.ilinux.io" appBase="/appdata/ilinux" unpackWARs="true" autoDeploy="true"/&gt;# 这里只要将Host写在已有的&lt;Engine&gt;中即可，用&lt;Host&gt;&lt;/Host&gt;或&lt;.../&gt;的方式都可以[root@test tomcat]# systemctl restart tomcat访问www.ilinux.io:8080，访问显示hello ilinux上传shopxx-a5-Beta.zip到tomcat主机[root@test ~]# unzip shopxx-a5-Beta.zip[root@test ~]# cp -a /root/shopxx-v3.0-Beta/shopxx-3.0Beta/ /appdata/ilinux/# 放在/appdata/ilinux目录中，是因为上面在server.xml中的Host中定义了www.ilinux.io的网页目录路径[root@test ~]# ln -sv /appdata/ilinux/shopxx-3.0Beta/ /appdata/ilinux/shopxx访问www.ilinux.io:8080/shopxx，这里可以看到安装界面[root@test ~]# rm -f /appdata/ilinux/shopxx[root@test ~]# mkdir /e-shop[root@test ~]# cp -a /root/shopxx-v3.0-Beta/shopxx-3.0Beta/ /e-shop/[root@test ~]# cd /e-shop/[root@test e-shop]# ln -sv shopxx-3.0Beta/ shopxx[root@test e-shop]# vim /etc/tomcat/server.xml&lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Host name="www.ilinux.io" appBase="/appdata/ilinux" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/eshop" docBase="/e-shop/shopxx/" reloadable="true"/&gt; &lt;/Host&gt;# 这里一定要注意，Context一定要定义在某个Host中，不然是无法访问的。Context类似alias，就是将设置的URL指向设置的路径，这里用path设置URL，docBase设置真正的路径，reloadable表示是否自动装载。这时访问eshop时就会到/e-shop/shopxx找文件了[root@test e-shop]# systemctl restart tomcat访问www.ilinux.io:8080/eshop，这时也可以看到安装界面 添加日志功能123456789101112[root@test tomcat]# vim server.xml&lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Host name="www.ilinux.io" appBase="/appdata/ilinux" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/eshop" docBase="/e-shop/shopxx/" reloadable="true"/&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="ilinux_access_log." suffix=".log" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b"/&gt; &lt;/Host&gt; [root@test tomcat]# systemctl restart tomcat访问www.ilinux.io:8080/eshop[root@test ~]# tail -f /var/log/tomcat/ilinux_access_log.2019-01-17.log nginx反向代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566准备两台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。另一台是内网主机，地址：172.16.106.133。同步两台服务器的时间* tomcat[root@test ~]# yum install -y java-1.8.0-openjdk-devel tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp[root@test tomcat]# vim tomcat-users.xml&lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;user name="tomcat" password="tomcat" roles="admin-gui,manager-gui" /&gt;[root@test ~]# systemctl start tomcat[root@test ~]# ss -tln访问http://172.16.106.133:8080/，测试tomcat是否正常* 反代服务器[root@test ~]# yum install -y nginx[root@test ~]# cd /etc/nginx/[root@test nginx]# vim conf.d/ilinux.confserver &#123; listen 80; server_name www.ilinux.io; location / &#123; proxy_pass http://172.16.106.133:8080; &#125;&#125;[root@test nginx]# nginx -t[root@test nginx]# systemctl start nginx设置本机hosts文件，可以解析www.ilinux.io;访问www.ilinux.io。这时如果不关闭firewall是不能访问的，如果关闭了firewall而未关闭selinux会提示502无法访问* tomcat[root@test ~]# mkdir -pv /var/lib/tomcat/webapps/test/&#123;WEB-INF,META-INF,classes,lib&#125;[root@test ~]# vim /var/lib/tomcat/webapps/test/index.jsp&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("magedu.com","magedu.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;访问www.ilinux.io/test/，www.ilinux.io/manager* 反代服务器[root@test ~]# tail -f /var/log/nginx/access.log[root@test nginx]# vim conf.d/ilinux.conf server &#123; listen 80; server_name www.ilinux.io; location / &#123; proxy_pass http://172.16.106.132:8080; &#125; location ~*\.(jsp|do)$ &#123; proxy_pass http://172.16.106.133:8080; &#125;&#125;# 这样设置就可以实现动静分离访问http://www.ilinux.io/test/index.jsp，如果不写后面的index.jsp会打不开页面 http反向代理123456789101112131415161718192021222324252627282930准备两台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。另一台是内网主机，地址：172.16.106.133。同步两台服务器的时间* 反代服务器[root@test ~]# yum install -y httpd[root@test ~]# cd /etc/httpd/[root@test httpd]# vim conf.d/ilinux-http-tomcat.conf&lt;VirtualHost *:80&gt; ServerName www.ilinux.io proxyRequests off # 关闭正向代理 ProxyPreserveHost on # 将主机头传到后端 ProxyVia on # 是否在响应报文中加上via首部 &lt;Proxy *&gt; # Proxy功能可以被谁使用 Require all granted &lt;/Proxy&gt; ProxyPass / http://172.16.106.133:8080/ # 将自己的哪个URL代理到后端的哪个URL，最后的/线不能少 ProxyPassReverse / http://172.16.106.133:8080/ # 这条不写也可以 &lt;Location /&gt; # 哪个URL可以被谁访问 Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@test httpd]# httpd -M# 看一下是否有proxy_module和proxy_http_module两个模块[root@test httpd]# httpd -t# 检查语法[root@test httpd]# systemctl start httpd[root@test httpd]# ss -tln访问 www.ilinux.io[root@test httpd]# tail -f /var/log/httpd/access_log# 可以使用之前的nginx反代到后端的httpd上，httpd再反代到本机的tomcat上。实现nat架构 ajp反向代理123456789101112131415161718192021222324准备两台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。另一台是内网主机，地址：172.16.106.133。同步两台服务器的时间* 反代服务器[root@test httpd]# cp /etc/httpd/conf.d/ilinux-http-tomcat.conf /etc/httpd/conf.d/iunix-ajp-tomcat.conf[root@test httpd]# vim conf.d/iunix-ajp-tomcat.conf&lt;VirtualHost *:80&gt; ServerName www.iunix.io proxyRequests off ProxyPreserveHost on ProxyVia on &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / ajp://172.16.106.133:8009/ # 改协议为ajp，端口为8009 ProxyPassReverse / ajp://172.16.106.133:8009/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@test httpd]# httpd -M# 注意proxy_ajp_module模块要加载[root@test httpd]# systemctl restart httpd访问www.iunix.io# ajp的好处是用浏览器是不能访问的，只要注释掉8080端口（因为ajp联系的是8009端口），更安全。显示的结果与http的结果是一样的，也是tomcat主页 httpd负载均衡1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374准备三台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。tomcat1是内网主机，地址：172.16.106.133。tomcat2地址：172.16.106.134。同步两台服务器的时间* 反代服务器[root@test httpd]# httpd -M# 要加载proxy_balancer_module模块[root@test httpd]# vim conf.d/ilinux-http-tomcat.conf&lt;Proxy balancer://tcsrvs&gt;# 定义组，balancer://是调用这个模块，不能变。tcsrvs是自定义的名字 BalancerMember http://172.16.106.133:8080 BalancerMember http://172.16.106.134:8080# 调度的成员 ProxySet lbmethod=byrequests# 定义算法，这是加权轮询的。byrequests：默认。基于请求数量计算权重。bytraffic：基于I/O流量大小计算权重。bybusyness：基于挂起的请求(排队暂未处理)数量计算权重。&lt;/Proxy&gt;&lt;VirtualHost *:80&gt; ServerName www.ilinux.io proxyRequests off ProxyPreserveHost on ProxyVia on &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@test httpd]# systemctl restart httpd[root@test httpd]# ss -tln* tomcat1[root@test ~]# scp -r /usr/share/tomcat/webapps/test/ 172.16.106.134:/root* tomcat2[root@test ~]# yum install -y java-1.8.0-openjdk-devel tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp[root@test ~]# vim /etc/profile.d/java.shexport JAVA_HOME=/usr[root@test ~]# cp -r test/ /usr/share/tomcat/webapps/[root@test ~]# vim /var/lib/tomcat/webapps/test/index.jsp &lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="blue"&gt;TomcatB.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("magedu.com","magedu.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@test ~]# vim /etc/tomcat/tomcat-users.xml&lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;user name="tomcat" password="tomcat" roles="admin-gui,manager-gui" /&gt;[root@test ~]# systemctl start tomcat[root@test ~]# ss -tln* 反代服务器[root@test httpd]# vim /etc/hosts192.168.1.14 www.ilinux.io www.iunix.io[root@test httpd]# for i in &#123;1..10&#125;;do curl -s http://www.ilinux.io/test/ | grep -i 'tomcat';done# 这时应该返回两台服务器的结果 &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;h1&gt;&lt;font color="blue"&gt;TomcatB.magedu.com&lt;/font&gt;&lt;/h1&gt; ajp负载均衡1234567891011121314151617181920212223242526272829准备三台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。tomcat1是内网主机，地址：172.16.106.133。tomcat2地址：172.16.106.134。同步两台服务器的时间* 反代服务器[root@test httpd]# vim conf.d/iunix-ajp-tomcat.conf &lt;Proxy balancer://tomcatsrvs&gt; BalancerMember ajp://172.16.106.133:8009 BalancerMember ajp://172.16.106.134:8009 ProxySet lbmethod=byrequests&lt;/Proxy&gt;&lt;VirtualHost *:80&gt; ServerName www.iunix.io proxyRequests off ProxyPreserveHost on ProxyVia on &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tomcatsrvs/ ProxyPassReverse / balancer://tomcatsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@test httpd]# systemctl restart httpd[root@test httpd]# for i in &#123;1..10&#125;;do curl -s http://www.iunix.io/test/ | grep -i 'tomcat';done &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;h1&gt;&lt;font color="blue"&gt;TomcatB.magedu.com&lt;/font&gt;&lt;/h1&gt; 会话粘性/内建管理页123456789101112131415161718192021222324252627282930[root@test httpd]# vim conf.d/ilinux-http-tomcat.confHeader add Set-Cookie "ROUTEID=%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGED&lt;Proxy balancer://tcsrvs&gt; BalancerMember http://172.16.106.133:8080 route=TomcatA BalancerMember http://172.16.106.134:8080 route=TomcatB ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID&lt;/Proxy&gt;&lt;VirtualHost *:80&gt; ServerName www.ilinux.io proxyRequests off ProxyPreserveHost on ProxyVia on &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location /bstatus&gt; SetHandler balancer-manager ProxyPass ! Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@test httpd]# httpd -t[root@test httpd]# systemctl restart httpd访问http://www.ilinux.io/bstatus可以看到管理页面，访问http://www.ilinux.io/test/按F12查看，可以看到cookie一项中有ROUTEID=TomcatA或B，表示cookie会话绑定 session会话绑定，用session cluster的方法实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677准备三台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。tomcat1是内网主机，地址：172.16.106.133。tomcat2地址：172.16.106.134。同步两台服务器的时间* 反代服务器[root@test ~]# vim /etc/nginx/nginx.confhttp &#123; upstream tcsrvs &#123; server 172.16.106.133:8080; server 172.16.106.134:8080; &#125;# 加入upstream段[root@test ~]# vim /etc/nginx/conf.d/ilinux.confserver &#123; listen 80; server_name www.ilinux.io; location / &#123; proxy_pass http://tcsrvs; &#125;&#125;# 这里没有在两台tomcat主机上再安装nginx进行静态处理及动态内容反代[root@test ~]# systemctl start nginx[root@test ~]# ss -tln访问www.ilinux.io/test，这时是轮询的，这时的session ID是会改变的，只要刷新。因为被识别为新用户了。这个测试就是要让sessionID不变。# 查看官方文档第十八章，Clustering/Session Replication HOW-TO。这个组件就叫Cluster，只能放在Engine或Host内部。因为每个集群节点都要配置，所以时间都要同步。之后会通过多播地址228.0.0.4进行通信，多播端口是45564。只要监听这个地址和端口就可以成为成员。接收多播信息要监听在4000-4100之间。* tomcat1&amp;tomcat2[root@test ~]# vim /etc/tomcat/server.xml&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt;# 定义使用哪一个会话管理器，一共有五种；expireSessionsOnShutdown表示关机后会话是否过期，这里是不允许； &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt;# Channel是用来定义信道的 &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" # 多播地址最好改一下 port="45564" frequency="500" # 健康检测500毫秒 dropTime="3000"/&gt; # 3000毫秒没有响应就将节点去除 &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="172.16.106.133" # 改为自己的地址。如果是auto与hosts文件有关，它会做主机名反解 port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;# 在想使用集群的Host中添加上面的内容[root@test ~]# cp web.xml /var/lib/tomcat/webapps/test/WEB-INF/# 给test提供一个web.xml文件[root@test ~]# vim /var/lib/tomcat/webapps/test/WEB-INF/web.xml &lt;distributable/&gt;# 在web-app段内任一位置添加&lt;distributable/&gt;才能实现上面的集群功能。当然，还要是在想实现集群功能的页面中的web.xml文件中添加，这里就是在test的web.xml文件中添加的[root@test ~]# scp /etc/tomcat/server.xml 172.16.106.133:/etc/tomcat[root@test ~]# scp /var/lib/tomcat/webapps/test/WEB-INF/web.xml root@172.16.106.133:/var/lib/tomcat/webapps/test/WEB-INF[root@test test]# systemctl stop tomcat[root@test test]# systemctl start tomcat[root@test ~]# tail -f /var/log/tomcat/catalina.2019-01-17.log访问www.ilinux.io/test，这时不管是TomcatA还是B，session ID都是不会变的。测试中出现问题，Session无法绑定，原因是test中的WEB-INF目录的名字有问题，改回来就没问题了。 tomcat + memcached12345678910111213141516171819202122232425262728293031323334353637383940准备三台主机，第一台是反代服务器，两个接口，地址：192.168.1.14 172.16.106.132。tomcat1是内网主机，地址：172.16.106.133。tomcat2地址：172.16.106.134。同步两台服务器的时间* tomcat1 &amp; tomcat2[root@test ~]# yum install -y memcached[root@test ~]# systemctl start memcached[root@test ~]# cd /etc/tomcat/[root@test ~]# cp server.xml&#123;,.cluster&#125;# 将tomcat恢复成最初状态，将cluster一段删除[root@test ~]# vim server.xml&lt;Context path="/test" docBase="test" reloadable="true"&gt;# reloadable表示自动装载 &lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" memcachedNodes="m1:172.16.106.133:11211,m2:172.16.106.134:11211" failoverNodes="m2" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$" transcoderFactoryClass="de.javakaffee.web.msm.serializer.javolution.JavolutionTranscoderFactory" /&gt;# serializer后的javolution开头的j一定要小写# memcachedNodes中m1是自定义的名称，后面是节点的地址；failoverNodes="m2"表示m2是备用节点，如果m1有故障m2才上线。requestUriIgnorePattern指有些内容是不缓存的，因为是静态文件。 &lt;/Context&gt;[root@test ~]# scp /etc/tomcat/server.xml 172.16.106.134:/etc/tomcat/下载相关包到两台tomcat1. javolution-5.4.3.1.jar # 流式化工具2. msm-javolution-serializer-1.9.7.jar # MSM支持两种模式即粘性sessions和非粘性sessions3. memcached-session-manager-1.9.7.jar # memcached会话管理器4. memcached-session-manager-tc7-1.9.7.jar # memcached会话管理器5. spymemcached-2.11.1.jar # 驱动：tomcat连接memcached[root@test ~]# scp *.jar 172.16.106.134:/usr/share/java/tomcat/[root@test ~]# systemctl stop tomcat.[root@test ~]# systemctl start tomcat[root@test ~]# tail -f /var/log/tomcat/catalina.2019-01-17.log# 监控日志，看启动是否有问题。启动没有问题后，访问www.ilinux.io/test，这时的SessionID是不会有变化的。因为sticky设置成了true，如果是false，那么就会有变化了。SessionID的最后有m1或m2的标识，可以知道是在哪个memcached上。* tomcat1[root@test ~]# systemctl stop memcached再访问www.ilinux.io/test，这时的SessionID还是不会有变化，只是Session ID一行最后变成了m2。切记，一定要先启动memcached再启动tomcat。[root@test ~]# yum install -y libmemcached-devel# 这个包是C与memcached连接用的，提供了很多命令[root@test ~]# memstat --servers="172.16.106.133"# 显示memcached的各种数据 memcached安装使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263在tomcat主机上安装测试[root@test ~]# yum install -y telnet[root@test ~]# vim /etc/sysconfig/memcachedPORT="11211" # 端口USER="memcached" # 启动服务的用户名MAXCONN="1024" # 最大并发连接数;存储层是不面向用户的，是从前面的反代发来的，所以1024并不小CACHESIZE="64" # 缓存空间大小，这要改一下，如2GOPTIONS=""[root@test ~]# cat /usr/lib/systemd/system/memcached.service [Unit]Description=Memcached Before=httpd.serviceAfter=network.target[Service]Type=simpleEnvironmentFile=-/etc/sysconfig/memcachedExecStart=/usr/bin/memcached -u $USER -p $PORT -m $CACHESIZE -c $MAXCONN $OPTIONS[Install]WantedBy=multi-user.target# 可以看到，启动时就是调用配置文件中的几个参数[root@test ~]# telnet 127.0.0.1 11211statsstats slabs # 查看内存分配器add mykey 1 600 13 # 设置存储数据的信息，这里存储的键叫mykey，标志位是1，过期时间是600秒，占用内存大小是13个字符。www.ilinux.io # 这是要存储的数据，成功后返回STOREDstats # 这时cmd_set的值是1了。get mykey # 查看mykey的信息append mykey 1 600 12# 在后面追加数据www.iunix.io # 返回了NOT_STORED，因为数据过期了，不能追加get mykeyprepend mykey 1 600 7 # 在前面补http:// # 添加这些内容get mykeydelete mykeyget mykeyadd counter 1 600 1 # 设置一个计数器0 # 值是0get counterincr counter 1 # 增加1get counterincr counter 2decr counter 1 # 减1flush_all # 清空数据quit# 退出 tomcat + redis实现session绑定1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465准备一台redis，两台tomcat* 反代服务器[root@test ~]# yum install -y redis[root@test ~]# vim /etc/redis.confbind 0.0.0.0[root@test ~]# systemctl start redis[root@test ~]# vim /etc/nginx/nginx.confhttp &#123;...upstream tcsrvs &#123; server 192.168.1.13:8080; server 192.168.1.15:8080; &#125;[root@test ~]# vim /etc/nginx/conf.d/ilinux.confserver &#123; listen 80; server_name www.ilinux.io; location / &#123; proxy_pass http://tcsrvs; &#125;&#125;* tomcat1 &amp; tomcat 2下载commons-pool2-2.0.jar、jedis-2.7.2.jar、tomcat-redis-session-manager1.2.jar到/usr/share/java/tomcat中# 试过上面三个包的其他版本，tomcat启动时均有报错，用上面三个版本没有问题。可以个人百度网盘下载。参考：https://my.oschina.net/xshuai/blog/916122[root@test tomcat]# vim /etc/tomcat/context.xml&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt; &lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="192.168.1.14" port="6379" database="0" maxInactiveInterval="60"/&gt;[root@test tomcat]# mkdir -pv /var/lib/tomcat/webapps/test/&#123;WEB-INF,META-INF,classes,lib&#125;[root@test tomcat]# vim /usr/share/tomcat/webapps/test/index.jsp&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("magedu.com","magedu.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@test tomcat]# cd /usr/share/java/tomcat[root@test tomcat]# scp /etc/tomcat/context.xml 192.168.1.13:/etc/tomcat/[root@test tomcat]# scp jedis-2.7.2.jar commons-pool2-2.0.jar tomcat-redis-session-manager1.2.jar 192.168.1.13:/usr/share/java/tomcat/[root@test tomcat]# scp -r /usr/share/tomcat/webapps/test/ 192.168.1.13:/usr/share/tomcat/webapps/[root@test tomcat]# vim /etc/tomcat/tomcat-users.xml&lt;role rolename="admin-gui"/&gt;&lt;role rolename="manager-gui"/&gt;&lt;user name="admin" password="adminadmin" roles="admin-gui,manager-gui" /&gt;[root@test tomcat]# scp /etc/tomcat/tomcat-users.xml 192.168.1.13:/etc/tomcat[root@test tomcat]# systemctl start tomcat# 启动两台tomcat访问http://www.ilinux.io/test/，这时可以看到sessionID是不会变化的]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux性能监控命令]]></title>
    <url>%2F2019%2F01%2F15%2Flinux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[CPU查看1234567891011[root@test ~]# cat /proc/cpuinfo |grep "physical id"|sort|uniq|wc -l1# 查看物理cpu个数[root@test ~]# cat /proc/cpuinfo |grep "cpu cores"|wc -l 2# 查看每个物理cpu中的核心数[root@test ~]# cat /proc/cpuinfo |grep "processor"|wc -l 2# 逻辑cpu的个数。物理cpu个数*核数=逻辑cpu个数（不支持超线程技术的情况下）[root@test ~]# lscpu# 此命令也可查询上述信息 内存查看123456789101112131415161718[root@test ~]# free -h total used free shared buff/cache availableMem: 976M 127M 510M 55M 338M 625MSwap: 2.0G 0B 2.0G# total：内存总数# used：已经使用的内存数# free：空闲内存数# shared：多个进程共享的内存总额# - buffers/cache：(已用)的内存数，即used-buffers-cached(CentOS6)# + buffers/cache：(可用)的内存数，即free+buffers+cached(CentOS6)# Buffer Cache用于针对磁盘块的读写；# Page Cache用于针对文件inode的读写，这些Cache能有效地缩短I/O系统调用的时间。# 对操作系统来说free/used是系统可用/占用的内存；# 对应用程序来说-/+ buffers/cache是可用/占用内存,因为buffers/cache很快就会被使用。# 经验公式：# 应用程序可用内存/系统物理内存&gt;70%，表示系统内存资源非常充足，不影响系统性能;# 应用程序可用内存/系统物理内存&lt;20%，表示系统内存资源紧缺，需要增加系统内存;# 20%&lt;应用程序可用内存/系统物理内存&lt;70%，表示系统内存资源基本能满足应用需求，暂时不影响系统性能 磁盘查看12345678[root@test ~]# fdisk -l# 查看硬盘及分区信息[root@test ~]# df -h# 查看文件系统的磁盘空间占用情况[root@test ~]# du -sh /etc35M /etc# 查看linux系统中某目录的大小 其他参数123456789101112[root@test ~]# lsmod# 查看系统已载入的相关模块[root@test ~]# lspci# 查看pci设置[root@test ~]# uname -aLinux test 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux# 查看内核版本号等信息，也可以使用-r选项，只显示内核信息[root@test ~]# file /lib/systemd/systemd# 查看系统是32位还是64位的[root@test ~]# cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core)# 查看发行版 uptime命令123[root@test ~]# uptime 21:14:43 up 1 min, 1 user, load average: 0.05, 0.03, 0.01 # load average三值大小一般不能大于系统CPU的个数。系统有8个CPU,如load average三值长期大于8，说明CPU很繁忙，负载很高，可能会影响系统性能。如load average输出值小于CPU个数，则表示CPU有空闲时间片，比如本例中的输出，CPU是非常空闲的 PS命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263用途显示进程的状态。语法ps [options] [--help]参数-A 列出所有的行程-w 显示加宽可以显示较多的资讯au 显示较详细的资讯aux 显示所有包含其他使用者的行程，也可使用-ef参数* au(x) 输出格式 :USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDUSER: 进程拥有者PID: pid%CPU: 占用的 CPU 使用率%MEM: 占用的内存使用率VSZ: 占用的虚拟内存大小RSS: 占用的内存大小TTY: 终端的次要装置号码 (minor device number of tty)STAT: 此进程的状态:D: 不可中断的R: 正在执行中S: 静止状态T: 暂停执行Z: 不存在但暂时无法消除W: 没有足够的内存分页可分配&lt;: 高优先级的进程N: 低优先级的进程L: 有内存分页分配并锁在内存内 (实时系统或A I/O)START: 进程开始时间TIME: 执行的时间COMMAND:所执行的指令例[root@test ~]# ps -A PID TTY TIME CMD 1 ? 00:00:02 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:00 ksoftirqd/0# 显示进程信息[root@test ~]# ps -u root PID TTY TIME CMD 1 ? 00:00:02 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:00 ksoftirqd/0# 显示root用户的进程信息[root@test ~]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:02 ? 00:00:02 /usr/lib/systemd/systemd --switched-root --sroot 2 0 0 10:02 ? 00:00:00 [kthreadd]root 3 2 0 10:02 ? 00:00:00 [ksoftirqd/0]# 显示所有命令，连带命令行[root@test ~]# ps axo user,comm,pid,psr,pcpuUSER COMMAND PID PSR %CPUroot systemd 1 1 0.0root kthreadd 2 0 0.0root ksoftirqd/0 3 0 0.0# 这个命令是查看进程的名称、PID以及CPU的占用率。psr表示绑定内核线程的处理器（如果有）的逻辑处理器号。 对一个进程来说，如果它的线程全都绑定到同一处理器上，那么显示该字段。pcpu表示CPU的占用率。comm表示进程名称。pid表示进程的ID号 top命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133用途用于实时显示 process 的动态。语法top [-] [d delay] [c] [S] [s] [i] [n] [b]参数d : 改变显示的更新速度，或在交互式指令列( interactive command)按 sc : 切换显示模式，共有两种模式，一是只显示执行程序的名称，另一种是显示完整的路径与名称S : 累积模式，会将己完成或消失的子行程 ( dead child process ) 的 CPU time 累积起来s : 安全模式，将交互式指令取消, 避免潜在的危机i : 不显示任何闲置 (idle) 或无用 (zombie) 的进程n : 更新的次数，完成后将会退出 topb : 批次模式，搭配 "n" 参数一起使用，可以用来将 top 的结果输出到文件内例[root@test ~]# top# 显示进程信息top - 17:44:23 up 7:42, 4 users, load average: 0.02, 0.02, 0.05Tasks: 110 total, 1 running, 109 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.5 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 stKiB Mem : 999720 total, 522516 free, 131076 used, 346128 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 640836 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 893 root 20 0 549.2m 18.2m 5.7m S 0.3 1.9 0:03.52 /usr/bin/python -Es /us+ * 统计信息区前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：01:06:48：当前时间up 1:22：系统运行时间，格式为时:分1 user：当前登录用户数load average: 0.06, 0.60, 0.48：系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：Tasks: 29 total：进程总数1 running：正在运行的进程数28 sleeping：睡眠的进程数0 stopped：停止的进程数0 zombie：僵尸进程数Cpu(s): 0.3% us：用户空间占用CPU百分比1.0% sy： 内核空间占用CPU百分比0.0% ni：用户进程空间内改变过优先级的进程占用CPU百分比98.7% id：空闲CPU百分比0.0% wa：等待输入输出的CPU时间百分比0.0% hi0.0% si最后两行为内存信息。内容如下：Mem: 191272k total：物理内存总量173656k used：使用的物理内存总量17616k free：空闲内存总量22052k buffers：用作内核缓存的内存量Swap: 192772k total：交换区总量0k used：使用的交换区总量192772k free：空闲交换区总量123988k cached：缓冲的交换区总量。# 内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小。相应的内存再次被换出时可不必再对交换区写入。* 进程信息区统计信息区域的下方显示了各个进程的详细信息。PID：进程idPPID：父进程idRUSER Real user nameUID：进程所有者的用户idUSER：进程所有者的用户名GROUP：进程所有者的组名TTY：启动进程的终端名。不是从终端启动的进程则显示为 ?PR：优先级NI：nice值。负值表示高优先级，正值表示低优先级P：最后使用的CPU，仅在多CPU环境下有意义%CPU：上次更新到现在的CPU时间占用百分比TIME：进程使用的CPU时间总计，单位秒TIME+：进程使用的CPU时间总计，单位1/100秒%MEM：进程使用的物理内存百分比VIRT：进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESSWAP：进程使用的虚拟内存中，被换出的大小，单位kb。RES：进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATACODE：可执行代码占用的物理内存大小，单位kbDATA：可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kbSHR：共享内存大小，单位kbnFLT：页面错误次数nDRT：最后一次写入到现在，被修改过的页面数。S：进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程COMMAND：命令名/命令行WCHAN：若该进程在睡眠，则显示睡眠中的系统函数名Flags：任务标志* 更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定。按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转。* 交互命令h或者?：显示帮助画面，给出一些简短的命令总结说明。k：终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。i：忽略闲置和僵死进程。这是一个开关式命令。q：退出程序。r ：重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。S：切换到累计模式。s：改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。f或者F：从当前显示中添加或者删除项目。o或者O：改变显示项目的顺序。l：切换显示平均负载和启动时间信息。m：切换显示内存信息。t：切换显示进程和CPU状态信息。c：切换显示命令名称和完整命令行。M：根据驻留内存大小进行排序。P：根据CPU使用百分比大小进行排序。T：根据时间/累计时间进行排序。W：将当前设置写入~/.toprc文件中。1：查看CPU数量[root@test ~]# top -c# 显示完整命令[root@test ~]# top -b# 以批处理模式显示程序信息[root@test ~]# top -S# 以累积模式显示程序信息[root@test ~]# top -n 2# 设置信息更新次数，这里会更新两次后终止更新显示[root@test ~]# top -d 3# 设置信息更新时间，这条命令更新周期为3秒[root@test ~]# top -p 1# 显示指定的进程信息 iostat命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455用法：iostat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ]]常用选项说明：-c：只显示系统CPU统计信息，即单独输出avg-cpu结果，不包括device结果-d：单独输出Device结果，不包括cpu结果-k/-m：输出结果以kB/mB为单位，而不是以扇区数为单位-x：输出更详细的io设备统计信息interval/count：每次输出间隔时间，count表示输出次数，不带count表示循环输出# 使用此命令需要安装sysstat包例[root@test ~]# iostat# 从系统开机到当前执行时刻的统计信息# avg-cpu: 总体cpu使用情况统计信息，对于多核cpu，这里为所有cpu的平均值。重点关注iowait值，表示CPU用于等待io请求的完成时间。# Device：各磁盘设备的IO统计信息。各列含义如下：# Device：以sdX形式显示的设备名称# tps： 每秒进程下发的IO读、写请求数量# KB_read/s：每秒从驱动器读入的数据量，单位为K。# KB_wrtn/s：每秒从驱动器写入的数据量，单位为K。# KB_read：读入数据总量，单位为K。# KB_wrtn：写入数据总量，单位为K。# 重点关注参数：# iowait% 表示CPU等待IO时间占整个CPU周期的百分比，如果iowait值超过50%，或者明显大于%system、%user以及%idle，表示IO可能存在问题。# avgqu-sz 表示磁盘IO队列长度，即IO等待个数。# await 表示每次IO请求等待时间，包括等待时间和处理时间# svctm 表示每次IO请求处理的时间# %util 表示磁盘忙碌情况，一般该值超过80%表示该磁盘可能处于繁忙状态。[root@test ~]# ll /dev/centos/total 0lrwxrwxrwx 1 root root 7 Jan 16 21:13 root -&gt; ../dm-0lrwxrwxrwx 1 root root 7 Jan 16 21:13 swap -&gt; ../dm-1# 可以使用此命令查看dm-*对应的分区名称[root@test ~]# iostat -x -k -d 1 2Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.02 0.62 0.12 12.85 1.85 40.04 0.00 0.32 0.28 0.55 0.16 0.01dm-0 0.00 0.00 0.34 0.13 11.44 1.58 55.41 0.00 0.52 0.46 0.65 0.21 0.01dm-1 0.00 0.00 0.01 0.00 0.30 0.00 47.40 0.00 0.13 0.13 0.00 0.06 0.00# 每隔1秒输出磁盘IO的详细信息，总共采样2次# rrqm/s：每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并# wrqm/s：每秒对该设备的写请求被合并次数# r/s：每秒完成的读次数# w/s：每秒完成的写次数# rkB/s：每秒读数据量(kB为单位)# wkB/s：每秒写数据量(kB为单位)# avgrq-sz：平均每次IO操作的数据量(扇区数为单位)# avgqu-sz：平均等待处理的IO请求队列长度# await：平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位)# svctm：平均每次IO请求的处理时间(毫秒为单位)# %util：采用周期内用于IO操作的时间比率，即IO队列非空的时间比率[root@test ~]# iostat -x 1 5# 查看硬盘的I/O性能。每隔一秒显示一次，显示5次。如果%util接近100%,说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果idle小于70%，I/O的压力就比较大了，说明读取进程中有较多的wait。 vmstat命令12345678910111213141516171819202122[root@test ~]# vmstat 2 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 766596 2108 116392 0 0 334 36 144 191 0 1 98 0 0 0 0 0 766596 2108 116392 0 0 0 0 180 148 0 0 100 0 0 # 显示系统各种资源之间相关性能简要信息，主要看CPU负载情况。2表示每个两秒采集一次服务器状态，2表示只采集两次。也可以只使用vmstat 2命令，每2秒显示一次，一直监控# r：表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。# b：表示阻塞的进程,这个不多说，进程阻塞，大家懂的。# swpd：虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。# free：空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。# buff：Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M# cache：cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)# si：每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。# so：每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。# bi：块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒# bo：块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。# in：每秒CPU的中断次数，包括时间中断# cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。# us：用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。# sy：系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。# id：空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。# si、so的值长期不为0，表示系统内存不足。需增加系统内存。 sar命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269 sar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等，sar命令由sysstat安装包安装用法: sar [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ]选项:-A：所有报告的总和-b：显示I/O和传递速率的统计信息-B：显示换页状态-d：输出每一块磁盘的使用信息-e：设置显示报告的结束时间-f：从制定的文件读取报告-i：设置状态信息刷新的间隔时间-P：报告每个CPU的状态-R：显示内存状态-u：输出cpu使用情况和统计信息-v：显示索引节点、文件和其他内核表的状态-w：显示交换分区的状态-x：显示给定进程的装-r：报告内存利用率的统计信息例[root@test ~]# sar -u 3 4Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:18:58 PM CPU %user %nice %system %iowait %steal %idle09:19:01 PM all 0.00 0.00 0.00 0.00 0.00 100.0009:19:04 PM all 0.00 0.00 0.17 0.00 0.00 99.8309:19:07 PM all 0.00 0.00 0.17 0.00 0.00 99.8309:19:10 PM all 0.00 0.00 0.00 0.00 0.00 100.00Average: all 0.00 0.00 0.08 0.00 0.00 99.92# 每间隔3秒钟统计一次总共统计4次# %user：显示用户进程消耗的CPU 时间百分比。# %nice：显示运行正常进程所消耗的CPU 时间百分比。# %system：显示系统进程消耗的CPU时间百分比。# %iowait：显示IO等待所占用的CPU时间百分比# %steal：显示在内存相对紧张的环境下pagein强制对不同的页面进行的steal操作 。# %idle：显示CPU处在空闲状态的时间百分比。# 如果系统CPU整体利用率不高，而应用响应缓慢，可能是在一个多CPU的系统中，程序使用了单线程的原因。单线程只使用一个CPU，导致这个CPU占用率为100%，无法处理其它请求，而其它的CPU却闲置，这就导致了整体CPU使用率不高，而应用缓慢现象的发生。# 在以上的显示当中，主要看%iowait和%idle，%iowait过高表示存在I/O瓶颈，即磁盘IO无法满足业务需求，如果%idle过低表示CPU使用率比较严重，需要结合内存使用等情况判断CPU是否瓶颈。[root@test ~]# sar -P 1 3 3Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:36:03 PM CPU %user %nice %system %iowait %steal %idle11:36:06 PM 1 0.00 0.00 0.00 0.00 0.00 100.0011:36:09 PM 1 0.00 0.00 0.33 0.00 0.00 99.6711:36:12 PM 1 0.00 0.00 0.00 0.00 0.00 100.00Average: 1 0.00 0.00 0.11 0.00 0.00 99.89# 使用-P选项指定监控1号CPU信息，每3秒显示一次，一共显示3次[root@test ~]# sar -u -o /tmp/1.txt 2 3Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:37:52 PM CPU %user %nice %system %iowait %steal %idle11:37:54 PM all 0.00 0.00 0.00 0.00 0.00 100.0011:37:56 PM all 0.00 0.00 0.25 0.00 0.00 99.7511:37:58 PM all 0.00 0.00 0.00 0.00 0.00 100.00Average: all 0.00 0.00 0.08 0.00 0.00 99.92# 保存监控文件，保存后的文件是二进制的，无法使用vim和cat直接打开[root@test ~]# sar -u -f /tmp/1.txt Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:37:52 PM CPU %user %nice %system %iowait %steal %idle11:37:54 PM all 0.00 0.00 0.00 0.00 0.00 100.0011:37:56 PM all 0.00 0.00 0.25 0.00 0.00 99.7511:37:58 PM all 0.00 0.00 0.00 0.00 0.00 100.00Average: all 0.00 0.00 0.08 0.00 0.00 99.92# 从二进制文件读取[root@test ~]# sar -qLinux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:13:34 PM LINUX RESTART09:20:01 PM runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked09:30:01 PM 0 113 0.00 0.01 0.01 009:40:01 PM 0 113 0.08 0.03 0.02 0# 查看平均负载# runq-sz：运行队列的长度（等待运行的进程数，每核的CP不能超过3个）# plist-sz：进程列表中的进程（processes）和线程数（threads）的数量#ldavg-1：最后1分钟的CPU平均负载，即将多核CPU过去一分钟的负载相加再除以核心数得出的平均值，5分钟和15分钟以此类推#ldavg-5：最后5分钟的CPU平均负载#ldavg-15：最后15分钟的CPU平均负载[root@test ~]# sar -rLinux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:13:34 PM LINUX RESTART09:20:01 PM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty09:30:01 PM 765604 234116 23.42 2108 77200 268076 8.66 83636 62712 009:40:01 PM 765664 234056 23.41 2108 77212 268076 8.66 83944 62428 0# 查看内存使用情况# kbmemfree：空闲的物理内存大小# kbmemused：使用中的物理内存大小# %memused：物理内存使用率# kbbuffers：内核中作为缓冲区使用的物理内存大小，kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. # kbcached：缓存的文件大小# kbcommit：保证当前系统正常运行所需要的最小内存，即为了确保内存不溢出而需要的最少内存（物理内存+Swap分区）# commit 这个值是kbcommit与内存总量（物理内存+swap分区）的一个百分比的值[root@test ~]# sar -WLinux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:13:34 PM LINUX RESTART09:20:01 PM pswpin/s pswpout/s09:30:01 PM 0.00 0.0009:40:01 PM 0.00 0.00# 查看系统swap分区的统计信息# pswpin/s：每秒从交换分区到系统的交换页面（swap page）数量# pswpott/s：每秒从系统交换到swap的交换页面（swap page）的数量[root@test ~]# sar -bLinux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:13:34 PM LINUX RESTART09:20:01 PM tps rtps wtps bread/s bwrtn/s09:30:01 PM 0.08 0.00 0.08 0.00 1.1809:40:01 PM 0.09 0.00 0.09 0.00 1.12# 查看I/O和传递速率的统计信息# tps：磁盘每秒钟的IO总数，等于iostat中的tps# rtps：每秒钟从磁盘读取的IO总数# wtps：每秒钟从写入到磁盘的IO总数# bread/s：每秒钟从磁盘读取的块总数# bwrtn/s：每秒钟此写入到磁盘的块总数[root@test ~]# sar -dp 2 2Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:44:35 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util11:44:37 PM sda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00# sar –d组合，可以对系统的磁盘IO做一个基本的统计# DEV 磁盘设备的名称，如果不加-p，会显示dev253-0类似的设备名称，因此加上-p显示的名称更直接# tps：每秒I/O的传输总数# rd_sec/s：每秒读取的扇区的总数# wr_sec/s：每秒写入的扇区的总数# avgrq-sz：平均每次次磁盘I/O操作的数据大小（扇区）# avgqu-sz：磁盘请求队列的平均长度# await：平均每次设备I/O操作等待时间（毫秒）# svctm：平均每次设备I/O操作的服务时间（毫秒）# %util：一秒钟有百分之几的时间用于I/O操作# 对磁盘IO性能评判标准：# 正常svctm应小于await值，而svctm和磁盘性能有关，CPU、内存负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。# await值取决svctm和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。# %util：衡量磁盘I/O重要指标，如%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷工作，该磁盘可能存在瓶颈。可优化程序或者 通过更换 更高、更快的磁盘。[root@test ~]# sar -vLinux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)09:13:34 PM LINUX RESTART09:20:01 PM dentunusd file-nr inode-nr pty-nr09:30:01 PM 8571 1088 17484 109:40:01 PM 8574 1120 17481 1# 进程、inode、文件和锁表状态# dentunusd：在缓冲目录条目中没有使用的条目数量# file-nr：被系统使用的文件句柄数量# inode-nr：已经使用的索引数量 # pty-nr：使用的pty数量================================================================================这里面的索引和文件句柄值不是ulimit -a查看到的值，而是sysctl.conf里面定义的和内核相关的值， max-file表示系统级别的能够打开的文件句柄的数量， 而ulimit -n控制进程级别能够打开的文件句柄的数量，可以使用sysctl -a | grep inode和sysctl -a | grep file查看，具体含义如下：file-max中指定了系统范围内所有进程可打开的文件句柄的数量限制(系统级别， kernel-level)。 （The value in file-max denotes the maximum number of file handles that the Linux kernel will allocate）。当收到"Too many open files in system"这样的错误消息时， 就应该增加这个值了。[root@test ~]# cat /proc/sys/fs/file-max95823[root@test ~]# echo 100000 &gt; /proc/sys/fs/file-max或者[root@test ~]# echo ""fs.file-max=65535" &gt;&gt; /etc/sysctl.conf[root@test ~]# sysctl -pfile-nr 可以查看系统中当前打开的文件句柄的数量。 他里面包括3个数字： 第一个表示已经分配了的文件描述符数量， 第二个表示空闲的文件句柄数量， 第三个表示能够打开文件句柄的最大值（跟file-max一致）。 内核会动态的分配文件句柄， 但是不会再次释放他们（这个可能不适应最新的内核了， 在我的file-nr中看到第二列一直为0， 第一列有增有减） man bash， 找到说明ulimit的那一节：提供对shell及其启动的进程的可用资源（包括文件句柄， 进程数量， core文件大小等）的控制。 这是进程级别的， 也就是说系统中某个session及其启动的每个进程能打开多少个文件描述符， 能fork出多少个子进程等... 当达到上限时， 会报错"Too many open files"或者遇上Socket/File: Can’t open so many files等================================================================================[root@test ~]# sar -n DEV 1 1Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:52:46 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s11:52:47 PM ens35 0.00 0.00 0.00 0.00 0.00 0.00 0.0011:52:47 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0011:52:47 PM ens33 0.00 0.00 0.00 0.00 0.00 0.00 0.00# 每间隔1秒统计一次，总计统计1次# sar -n选项使用6个不同的开关：DEV，EDEV，NFS，NFSD，SOCK，IP，EIP，ICMP，EICMP，TCP，ETCP，UDP，SOCK6，IP6，EIP6，ICMP6，EICMP6和UDP6 ，DEV显示网络接口信息，EDEV显示关于网络错误的统计数据，NFS统计活动的NFS客户端的信息，NFSD统计NFS服务器的信息，SOCK显示套接字信息，ALL显示所有5个开关。它们可以单独或者一起使用。 # IFACE：本地网卡接口的名称# rxpck/s：每秒钟接受的数据包# txpck/s：每秒钟发送的数据库# rxKB/S：每秒钟接受的数据包大小，单位为KB# txKB/S：每秒钟发送的数据包大小，单位为KB# rxcmp/s：每秒钟接受的压缩数据包# txcmp/s：每秒钟发送的压缩包# rxmcst/s：每秒钟接收的多播数据包 [root@test ~]# sar -n EDEV 1 1Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:55:30 PM IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s11:55:31 PM ens35 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011:55:31 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011:55:31 PM ens33 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00# 统计网络设备通信失败信息# IFACE：网卡名称# rxerr/s：每秒钟接收到的损坏的数据包# txerr/s：每秒钟发送的数据包错误数# coll/s：当发送数据包时候，每秒钟发生的冲撞（collisions）数，这个是在半双工模式下才有# rxdrop/s：当由于缓冲区满的时候，网卡设备接收端每秒钟丢掉的网络包的数目# txdrop/s：当由于缓冲区满的时候，网络设备发送端每秒钟丢掉的网络包的数目# txcarr/s：当发送数据包的时候，每秒钟载波错误发生的次数# rxfram：在接收数据包的时候，每秒钟发生的帧对其错误的次数# rxfifo：在接收数据包的时候，每秒钟缓冲区溢出的错误发生的次数# txfifo：在发生数据包 的时候，每秒钟缓冲区溢出的错误发生的次数[root@test ~]# sar -n SOCK 1 1 Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:57:03 PM totsck tcpsck udpsck rawsck ip-frag tcp-tw11:57:04 PM 568 3 4 0 0 0Average: 568 3 4 0 0 0# 统计socket连接信息# totsck：当前被使用的socket总数# tcpsck：当前正在被使用的TCP的socket总数# udpsck：当前正在被使用的UDP的socket总数# rawsck：当前正在被使用于RAW的skcket总数# if-frag：当前的IP分片的数目# tcp-tw：TCP套接字中处于TIME-WAIT状态的连接数量[root@test ~]# sar -n TCP 1 3Linux 3.10.0-693.el7.x86_64 (test) 01/16/2019 _x86_64_ (2 CPU)11:59:25 PM active/s passive/s iseg/s oseg/s11:59:26 PM 0.00 0.00 0.00 0.0011:59:27 PM 0.00 0.00 1.00 1.0011:59:28 PM 0.00 0.00 1.00 1.00Average: 0.00 0.00 0.67 0.67# TCP连接的统计# active/s：新的主动连接# passive/s：新的被动连接# iseg/s：接受的段# oseg/s：输出的段================================================================================sar -n 使用总结-n DEV ： 网络接口统计信息。-n EDEV ： 网络接口错误。-n IP ： IP数据报统计信息。-n EIP ： IP错误统计信息。-n TCP ： TCP统计信息。-n ETCP ： TCP错误统计信息。-n SOCK ： 套接字使用。================================================================================常用命令sar -b 5 5：IO传送速率sar -B 5 5：页交换速率sar -c 5 5：进程创建的速率sar -d 5 5：块设备的活跃信息sar -n DEV 5 5：网路设备的状态信息sar -n SOCK 5 5：SOCK的使用情况sar -n ALL 5 5：所有的网络状态信息sar -P ALL 5 5：每颗CPU的使用状态信息和IOWAIT统计状态 sar -q 5 5：队列的长度（等待运行的进程数）和负载的状态sar -r 5 5：内存和swap空间使用情况sar -R 5 5：内存的统计信息（内存页的分配和释放、系统每秒作为BUFFER使用内存页、每秒被cache到的内存页）sar -u 5 5：CPU的使用情况和IOWAIT信息（同默认监控）sar -v 5 5 ：inode, file and other kernel tablesd的状态信息sar -w 5 5 ：每秒上下文交换的数目sar -W 5 5：SWAP交换的统计信息(监控状态同iostat 的si so)sar -x 2906 5 5：显示指定进程(2906)的统计信息，信息包括：进程造成的错误、用户级和系统级用户CPU的占用情况、运行在哪颗CPU上sar -y 5 5：TTY设备的活动状态sar将结果输出到文件(-o)和读取记录信息(-f) netstat命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100功能说明：显示网络状态。语 法：netstat [-acCeFghilMnNoprstuvVwx] [-A&lt;网络类型&gt;][--ip]补充说明：利用netstat指令可让你得知整个Linux系统的网络情况。参 数：-a 或--all：显示所有连线中的Socket。-A ：&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。-c或--continuous：持续列出网络状态。-C或--cache：显示路由器配置的快取信息。-e或--extend：显示网络其他相关信息。-F或--fib：显示FIB。-g或--groups：显示多重广播功能群组组员名单。-h或--help：在线帮助。-i或--interfaces：显示网络界面信息表单。-l或--listening：显示监控中的服务器的Socket。-M或--masquerade：显示伪装的网络连线。-n或--numeric：直接使用IP地址，而不通过域名服务器。-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称。-o或--timers：显示计时器。-p或--programs：显示正在使用Socket的程序识别码和程序名称。-r或--route：显示 Routing Table。-s或--statistice：显示网络工作信息统计表。-t或--tcp：显示TCP 传输协议的连线状况。-u或--udp：显示UDP传输协议的连线状况。-v或--verbose：显示指令执行过程。-V或--version：显示版本信息。-w或--raw：显示RAW传输协议的连线状况。-x或--unix：此参数的效果和指定”-A unix”参数相同。–ip或--inet：此参数的效果和指定”-A inet”参数相同。网络连接状态详解共有12中可能的状态，前面11种是按照TCP连接建立的三次握手和TCP连接断开的四次挥手过程来描述的。1. LISTEN：首先服务端需要打开一个socket进行监听，状态为LISTEN。/* The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求*/2. SYN_SENT：客户端通过应用程序调用connect进行active open。于是客户端tcp发送一个SYN以请求建立一个连接。之后状态置为SYN_SENT。/*The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 */3. SYN_RECV：服务端应发出ACK确认客户端的 SYN，同时自己向客户端发送一个SYN。之后状态置为SYN_RECV。/* A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 */4. ESTABLISHED：代表一个打开的连接，双方可以进行或已经在数据交互了。/* The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 */5. FIN_WAIT1：主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态。/* The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 */6. CLOSE_WAIT：被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序)，并进入CLOSE_WAIT。/* The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 */7. FIN_WAIT2：主动关闭端接到ACK后，就进入了 FIN-WAIT-2 。/* Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 */8. LAST_ACK:：被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN，等待对方的ACK。就进入了LAST-ACK 。/* The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 */9. TIME_WAIT：在主动关闭端接收到FIN后，TCP 就发送ACK包，并进入TIME-WAIT状态。/* The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 */10. CLOSING: 比较少见。/* Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 */11. CLOSED：被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束。/* The socket is not being used. 没有任何连接状态 */12. UNKNOWN：未知的Socket状态。/* The state of the socket is unknown. */SYN： (同步序列编号，Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。ACK：(确认编号，Acknowledgement Number)是对TCP请求的确认标志，同时提示对端系统已经成功接收所有数据。FIN： (结束标志，FINish)用来结束一个TCP回话。但对应端口仍处于开放状态，准备接收后续数据。例[root@test ~]# netstat -a# 列出所有端口[root@test ~]# netstat -at# 列出所有TCP端口[root@test ~]# netstat -au# 列出所有UDP端口[root@test ~]# netstat -l# 只显示监听端口[root@test ~]# netstat -lt# 显示监听TCP端口[root@test ~]# netstat -lu# 显示监听UDP端口[root@test ~]# netstat -lx# 显示监听UNIX端口[root@test ~]# netstat -s# 显示所有端口的统计信息[root@test ~]# netstat -st# 显示所有TCP的统计信息[root@test ~]# netstat -su# 显示所有UDP的统计信息[root@test ~]# netstat -p# 显示 PID 和进程名称[root@test ~]# netstat -rKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Ifacedefault bogon 0.0.0.0 UG 0 0 0 ens33172.16.106.0 0.0.0.0 255.255.255.0 U 0 0 0 ens35192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 ens33# 显示核心路由信息[root@test ~]# netstat -rnKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface0.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 ens33172.16.106.0 0.0.0.0 255.255.255.0 U 0 0 0 ens35192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 ens33# 显示数字格式，不查询主机名称[root@test ~]# netstat -c# netstat 将每隔一秒输出网络信息[root@test ~]# netstat -ie# 显示网络接口列表详细信息，结果如ifconfig[root@test ~]# netstat -ant|grep "192.168.1.14:22"|awk '&#123;print $5&#125;'|sort|uniq -c|sort -nr|head -20 1 192.168.1.9:51292# 查看连接某服务端口最多的的IP地址。uniq的-c或--count选项是在每列旁边显示该行重复出现的次数。[root@test ~]# netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn 4 LISTEN 1 Foreign 1 ESTABLISHED 1 established)# TCP各种状态列表 系统连接状态查看TCP连接状态123456netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c|sort -rnnetstat -n | awk '/^tcp/ &#123;++S[$NF]&#125;;END &#123;for(a in S) print a, S[a]&#125;'netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125;; END &#123;for(key in state) print key,"\t",state[key]&#125;'netstat -n | awk '/^tcp/ &#123;++arr[$NF]&#125;;END &#123;for(k in arr) print k,"\t",arr[k]&#125;'netstat -n |awk '/^tcp/ &#123;print $NF&#125;'|sort|uniq -c|sort -rnnetstat -ant | awk '&#123;print $NF&#125;' | grep -v '[a-z]' | sort | uniq -c 查找请求数请20个IP（常用于查找攻击来源）12netstat -anlp|grep 80|grep tcp|awk '&#123;print $5&#125;'|awk -F: '&#123;print $1&#125;'|sort|uniq -c|sort -nr|head -n20netstat -ant |awk '/:80/&#123;split($5,ip,':');++A[ip[1]]&#125;END&#123;for(i in A) print A[i],i&#125;' |sort -rn|head -n20 用tcpdump嗅探80端口的访问看看谁最高1[root@test ~]# tcpdump -i ens33 -tnn dst port 80 -c 1000 | awk -F"." '&#123;print $1"."$2"."$3"."$4&#125;' | sort | uniq -c | sort -nr |head -20 查找较多time_wait连接1netstat -n|grep TIME_WAIT|awk '&#123;print $5&#125;'|sort|uniq -c|sort -rn|head -n20 找查较多的SYN连接1netstat -an | grep SYN | awk '&#123;print $5&#125;' | awk -F: '&#123;print $1&#125;' | sort | uniq -c | sort -nr | more 根据端口列进程PID1netstat -ntlp | grep 80 | awk '&#123;print $7&#125;' | cut -d/ -f1 网站日志分析（Apache）获得访问前10位的ip地址12cat access.log|awk '&#123;print $1&#125;'|sort|uniq -c|sort -nr|head -10cat access.log|awk '&#123;counts[$(11)]+=1&#125;; END &#123;for(url in counts) print counts[url], url&#125;' 访问次数最多的文件或页面,取前201cat access.log|awk '&#123;print $11&#125;'|sort|uniq -c|sort -nr|head -20 列出传输最大的几个exe文件（分析下载站的时候常用）1cat access.log |awk '($7~/\.exe/)&#123;print $10 " " $1 " " $4 " " $7&#125;'|sort -nr|head -20 列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数1cat access.log |awk '($10 &gt; 200000 &amp;&amp; $7~/\.exe/)&#123;print $7&#125;'|sort -n|uniq -c|sort -nr|head -100 如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面1cat access.log |awk '($7~/\.php/)&#123;print $NF " " $1 " " $4 " " $7&#125;'|sort -nr|head -100 列出最最耗时的页面(超过60秒的)的以及对应页面发生次数1cat access.log |awk '($NF &gt; 60 &amp;&amp; $7~/\.php/)&#123;print $7&#125;'|sort -n|uniq -c|sort -nr|head -100 列出传输时间超过 30 秒的文件1cat access.log |awk '($NF &gt; 30)&#123;print $7&#125;'|sort -n|uniq -c|sort -nr|head -20 统计网站流量（G)1cat access.log |awk '&#123;sum+=$10&#125; END &#123;print sum/1024/1024/1024&#125;' 统计404的连接1awk '($9 ~/404/)' access.log | awk '&#123;print $9,$7&#125;' | sort 统计http status12cat access.log |awk '&#123;counts[$(9)]+=1&#125;; END &#123;for(code in counts) print code, counts[code]&#125;'cat access.log |awk '&#123;print $9&#125;'|sort|uniq -c|sort -rn 蜘蛛分析12/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E 'bot|crawler|slurp|spider'# 查看是哪些蜘蛛在抓取内容 网站日分析Squid1zcat squid_access.log.tar.gz| awk '&#123;print $10,$7&#125;' |awk 'BEGIN&#123;FS="[ /]"&#125;&#123;trfc[$4]+=$1&#125;END&#123;for(domain in trfc)&#123;printf "%s\t%d\n",domain,trfc[domain] 查看数据库执行的sql1tcpdump -i eth0 -s 0 -l -w - dst port 3306 | strings | egrep -i 'SELECT|UPDATE|DELETE|INSERT|SET|COMMIT|ROLLBACK|CREATE|DROP|ALTER|CALL' 系统Debug分析12345strace -p pid# 调试命令gdb -p pid# 跟踪指定进程的PID]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>性能监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shellScript语法及使用方法]]></title>
    <url>%2F2019%2F01%2F13%2FshellScript%E8%AF%AD%E6%B3%95%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[清除日志的三种方法1231. echo &gt; test.log 或 echo "" &gt; test.log2. &gt;test.log3. cat /dev/null &gt; test.log Shell脚本执行方式 当shell脚本以非交互的方式运行时，它会先查找环境变量ENV，该变量指定了一个环境文件（通常是.bashrc），然后从该环境变量文件开始执行，当读取了ENV文件后，SHELL才开始执行shell脚本中的内容。 12345678910111213141516171819201. bash script-name或sh script-name（推荐使用）；没有执行权限也可以执行。2. path/script-name或./script-name（当前路径 下执行脚本）3. source script-name或. script-name# 注意“.”点号；使用source或点号来加载或读入脚本，然后，依次执行指定shell脚本文件son.sh中的所有语句。这些语句将作为当前父shell脚本father.sh进程的一部分运行。因此，使用source或点号可以将son.sh自身脚本中的变量的值或函数等的返回值传递到当前的父shell脚本father.sh中使用。这就是在脚本中使用点或source加载文件的意义，为使用加载的文件中的内容可被当前脚本使用。这是第三种方法与前两种的最大区别。全局环境变量：/etc/profile、/etc/profile.d、/etc/bashrc用户环境变量：./bash_profile、.bashrc例：[root@template sh]# vim tesh1.sh#!/bin/bash#userdir=`pwd`[root@template sh]# chmod +x tesh1.sh [root@template sh]# bash tesh1.sh [root@template sh]# echo $userdir# 没有执行结果[root@template sh]# . tesh1.sh [root@template sh]# echo $userdir/root/sh# 用source或点号执行后，再用echo命令执行才有结果。用source或点号执行才能将变量加载到当前环境变量。 shell脚本开发基本规范及习惯123456789101112131415161718191. 开头指定脚本解释器2. 开头加版本版权等信息 #Date: 16:29 2012-3-30 时间 #Authou: oldboy 作者 #Mail：aaaa@qq.com 联系方式 #Function：this scripts function is ... 脚本的功能是什么 #Version： 1.1 脚本的版本号# 可配置vim编辑文件时自动加上以上信息，方法是修改~/.vimrc配置文件3. 脚本中不用中文件注释4. 脚本以.sh为扩展名5. 代码书写优秀习惯 1. 成对内容的一次写出来，防止挂失 2. []中括号两端要有空格 3. 流程控制语句一次书写完 if 条件内容 then 内容 fi6. 通过缩进让代码易读 变量分类123456789101112131415161718192021222324252627282930313233343536373839404142* 变量分两类：环境变量（全局变量）和局部变量* 环境变量可以在命令中设置，但用户退出时这些变量值也会丢失，因此最好在用户家目录下的.bash_profile文件中或全局设置/etc/bashrc，/etc/profile文件或者/etc/profile.d中定义。将环境变量放入profile文件中，每次用户登录时这些变量值都将被初始化。* 有一些环境变量，比如HOME、PATH、SHELL、UID、USER等，在用户登录之前就已经被/bin/login程序设置好了。通常环境变量定义并保存在用户家目录下的.bash_profile文件中* PS1环境变量定义用户登录后的提示符如[\u@\h \W]$，\u表示用户名，\h表示主机名，\W表示路径TMOUT＝3600，此变量表示多久不操作就退出终端UID＝0，此变量表示用户的UIDUSER＝root，此变量表示当前用户的用户名HISTFILESIZE=50，历史文件能包含的最大行数HISTSIZE=50，记录在命令行历史文件中的命令行数HISTFILE=/root/.bash_history，历史记录文件的全路径 # 上面的环境变量都可以加到/etc/profile文件中，加入后用source或点号加载生效。* 设置环境变量要在给环境变量赋值后或设置变量时用export命令。带-x选项的declare内置命令也可以完成同样的功能。（注意：输出变量时不要在变量名前加$）1. export 变量名＝value2. 变量名＝value --&gt; export 变量名3. declare -x 变量名＝value# 可以查看/etc/profile文件中是如何定义变量的用unset 变量名取消环境变量，变量名前不要加$符号。如果要永久生效，也要写到/etc/profile中。* 局部变量变量名＝value变量名＝'value'变量名="value"shell中变量名的要求：一般是字母，数字，下划线组成。字母开头* 自定义变量建议1. 纯数字（不带空格），定义方式可以不加引号（单或双）2. 没特殊情况，字符串一般用双引号定义，特别是多个字符串中间有空格时3. 变量内容需要原样输出时，要用单引号''* 变量命名规范1. 变量命名要统一，使用全部大写字母2. 避免无含义字符或数字# 看/etc/init.d/functions脚本中如何定义变量* 把命令定义为变量，就是将命令的执行结果给变量，用反引号或$()括起命令即可。tar zcf etc_$&#123;cmd&#125;_oldboy.tar.gz /etc# 这里cmd是自定义的变量，但如果要这样使用，要用大括号括起，因为如果不括起，系统就不能分辨出哪个是变量，可以会找$cmd_oldboy，这会执行错误。 位置变量123456789101112131415161718192021222324252627$0：获取当前执行的shell脚本的文件名$n：获取当前执行的shell脚本的第n个参数$*：获取当前shell的所有参数，将所有的命令行参数视为单个字符$#：获取当前shell命令行中参数的总个数$!：执行上一个指令的PID$?：获取执行结果返回值 执行结果返回值的意义： 0：正确执行 2：权限拒绝 1－125：表示运行失败 126：找到该命令了，但是无法执行 127：未找到要运行的命令 &gt;128：命令被系统强制结束$$：获取当前shell的进程号（PID）$_：在此之前执行的命令或脚本的最后一个参数$@：这个程序的所有参数，如"$1" "$2" "$3"...=======================================================================================$*与 $@区别$*：将所有的命令行所有参数视为单个字符串，等同于“$1$2$3”$@：将命令行每个参数视为单独的字符串，等同于"$1""$2""$3"。这是将参数传递给其他程序的最佳 方式，因为他会促使所有内嵌在每个参数里的任何空白。=======================================================================================例：sh n.sh "1 2 3"# 用引号括起的部分表示一个参数。basename：获取名称，也就是最后的一段dirname：获取文件所在路径，也就是最后一段前面的内容 常用内部命令1234567891011121314151617181920echoexecevalexportreadonlyreadshift# 按如下方式重新命名所有的位置参数变量，即$2成为$1，$3成为$2...在程序中每使用一次shift语句，都使所有的位置参数依次向左移动一个位置，并使位置参数$#减1，直到减到0为止。可以查看ssh-copy-id脚本是如何使用shift的waitexit点 字符串操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172* 判断读取字符串的值$&#123;var&#125;：变量var的值, 与$var相同$&#123;var-DEFAULT&#125;：如果var没有被声明, 那么就以$DEFAULT作为其值 *$&#123;var:-DEFAULT&#125;：如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *例[root@template sh]# echo $&#123;bbb-'ok'&#125;ok[root@template sh]# echo $bbb# bbb没有被声明过$&#123;var=DEFAULT&#125;：如果var没有被声明, 那么就以$DEFAULT作为其值 *$&#123;var:=DEFAULT&#125;：如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *例[root@template sh]# echo $&#123;abc='ok'&#125;ok[root@template sh]# echo $abcok$&#123;var+OTHER&#125;：如果var声明了, 那么其值就是$OTHER, 否则就为null字符串$&#123;var:+OTHER&#125;：如果var被设置了, 那么其值就是$OTHER, 否则就为null字符串 $&#123;var?ERR_MSG&#125;：如果var没被声明, 那么就打印$ERR_MSG *$&#123;var:?ERR_MSG&#125;：如果var没被设置, 那么就打印$ERR_MSG * $&#123;!varprefix*&#125;：匹配之前所有以varprefix开头进行声明的变量$&#123;!varprefix@&#125;：匹配之前所有以varprefix开头进行声明的变量# $&#123;!varprefix*&#125;与$&#123;!varprefix@&#125;相似，可以通过变量名前缀字符，搜索已经定义的变量,无论是否为空值。例[root@template sh]# var1=11;var2=22;var3=33[root@template sh]# echo $var111[root@template sh]# echo $var222[root@template sh]# echo $var333[root@template sh]# echo $&#123;!v@&#125;var1 var2 var3[root@template sh]# echo $&#123;!v*&#125;var1 var2 var3* 字符串操作 * 截取长度$&#123;#string&#125;：$string的长度 * 截取字符串$&#123;string:position&#125;：在$string中, 从位置$position开始提取子串$&#123;string:position:length&#125;：在$string中, 从位置$position开始提取长度为$length的子串 * 删除子串$&#123;string#substring&#125;：从变量$string的开头, 删除最短匹配$substring的子串$&#123;string##substring&#125;：从变量$string的开头, 删除最长匹配$substring的子串$&#123;string%substring&#125;：从变量$string的结尾, 删除最短匹配$substring的子串$&#123;string%%substring&#125;：从变量$string的结尾, 删除最长匹配$substring的子串$&#123;变量名#substring正则表达式&#125;：从字符串开头开始配备substring，删除匹配上的表达式。$&#123;变量名%substring正则表达式&#125;：从字符串结尾开始配备substring，删除匹配上的表达式。# $&#123;test##*/&#125;,$&#123;test%/*&#125; 分别是得到文件名，或者目录地址最简单方法。 * 字符串替换$&#123;string/substring/replacement&#125;：使用$replacement, 来代替第一个匹配的$substring$&#123;string//substring/replacement&#125;：使用$replacement, 代替所有匹配的$substring$&#123;string/#substring/replacement&#125;：如果$string的前缀匹配$substring, 那么就用$replacement来代替匹配到的$substring$&#123;string/%substring/replacement&#125;：如果$string的后缀匹配$substring, 那么就用$replacement来代替匹配到的$substring# "* $substring" 可以是一个正则表达式。# $&#123;变量/查找/替换值&#125; 一个“/”表示替换第一个，”//”表示替换所有,当查找中出现了：”/”请加转义符”\/”表示。例[root@template sh]# num=oldboy5343[root@template sh]# echo "$&#123;num//[0-9]/&#125;" oldboy# 这是使用空来代替oldboy5343中的所有数字，所以取的值只有字母[root@template sh]# echo "$&#123;num//[0-9]/a&#125;"oldboyaaaa 变量的数值计算123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177* (())用法：此方法很常用，且效率高。执行简单的整数运算，只需将特定的算术表达式用"$((算术运算表达式))"。shell的算术运算符号都置于"$((算术运算表达式))"的语法中。这一语法如同双引号功能，除了内嵌双引号无需转义。=======================================================================================运算符++ --：增加及减少，可前置也可放在结尾。放在开头表示先自增或自减再赋值，放在结尾表示先赋值再自增或自减。变量话前，先输出变量值，变量在后，就是先运算后输出变量的值。+ - ! ~ ：一元的正号与负号；逻辑与位的取反* / %：乘法、除法、与取余+ - ：加法、减法&lt; &lt;= &gt; &gt;=：比较符号== !=：判断相等与不相等&lt;&lt; &gt;&gt;：向左位移、向右位移&amp;：位的AND^：位的异或｜：位的或&amp;&amp;：逻辑的AND||：逻辑的OR?：条件表达式= += -= *= /= %= &amp;= ^=&lt;&lt;= &gt;&gt;= \=：赋值运算符=======================================================================================例[root@template sh]# echo $((3&gt;2))1# 判断，如果是真就输出1，假输出0# 括号两边有几个空格不敏感，也可以没有[root@template sh]# echo $((3&gt;8))0[root@template sh]# ((a=1+2**3-4%3))# **是幂，表示几次方[root@template sh]# echo $a8[root@template sh]# b=$((1+2**3-4%3))[root@template sh]# echo $b8[root@template sh]# echo $((1+2**3-4%3))8[root@template sh]# echo $((a+=1))9# a++表示先赋值再自增1、++a表示先自增1再赋值、a--与--a同理[root@template sh]# echo $((100*(100+1)/2))5050[root@template sh]# echo $((1000*(1000+1)/2))500500# 从1加到100的计算公式是n*(n+1)/2，只要从1开始，间隔为1的相加计算都可以用此公式[root@template sh]# echo $((1.1+1))-bash: 1.1+1: syntax error: invalid arithmetic operator (error token is ".1+1")# 双括号中只能使用整数，不能使用小数例：使用传参的方式对两个变量进行计算[root@template sh]# vim test2.shecho "a-b=$(($a-$b))"#!/bin/bash#a=$1b=$2echo "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))"[root@template sh]# chmod +x test2.sh [root@template sh]# bash test2.sh 5 2a-b=3a+b=7a*b=10a/b=2a**b=25a%b=1* []的用法，$[算术运算表达式]，与$((算术运算表达式))相同* let命令的用法格式： let 赋值表达式 let i=$[$i+1] # 这里不加let也可以，因为有中括号了 let i++ let i+=1 例[root@template sh]# i=2[root@template sh]# let i=i+9[root@template sh]# echo $i11# let i=i+8等同于((i=i+8))，但双括号效率更高例：利用let计数监控web服务状态[root@template sh]# vim web.sh ServerMonitor() &#123; timeout=10 fails=0 success=0 while true;do /usr/bin/wget --timeout=$timeout --tries=1 http://192.168.1.24 -q -O /dev/null if [ $? -ne 0 ];then let fails+=1 success=0 else fail=0 let success=1 fi if [ $success -eq 1 ];then exit 0 fi if [ $fails -ge 2 ];then Critical="web应用服务故障" echo $Critical fi sleep 10done&#125;ServerMonitor# 探测主页，之后判断，如果返回值不是0，fails变量就自增1，否则success变量就等于1。再判断success变量是否等于1,如果等于1，如果是，就正常退出，返回0。再判断fails变量是否大于等于2,如果是就定义一个变量Critical，并显示变量值。最后，每10秒检查一次。* expr命令用法# expr命令一般用于整数值，但也可用于字符串，用来求表达式变量的值，同时expr也是一个手工命令行计算器。语法： expr Expression例[root@template sh]# expr 2 + 24# 运算符两侧必须有空格[root@template sh]# expr 2 - 20[root@template sh]# expr 2 \* 24# 乘号要转义[root@template sh]# expr 2 / 2 1[root@template sh]# expr 3 % 21[root@template sh]# i=0[root@template sh]# i=`expr $i + 1`[root@template sh]# echo $i1# expr在循环中可用于增量计算。首先，循环初始化为0，然后循环值加1，反引号的用法为命令替代。最其本的一种是从(expr)命令接受输出并将之放入循环变量[root@template sh]# expr $[2+3]5# expr如果加上$[]后，运算符两侧就不用空格了。运算符两侧必须为整数例：ssh-copy-id脚本中使用expr命令if expr "$1" : ".*\.pub";then# 冒号两侧一样要有空格# 配置结果可能为expr id_dsa.pub:".*\.pub"，匹配*.pub格式的文件如果是则为真。如：[root@template sh]# expr ~/.ssh/id_rsa.pub : ".*\.pub"21# 如果为真就会打印出字符数，假就显示0[root@template sh]# expr ~/.ssh/id_rsa.pub : ".*\.pub" &amp;&amp; echo 1||echo 0211[root@template sh]# expr ~/.ssh/id_rsa.p : ".*\.pub" &amp;&amp; echo 1||echo 0 00# 判断文件或字符串的扩展名例：判断变量是否为整数[root@template sh]# vim expr.sh#!/bin/bash#read -p "Pls input: " aexpr $a + 0 &amp;&gt; /dev/null[ $? -eq 0 ] &amp;&amp; echo int || echo chars例：计算字符串的长度[root@template sh]# chars=`seq -s " " 100` # -s选项表示指定分隔符，上面是以空格为分隔符。默认是回车。[root@template sh]# echo $&#123;#chars&#125; 291[root@template sh]# echo $(expr length "$chars")291* $[]的用法与(())一样，效果也一样[root@template sh]# echo $((2-2))0[root@template sh]# echo $[2-2]0 read命令1234567891011121314151617181920212223242526272829303132333435363738394041可以使用read命令从标准输入获得参数语法： read [参数] [变量名]常用选项： -p prompt：设置提示信息 -t timeout：设置输入等待时间，单位默认为秒例[root@template sh]# read -p "pls input two number: " a bpls input two number: 1 2 或[root@template sh]# echo -n "pls input two number: ";read a bpls input two number: 4 3[root@template sh]# echo $a4[root@template sh]# echo $b3# 这两种方式都可以使用read获得参数例[root@template sh]# vim read.sh #!/bin/bash#read -t 10 -p "Pls input two number: " a becho "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))"[root@template sh]# vim read1.sh #!/bin/bash#echo -n "Pls input two number"read a becho "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 条件测试12345678910111213141516171819202122232425262728293031323334353637383940414243* 测试语句条件测试语法1. test &lt;测试表达式&gt;2. [&lt;测试表达式&gt;]3. [[&lt;测试表达式&gt;]]# 格式1和格式2是一样的，只是写法不同。格式3为扩展的test命令。在[[]]中可以使用通配符进行模式匹配。&amp;&amp;、||、&gt;、&lt;等操作符，但不能用于[]中。对整数进行关系运算，也可以使用shell的算术运算符(())* 文件测试操作符-f 文件：若文件存在且为普通文件则为真-d 文件：若文件存在且为目录则为真-s 文件：若文件存在且不为空（文件大小非0）则为真-e 文件：若文件存在则为真，要与-f区别，-f只判断是否为普通文件-r 文件：若文件可读则为真-w 文件：若文件可写则为真-x 文件：若文件可执行则为真-L 文件：若文件存在且为链接文件则为真f1 -nt f2：若文件f1比f2新则为真f1 -ot f2：若文件f1比f2旧则为真例：test[root@template sh]# test -f file &amp;&amp; echo true||echo false false[root@template sh]# test -f expr.sh &amp;&amp; echo true||echo false true[root@template sh]# test ! -f file &amp;&amp; echo true||echo falsetrue# 使用!号可以取反例：[][root@template sh]# [ -f file ] &amp;&amp; echo true || echo falsefalse[root@template sh]# [ ! -f file ] &amp;&amp; echo true || echo falsetrue例：[[]][root@template sh]# [[ -f file ]] &amp;&amp; echo true || echo false false[root@template sh]# [[ ! -f file ]] &amp;&amp; echo true || echo falsetrue[root@template sh]# [[ -f file &amp;&amp; -f expr.sh ]] &amp;&amp; echo true || echo falsefalse[root@template sh]# [[ ! -f file &amp;&amp; -f expr.sh ]] &amp;&amp; echo true || echo falsetrue 字符串及整数操作符1234567字符串测试操作符的作用：比较两个字符串是否相同、字符串长度是否为零，字符串是否为NULL（bash区分零长度字符串与空字符串）等。=比较两个字符串是相同，与==等价，如if[ "$a" = "$b" ]，其中$a这样的变量最好用""括起来，因为如果中间有空格，*等符号就可能出错了，也可以用[ "$&#123;a&#125;" = "$&#123;b&#125;" ]这样的方法。!=比较两个字符串是否相同，不同则为真* 字符串测试操作符-z "字符串"：若串长度为0则为真-n "字符串"：若串长度不为0则为真"串1"="串2"：若串1等于串2则为真，也可以使用==代替="串1"!="串2"：若串1不等于串2则为真 整数二元比较操作符 在[]中使用的比较符 在(())和[[]]中使用的比较符 说明 -eq == equal -ne != not equal -gt &gt; greater than -ge &gt;= greater equal -lt &lt; less thean -le &lt;= less equal 在[]中也可以使用&gt;、&lt;、=号，但&gt;、&lt;号要转义 逻辑操作符逻辑连接符 在[]中使用的逻辑操作符 在[[]]中使用的逻辑操作符 说明 -a &amp;&amp; 与，两端都为真，则为真 -o \ \ 或，两端有一端为真则为真 ! ! 非，相反则为真 单级与多级菜单1234567891011121314151617181920212223242526272829303132333435363738[root@template ~]# vim menu.sh#!/bin/bash#menu() &#123; cat &lt;&lt; END 1. [install lamp] 2. [install lnmp] 3. [install nfs] 4. [install rsync] Pls input the num that you want:END# 测试中，如果将END改为EOF会报错，内容如下：# menu.sh: line 14: warning: here-document at line 4 delimited by end-of-file (wanted `EOF')# menu.sh: line 15: syntax error: unexpected end of fileread a[ $a -eq 1 ] &amp;&amp; &#123;cat &lt;&lt; END[1. install apache][2. install mysql][3. install php]END&#125;&#125;menuread becho "You selected $b"[root@template ~]# bash menu.sh 1. [install lamp] 2. [install lnmp] 3. [install nfs] 4. [install rsync] Pls input the num that you want:1[1. install apache][2. install mysql][3. install php]1You selected 1 if条件语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210* if条件单分支语法：if [条件] then 指令fi或if [条件];then 指令fi特殊写法：if [ -f "$file" ];then echo 1;fi，相当于：[ -f "$file" ] &amp;&amp; echo 1例[root@template sh]# vim if.sh #!/bin/bash#cur_free=`free -m|awk '/buffers\// &#123;print $NF&#125;'`chars="current memory is $cur_free"if [ $cur_free -lt 900 ];then echo $charsfi[root@template sh]# chmod +x if.sh [root@template sh]# ./if.shcurrent memory is 855* 双分支、多分支if语句双分支语法：if [条件];then 指令else 指令fi多分支语法：if [条件];then 指令elif [条件];then 指令else 指令fi例[root@template sh]# vim if1.sh #!/bin/bash#a=$1b=$2if [ $# -ne 2 ];then echo "Usage: sh $0 num1 num2" exit 1fi[ -n "`echo $1|sed 's/[0-9]//g'`" ] &amp;&amp; echo "first parameter must num" &amp;&amp; exit 1[ -n "`echo $2|sed 's/[0-9]//g'`" ] &amp;&amp; echo "second parameter must num" &amp;&amp; exit 1# 这里是要显示输入的内容，将内容传给sed命令，sed命令将数字部分都替换为空，再对这个显示的值做字符串长度的计算，如果不是0就要提示应该输入数字，不然就退出。if [ $a -gt $b ];then echo "yes,$a &gt; $b"elif [ $a -eq $b ];then echo "yes,$a = $b"else echo "yes,$a &lt; $b"fi[root@template sh]# bash if1.sh 99 89yes,99 &gt; 89[root@template sh]# bash if1.sh 99 99yes,99 = 99[root@template sh]# bash if1.sh 69 99 yes,69 &lt; 99例：检查mysql是否启动[root@template sh]# vim check_db.sh#!/bin/bash#portNum=`netstat -lnt|grep 3306|wc -l`if [ $portNum -eq 1 ];then echo "db is running"else service mysqld startfi# 脚本的名称中最好不要包括要查询的服务的名称，如这里就是mysql例：检查mysql是否启动，更完整 [root@template sh]# vim check1_db.sh#!/bin/bash#LogPath=/tmp/mysql.logportNum=`netstat -lnt|grep 3306|wc -l`mysqlProcessNum=`ps -ef|grep mysqld|grep -v grep|wc -l`if [ $portNum -eq 1 ] &amp;&amp; [ $mysqlProcessNum -eq 2 ];then echo "db is running"else /etc/init.d/mysqld start sleep 10 portNum=`netstat -lnt|grep 3306|wc -l` mysqlProcessNum=`ps -ef|grep mysqld|grep -v grep|wc -l` if [ $portNum -ne 1 ] &amp;&amp; [ $mysqlProcessNum -ne 2 ];then while true;do killall mysqld &gt; /dev/null 2&gt;&amp;1 [ $? -ne 0 ] &amp;&amp; break sleep 1 done /etc/init.d/mysqld start &gt;&gt; $LogPath &amp;&amp; status="successful" || status="failure" mail -s "mysql startup status is $status" root@localost &lt; $LogPath fifi例：检查mysql是否启动，利用mysql帐号登录测试#!/bin/bash#LogPath=/tmp/mysql.logmysql -uroot -p'centos' -S /var/lib/mysql/mysql.sock -e "select version();" &gt;&amp; /dev/null# 这里的用户名与密码一定要正确，不然也会执行失败，使下面判断mysql为未启动状态。if [ $? -eq 0 ];then echo "db is running"else /etc/init.d/mysqld start &gt; $LogPath sleep 10 mysql -uroot -p'centos' -S /var/lib/mysql/mysql.sock -e "select version();" &gt;&amp; /dev/null if [ $? -ne 0 ];then while true;do killall mysqld &gt; /dev/null 2&gt;&amp;1 [ $? -ne 0 ] &amp;&amp; break # 这里只检查killall命令执行是否正确，如果正确就跳出循环。个人认为还应该加上检查进程是否存在更准确 sleep 1 done /etc/init.d/mysqld start &gt;&gt; $LogPath &amp;&amp; status="successful" || status="failure" mail -s "mysql startup status is $status" root@localost &lt; $LogPath fifi例：检查mysql是否启动的php脚本&lt;?php $link_id=mysql_connect('localhost','root','centos') or mysql_error(); if ($link_id) &#123; echo "mysql successful !"; &#125; else &#123; echo mysql_error(); &#125;?&gt;监控mysql数据库是否异常的多种方法1. 根据mysql端口号监控mysql(本地)2. 根据mysql进程监控mysql(本地)。只能本地监控，进程在服务可能不正常，如：负载很高，CPU很高，连接数满了，另外，进程也可以远程监控，如通过ssh key，expect3. 通过mysql客户端命令及用户帐户连接mysql，然后根据返回命令状态或返回内容确认mysql是否正常（本地和远程连接判断）。必须要有mysql客户端，要有数据库的帐号与密码及连接数据库主机授权。4. 通过php/java程序url方式监控mysql，此方法最接近用户访问，效果最好。报警的最佳方式不是服务是否开启了，而是网站的用户是否还能正常访问5. 以上四种方法的综合运用例：本地监控web服务[root@template sh]# vim check_web.sh #!/bin/bash#HttpPortNum=`netstat -tln|grep 80|wc -l`if [ $HttpPortNum -ge 1 ];then echo "web is running"else echo "web is not running" /etc/init.d/nginx startfi例：远程监控web服务[root@template sh]# vim check1_web.sh#!/bin/bash#HttpPortNum=`nmap 192.168.1.24 -p 80|grep open|wc -l`if [ $HttpPortNum -ge 1 ];then echo "web is running"else echo "web is not running" /etc/init.d/nginx startfi例：通过url地址远程监控web服务[root@template sh]# vim check2_web.sh #!/bin/bash#wget -T 10 -q --spider http://192.168.1.24 &gt; /dev/null# -T表示超时时间，-q表示静默模式，--spider表示爬虫if [ $? -eq 0 ];then echo "web is running"else echo "web is not running"fi例：通过状态码查看服务是否启动[root@template sh]# vim check3_web.sh #!/bin/bash#[ -f /etc/init.d/functions ] &amp;&amp; . /etc/init.d/functionshttpCode=`curl -I -s 192.168.1.24|head -1|cut -d" " -f2`if [ "$httpCode" == "200" ];then action "nginx is running" /bin/true # action是调用functions函数else action "nginx is not running" /bin/false sleep 1 /etc/init.d/nginx start action "nginx is started" /bin/truefi例：使用传参的方式查看服务是否启动[root@template sh]# vim check4_web.sh #!/bin/bash#if [ $# -ne 2 ];then echo "Usage: $0 ip port "fiPortNum=`nmap $1 -p $2 |grep open|wc -l`if [ $PortNum -eq 1 ];then echo "$1 $2 is open"else echo "$1 $2 is closed"fi case条件语句1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980语法case "字符串变量" in 值1) 指令 ... ;; 值2) 指令 ... ;; *) 指令 ... ;;esac例：[root@template sh]# vim plus_color.sh #!/bin/bash#new_chars() &#123;RED_COLOR='\E[1;31m'GREEN_COLOR='\E[1;32m'YELLOW_COLOR='\E[1;33m'BLUE_COLOR='\E[1;34m'PINK_COLOR='\E[1;35m'RES='\E[0m'if [ $# -ne 2 ];then echo "Usage $0 content &#123;red|yellow|blue|green&#125;" exitficase "$2" in red|RED) echo -e "$&#123;RED_COLOR&#125;$1$&#123;RES&#125;" ;; yellow|YELLOW) echo -e "$&#123;YELLOW_COLOR&#125;$1$&#123;RES&#125;" ;; green|GREEN) echo -e "$&#123;GREEN_COLOR&#125;$1$&#123;RES&#125;" ;; blue|BLUE) echo -e "$&#123;BLUE_COLOR&#125;$1$&#123;RES&#125;" ;; pink|PINK) echo -e "$&#123;PINK_COLOR&#125;$1$&#123;RES&#125;" ;; *) echo "Usage $0 content &#123;red|yellow|blue|green&#125;" ;;esac&#125;new_chars abc rednew_chars abc yellownew_chars abc greennew_chars abc bluenew_chars abc pink例：利用case语句启动web服务[root@template sh]# vim nginx#!/bin/bash#nginx="/etc/init.d/nginx". /etc/init.d/functionscase "$1" in start) $nginx start &gt;&amp; /dev/null [ $? -eq 0 ] &amp;&amp; action "nginx is started" /bin/true ||\ action "nginx is started" /bin/false ;; stop) $nginx stop &gt;&amp; /dev/null [ $? -eq 0 ] &amp;&amp; action "nginx is stoped" /bin/true ||\ action "nginx is stoped" /bin/false ;; restart) $nginx restart &gt;&amp; /dev/null [ $? -eq 0 ] &amp;&amp; action "nginx is restarted" /bin/true ||\ action "nginx is restarted" /bin/false ;; *) echo "Usage: $0 &#123;start|stop|restart&#125;" exit ;;esac while语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173语法while 条件;do 指令done# 条件满足就退出while读文件方式方式一exec &lt; FILEsum=0while read linedo cmddone方式二cat $&#123;FILE_PATH&#125; | while read linedo cmddone方式三while read linedo cmddone &lt; FILE例[root@template sh]# vim while1.sh#!/bin/bash#while true;do uptime sleep 2done# while true表示永远为真，是死循环[root@template sh]# vim while2.sh#!/bin/bash#while [ 1 ];do uptime usleep 1000000done# 这里的条件为[ 1 ]，也是死循环的意思。usllep是使用微秒为单位=======================================================================================ctrl+z：暂停执行当前脚本或任务bg：把当前脚本或任务放到后台执行fg：把当前脚本或任务拿到前台执行，如果有多个任务，可以fg加任务编号调出，如fg 1jobs：查看执行的脚本或任务=======================================================================================例[root@template sh]# vim while3.sh #!/bin/bash#i=1sum=0while ((i &lt;= 100));do ((sum=sum+i)) ((i++))doneecho $sum例：循环竖向打印10-1，使用双小括号[root@template sh]# vim while4.sh#!/bin/bash#i=10while ((i&gt;0));do echo $i ((i--))done例：循环竖向打印10-1，使用双中括号[root@template sh]# vim while5.sh#!/bin/bash#i=10while [[ $i&gt;0 ]];do echo $i ((i--))done# 使用双中括号时必须使用$i，而不能用i例：循环竖向打印10-1，使用单中括号[root@template sh]# vim while6.sh#!/bin/bash#i=10while [ $i -gt 0 ];do echo $i ((i--)) # 这里也可以写为let i--或i=$[$i-1]，中括号中不能写成i--这样的形式。done# 使用单中括号时，while的比较运算符要使用-gt的形式，或使用\&gt;的形式，也就是使用大于号时要转义例：[root@template sh]# vim while7.sh#!/bin/bash#read -t 20 -p "pls input the num: " iwhile ((--i));do# 当i为0时就会退出循环 echo $idone例：测试负载均衡是否平均分配到了节点[root@template sh]# vim while8.sh#!/bin/bash#while true;do curl -I -s http://www.test.com|head -1 sleep 10done例：数组方法[root@template sh]# vim check_url.sh#!/bin/bash#. /etc/init.d/functionsurl_list=(http://www.baidu.comhttp://www.sina.comhttp://www.sohu.comhttp://192.168.1.24)wait_time() &#123; echo -n "3秒后，执行此操作" for ((i=0;i&lt;3;i++));do echo -n ".";sleep 1 done echo&#125;check_url() &#123; wait_time echo 'check url...' for ((i=0;i&lt;`echo $&#123;#url_list[*]&#125;`;i++));do judge=($(curl -I -s $&#123;url_list[$i]&#125;|head -1|tr "\r" "\n"))# 这里还是将结果当作一个数组传给judge变量，下面对数组的各值做判断。 if [[ "$&#123;judge[1]&#125;" == '200' &amp;&amp; "$&#123;judge[2]&#125;" == 'OK' ]];then # 这里的问题是只以200状态码与OK为正常，如果是301也是正常的，但这里就会判断为不正常。 action "$&#123;url_list[$i]&#125;" /bin/true else action "$&#123;url_list[$i]&#125;" /bin/false fi done&#125;check_url=======================================================================================curl命令-I/--head：只显示响应报文首部信息-s/--silent：静音模式。不输出任何东西-o/--output：把输出写到一个文件中，这是保存网页的方法-w/--write-out [format]：如 -w %&#123;http_code&#125;可以取得网页的状态码。例curl -o /dev/null -s -w %&#123;http_code&#125; www.linux.com=======================================================================================例：读日志文件，计算其中所有行的日志各元素的访问字节数的总和[root@template sh]# vim while9.sh #!/bin/bash#sum=0while read line;do size=`echo $line|awk '&#123;print $10&#125;'` # 以空格为分隔符，日志的第10段是访问数据的大小 [ "$size" == "-" ] &amp;&amp; continue ((sum=sum+$size))done &lt; /var/log/nginx/access.logecho $sum until语句12345语法until 条件;do 指令done# 条件不满足就退出，until应用场合不多见 for循环12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758语法for 变量名 in 变量取值列表do 指令done# 在此结构中"in 变量取值列表"可省略，省略时相当于in "$@"，使用for i 就相当于使用for i in "$@" for ((exp1;exp2;exp3))do 指令done例[root@template sh]# vim for1.sh#!/bin/bash#size=`awk '&#123;print $10&#125;' $1`sum=0for num in $size;do [ -n "$num" -a "$num" = "$&#123;num//[^0-9]/&#125;" ] || continue # 这里要判断一下，$sum是否不为空，再判断，替换了$num中开头的数字后，$num是否等于$num，如果等于，说明这里有字母，就退出本轮循环。 ((sum=$num+sum))doneecho "Log size: $sum bytes=`echo $(($sum/1024))`KB"[root@template sh]# ./for1.sh /var/log/nginx/access.log Log size: 139959 bytes=136KB另一种方法[root@template sh]# echo `awk '&#123;print $10&#125;' /var/log/nginx/access.log|grep -v -|tr "\n" "+"|sed 's/3698+$/3698/'`|bc139959例：批量改名[root@template sh]# vim for2.sh#!/bin/bash#for filename in `ls *.jpg`;do mv $filename `echo $filename|cut -d . -f1`.gitdone例：乘法表[root@template sh]# vim for3.sh#!/bin/bash#for i in `seq 9`;do for j in `seq 9`;do [ $j -le $i ] &amp;&amp; echo -en "$j * $i = `expr $i \* $j` \c" # -n表示不换行输出，-e表示激活转义字符，\c表示最后不加上换行符号 done echo " "done例：访问十次页面[root@template sh]# vim for4.sh #!/bin/bash#for ((i=0;i&lt;=10;i++));do curl http://192.168.1.24/index1.htmldone 取随机数的方法1234567891011121314151617181920212223242526272829303132方法一[root@template sh]# echo $RANDOM9066方法二[root@template sh]# openssl rand -base64 8sT9rgkzhDKQ=[root@template sh]# openssl rand -base64 10dK5aymAlYRlJxA==方法三[root@template sh]# date +%s%N1547475685362659766# 通过时间获取随机数方法四[root@template sh]# head /dev/urandom | cksum 3543804650 1922# /dev/random设备，存储着系统当前运行的环境的实时数据。它可以看作是系统某个时候，唯一值数据，因此可以用作随机数元数据。/dev/urandom这个设备数据与random里面一样，只是，它是非阻塞的随机数发生器，读取操作不会产生阻塞。方法五[root@template sh]# cat /proc/sys/kernel/random/uuid 9794b963-3311-483e-aa9b-ace2df623d07方法六[root@template sh]# yum install -y expect[root@template sh]# mkpasswd -l 8E&gt;jC45ut[root@template sh]# cat /proc/sys/kernel/random/uuid | md5sum | cut -c 1-9c1baddd2e# 上面的命令得到随机数后都通过md5sum再计算一次得到一个数字，到通过cut命令取指定长度的数字。cut的-c选项就是仅显示行中指定范围的字符 break、continue、exit对比 命令 说明 break n n表示跳出循环的层数，如果省略n表示跳出整个循环 continue n n表示退出到第n层继续循环，如果省略n表示跳过本次循环，忽略本次循环的接任代码，进入循环的下一次循环 exit n 退出当前shell程序，终止整个shell脚本，并返回n。n也可以省略。 return 与exit相似，在函数中使用，用于跳出函数 shell函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283语法简单的语法：函数名() &#123; 指令 return n&#125;规范的语法：function 函数名() &#123; 指令 return n&#125;调用函数：1. 直接执行函数名即可。注意，不需要带小括号例：函数名2. 带参数的函数执行方法：例：函数名 参数1 参数2# 在函数体中的位置参数($1、$2、$3、$#、$*、$?、$@)都可以是函数# 父脚本的参数则临时地被函数参数所掩盖或隐藏# $0比较特殊，它仍然是父脚本的名称# 函数一定要在调用之前定义并加载例[root@template sh]# vim func1.sh#!/bin/bash#if [ $# -ne 1 ];then echo "error" &amp;&amp; exit 1fiCheck_Url() &#123; curl -I -s $1|head -1 &amp;&amp; return 0||return 1&#125;Check_Url $1# Check_Url后的$1是命令行的第一个参数，curl中的$1是函数的第一个参数。这两个$1的作用是不一样的例：生产环境批量检查web服务是否正常并且发送相关邮件[root@template sh]# vim check_service.sh#!/bin/bash#RETVAL=0FAILCOUNT=0SCRIPTS_PATH="/root/sh"MAIL_GROUP="root@localhost"LOG_FILE="/tmp/web_check.log"GetUrlStatus() &#123; for ((i=1;i&lt;=3;i++));do wget -T 10 --tries=1 --spider http://$&#123;1&#125; &gt; /dev/null 2&gt;&amp;1 [ $? -ne 0 ] &amp;&amp; let FAILCOUNT+=1 done # 访问三次页面，如果返回值不是0，变量FAILCOUNT就自增1。 if [ $FAILCOUNT -gt 1 ];then RETVAL=1 NowTime=`date +"%m-%d %H:%M:%S"` SC="http://$&#123;1&#125; service is error,$&#123;NowTime&#125;." echo "send to : $MAIL_USER, Title: $SUBJECT_CONTENT" &gt; $LOG_FILE for MAIL_USER in $MAIL_GROUP;do mail -s "$SC" $MAIL_USER &lt; $LOG_FILE done else RETVAL=0 fi return $RETVAL # 判断变量FAILCOUNT是否大于1，如果大于1,就发邮件，并记入日志文件，并将变量RETVAL的值改为1，否则RETVAL的值是0，RETVAL的值就是返回码，退出函数。&#125;[ ! -d "$SCRIPTS_PATH" ] &amp;&amp; mkdir -p $SCRIPTS_PATH[ ! -f "$SCRIPTS_PATH"/domain.list ] &amp;&amp; &#123;cat &gt; $SCRIPTS_PATH/domain.list &lt;&lt; ENDwww.baidu.comwww.sohu.com192.168.1.24END&#125;# 判断变量SCRIPTS_PATH指定的目录是否存在，不存在就创建，再判断变量SCRIPTS_PATH中的domain.list文件是否存在，不存在就创建，其中是网页地址。for URL in `cat $SCRIPTS_PATH/domain.list`;do echo -n "checking $URL: " GetUrlStatus $URL &amp;&amp; echo ok || echo nodone# 循环检查domain.list文件中的网址，将变量URL的值给GetUrlStatus函数，在GetUrlStatus函数中由$1接收。如果返回值是0就显示ok，否则显示no[root@template sh]# bash check_service.sh checking www.baidu.com: okchecking www.sohu.com: okchecking 192.168.1.24: noYou have new mail in /var/spool/mail/root 优化linux系统12345678910111. 安装系统时精简安装包，最小化安装2. 配置国内高速yum源3. 禁用开机不需要启动的服务4. 优化系统内核参数，/etc/sysctl.conf5. 增加系统文件描述符、堆栈等配置6. 有外网IP的机器要开启配置防火墙，仅对外开启需要提供服务的端口，配置或关闭selinux7. 清除无用的默认系统帐户或组（非必须）8. 锁定敏感文件，如/etc/passwd（非必须）9. 配置服务器和互联网时间同步10. 配置sudo对普通用户权限精细控制11. 把以上10点写成一键优化脚本 数组1234567891011121314151617181920212223242526272829303132333435363738394041方法一array=(value1 value2 value3 ...)echo $&#123;#array[@]&#125;echo $&#123;#array[*]&#125;echo $&#123;#array[0]&#125;# 计算数组中的共有几个值echo $&#123;array[*]&#125;# 列出数组中的所有值echo $&#123;array[0]&#125;# 列出数组中的某个值，数组的下标从0开始array[3]=4# 给某个数组下标赋值array[0]=abc# 给已有的数组下标修改值unset array# 删除整个数组unset array[0]# 删除数组中某个下标的值echo $&#123;array[@]:1:3&#125;# 从第几个元素开始截取，截取几个array=($&#123;array[@]/5/6&#125;)# 将第5个元素的值改为6echo $&#123;array[@]#o&#125;# 从左开始最短匹配删除echo $&#123;array[@]#fo&#125;echo $&#123;array[@]%t*e&#125;echo $&#123;array[@]%%t*e&#125;# 数组也是变量，因此也适合于变量的子串处理的功能应用。方法二array=([1]=one [2]=two [3]=three)# 定义下标与值方法三array[0]=a array[1]=b array[2]=c 方法四declare -a array方法五array=($(ls)) trap信号12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849trap使用信号的方法trap命令用于指定在接收到信号后将要采取的行动。trap命令的一种常见用途是在脚本程序被中断时完成清理工作。历史上，shell总是用数字来代表信号，而新的脚本程序应该使用的名字，它们保存在用#include命令包含进来的signal.h头文件中，在使用信号名时需要省略SIG前缀。你可以在命令提示符下输入命令trap -l来查看信号编号及其关联的名称。脚本程序通常是以从上到下的顺序解释执行的，所以必须在你想保护的那部分代码以前指定trap命令。如果要重置桔某个信号的处理条件到其默认值，只需简单的将command设置为-。如果要忽略某个信号，就把command设置为空字符串''，一个不带参数的trap命令将列出当前设置的信号及其行动的清单。exit命令后传输就是就是这个信号的代码例[root@template ~]# trap "" 2# 屏蔽ctrl+c信号 [root@template ~]# trap ":" 2# 恢复ctrl+c信号 [root@template ~]# trap "echo -n 'you are typing ctrl+c'" 2 [root@template ~]# ^Cyou are typing ctrl+c# 设置一个提示，当输入指定信号时就会提示[root@template ~]# trap "" HUP INT QUIT TSTP TERM# 屏蔽多个信号[root@template ~]# trap ":" HUP INT QUIT TSTP TERM# 恢复多个信号 例[root@template sh]# vim showdate.sh#!/bin/bash#trap 'echo “you go…”;exit 1' INTwhile :; do date sleep 2done# 捕捉到信號，顯示命令。要想用ctrl+c退出，要在echo you go后加&amp;&amp; exit 1例[root@template sh]# vim ping.sh #!/bin/sh#NET=192.168.1FILE=`mktemp /tmp/file.XXXXX`clearup() &#123; echo “quit…” rm -f $FILE exit 1&#125;trap 'clearup' INT# 测试发现，只要有退出码，就可以使用ctrl+c退出脚本。如上面的退出码是exit 1。如果注释了上面的函数，再使用ctrl+c退出时只能退出当前ping的命令，脚本会继续ping下一个地址。for I in &#123;200..254&#125;; do if ping -c 1 -W 1 $NET.$I &amp;&gt; /dev/null; then echo “$NET.$I is up .” | tee &gt;&gt; $FILE else echo “$NET.$I is down” fidone]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>ShellScript语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis命令]]></title>
    <url>%2F2019%2F01%2F08%2Fredis%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[安装12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@test ~]# yum install -y redis[root@test ~]# rpm -ql redis/etc/logrotate.d/redis/etc/redis-sentinel.conf/etc/redis.conf/etc/systemd/system/redis-sentinel.service.d/etc/systemd/system/redis-sentinel.service.d/limit.conf/etc/systemd/system/redis.service.d/etc/systemd/system/redis.service.d/limit.conf/usr/bin/redis-benchmark：评估redis性能/usr/bin/redis-check-aof：检测工具/usr/bin/redis-check-rdb：检测工具/usr/bin/redis-cli/usr/bin/redis-sentinel/usr/bin/redis-server：主程序/usr/lib/systemd/system/redis-sentinel.service/usr/lib/systemd/system/redis.service/usr/libexec/redis-shutdown.../var/lib/redis：数据存储目录/var/log/redis/var/run/redis[root@test ~]# systemctl start redis# 启动[root@test ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:6379 *:* # 监听127地址的6379端口，要监听在所有地址，需要认证，只有密码，没有用户名[root@test ~]# redis-cli -h localhost -p 6379# 连接本机的redis，-h指定地址，-p指定端口，-a指定密码，连接本机时不用密码localhost:6379&gt; SELECT 0OK# 切换数据库，数据库以数字表示，默认是16个库，0－15# help @&lt;group&gt;可查看一组命令的使用格式；help &lt;command&gt;可查看单个命令的使用方法；help &lt;tab&gt;可切换命令组；localhost:6379&gt; help @listlocalhost:6379&gt; SET name tomOK# 设置健为name，值为tomlocalhost:6379&gt; GET name"tom"localhost:6379&gt; APPEND name brown(integer) 8# 在name的值后追加值brownlocalhost:6379&gt; GET name"tombrown"localhost:6379&gt; STRLEN name(integer) 8# 查看name值有多长localhost:6379&gt; SET count 0OK# 设置一个计数器叫count，值为0localhost:6379&gt; INCR count(integer) 1# count计数器的值加1localhost:6379&gt; INCRBY count 10(integer) 11# 在count计数器上加10localhost:6379&gt; DECR count(integer) 10# 计数器减1localhost:6379&gt; DECRBY count 3(integer) 7# 计数器减3# 先进先出FIFO(First IN First Out)，后进先出 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120* 查看配置语法redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME例 localhost:6379&gt; CONFIG GET loglevel1) "loglevel"2) "notice"localhost:6379&gt; CONFIG GET * 1) "dbfilename" 2) "dump.rdb" 3) "requirepass" ... # 使用 * 号获取所有配置项 * 编辑配置 语法 redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 例 localhost:6379&gt; CONFIG SET loglevel "notice" OK [root@test ~]# vim /etc/redis.conf daemonize no # Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 pidfile /var/run/redis.pid # 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 port 6379 # 指定Redis监听端口，默认端口为6379 bind 127.0.0.1 # 绑定的主机地址 timeout 300 # 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 loglevel verbose # 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose logfile stdout # 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null databases 16 # 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库id save &lt;seconds&gt; &lt;changes&gt; # 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 # Redis默认配置文件中提供了三个条件： # save 900 1 # save 300 10 # save 60 10000 # 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 rdbcompression yes # 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 dbfilename dump.rdb # 指定本地数据库文件名，默认值为dump.rdb dir ./ # 指定本地数据库存放目录 slaveof &lt;masterip&gt; &lt;masterport&gt; # 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 masterauth &lt;master-password&gt; # 当master服务设置了密码保护时，slav服务连接master的密码 requirepass foobared # 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭 maxclients 128 # 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxmemory &lt;bytes&gt; # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 appendonly no # 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendfilename appendonly.aof # 指定更新日志文件名，默认为appendonly.aof appendfsync everysec # 指定更新日志条件，共有3个可选值： # no：表示等操作系统进行数据缓存同步到磁盘（快） # always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） # everysec：表示每秒同步一次（折中，默认值） vm-enabled no # 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中 vm-swap-file /tmp/redis.swap # 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-max-memory 0 # 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-page-size 32 # Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值 vm-pages 134217728 # 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。 vm-max-threads 4 # 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 glueoutputbuf yes # 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 # 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 activerehashing yes # 指定是否激活重置哈希，默认为开启 include /path/to/local.conf # 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 List（列表）123456789101112131415161718192021222324252627282930313233343536373839localhost:6379&gt; LPUSH weekdays Mon Tue(integer) 2# 追加一个weekdays队列，但从右进，值是Mon Tuelocalhost:6379&gt; LINDEX weekdays 0"Tue"# 查看队列最左侧的索引值，显示Tuelocalhost:6379&gt; LRANGE weekdays 0 11) "Tue"2) "Mon"# 获取列表指定范围内的元素localhost:6379&gt; RPUSH weekdays Wed Thu(integer) 4# 向weekdays队列中追加值Wed和Thulocalhost:6379&gt; LINDEX weekdays 3"Thu"# 查看索引为3的值。因为是从0开始编号的，所以第3个是Thulocalhost:6379&gt; LRANGE weekdays 0 51) "Tue"2) "Mon"3) "Wed"4) "Thu"# 获取列表指定范围内的元素localhost:6379&gt; LPOP weekdays"Tue"# 从weekdays队列最左侧删除数据localhost:6379&gt; RPOP weekdays"Thu"# 从weekdays队列最右侧删除数据localhost:6379&gt; LINSERT weekdays BEFORE Wed Fri(integer) 3# 在Wed前插入数据Fri。BEFORE在指定元素前插入数据，AFTER是在指定元素之后插入数据localhost:6379&gt; LINDEX weekdays 1"Fri"# 显示Fri，因为上面将Fri插入在了原来索引为1的Web前localhost:6379&gt; LRANGE weekdays 0 101) "Mon"2) "Fri"3) "Wed"# 获取列表指定范围内的元素 hash（哈希）12345678910111213141516171819202122232425262728293031323334localhost:6379&gt; HSET stu1 name tom(integer) 1# 定义一个名字叫stu1的表name名字叫tomlocalhost:6379&gt; HSET stu1 age 17(integer) 1localhost:6379&gt; HMSET stu1 gender Male major KuihuaOK# HMSET可以设置多个下标，gender和major是下标，Male和Kuihua是值localhost:6379&gt; HKEYS stu11) "name"2) "age"3) "gender"4) "major"# 查看stu1的下标的名字localhost:6379&gt; HVALS stu11) "tom"2) "17"3) "Male"4) "Kuihua"# 查看下标的值localhost:6379&gt; HDEL stu1 major(integer) 1# 删除stu1的下标majorlocalhost:6379&gt; HKEYS stu11) "name"2) "age"3) "gender"# 查看下标localhost:6379&gt; HLEN stu1(integer) 3# 查看key上有几个元素localhost:6379&gt; HSTRLEN stu1 name(integer) 3# 查看name元素有几个字节 Set（集合）1234567891011121314151617181920212223242526272829303132333435363738394041localhost:6379&gt; SADD tom lucy lily hanmeimei(integer) 3# 创建一个集合叫tom，tom后的是他的好友的名字localhost:6379&gt; SADD jerry lucy obama trump(integer) 3localhost:6379&gt; SINTER tom jerry1) "lucy"# 查看tom和jerry的交集localhost:6379&gt; SUNION tom jerry1) "lucy"2) "lily"3) "hanmeimei"4) "trump"5) "obama"# 查看tom和jerry的并集localhost:6379&gt; SDIFF tom jerry1) "lily"2) "hanmeimei"# 查看差集，tom有的而jerry没有朋友的名字localhost:6379&gt; SDIFF jerry tom1) "trump"2) "obama"localhost:6379&gt; SMEMBERS tom1) "lily"2) "lucy"3) "hanmeimei"# 查看tom集合的所有元素localhost:6379&gt; SMEMBERS jerry1) "trump"2) "obama"3) "lucy"localhost:6379&gt; SUNIONSTORE friends tom jerry(integer) 5# 查看并集并保存，保存的键名叫friendslocalhost:6379&gt; SMEMBERS friends1) "lucy"2) "lily"3) "hanmeimei"4) "trump"5) "obama"# 查看 sorted set（有序集合）123456789101112131415161718192021localhost:6379&gt; ZADD colors 1 red 2 blue 8 green 5 gray(integer) 4# 创建一个叫colors的集合。添加时提示“OOM command not allowed when used memory &gt; 'maxmemory'”，是因为配置文件中设置了maxmemory的值，现在已经达到了上限，所以报错。localhost:6379&gt; ZCARD colors(integer) 4# 查看colors有几个成员localhost:6379&gt; ZSCORE colors green"8"# 查看成员green的分数localhost:6379&gt; ZCOUNT colors 2 6(integer) 2# 统计一个范围分数的成员个数localhost:6379&gt; ZRANGE colors 0 51) "red"2) "blue"3) "gray"4) "green"# 返回所指范围内的值localhost:6379&gt; ZRANK colors gray(integer) 2# 查看元素的索引是几 发布订阅12345678910111213141516171819202122232425262728293031323334353637localhost:6379&gt; SUBSCRIBE militaryReading messages... (press Ctrl-C to quit)1) "subscribe"2) "military"3) (integer) 1# 订阅频道，这时会停留在频道中再打开一个窗口连接redis[root@test ~]# redis-cli -h localhostlocalhost:6379&gt; PUBLISH military caoxian(integer) 1# 向military频道中发布一条信息回到之前的窗口，这时会显示刚发布的信息localhost:6379&gt; SUBSCRIBE military financeReading messages... (press Ctrl-C to quit)1) "subscribe"2) "military"3) (integer) 11) "subscribe"2) "finance"3) (integer) 2# 在第一个窗口重新订阅两个频道到新窗口重新发布信息localhost:6379&gt; PUBLISH finance bitcorn(integer) 1回到之前的窗口[root@test ~]# redis-cli -h localhost -p 6379localhost:6379&gt; SUBSCRIBE military financeReading messages... (press Ctrl-C to quit)1) "subscribe"2) "military"3) (integer) 11) "subscribe"2) "finance"3) (integer) 21) "message"2) "finance"3) "bitcorn" 认证12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@test ~]# vim /etc/redis.confrequirepass mageedu# 设置密码为mageedu[root@test ~]# redis-cli127.0.0.1:6379&gt; GET name(error) NOAUTH Authentication required.# 这时是不能使用的，要密码127.0.0.1:6379&gt; AUTH mageeduOK# 给密码127.0.0.1:6379&gt; GET name"tombrown"# 这时就能得到数据了127.0.0.1:6379&gt; INFO Server# Serverredis_version:3.2.12redis_git_sha1:00000000redis_git_dirty:0redis_build_id:7897e7d0e13773fredis_mode:standaloneos:Linux 3.10.0-693.el7.x86_64 x86_64arch_bits:64multiplexing_api:epollgcc_version:4.8.5process_id:2591run_id:af2243e0cf36e57e000b383901b8c832530fc91etcp_port:6379uptime_in_seconds:74uptime_in_days:0hz:10lru_clock:3412915executable:/usr/bin/redis-serverconfig_file:/etc/redis.conf# 查看服务器信息127.0.0.1:6379&gt; INFO# 查看所有信息127.0.0.1:6379&gt; INFO Clients# Clientsconnected_clients:1client_longest_output_list:0client_biggest_input_buf:0blocked_clients:0127.0.0.1:6379&gt; INFO Memory# Memoryused_memory:814480used_memory_human:795.39Kused_memory_rss:5947392used_memory_rss_human:5.67Mused_memory_peak:815328used_memory_peak_human:796.22Ktotal_system_memory:1023713280total_system_memory_human:976.29Mused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionmem_fragmentation_ratio:7.30mem_allocator:jemalloc-3.6.0# 内存信息，其中的maxmemory_policy:noeviction表示最大内存用尽后的策略，noeviction表示不处理，新数据就没法存了。还可以使用内存的淘汰策略localhost:6379&gt; CLIENT LISTid=2 addr=127.0.0.1:44490 fd=5 name= age=216 idle=44 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=clientid=3 addr=127.0.0.1:44492 fd=6 name= age=10 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client# 显示所有连接上服务器的客户端 测试：修改配置文件1234567891011121314151617181920212223242526272829303132333435363738[root@test ~]# vim /etc/redis.conf #######INCLUDES############## //包含段 #####NETWORK######### bind 0.0.0.0 # 监听所有地址 protected-mode yes # 是否工作在保护模式，无论监听哪个地址，都只能本机连接。不使用监听地址和认证功能此项才生效 prot 6379 # 监听端口 timeout 0 # 客户端空闲超时时间，超时就与客户端断开连接 tcp-keepalive 300 # 客户端与服务器tcp连接保持时长 ######SECURITY####### requirepass mageedu # 认证密码 ########LIMITS###### maxclients 10000 # 最大并发连接数 maxmemory # 最大内存。最好手动设置 maxmemory-policy # 内存淘汰策略；noeviction不启用淘汰机制； maxmemory-samples 5 # 淘汰的样本数量，每次找5个并淘汰1个 ######SLOW LOG##### slowlog-log-slower-than 10000 # 慢查询的时间，微秒[root@test ~]# systemctl restart redis* 换一台主机[root@test ~]# redis-cli -h 192.168.1.14192.168.1.14:6379&gt; GET name(error) NOAUTH Authentication required.192.168.1.14:6379&gt; auth mageeduOK192.168.1.14:6379&gt; get name"tombrown" 实时配置12345678910111213141516171819202122232425127.0.0.1:6379&gt; CONFIG GET requirepass1) "requirepass"2) "mageedu"127.0.0.1:6379&gt; CONFIG SET requirepass 123456OK127.0.0.1:6379&gt; CONFIG GET requirepass1) "requirepass"2) "123456"# 将密码从mageedu改为123456127.0.0.1:6379&gt; CONFIG REWRITEOK# 将内存中的数据覆盖配置文件中的值127.0.0.1:6379&gt; CONFIG SET appendonly yesOK# 启动AOF功能.这是为了让数据在写入内存时就记入日志，防止断电时数据丢失[root@test ~]# vim /etc/redis.conf requirepass "123456"aof-rewrite-incremental-fsync yes# 配置文件中有两条配置了[root@test ~]# ls /var/lib/redis/appendonly.aof dump.rdb# 这时有.aof的文件了127.0.0.1:6379&gt; CONFIG RESETSTATOK# 重置INFO命令输出的数据 主从复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 准备三台主机，node1-3，第一台为主节点，后两台为从节点* node1 192.168.1.14[root@node1 ~]# vim /etc/redis.conf bind 0.0.0.0 requirepass "123456"[root@node1 ~]# systemctl restart redis* node2、3 192.168.1.15 192.168.1.13[root@node2 ~]# vim /etc/redis.conf bind 0.0.0.0 requirepass "123456"[root@node2 ~]# systemctl start redis[root@node2 ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:6379 *:* 127.0.0.1:6379&gt; SLAVEOF 192.168.1.14 6379OK# 指明主节点地址和端口就可以了127.0.0.1:6379&gt; CONFIG SET masterauth 123456OK# 设置主节点的认证密码127.0.0.1:6379&gt; CONFIG REWRITEOK# 写入配置文件=======================================================================================也可以直接写入配置文件[root@node3 ~]# vim /etc/redis.confslaveof 192.168.1.14 6379masterauth "123456"=======================================================================================* node1 192.168.1.14127.0.0.1:6379&gt; INFO Replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.15,port=6379,state=online,offset=197,lag=1slave1:ip=192.168.1.13,port=6379,state=online,offset=197,lag=0master_repl_offset:197repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:196# 可以看到两个从节点* node2 192.168.1.15127.0.0.1:6379&gt; GET name"tombrown"# 可以看到有信息了* node3 192.168.1.13127.0.0.1:6379&gt; GET name"tombrown"127.0.0.1:6379&gt; SMEMBERS jerry1) "lucy"2) "obama"3) "trump"# node3上也可以查询到信息了127.0.0.1:6379&gt; CONFIG GET slave-read-only1) "slave-read-only"2) "yes"# 查看从节点的配置是否为只读。只有当前节点为从节点时才有效。可以通过CONFIG SET slave-read-only no来设置此项为yes或no127.0.0.1:6379&gt; SET hikey hellothere(error) READONLY You can't write against a read only slave.# 在从节点上是不可以设置数据的，有错误提示 redis-sentinel123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247# 准备三台主机，node1：192.168.1.14，node2：192.168.1.15，node3：192.168.1.13* 三台主机[root@node1 ~]# vim /etc/sudoers # Defaults requiretty# 如果有此项就注释掉[root@node1 ~]# vim /etc/sudoers.d/redis redis ALL=(ALL) NOPASSWD:/sbin/ip,NOPASSWD:/sbin/arping# 这是为了让redis用户使用sudo命令时不用密码也可执行ip和arping命令。因为redis-sentinel进程是以redis身份运行的，所以执行脚本时也是redis用户，但redis用户是没有权限设置本机地址的，所以要给它权限。[root@node1 ~]# vim /opt/notify_mymaster.sh#!/bin/bash#MASTER_IP=$&#123;6&#125;LOCAL_IP='192.168.1.14'# 设置为每台主机的本地地址VIP='192.168.1.10'# 虚拟IP地址不能变NETMASK='24'INTERFACE='ens33'# 本地地址所在的网卡if [ $&#123;MASTER_IP&#125; = $&#123;LOCAL_IP&#125; ];then sudo /usr/sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; sudo /usr/sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else sudo /usr/sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; exit 0fiexit 1[root@node1 ~]# chmod 777 /opt/notify_mymaster.sh# 脚本一定要有执行权限，不然sentinel服务无法启动* node1[root@node1 ~]# /etc/redis.conf bind 0.0.0.0[root@node1 ~]# systemctl start redis[root@test ~]# redis-cli127.0.0.1:6379&gt; CONFIG SET requirepass redisqwer1234OK127.0.0.1:6379&gt; CONFIG SET masterauth redisqwer1234OK127.0.0.1:6379&gt; CONFIG REWRITEOK* node2&amp;3[root@node1 ~]# /etc/redis.conf bind 0.0.0.0[root@node1 ~]# systemctl start redis127.0.0.1:6379&gt; slaveof 192.168.1.14 6379OK Already connected to specified master127.0.0.1:6379&gt; CONFIG SET masterauth redisqwer1234OK127.0.0.1:6379&gt; CONFIG SET requirepass redisqwer1234OK127.0.0.1:6379&gt; CONFIG REWRITEOK# 这里的三个节点都应该设置masterauth和requirepass的值，requirepass的值是自己作为主节点时，别人请求要用的认证密码。masterauth是与主节点通信时要用到的认证密码。也就是说，masterauth指向的密码就是requirepass设置的密码。因为三个节点都可以做主节点，所以都要设置。如果只设置一个，那么在主节点查看从节点信息时，有可能只显示一个。可在从节点查看/var/log/redis/redis.conf日志，日志中会显示不能加入集群的信息* node1127.0.0.1:6379&gt; INFO replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.15,port=6379,state=online,offset=351,lag=0slave1:ip=192.168.1.13,port=6379,state=online,offset=351,lag=1master_repl_offset:351repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:350[root@node1 ~]# vim /etc/redis-sentinel.confport 26379bind 0.0.0.0dir "/tmp"sentinel myid 8da3fbcd01dafcbb9558f1ac5b52406a3afd00desentinel monitor mymaster 192.168.1.14 6379 2# sentinel监听主节点的地址和端口，2表示至少有几个sentinel进行选举才能通过sentinel down-after-milliseconds mymaster 5000# 多久连接不到主节点就认为它宕机了，这是主观宕机。这里默认是30秒，可改为5000sentinel failover-timeout mymaster 60000# 故障转移多久完成不了，就进行新的转移。这个时间不要太短。这里是3分钟sentinel parallel-syncs 1# 一次只给几个从节点同步。并行同步的数量sentinel auth-pass mymaster redisqwer1234# 认证mymaster的主节点的密码，建议用随机字符串。如果不写此项就无法用sentinel slaves mymaster命令查看到从节点的信息sentinel config-epoch mymaster 0sentinel client-reconfig-script mymaster /opt/notify_mymaster.sh# 故障转移时执行notify_mymaster.sh脚本。加入这一行，sentinel的client-reconfig-script在每次执行时会传递出7个参数，第6个就是主redis的地址，所以脚本中定义了MASTER_IP=$&#123;6&#125;logfile "/var/log/redis/sentinel.log"supervised systemdsentinel leader-epoch mymaster 0sentinel known-slave mymaster 192.168.1.13 6379sentinel known-slave mymaster 192.168.1.15 6379sentinel current-epoch 0# 上面五行是启动sentinel后自动添加的[root@test ~]# scp /etc/redis-sentinel.conf 192.168.1.13:/etc[root@test ~]# scp /etc/redis-sentinel.conf 192.168.1.15:/etc# 将配置文件复制到另两个节点[root@test ~]# systemctl start redis-sentinel# 从主节点启动三个节点的服务[root@test ~]# redis-cli -h 192.168.1.14 -p 26379# 在主节点连接192.168.1.14:26379&gt; SENTINEL master mymaster 1) "name" 2) "mymaster" 3) "ip" 4) "192.168.1.14" 5) "port" 6) "6379" 7) "runid" 8) "84336d6f7ef4fddbc8d21622fabfedd6e3354817" 9) "flags"10) "master"11) "link-pending-commands"12) "0"13) "link-refcount"14) "1"15) "last-ping-sent"16) "0"17) "last-ok-ping-reply"18) "963"19) "last-ping-reply"20) "963"21) "down-after-milliseconds"22) "5000"23) "info-refresh"24) "3142"25) "role-reported"26) "master"27) "role-reported-time"28) "1177509"29) "config-epoch"30) "0"31) "num-slaves"32) "2" # 可以看到从节点的数量33) "num-other-sentinels"34) "0"35) "quorum"36) "2"37) "failover-timeout"38) "60000"39) "parallel-syncs"40) "1"41) "client-reconfig-script"42) "/opt/notify_mymaster.sh"192.168.1.14:26379&gt; SENTINEL slaves mymaster1) 1) "name" 2) "192.168.1.13:6379" 3) "ip" 4) "192.168.1.13" 5) "port" 6) "6379" 7) "runid" 8) "80bc33312e088d2238d455269493e1cb22e78576" 9) "flags" 10) "slave" 11) "link-pending-commands" 12) "0" 13) "link-refcount" 14) "1" 15) "last-ping-sent" 16) "0" 17) "last-ok-ping-reply" 18) "6" 19) "last-ping-reply" 20) "6" 21) "down-after-milliseconds" 22) "5000" 23) "info-refresh" 24) "5510" 25) "role-reported" 26) "slave" 27) "role-reported-time" 28) "1260331" 29) "master-link-down-time" 30) "0" 31) "master-link-status" 32) "ok" # 这里的状态应该显示OK 33) "master-host" 34) "192.168.1.14" 35) "master-port" 36) "6379" 37) "slave-priority" 38) "100" 39) "slave-repl-offset" 40) "311944"2) 1) "name" 2) "192.168.1.15:6379" 3) "ip" 4) "192.168.1.15" 5) "port" 6) "6379" 7) "runid" 8) "524e2a7f1c021b610272b7d5a71629617279238d" 9) "flags" 10) "slave" 11) "link-pending-commands" 12) "0" 13) "link-refcount" 14) "1" 15) "last-ping-sent" 16) "0" 17) "last-ok-ping-reply" 18) "6" 19) "last-ping-reply" 20) "6" 21) "down-after-milliseconds" 22) "5000" 23) "info-refresh" 24) "5663" 25) "role-reported" 26) "slave" 27) "role-reported-time" 28) "1260331" 29) "master-link-down-time" 30) "0" 31) "master-link-status" 32) "ok" # 这里的状态应该显示OK 33) "master-host" 34) "192.168.1.14" 35) "master-port" 36) "6379" 37) "slave-priority" 38) "100" 39) "slave-repl-offset" 40) "311805" [root@test ~]# ip addr add 192.168.1.111/24 dev ens33 # 第一次启动需要手动配置VIP地址 [root@test opt]# redis-cli -p 26379 127.0.0.1:26379&gt; sentinel failover mymasterOK# 这样可以切换主节点127.0.0.1:26379&gt; sentinel master mymaster# 可以查看切换后的主节点# 之后可以在切换到的主节点上执行sentinel failover mymaster命令，看一下切换的结果 =======================================================================================配置方法：1. 所有节点设置同样的requirepass和masterauth，最后要写入配置文件2. 配置redis可以设置IP地址的权限3. 配置监控脚本4. 设置sentinel脚本，将sentinel脚本复制到所有节点5. 按顺序启动主节点与从节点的sentinel服务排错方法：按配置方法设置好并启动后，在主节点的sentinel中看不到从节点的信息。可以查看各节点的/var/log/redis/sentinel.log、/var/log/redis/redis.log、/var/log/messages三个日志文件，停止三个节点的sentinel服务，按顺序从主节点启动sentinel日志，再查看日志文件中的报错。=======================================================================================]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis概念]]></title>
    <url>%2F2019%2F01%2F08%2Fredis%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[ACID 原子性（Atomic:）：要么整个事务成功，要么整个不成功。 一致性（Consistency）：数据库在事务之间处于一个一致的状态中。比方说，如果一条记录指向另一条记录，而到事务结束时这个指向是无效的，那么整个事务就必须回滚。 隔离性（Isolation）：在其他事务结束之前，事务看不到被它们更改的数据。 持久性（Durability）：一旦数据库系统通知用户事务成功，数据就永不丢失。 BASE 基本可用（Basically Available）：用户都有一种愚蠢的期望，就是当他们把浏览器指向一个网页时，就会有某些信息出现。这是你期望发生的，即便系统的某些部分宕机了也一样。这听上去微不足道，事实却并非如此；有很多系统只要一台服务器宕了，整个系统就宕了。 可伸缩（Scalable）：添加更多的服务器使得服务更多的客户成为可能。不是创建一个巨大的怪物服务器，而是添加更多的服务器，这更具有前瞻性，而且也通常更便宜。重申一下，这是用户的期望之一：信息不仅仅是出现，而且还要快速地出现。（注意这项用户期望不仅要求伸缩性，还同时要求性能。） 最终一致（Eventually Consistent）：如果数据最终在所有副本出现的地方变为可用，这就足够了（如上一点所述，你可以有很多副本）。这里的期望是，信息要快速出现才会显得及时。 当你在Craigslist上发布一个广告，它不会马上出现在列表和搜索结果中，这不是太大的问题；但如果一个广告需要几天才出现，就没有人会去用那个网站了。 CAP C: Consistency 一致性：多个数据节点上的数据一致； A: Availability 可用性(指的是快速获取数据)：用户发出请求后的有限时间范围内返回结果； P: Tolerance of network Partition 分区容忍性(分布式)：网络发生分区后，服务是否依然可用； BASE一般与由大量服务器组成的系统有关。在一致性、可用性和分区宽容度这三者中，你只能选择两者而不能三者兼而有之。在任何时间点，不管哪台服务器应答了一个请求，所有服务器都会给出同样的答案。可用性的意思是即使某些服务器宕机了，整个系统仍能正常工作。最后，分区宽容度是指两台服务器之间的通信可以丢失，而系统仍能正常工作。虽然SQL数据库大多是兼容ACID的，但注重BASE的数据库更适合Web应用程序。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql客户端命令]]></title>
    <url>%2F2019%2F01%2F07%2Fmysql%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[mysql1234567891011121314151617181920212223242526272829303132333435选项--user, -u # 用户--host -h# 地址--password -p# 密码--port# 端口--protocol--database DATABASE, -D # 在连入數據庫時指定默認庫。如mysql -D mydb，在登入時指定了mydb為默認庫--compress # 語句先壓縮再發送或返回例：用mysql导入sql文件1. vim test.sql CREATE DATABASE testdb; CREATE TABLE testdb.tb1(id INT, name CHAR(20));2. mysql -uroot -p3. mysql&gt;\. /root/test.sql # 用\.載入數據庫，用soucer也可加载脚本或4. mysql &lt; test.sql # 輸入重定向也能載入數據庫5. SHOW DATABASES；# 查看载入的数据库# -e選項：不進入服務器，傳命令到服務器mysql -e 'CREATE DATABASE edb;'mysql -e 'SHOW DATABASES;'mysql -e 'SELECT * FROM jiaowu.students;'例1：插入一張表，且mysql規定第一條數據必須手動插入，之後可寫腳本輸入數據，可將下面語句寫入腳本，用變量引用字段的值，寫一個死循環mysql -e “INSERT INTO jiaowu.students (Name,Age,Gender,CID1,CID2,TID,CreateTime) VALUES ('stu1',23,'F',4,1,6);”# 测试这里一定要用双引号，单引号不行 mysqladmin123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051语法：mysqladmin [options] command [arg] [command [arg]] … # [arg]是參數create：建庫。例：mysqladmin create hellodb# 这里不用指明用户名密码等信息，因为mysqladmin可以读取到在家目录创建的.my.cnf文件 debugdrop DATABASES：刪庫ping：看數據庫是否在線。例：mysqladmin -uroot -p -h172.16.0.1 pingprocesslist：正在執行的線程列表顯示 例：mysqladmin processliststatus：狀態例：mysqladmin status --sleep 2 # 兩秒顯示一次mysqladmin status --sleep 2 --count 2 # 兩秒顯示一次共顯示兩次extended status：顯示mysql的狀態變量及其值，监控mysql服务器非常重要的手段variables：顯示服務器變量flush-privileges：讓mysqld重讀授權表flush-tables：關閉所有已打開的表flush-threads：重置線程緩存，清除线程池中的空闲线程flush-status：重置大多數的服務器狀態變量，慎用flush-logs：二進制和中繼日志滾動flush-hosts：清除主機的內部信息，包括緩存，及由於太多的登陸而拒絕的登陸flush-kill：杀死mysql的进程reload：讓mysqld重讀授權表refresh：相當於同時執行flush-hosts和flush-logsshutdown：停止mysql服務器；用start可以启动version：版本號與相關狀態信息顯示start-slave：啟動復制，啟動從服務器復制線程，一般是启动兩個进程，SQL thread, IO threadstop-slave：關閉復制線程 mysqlbinlog12345678910111213141516171819202122232425262728293031选项--start-datetime--stop-datetime--start-position--stop-position# 如果不用選項會顯示全部內容例：mysqlbinlog mysql-bin.000005 # 查看內容中有文件頭的內容，這是無論如何都會顯示的mysqlbinlog --start-position=177 --stop-position=358 mysql-bin.000005 # 查看位置從177到358mysqlbinlog --start-datetime=’130425 15:14:39’ mysql-bin.000005 # 查看某時開始的，沒有指定結束時間會顯示到文件尾部為止mysqlbinlog --start-datetime=’130425 15:14:39’ mysql-bin.000005 &gt; /root/a.sql # 將結果重定向到一個.sql文件中，之後可導入mysql執行一次，這就是即時點恢復# 二進制日志的輪動除重啟服務器外還可以用FLUSH LOGS;来實現，這是在主服務器上，如果是從服務器就是中繼服務器才滾動# 二進制日志文件不能手動刪除，會影響mysql服務器啟動。要用mysql命令PURGE BINARY LOGS TO ‘mysql-bin.000003’; # 刪除000003以前的二進制文件SHOW BINARY LOGS; # 查看現有的所有二進制文件binlog_format # 二進制日制的格式，MIXED是混合模式log_bin # 是否記錄二進制日志]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql客户端命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql概念]]></title>
    <url>%2F2019%2F01%2F07%2Fmysql%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[约束 constraint 約束：明確有效數據範圍；定義數據時要有約束 域約束：數據類型約束 外鍵約束：引用完整性約束；是降低數據冗餘的手段；一個表中填的值一定要保證在另外一個表中有相同的值才允許使用。級連表示如果這張表被其他表依賴，如果刪除了這張表，被依賴的表也會被刪。一般不用。與外鍵約束有關。 主鍵約束：某字段能惟一標識此字段所屬的實體，並且不允許為空，不能有相同值。可當主鍵的鍵叫候選鍵。一個表只能有一個主鍵 唯一性約束：每一行的某字段都不允許出現相同值，可以為空，一張表可以有多個唯一鍵。 檢查性約束：age:int定義符合現實的邏輯。 mysql的rpm包 mysql-client ：提供客戶端及組件 mysql-debuginfo：可幫助調試mysql，一般開發人員用 my-devel：開發組件，開發用的頭文件與庫文件 mysql-embedded：嵌入式服務專用 mysql-ndb-management ：Cluster server上專用的組件，平常不用 mysql-server mysql-shared：共享庫 mysql-shared-compat：為老版本的兼容庫，是shared的補充 mysql-test：測試用組件 mysql-version.platform.src.rpm：源碼格式的rpm包 安裝後的目錄結構 bin：二進制程序，命令 data：數據目錄 include：頭文件 lib：庫文件 man：手冊 mysql-test：測試組件 scripts：初始化腳本 share：語言版本 sql-bench：基准測試 support-files：腳本、樣例、等 linux mysql啟動時查找的配置文件1234567891011121314151617每次啓動，mysql都要讀取下面文件1. /etc/my.cnf2. /etc/mysql/my.cnf3. $MYSQL_HOME/my.cnf# mysql實例運行下my.cnf。一個數據庫服務器上可以提供多個web服務主機，mysql也可以提供多個不同的mysql服務器，只要它們監聽在不同的端口上就行，因爲不支持基於名稱的，所以要監聽在不同端口上，每個監聽在不同端口上的mysql服務稱爲一個mysql實例，每個實例都有自己的運行目錄，就叫MYSQL_HOME，所以每個實例都可以到自己的家目錄下找my.cnf；4. /path/to/fiel when defaults-extra-file=/path/to/file is specified # 在啓動mysql服務器時可以給它傳遞一個參數，叫--defaults-extra-file5. ~/.my.conf/etc/my.cnf --&gt; /etc/mysql/my.cnf --&gt; $MYSQL_HOME/my.cnf --&gt; --default-extra-file=/path/to/somefile --&gt; ~/.my.cnf配置文件中大多數的參數都可以命令行直接指定的也就是在啓動mysql時，在命令行可指定的參數也基本都可寫在配置文件中，寫在配置文件中時就不要加-了。如-host，在配置文件中直接寫host = ××× 就可以了。再如default-extra-file也可寫爲default_extra_file，這兩種格式都對，但建議寫爲統一格式，要寫在對應的段[×××]下。 windows mysql啟動時查找的配置文件12341. %WINDIR%\my.ini, %WINDIR%\my.cnf2. C:\my.ini, C:\my.cnf3. %INSTALLDIR%\my.ini, %INSTALLDIR%\my.cnf4. /path/to/file when defaults-extra-file=/path/to/file is specified 請求過程 當用戶需要連到數據庫上來完成某種操作時，由連接器負責接收用戶請求，並將請求轉發給線程管理器，線程管理器給它創建一個線程，線程管理器將線程權限轉給用戶模塊，用戶模塊來驗證用戶是否有訪問權限，如果沒有就終止，有就建立連接。之後用戶發起命令，由命令分發模块來完成用戶請求內容是否從緩存中直接返回，是否記錄日志，如果緩存中沒有的話， 可能就要將命令語句轉給解析器分析生成執行树，並交由底層的對應模塊處理，如果是SELECT語句就交給優化器，來生成更優的執行過程，如果用戶發起與數據定義相關的命令都要交給表定義模塊，如INSERT,DELECT等，如果用戶要維護一張表，就交給表維護模塊來完成，用戶每發起一次命令語句，狀態信息都要更新，最終，不論用戶是哪種請求都要判斷用戶是否有對應的訪問權限，這由訪問控制模塊來完成，如果有，就由表管理器負責後續的動作，如讀取表結構、修改表結構、施加表鎖，最終由存儲引擎來負責到對應文件中去找對應的數據。存儲引擎是真正與磁盤打交道的接口。這就是mysql的微觀結構 mysql基礎架構 面對用戶的一端是連接管理器，接收請求並建立連接後的下一層是查詢緩存和分析器，如果查詢緩存中有結果就直接返回給用戶，查詢緩存只與讀操作有關，與寫無關，且只與讀操作的查詢操作有關，如果緩存中沒有結果，就由分析器來分析，分析的結果如果發現緩存中有結果還會從緩存中返回結果，如果沒有結果就交給優化器完成優化，而後就交給存儲引擎，或交給執行引擎再交給存儲引擎完成操作。這就是mysql的基礎架構。連接管理器就是監聽在某個套接字上接收用戶請求，接收後創建一個線程予以響應，因為創建線程很消耗資源，也為了加速線程的創建，所以有了重用線程的概念，用戶退出後線程不被銷毀，而是放到空閒線程池中，有新的用戶請求時直接從空閒線程中拿一個給用戶響應，創建連接後會驗證用戶的連入權限，連入的所有用戶的操作都在它自身的線程地址空間內完成，因CPU有限，每個用戶發起的操作都在CPU上輪流進行，如果有一個非常慢的話會使其他用戶請求非常慢。在遠程連接mysql服務器時數據通過tcp/ip協議傳輸，是明文的，如果是機密的數據，會話管理器（連接管理器）還要進行加密 當我們發起查詢請求後mysql服務器會負責解析每一個查詢，並在mysql進程內部創建一個解析樹，它會去解析每一個請求，並為這個請求創建一個解析樹，解析執行過程並優化，最後計算出最優執行路徑，這就是解析器和優化器的作用。優化器的優化是自我判定的，與實際場景可能有出入，所以結果未必是最佳的。作為用戶可以給優化器提示，在執行語句中，這就避免優化器再去查找。優化器在優化中不會考慮存儲引擎的不同，每一個查詢執行結束之後，如果結果是決定性的，mysql會將結果緩存下來，但視查詢結果大小，不是所有結果都可以緩存的，一定是小於某個上限的才緩存。 緩存（一段內存空間）中的內容被分成了三個區域，每個區域中有一個叫作緩存槽的東西，每個查詢結果都會佔用這個槽的，為了便於管理，槽是有下限的，因為每個結果都要佔用一個槽，如果結詢結果比槽小的多，還要進行緩存，這會浪費槽，如果不浪費，自動去減小緩存空間，也會使緩存中產生大量的碎片，這也會影響執行效率。為了發揮緩存的效能提高效率，對緩存要進行優化，要有限定。非確定性結果，每次結果都不同，如查看時間（SELECT CURRENT_TIME()）一般不緩存。兩個語句一樣也不一定就能緩存，比如兩個查詢的用戶權限不同，有一方沒有查詢權限，就不能緩存。沒有緩存就由解析樹處理，如果有緩存就要查在緩存中是否命中，這會使每條語句都去找一次緩存，成了額外開銷，如此要計算益處與開銷的平衡 讀寫操作同時請求同一張表，任何時候（不只mysql）有兩個用戶同時讀寫同一個文件的數據時都會有並發控制的問題 並發控制是為了提高性能，可以使兩個並發的操作不會互相影響。不能使用串行的方法，一個用戶操作完下個用戶再操作的機制。很多服務器都引入了多版本並發控制的機制，叫作MVCC，每個用戶操作的都是一個數據的副本或快照，最後再完成快照合並，快照會有一個時間值，用來判定快照的先後。時間快照是數據庫必備的功能，要實現時間並發控制就要有鎖功能，多版本並發控制是用其他功能實現的 客戶端命令：mysql、mysqladmin、mysqldump、mysqllimport、mysqlcheck 服務器：mysqld、mysqld_safe、mysqld_multi（不同端口的mysql3306、3307、3308運行在一臺服務器上，相當於多臺服務器） 數據如何存儲到磁盤 磁盤按塊加載數據到內存，如果數據只佔了塊的一部分，也要加載整個塊。多個磁盤塊可組成一個數據塊。由存儲引擎管理。一般使用定長表結構，而不用變長，這樣可以使存取速度加快。因爲塊中的行會被刪除，就空出了空間，所以要做碎片整理，碎片會使裝載速度變慢，爲了管理這樣的數據，每個塊要有塊頭，塊頭裏要有行的信息，有多少空閒行等。這個塊不一定都是磁盤塊，可能是多個磁盤塊組成的數據塊，數據塊由存儲引擎來管理，只用磁盤塊也可以。定長的表的執行速度更快。 文件中記錄組織 堆文件組織：一條記錄可以放在文件中的任何地方，維護簡便，管理不便 順序文件組織：根據“搜索碼”的值順序存放 散列文件組織：分成N個塊，叫桶，將某行的不同列進行hash運算，結果相同的放在一起。hash索引 程序語言連接數據的方式有兩種 動態SQL：通過函數或方法與數據庫服務建立連接，然後通過協議將查詢語句直接送到服務器端；簡單的方式屬於動態SQL 嵌入式SQL：用程序開發語言的格式寫的，通過API直接連到服務器上，連接之前要先編譯 语句中的错误提示12345-&gt;：语句未结束，继续輸入'&gt;：缺單引號的後一半"&gt;：缺雙引號的後一半`&gt;：缺反引號的後一半/*&gt;：缺多行注釋的後一半 補全 要把數據庫中的表都載入內存中才能補全 名稱補全：mysql連接時用-A或–no-auto-rehash或–disable-auto-rehash來禁用補全功能；默認是有此功能的，或在mysql中用rehash或#命令就可以名稱補全了，但是是對新建命令的補全。 mysql不能啟動問題的原因 啟動時會在datadir =/mydata/data 指定的路徑下生成一個hostname.err的錯誤日志，mysql啟動後的錯誤信息都在此日志中，如果啟動錯誤還沒有錯誤日志，應該就是數據目錄指錯了。修改配置文件定義datadir =即可。测试中因为用的是mariadb，没有在目录中找到hostname.err日志，只有/var/log中的mariadb的日志，且只有一个mariadb.log 此前的服務未關閉套接字被佔用，用killall mysqld就可以了 數據初始化失敗 數據目錄位置錯誤 數據目錄權限問題 如果解決不了可重新初始化數據庫試一下 數據類型 數值型，不需要指定長度 精確數值 int：整型（TINYINT微整型1字節、SMALLINT小整型2、MEDIUMINT中整型3、INT整型4、BIGINT大整型8） DECIMAL：精確定點數 近似數值 FLOAT：單精度浮點型4 DOUBLE：雙精度浮點型8 real：實數 NUMERIC：定點數值 DECIMAL：定點數值 // 數值後加數字表示顯示幾位數字 字符型，一定要指定長度 定長：CHAR(#)（不區分大小寫），BINARY（區分） 變長:VARCHAR(#)（不區分大小寫），VARBINARY（區分） text（不區分大小寫） BLOB：二進制大對象（區分） ENUM：枚舉（在給定的選項中選） SET：集合（1-64個字符串，一組數值的組合值） // CHAR最多存儲255個字符，VARCHAR最多存儲65535個字符，每個VARCHAR存儲時會多佔一個字節，因為要有一個結束符，VARCHAR在255個字符內只需要一個結束符，超出255就需要兩個結束符。text上不能索引整個字段，CHAR上可以 字符串修飾屬性 NOT NULL：不能為空 NULL：可為空（默認） DEFAULT：給一個默認值 CHARACTER SET：字符集 COLLATION：排序規則 二進制大對象，區分大小寫，因爲按字節排序 TINYBLOB 255 MEDIUMBLOB 16M LONGBLOB 4G BLOB 64K BINARY 255 VARBINARY 65535 // 大對象存儲在一個單獨的位置，表上只是一個指針，故無法在表上建索引 日期時間型 date：日期 time：時間 datetime：日期時間 timestamp：時間戳 YEAR：年 數據類型的作用 存入值的類型； 使用空間大小； 定長還是變長的； mysql如何對其進行比較和排序； 是否可以創建索引 // 域屬性修飾符就是定義域限制的 只要在一個域上定義了數據類型，它能作出以下限定 它能表示哪個种類的數據 定義最大最小值，定義空間 確定是變長還是定長的 mysql如何比較排序字符，是否区分大小寫 這樣的類型是否能夠創建索引，是否能夠索引 查看表结构文件1234567891011121314ls /var/lib/mysql # 查看mysql的datadir目录，这里的目录就是数据库中的表，如mysql,test等，在目录内有表结构文件對myISAM引擎來說每表三個文件，MyISAM表是無事務，支持表鎖1. .frm: 表結構定義文件2. .MYD：表數據文件3. .MYI：表索引文件對InnoDB引擎來說，支持事務，行鎖；要打開每表一個單獨的表空間。每表一個表空間會創建下面兩個文件。所有表共享一個表空間文件；建議：每表一個獨立的表空間文件1. .frm: 表結構文件2. .ibd：表空間（同时存储表數據和表索引）# 建議打開innodb_file_per_table一項為ON，實現每表一個獨立表空間，在mysql中用SHOW GLOBAL VARIABLES LIKE '%innodb%';命令查看全局变量中与innodb相关的項，其中的innodb_file_per_table应该是ON。5.6中默認已打開了此項，不然可以在my.cnf中加入innodb_file_per_table = ON或1一行即可打開。db.opt標記當前庫的字符集和排序規則的定义，也就是数据库的默认选项 存储引擎12345678910111213141516171819202122232425SHOW ENGINES; # 查看存儲引擎MyISAM# 不支持事務，默認只支持表鎖，讀性能更好，寫性能差，不支持外鍵，支持B樹索引、FULLTEXT索引、空間索引、支持表壓縮；.frm（表格式） .MYD（數據文件） .MYI（索引文件）InnoDB# 支持事務，支持行級鎖、支持B樹索引、聚簇索引、自適應hash索引，使用表空間、raw磁盤設備； .frm（表格式） .ibd（表空間）# 將innodb_file_per_table改成ON就會為每表創建一個表空間了MRG_MYISAM:# 可將兩個表合成一張表，也就是建一個兩張表合在一起的存儲引擎CSV# 方便移植，一般不用ARCHIVE# 用來實現歸檔的MEMORY# 在內存中建立存儲引擎BLACKHOLE# 黑洞# 也可用第三方存儲引擎，不建議混合使用存儲引擎]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql锁与事物]]></title>
    <url>%2F2019%2F01%2F06%2Fmysql%E9%94%81%E4%B8%8E%E4%BA%8B%E7%89%A9%2F</url>
    <content type="text"><![CDATA[锁 mysql一般會自動加鎖；最簡單的並發控制機制就是加鎖。鎖粒度從大到小，mysql僅支持表級鎖，行鎖需要由存儲引擎完成，一般不用在服務器上加鎖 讀鎖：同一個文件可以被多個用戶讀取。這是共享鎖 寫鎖：獨佔鎖，可以多人讀，但不允許寫；一個文件在寫時，不允許其他人讀與寫 表鎖：鎖定一張表 頁鎖：鎖定數據塊的，一個塊內有多行 行鎖： 123456789MariaDB [mysql]&gt; use jiaowuMariaDB [jiaowu]&gt; LOCK TABLES tutors read;# 给tutors表施加读锁* 再打开一个终端MariaDB [jiaowu]&gt; INSERT INTO tutors (Tname,Gender,Age) VALUES ('jerry','M',50);# 这时控制台会停住，因为表有读锁。如果換一臺主機连接数据库，插入数据会提示"Table 'tutors' was locked with a READ lock and can't be updated"* 回到加锁的终端MariaDB [jiaowu]&gt; UNLOCK tables;# 去除锁。这时会马上插入数据 事物 事務指多項操作要作爲一個處理單元來進行對待。它們要麼同時執行，要麼同時不執行。這需要大量CPU與IO操作。能啓動事務的是sql語句或ODBC中的一堆指令。多事務同時執行，彼此之間以互不影響的方式進行並發，事務之間交互，通過數據集。 如果一個存儲引擎是滿足事務的，要滿足ACID的測試 RDBMS：要滿足四種ACID測試，叫ACID(原子發Automicity、一致性Consistency、隔離性Isolation、持久性Durability) MYISAM不支持事務，INNODB支持 Automicity原子性：事務所引起的數據庫操作，要麼都完成，要麼都不執行 Consistency一致性：當事務執行完成後總和是一致的，如銀行轉帳，這與隔離性有關，要在隔離中執行 Isolation隔離性：通過事務調度來實現，彼此之間以互不影響的方式進行並發，或事務之間影響降到最小 Durability持久性：一旦事務成功完成，不能再發生變化，系統必須保證任何故障都不會引起事務表現出不一致性 事務提交之前就已經寫出數據至持久性存儲 結合事務日志完成，事務日志產生的是順序IO，數據文件是隨機IO 事務的狀態 活動的：active 部分提交的：最後一條語句執行後 失敗的：提交未完成 中止的：沒提交 提交的：完成的 事務提交就無法撤銷。狀態的轉換是一個事務從活動狀態到部分提交狀態或失敗狀態，部分提交到提交狀態，如果是未完成就到失敗狀態，失敗再到终止 活动 –&gt; 部分提交 –&gt; 提交 活动 –&gt; 部分提交 –&gt; 失败 –&gt; 终止 活动 –&gt; 失败 –&gt; 终止 事務：並發執行 提高吞吐量和資源利用率 減少等待時間 事務調度 可恢復調度 無級聯調度 並發控制依賴的技術手段 鎖 時間戳：記錄每個事務的啓動時間，執行時間 多版本和快照隔離 事務日志事務日志，對mysql很重要，mysql每一次操作都先在日志操作中完成，過一段時間才寫到磁般文件中。mysql中支持事務的引擎每次操作都是先在日志中完成，也就是增刪查改功能要先在內存中完成，完成後會立即寫到日志中去，過一段時間才寫到磁盤空間中去或叫磁盤文件中去，是將事務日志的查詢再在文件上走一遍，所以在事務引擎上的寫操作幾乎每次都要執行兩遍，日志中一次，數據文件中一次，寫在日志中非常快，因爲日志中記錄的只是操作，而不是操作數據本身，日志中記錄的是操作過程，所以操作過程可以在數據上重新執行一遍，所以叫redo。事務提交了就是完成了。服務器啓動時要讀日志，將未同步但已提交的事務同步到數據文件中去。這就是修復過程。如果在崩潰時還沒有提交事務，那麼此事務中的前幾條操作要撤消。日志文件通常不要太大，事務越小越好。日志文件不能只有一個，有兩個，第一個寫滿寫每二個，寫第二個時將第一個提交，這兩個文件組成了日志組。磁盤壞了，爲了保證事務不丟失，不可將事務日志與磁盤放在一起。這些日志就是爲了提供ACID功能的兼容性的。在mysql中叫事務日志，它自我能完成重做、撤消與自我修復 事務日志： 重做日志redo log：每一個操作在真正寫到數據庫之前，它先被寫到日志裏，下一次這個操作就算崩潰了，它可以根據重做日志再走一遍；這意味着我們的一系列操作可以無限次地根據這個日志重復地執行N遍 撤消日志 undo log：我們的每一次操作在操作以前，要把它的原有狀態保留下來。萬一要還原原來狀態時，可以撤消此次所做的任何一次操作 隔離級別 READ-UNCOMMITTED ：讀未提交，隔離級別最低；別人的操作馬上能看到，幹擾最大 READ-COMMITTED ：讀提交；別人提交後才能看到。也有問題 REPATABLE-READ ：可重讀，無論是否提交看到的都是一樣的，直到提交。會產生幻讀 SERIALIZABLE ：可串行。可解決幻讀。 隔離級別越高並發能力越差。mysql默認是可重讀，可適當降低mysql隔離級別，這會提高mysql性能，如果對並發能力要求不高的情況下，用SHOW GLOBAL VARIABLES LIKE ‘%iso%’可查看隔離級別。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288MariaDB [jiaowu]&gt; START TRANSACTION;# 啟動事務MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 2 | HuangYaoshi | M | 63 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 8 | HuYidao | M | 42 || 9 | NingZhongze | F | 49 || 10 | jerry | M | 50 |+-----+--------------+--------+------+MariaDB [jiaowu]&gt; DELETE FROM tutors WHERE Tname LIKE 'Hu%'; Query OK, 2 rows affected (0.00 sec)# 刪除以Hu開頭的兩行MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 || 10 | jerry | M | 50 |+-----+--------------+--------+------+MariaDB [jiaowu]&gt; ROLLBACK;# 事務回滾MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 2 | HuangYaoshi | M | 63 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 8 | HuYidao | M | 42 || 9 | NingZhongze | F | 49 || 10 | jerry | M | 50 |+-----+--------------+--------+------+# 被刪除的行被恢復MariaDB [jiaowu]&gt; DELETE FROM tutors WHERE Tname LIKE 'Hu%';Query OK, 2 rows affected (0.00 sec)# 再次删除两行MariaDB [jiaowu]&gt; COMMIT;# 提交事務，這樣就不能恢復了MariaDB [jiaowu]&gt; ROLLBACK;MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 || 10 | jerry | M | 50 |+-----+--------------+--------+------+# 提交后，再回滚也不能恢复了MariaDB [jiaowu]&gt; SHOW VARIABLES LIKE 'autocommit';+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+# autocommit函數是自動提交，如果沒有明確啟動事務，默認每一個操作是autocommit自動提交的，但這會產生大量磁盤IO。建議明確使用事務，並且關閉自動提交，這是優化服務器的一種策略。用命令SET @@autocommit=0關閉.切記，先啟動事務，最後要提交。测试中autocommit默认=======================================================================================全局變量：與用戶無關，服務器啟動就生效了，有管理權限的用戶才能修改。對當前會話無效，只對新建立會話有效。查看方法：SHOW GLOBAL VARIABLES [LIKE 'VALUE']，修改方法：SET GLOBAL @@VARIABLES ='VALUE'會話變量：客戶端連接服務器時可以顯示的變量，對當前會話立即生效，會話終止變量失效。查看方法：SHOW [SESSION] VARIABLES [LIKE 'VALUE']，修改方法：SET @@[SESSION.]VARIABLES ='VALUE'=======================================================================================MariaDB [jiaowu]&gt; SET @@autocommit=0;# 关闭会话变量的自动提交MariaDB [jiaowu]&gt; SHOW VARIABLES LIKE 'autocommit'; +---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | OFF |+---------------+-------+MariaDB [jiaowu]&gt; DELETE FROM tutors WHERE Age=90;# 删除年龄为90的人MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 |+-----+--------------+--------+------+# 查看，第5条被删除了MariaDB [jiaowu]&gt; ROLLBACK;# 回滚MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 |+-----+--------------+--------+------+# 第5条数据又回来了* 保存点# 保存點：SAVEPOINT sid，可撤銷到指定的保存點# 回滾至保存點：ROLLBACK TO sidMariaDB [jiaowu]&gt; DELETE FROM tutors WHERE TID=1;MariaDB [jiaowu]&gt; SAVEPOINT ab;# 保存，保存的名字不能是數字MariaDB [jiaowu]&gt; DELETE FROM tutors WHERE TID=3;MariaDB [jiaowu]&gt; SAVEPOINT aC;MariaDB [jiaowu]&gt; DELETE FROM tutors WHERE TID=4;MariaDB [jiaowu]&gt; SAVEPOINT ad;MariaDB [jiaowu]&gt; ROLLBACK TO aC;MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 |+-----+--------------+--------+------+# 回滚到aC保存点，这个保存点是删除了TID=3后的保存点，所以表中没有TID=3的数据，如果回滚到ab保存点，就会有TID=3的数据。如果要回滚到TID=1状态，就直接使用ROLLBACK命令。* 测试隔离级别# 打开兩個mysql會話，隔離級別都設爲READ UNCOMMITTED，查看第一個事務的操作是否影響第二個MariaDB [jiaowu]&gt; SELECT @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+# 查看会话变量，用SHOW SESSION VARIABLES LIKE '%tx_iso%';也可以查询到同样的结果。MariaDB [jiaowu]&gt; SET tx_isolation='READ-UNCOMMITTED';# 兩個会话都調為讀未提交MariaDB [jiaowu]&gt; SELECT @@tx_isolation; +------------------+| @@tx_isolation |+------------------+| READ-UNCOMMITTED |+------------------+MariaDB [jiaowu]&gt; START TRANSACTION;# 兩個会话都啟動事務MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 || 3 | Miejueshitai | F | 72 || 4 | OuYangfeng | M | 76 || 5 | YiDeng | M | 90 || 6 | YuCanghai | M | 56 || 7 | Jinlunfawang | M | 67 || 9 | NingZhongze | F | 49 |+-----+--------------+--------+------+MariaDB [jiaowu]&gt; UPDATE tutors SET Age=50 WHERE TID=1;# 其中一個調整MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 50 |# 另一個查看，雖未提交也可看到變化MariaDB [jiaowu]&gt; ROLLBACK;# 修改數據的一方撤銷了MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 |# 另一個查看與，數據又回到之前MariaDB [jiaowu]&gt; COMMIT;# 两个会话都要提交* 再測讀提交，對方不提交就看不到MariaDB [jiaowu]&gt; SET tx_isolation='READ-COMMITTED';MariaDB [jiaowu]&gt; START TRANSACTION;# 两个会话都要设置成READ-COMMITTED，并启动事务MariaDB [jiaowu]&gt; UPDATE tutors SET Age=50 WHERE TID=1;ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED.# 修改数据时有报错。=======================================================================================从 MySQL 5.1.12 开始，可以用以下三种模式来实现：基于SQL语句的复制(statement-based replication, SBR)，基于行的复制(row-based replication, RBR)，混合模式复制(mixed-based replication, MBR)。相应地，binlog的格式也有三种：STATEMENT，ROW，MIXED。如果你采用默认隔离级别REPEATABLE-READ，那么建议binlog_format=ROW。如果你是READ-COMMITTED隔离级别，binlog_format=MIXED和binlog_format=ROW效果是一样的，binlog记录的格式都是ROW，对主从复制来说是很安全的参数。参考：https://blog.csdn.net/wsyw126/article/details/73011497=======================================================================================MariaDB [jiaowu]&gt; SET @@binlog_format=ROW;ERROR 1679 (HY000): Cannot modify @@session.binlog_format inside a transaction# 提示不能在事物中修改MariaDB [jiaowu]&gt; COMMIT;# 提交事物后，事物也就关闭了MariaDB [jiaowu]&gt; SET @@binlog_format=ROW;# 再修改就没问题了MariaDB [jiaowu]&gt; UPDATE tutors SET Age=50 WHERE TID=1; Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0# 在一个终端修改数据MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 |# 在另一个终端查看# 当一边修改数据，另一边查看时，数据是不会改变的，提交后才会修改 MariaDB [jiaowu]&gt; ROLLBACK;# 修改数据的终端回滚* 測试REPATABLE-READ# 結果未提交前不能看到變化，提交後仍未看到變量，因為需要兩方都提交才能看到變化MariaDB [jiaowu]&gt; SET tx_isolation='REPEATABLE-READ';MariaDB [jiaowu]&gt; START TRANSACTION;# 在两个终端修改MariaDB [jiaowu]&gt; UPDATE tutors SET Age=50 WHERE TID=1;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0# 在一个终端修改并查看数据MariaDB [jiaowu]&gt; SELECT * FROM tutors; +-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 50 |MariaDB [jiaowu]&gt; SELECT * FROM tutors; +-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 |# 在另一个终端查看到的数据与修改数据终端查看到的不一样MariaDB [jiaowu]&gt; COMMIT;# 修改数据的终端提交并查看MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 50 |MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 93 |# 在另一个终端查看，数据仍未变化MariaDB [jiaowu]&gt; COMMIT;# 只有这个终端也提交后再查看，数据才会变化MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 50 |* 測試可串行SERIALIZABLE# 效果與REPATABLE-READ一樣，但因一方未提交，另一方的操作不能繼續MariaDB [jiaowu]&gt; SET tx_isolation='SERIALIZABLE';MariaDB [jiaowu]&gt; START TRANSACTION;MariaDB [jiaowu]&gt; SELECT * FROM tutors;+-----+--------------+--------+------+| TID | Tname | Gender | Age |+-----+--------------+--------+------+| 1 | HongQigong | M | 50 |# 在两个终端执行上面操作MariaDB [jiaowu]&gt; UPDATE tutors SET Age=93 WHERE TID=1;# 在一个终端执行此命令，命令行会停住。先启动事物的终端命令行会停住，后启动的可以修改，但要等后启动事物的终端提交后，先启动事物的终端才可以操作，提交后的结果也以后提交的终端数据为准 MariaDB [jiaowu]&gt; UPDATE tutors SET Age=23 WHERE TID=1;# 在另一个执行此命令MariaDB [jiaowu]&gt; COMMIT;# 提交，这时命令行停住的终端又可以操作了，但如果这里长时间没有提交，命令行停住的终端会提示"Lock wait timeout exceeded; try restarting transaction"MariaDB [jiaowu]&gt; COMMIT;# 命令行停住的终端提交后，数据结果以此终端的修改为准]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql锁与事物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql集群]]></title>
    <url>%2F2019%2F01%2F05%2Fmysql%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[主从复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245# 准备两个节点，主节点有两块网卡，一为内网地址：172.16.106.132,一为外网地址：192.168.1.14。从节点为内网地址：172.16.106.133# 配置从节点可以访问外网* 从节点[root@http1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33IPADDR=172.16.106.133NETMASK=255.255.255.0GATEWAY=172.16.106.132DNS1=192.168.1.1# 加入上面内容* 主节点[root@test ~]# vim /etc/sysctl.conf net.ipv4.ip_forward = 1# 加入上面内容，开启转发功能[root@test ~]# sysctl -p[root@test ~]# iptables -t nat -I POSTROUTING -s 172.16.106.0/24 -j SNAT --to-source 192.168.1.14# 添加源地址转发，所有内网出去的数据的地址都改为主节点的外网地址192.168.1.14。# 安装mysql* 两节点上[root@test ~]# wget http://mirrors.ustc.edu.cn/mysql-repo/yum/mysql-5.7-community/el/7/x86_64/mysql-community-release-el7-7.noarch.rpm# 下载科大源[root@test ~]# yum install -y mysql-community-release-el7-7.noarch.rpm# 安装源[root@test ~]# yum install -y mysql-community-server# 安装mysql服务，这里安装的是5.6版本# 配置mysql* 主节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=1 log-bin=master-log[root@test ~]# systemctl start mysql* 从节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=11 relay_log=relay-log read_only=ON[root@test ~]# systemctl start mysql* 主节点# 到主节点上创建拥有复制权限的用户，创建的用户最好使用最小权限法则，并且只允许从某个节点连接mysql -uroot -pmysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'172.16.106.%' IDENTIFIED BY 'replpass';# 创建的用户最好指定一个具体地址，只让某个地址的某个用户可以有复制权限mysql&gt; FLUSH PRIVILEGES;mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000003 | 2643 | | | |+-------------------+----------+--------------+------------------+-------------------+# 查看二进制日志处于哪个位置，这里查到的是master-log.000003 2643，我们从这里向后手动复制即可* 从节点mysql -uroot -pmysql&gt; CHANGE MASTER TO MASTER_HOST='172.16.106.132',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000003',MASTER_LOG_POS=2643;# 连接用CHANGE MASTER TO命令,MASTER_HOST指向主节点地址，MASTER_CONNECT_RETRY是多长时间做一次复制，MASTER_LOG_FILE是指定主节点的日志文件，MASTER_LOG_POS是日志的位置mysql&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Master_Host: 172.16.106.132 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 2643 Relay_Log_File: relay-log.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: No Slave_SQL_Running: No Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 2643 Relay_Log_Space: 120 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULLMaster_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 0 Master_UUID: Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0# 这里会显示上面连接时指定的信息，如用户名，地址，端口等。其中Slave_IO_Running和Slave_SQL_Running表示本地的两个重要线程，复制时一定要用到，这里显示NO，表示未运行。Exec_Master_Log_Pos表示执行到主节点二进制的哪个位置了，如果与Read_Master_Log_Pos相同，表示与主节点是一样的，数据同步未落后。Seconds_Behind_Master表示落后主节点多长时间，这里是NULL，是因为上面说的两个线程没有启动，启动后就会显示数字了，正数表示落后的时间mysql&gt; START SLAVE;# 启动两个线程的命令；也可以用START SLAVE IO_THREAD/START SLAVE SQL_THREAD单独启动线程[root@http1 ~]# tail -100 /var/log/mysqld.log# 查看日志mysql&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.16.106.132 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 2643 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 284 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 2643 Relay_Log_Space: 451 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: e2b8a386-10a3-11e9-8f5d-000c295c6de3 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0# Slave_IO_Running与Slave_SQL_Running变为了Yes，Seconds_Behind_Master变为了0* 主节点mysql -uroot -pmysql&gt; CREATE DATABASE mydb;* 从节点mysql&gt; SHOW SLAVE STATUS\G# 查看变化mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || mydb |* 主节点mysql&gt; use mydbmysql&gt; CREATE TABLE tb1(id INT,Name CHAR(30));* 从节点mysql&gt; use mydbmysql&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tb1 |+----------------+mysql&gt; DESC tb1;+-------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || Name | char(30) | YES | | NULL | |+-------+----------+------+-----+---------+-------+mysql&gt; SHOW GLOBAL VARIABLES LIKE 'read_only';+---------------+-------+| Variable_name | Value |+---------------+-------+| read_only | ON |+---------------+-------+# 这里应该显示ON，查看全局变量read_only，是否为只读* 主节点[root@test ~]# mysql -uroot -p &lt; jiaowu.sql* 从节点mysql -uroot -pmysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || jiaowu |===========================================================================================流程：1. 主节点/etc/my.cnf打开server_id=1、log-bin=master-log（启动二进制日志）。启动服务2. 从节点server_id=11、relay_log=relay-log（启动中继日志）、read_only=ON（让从节点为只读）。启动服务 3. 到主节点上创建拥有复制权限的用户，创建的用户最好使用最小权限，并且只允许从某个节点连接4. 到从节点用CHANGE MASTER TO命令连接主节点=========================================================================================== 主主复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899# 准备两个节点，主节点有两块网卡，一为内网地址：172.16.106.132,一为外网地址：192.168.1.14。从节点为内网地址：172.16.106.133# 配置* 主节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=1 log-bin=master-log relay_log=relay-log auto_increment_offset=1 auto_increment_increment=2[root@test ~]# systemctl start mysql* 从节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=11 log-bin=master-log relay_log=relay-log auto_increment_offset=2 auto_increment_increment=2[root@http1 ~]# systemctl start mysql* 主节点mysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'172.16.106.133' IDENTIFIED BY 'replpass';# 这里设置用户只能从172.16.106.133连接，这个是从节点的内网地址mysql&gt; FLUSH PRIVILEGES;mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000004 | 444 | | | |+-------------------+----------+--------------+------------------+-------------------+* 从节点[root@http1 ~]# mysql -uroot -pmysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'192.168.1.14' IDENTIFIED BY 'replpass';# 这里只有添加主节点的192地址，主节点才能连接从节点，如果添加的是主节点的内网地址就无法连接。测试发现在主节点连接从节点时使用的是192的地址。mysql&gt; FLUSH PRIVILEGES;mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000001 | 444 | | | |+-------------------+----------+--------------+------------------+-------------------+mysql&gt; STOP SLAVE;mysql&gt; CHANGE MASTER TO MASTER_HOST='172.16.106.132',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000004',MASTER_LOG_POS=444;* 主节点mysql&gt;CHANGE MASTER TO MASTER_HOST='172.16.106.133',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000001',MASTER_LOG_POS=444;mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS\G* 从节点mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS\Gmysql&gt; create database mydb1;* 主节点mysql&gt; CREATE TABLE tbl1(id INT UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT,Name CHAR(30));* 从节点mysql&gt; INSERT INTO tbl1 (Name) VALUES ('stu1'),('stu2');mysql&gt; select * from tbl1;+----+------+| id | Name |+----+------+| 2 | stu1 || 4 | stu2 |+----+------+# 这时可以看到ID是2和4，因为配置文件中设置从2开始* 主节点mysql&gt; INSERT INTO tbl1 (Name) VALUES ('stu3'),('stu4');mysql&gt; select * from tbl1;+----+------+| id | Name |+----+------+| 2 | stu1 || 4 | stu2 || 5 | stu3 || 7 | stu4 |+----+------+这里可以看到是5和7，因为是从前面数据向下的ID号======================================================== * 如果主从节点数据不一致，解决的办法最好是，将从节点停掉，从主节点备份再恢复到从节点，再开启从节点复制功能。 * 数据库读写分离后，前端应该有一个读写分离器，读写分离器还可以做语句网关，禁止掉一些危险语句。数据库不应该面向互联网。公司人员远程管理时可通过VPN，拔号或跳板机连接服务器 # 双主模型创建过程1. 开启两台服务器的二进制日志和中继日志，设置数据ID从几开始和增长因子。之后启动服务2. 在两台服务器上创建有复制权限的用户。3. 在两台服务器上查看所处的日志位置，再通过CHANGE MASTER TO命令设置对方为主服务器4. 启动功能START SLAVE;。之后就可以测试了。======================================================== mysql+keeyalived123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232准备两台主机，node1：192.168.1.14，node2：192.168.1.15* 两台主机[root@test ~]# yum install -y keepalived* node1[root@test ~]# cp -p /etc/keepalived/keepalived.conf&#123;,.bak&#125;[root@test ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.1.101.120&#125;vrrp_script chk_mysql_port &#123; script "/etc/keepalived/chk_mysql.sh" interval 2 weight -5 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.101/24 dev ens33 label ens33:1 &#125; track_script &#123; chk_mysql_port &#125;&#125;[root@test ~]# yum install -y mailx[root@test ~]# vim /etc/mail.rcset from=budongchan@ccgoldenet.comset smtp=imap.exmail.qq.comset smtp-auth-user=budongchan@ccgoldenet.comset smtp-auth-password=CCjd1rj.comset smtp-auth=login# 加入上面的内容。以便下面实现邮件报警功能[root@test ~]# vim /etc/keepalived/chk_mysql.sh#!/bin/bash#counter=$(netstat -na|grep "LISTEN"|grep "3306"|wc -l)if [ "$&#123;counter&#125;" -eq 0 ]; then /usr/bin/systemctl start mysqld || /usr/bin/systemctl stop keepalived &amp;&amp; echo "MysqlError" | mailx -s "MysqlError" budongchan@ccgoldenet.comfi# 设置keepalived的监控脚本[root@test ~]# chmod +x /etc/keepalived/chk_mysql.sh[root@test ~]# scp /etc/keepalived/keepalived.conf 192.168.1.15:/etc/keepalived/[root@test ~]# scp /etc/keepalived/chk_mysql.sh 192.168.1.15:/etc/keepalived/[root@test ~]# scp /etc/mail.rc 192.168.1.15:/etc/[root@test ~]# systemctl start keepalived* node2 [root@test ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 router_id node2vrrp_script chk_mysql_port &#123; script "/etc/keepalived/chk_mysql.sh" interval 2 weight -5 fall 2 rise 1 &#125; vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 96 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.101/24 dev ens33 label ens33:1 &#125; track_script &#123; chk_mysql_port &#125; &#125;[root@test ~]# systemctl start keepalived[root@test ~]# tcpdump -i ens33 -nn -vv host 224.1.101.120# 测试，可以看到心跳包* 两个节点[root@test ~]# rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm[root@test ~]# yum -y install mysql-community-server* node1[root@test ~]# vim /etc/my.cnf[client]default-character-set = utf8mb4[mysql]default-character-set = utf8mb4[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0character-set-server = utf8mb4collation-server = utf8mb4_unicode_ciinnodb_file_per_table=ONskip_name_resolve=ONserver_id=1# 另一个节点server_id要改为2，如果一样，在启动后会有问题log-bin=master-logrelay_log=relay-logauto_increment_offset=1# 另一节点这里要改为2，表示以双数输入auto_increment_increment=2symbolic-links=0sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid[root@test ~]# systemctl start mysql[root@test ~]# scp /etc/my.cnf 192.168.1.15:/etc# 启动时，/var/lib/mysql数据目录中的performance_schema目录和一些文件的属主属组可能不是mysql，需要chown -R mysql.mysql /var/lib/mysql，不然无法启动[root@test ~]# mysql_secure_installation# 设置mysql密码等信息[root@test ~]# mysql -uroot -pmysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'192.168.1.15' IDENTIFIED BY 'replpass';mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000003 | 2674 | | | |+-------------------+----------+--------------+------------------+-------------------+mysql&gt; FLUSH PRIVILEGES;mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.15',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTERmysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.15',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000003',MASTER_LOG_POS=2436;* node2mysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'192.168.1.14' IDENTIFIED BY 'replpass'; mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000003 | 2674 | | | |+-------------------+----------+--------------+------------------+-------------------+mysql&gt; FLUSH PRIVILEGES;mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.14',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000003',MASTER_LOG_POS=2758;# 指定MASTER_LOG_POS最好看一下，可能有变化mysql&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.14 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 2758 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 284 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes# 在两个节点都查看一下* node1mysql&gt; CREATE DATABASE mydb;* node2mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || mydb |# 在node1上创建的库，在node2上可以看到mysql&gt; CREATE TABLE tbl1(id INT UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT,Name CHAR(30));# 在node2上创建表* node1mysql&gt; USE mydbmysql&gt; INSERT INTO tbl1(Name) VALUES ('stu1'),('stu2');# 在node1上可以向表中插入数据* node2mysql&gt; USE mydbmysql&gt; INSERT INTO tbl1(Name) VALUES ('stu1'),('stu2');mysql&gt; SELECT * FROM tbl1;+----+------+| id | Name |+----+------+| 1 | stu1 || 3 | stu2 || 4 | stu1 || 6 | stu2 |+----+------+# 在node2上插入数据后可以看到id号是node1插入单数，node2插入双数* node1[root@test ~]# systemctl stop mysqlJob for mysqld.service canceled.[root@test ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:26379 *:* LISTEN 0 128 *:6379 *:* LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 80 :::3306# 可以看到，停止了mysql服务，会被重新启动 半同步123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210* 主节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=1 log-bin=master-log[root@test ~]# systemctl start mysql* 从节点[root@test ~]# vim /etc/my.cnf [mysqld] innodb_file_per_table=ON skip_name_resolve=ON server_id=11 relay_log=relay-log[root@test ~]# systemctl start mysql* 主节点mysql&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'172.16.106.133' IDENTIFIED BY 'replpass'; mysql&gt; FLUSH PRIVILEGES;mysql&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-log.000005 | 434 | | | |+-------------------+----------+--------------+------------------+-------------------+* 从节点mysql&gt; CHANGE MASTER TO MASTER_HOST='172.16.106.132',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000005',MASTER_LOG_POS=434;mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.16.106.132 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000005 Read_Master_Log_Pos: 434 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 284 Relay_Master_Log_File: master-log.000005 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 434 Relay_Log_Space: 451 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: e2b8a386-10a3-11e9-8f5d-000c295c6de3 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0* 主节点mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';# 安装插件* 从节点mysql&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';mysql&gt; SHOW PLUGINS;# 在两个节点可以看到最下面一行中rpl_semi_sync_slave 已经是ACTIVE状态了* 主节点mysql&gt; SHOW GLOBAL VARIABLES LIKE '%semi%';+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 |+------------------------------------+-------+# 可以看到rpl_semi_sync_master_enabled一项还是OFF，要改为ON。rpl_semi_sync_master_timeout为10000，表示10秒；rpl_semi_sync_master_wait_no_slave表示如果没有半节点同步是否等待mysql&gt; SET @@global.rpl_semi_sync_master_enabled=ON;# 启动半同步mysql&gt; SHOW GLOBAL VARIABLES LIKE '%semi%';+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | ON |# 这时rpl_semi_sync_master_enabled是ON了* 从节点mysql&gt; SHOW GLOBAL VARIABLES LIKE '%rpl%';+---------------------------------+----------+| Variable_name | Value |+---------------------------------+----------+| rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 || rpl_stop_slave_timeout | 31536000 |+---------------------------------+----------+mysql&gt; SET @@global.rpl_semi_sync_slave_enabled=ON;mysql&gt; SHOW GLOBAL VARIABLES LIKE '%rpl%';+---------------------------------+----------+| Variable_name | Value |+---------------------------------+----------+| rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 || rpl_stop_slave_timeout | 31536000 |+---------------------------------+----------+* 主节点mysql&gt; SHOW GLOBAL STATUS LIKE 'rpl%';+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 0 |# 第一项Rpl_semi_sync_master_clients表示从节点有几个，这里是0* 从节点mysql&gt; STOP SLAVE IO_THREAD;mysql&gt; START SLAVE IO_THREAD;# 从节点需要先停止再启动IO线程，才能加入到半同步的节点* 主节点mysql&gt; SHOW GLOBAL STATUS LIKE 'rpl%';+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 1 |# 这时Rpl_semi_sync_master_clients是1了。[root@test ~]# mysql -uroot -p &lt; jiaowu.sqlmysql&gt; SHOW GLOBAL STATUS LIKE 'rpl%';+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 1 || Rpl_semi_sync_master_net_avg_wait_time | 498 || Rpl_semi_sync_master_net_wait_time | 10959 || Rpl_semi_sync_master_net_waits | 22 || Rpl_semi_sync_master_no_times | 0 || Rpl_semi_sync_master_no_tx | 0 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 625 || Rpl_semi_sync_master_tx_wait_time | 13762 || Rpl_semi_sync_master_tx_waits | 22 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 22 || Rpl_semi_sync_slave_status | OFF |+--------------------------------------------+-------+# 这时可以看到有数据的信息了* 从节点mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || jiaowu |# jiaowu库同步了=======================================================================================半同步复制创建过程1. 主节点打开server_id=1、log-bin=master-log。启动服务2. 从节点打开server_id=11、relay_log=relay-log。启动服务3. 主节点创建可以使用复制功能的帐号4. 从节点按主节点创建的帐号连接主节点5. 主节点安装插件INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';6. 从节点安装插件INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';7. 主节点启用半同步SET @@global.rpl_semi_sync_master_enabled=ON;8. 从节点启用半同步SET @@global.rpl_semi_sync_slave_enabled=ON;。重启IO线程STOP SLAVE IO_THREAD; --&gt; START SLAVE IO_THREAD;* 异步复制（Asynchronous replication）MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返回给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主库如果crash(crash[kræʃ]：崩溃)掉了，此时主库上已经提交的事务可能并没有传到从库上，如果此时，强行将从库提升为主库，可能导致新主库上的数据不完整。* 全同步复制（Fully synchronous replication）当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会受到严重的影响。* 半同步复制（Semisynchronous replication）介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。======================================================================================= 过滤器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121# 实现只复制某一个库（一般就到库级别，不会到表级别）。准备两台主机，主服务器地址：192.168.1.14，从服务器地址：192.168.1.15* 主节点[root@test ~]# yum install -y mariadb-server[root@test ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=1log-bin=master-log[root@test ~]# systemctl start mariadb[root@test ~]# mysql_secure_installation[root@test ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repluser'@'192.168.1.%' IDENTIFIED BY 'replpass'; # 创建只有192.168.1.15通过repluser用户可以同步 MariaDB [(none)]&gt; FLUSH PRIVILEGES;MariaDB [(none)]&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------------+----------+--------------+------------------+| master-log.000003 | 1989 | | |+-------------------+----------+--------------+------------------+* 从节点[root@test ~]# yum install -y mariadb-server[root@test ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=11relay_log=relay-log[root@test ~]# systemctl start mariadb[root@test ~]# mysql_secure_installation[root@test ~]# mysql -uroot -pcentosMariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.14',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_PORT=3306,MASTER_LOG_FILE='master-log.000003',MASTER_LOG_POS=1989;MariaDB [(none)]&gt; START SLAVE;MariaDB [(none)]&gt; SHOW SLAVE STATUS\GMariaDB [(none)]&gt; SHOW GLOBAL VARIABLES LIKE '%do_db%';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| replicate_do_db | |+-----------------+-------+MariaDB [(none)]&gt; SET @@global.replicate_do_db=mydb;MariaDB [(none)]&gt; START SLAVE;MariaDB [(none)]&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.14 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 1989 Relay_Log_File: relay-log.000003 Relay_Log_Pos: 530 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: mydb# Replicate_Do_DB变为了mydb，表示只同步这个库 * 主节点[root@test ~]# mysql -uroot -pcentos &lt; jiaowu.sqlMariaDB [(none)]&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || jiaowu |MariaDB [(none)]&gt; USE jiaowuMariaDB [jiaowu]&gt; SHOW TABLES;MariaDB [jiaowu]&gt; DROP TABLE students;* 从节点MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema |+--------------------+# 从库中并没有jiaowu库* 主节点MariaDB [jiaowu]&gt; CREATE DATABASE mydb;MariaDB [jiaowu]&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || jiaowu || mydb |* 从节点MariaDB [(none)]&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || mydb |# 从库同步了mydb库* 主节点MariaDB [mydb]&gt; CREATE TABLE tbl1 (id INT);MariaDB [mydb]&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tbl1 |+----------------+* 从节点MariaDB [(none)]&gt; SHOW TABLES FROM mydb;+----------------+| Tables_in_mydb |+----------------+| tbl1 |+----------------+# 同步了tbl1表 读写分离器 proxysql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332# 准备一个集群，有一个master主机，地址192.168.1.14，两个从节点，地址一个192.168.1.15，一个192.168.1.13。再准备一个读写分离器，地址是192.168.1.10。请求都到192.168.1.10，写到192.168.1.14，读到192.168.1.15和192.168.1.13。以上面的主从复制为基础# 一定要同步服务器的时间，保证所有服务器的时间是一样的* 从节点192.168.1.15，将只复制一个库改回来MariaDB [(none)]&gt; STOP SLAVE;MariaDB [(none)]&gt; SET @@global.replicate_do_db='';# 改为空就可以了MariaDB [(none)]&gt; START SLAVE;MariaDB [(none)]&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.14 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 7043 Relay_Log_File: relay-log.000004 Relay_Log_Pos: 530 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB:* 从节点192.168.1.13[root@test ~]# yum install -y mariadb-server[root@test ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=12relay_log=relay-logread_only=ON[root@test ~]# systemctl start mariadb* 主节点192.168.1.14[root@test ~]# mysqldump -uroot --all-databases -R -E --triggers -x --master-data=2 -p &gt; alldb.sql# --all-databases , -A：导出全部数据库。# --routines, -R：导出存储过程以及自定义函数。# --events, -E：导出事件。# --triggers：导出触发器。该选项默认启用，用--skip-triggers禁用它。# --lock-all-tables, -x：提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭--single-transaction 和--lock-tables 选项。# --master-data：该选项将当前服务器的binlog的位置和文件名追加到输出文件中(show master status)。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE MASTER命令前添加注释信息。[root@test ~]# scp alldb.sql 192.168.1.13:/root# 复制到刚加上来的从节点[root@test ~]# rm -rf alldb.sql* 从节点192.168.1.13[root@test ~]# mysql -uroot -p &lt; alldb.sqlMariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.14',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_LOG_FILE='master-log.000003',MASTER_LOG_POS=7043;# 设置与主节点同步MariaDB [(none)]&gt; START SLAVE;MariaDB [(none)]&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.14 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000003 Read_Master_Log_Pos: 7295 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 782 Relay_Master_Log_File: master-log.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes* 主节点192.168.1.14MariaDB [(none)]&gt; CREATE DATABASE testdb;# 到主节点创建一个库测试一下* 两个从节点MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || jiaowu || mydb || mysql || performance_schema || testdb |# 在两个从节点可以看到创建的库* 主节点192.168.1.14MariaDB [(none)]&gt; DROP DATABASE testdb;MariaDB [(none)]&gt; GRANT ALL ON *.* TO 'myadmin'@'192.168.1.%' IDENTIFIED BY 'mypass';# 创建一个有权限连接主从服务器的帐号。这个用户会同步到两个从节点MariaDB [(none)]&gt; FLUSH PRIVILEGES;* 两个从节点MariaDB [(none)]&gt; SELECT User FROM mysql.user;+----------+| User |+----------+| root || myadmin |* 分离器192.168.1.10下载 proxysql-1.3.6-1-centos7.x86_64.rpm[root@test ~]# yum install -y proxysql-1.3.6-1-centos7.x86_64.rpm[root@test ~]# cp /etc/proxysql.cnf&#123;,.bak&#125;[root@test ~]# vim /etc/proxysql.cnfdatadir="/var/lib/proxysql"# 数据目录路径，这是proxysql的状态数据，与mysql无关admin_variables=&#123; admin_credentials="admin:admin" # 登录proxysql进行管理时用的帐号密码 mysql_ifaces="127.0.0.1:6032;/tmp/proxysql_admin.sock" # 连接时用的地址和端口&#125;mysql_variables=&#123; threads=4 # 启动几个线程，它是单线程响应多个请求的，与CPU有关。测试时CPU为双核，但还是启动了四个线程 max_connections=2048 # 并发连接数 default_query_delay=0 default_query_timeout=36000000 have_compress=true poll_timeout=2000 interfaces="0.0.0.0:3306;/tmp/proxysql.sock" # 监听在所有地址的3306端口接收请求，测试调整上面的启动线程和此项的端口都不起作用，启动后还是启动4个线程，监听在6033端口。用1.4.7和1.3.6版本都是如此.恢复镜像后正常了 default_schema="mydb" # 登录后默认操作的数据库 stacksize=1048576 server_version="5.5.30" connect_timeout_server=3000 monitor_history=600000 monitor_connect_interval=60000 monitor_ping_interval=10000 monitor_read_only_interval=1500 monitor_read_only_timeout=500 ping_interval_server=120000 ping_timeout_server=500 commands_stats=true sessions_sort=true connect_retries_on_failure=10&#125;mysql_servers =# 每一组花括号记录一台服务器，用逗号隔开，再记录下一台服务器( # 要有括号，不然无法启动，在message日志中会提示语法错误&#123; address = "192.168.1.14" # no default, required . If port is 0 , address is interpred as a Unix Socket Domain port = 3306 # no default, required . If port is 0 , address is interpred as a Unix Socket Domain hostgroup = 0 # no default, required # 所处的主机组，将读定义一组，写定义一组 status = "ONLINE" # default: ONLINE # 配置完以后，这个服务器默认是在线的还是离线的 weight = 1 # default: 1 # 权重 compression = 0 # default: 0 # 压缩 max_connections = 200 # 最大并发连接数 # max_replication_lag = 10 # 读服务器是否延迟，这里默认是10秒&#125;,&#123; address = "192.168.1.15" # no default, required . If port is 0 , address is interpred as a Unix Socket Domain port = 3306 # no default, required . If port is 0 , ddress is interpred as a Unix Socket Domain hostgroup = 1 # no default, required status = "ONLINE" # default: ONLINE weight = 1 # default: 1 compression = 0 # default: 0 max_connections = 500&#125;,&#123; address = "192.168.1.13" # no default, required . If port is 0 , address is interpred as a Unix Socket Domain port = 3306 # no default, required . If port is 0 ,ddress is interpred as a Unix Socket Domain hostgroup = 1 # no default, required status = "ONLINE" # default: ONLINE weight = 1 # default: 1 compression = 0 # default: 0 max_connections = 500&#125;)mysql_users:# 定义以哪个用户组的身份连接至哪台服务器上(&#123; username = "myadmin" # no default , required password = "mypass" # default: '' default_hostgroup = 0 # default: 0 # 默认连接哪个组 active = 1 # default: 1 default_schema="mydb" # 连接后默认使用的数据库&#125;)mysql_query_rules:# 语句路由，实际是一个防火墙，可以屏蔽一些语句()scheduler=# 调度器()mysql_replication_hostgroups=# 指明哪个组读，哪个组写。可以同时调度多个集群(&#123; writer_hostgroup=0 reader_hostgroup=1 comment="test repl 1" # 说明&#125;)[root@test ~]# systemctl start proxysql# 启动[root@test ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:6032 *:* LISTEN 0 128 *:6033 *:* LISTEN 0 128 *:6033 *:* LISTEN 0 128 *:6033 *:* LISTEN 0 128 *:6033 *:*[root@test ~]# yum install -y mariadb# 安装客户端[root@test ~]# mysql -h192.168.1.10 -P6033 -umyadmin -pmypassWelcome to the MariaDB monitor. Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.5.30 (ProxySQL)# 连接后提示连接的是"Server version: 5.5.30 (ProxySQL)"MySQL [(none)]&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tbl1 || tbl2 |+----------------+MySQL [(none)]&gt; CREATE TABLE tbl3(id INT);MySQL [(none)]&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tbl1 || tbl2 || tbl3 |+----------------+* 两台从节点MariaDB [mydb]&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tbl1 || tbl2 || tbl3 |+----------------+# 两个从节点都有tbl3表了。这说明上面的创建语句被路由到了主节点上，因为如果路由到了从节点上，那么也只能有一个从服务器有此表，如果两个都有，说明是复制主节点的* 主节点192.168.1.14MariaDB [(none)]&gt; SHOW PROCESSlist;+------+----------+--------------------+------+-------------+-------+-----------------------------------------------------------------------+------------------+----------+| Id | User | Host | db | Command | Time | State | Info | Progress |+------+----------+--------------------+------+-------------+-------+-----------------------------------------------------------------------+------------------+----------+| 17 | repluser | 192.168.1.15:51118 | NULL | Binlog Dump | 15388 | Master has sent all binlog to slave; waiting for binlog to be updated | NULL | 0.000 || 21 | repluser | 192.168.1.13:41342 | NULL | Binlog Dump | 14775 | Master has sent all binlog to slave; waiting for binlog to be updated | NULL | 0.000 || 6183 | root | localhost | NULL | Query | 0 | NULL | SHOW PROCESSlist | 0.000 |+------+----------+--------------------+------+-------------+-------+-----------------------------------------------------------------------+------------------+----------+# 可以看到有几个客户端连上来了MariaDB [(none)]&gt; USE mydbMariaDB [mydb]&gt; SHOW TABLES;+----------------+| Tables_in_mydb |+----------------+| tbl1 || tbl2 || tbl3 |+----------------+# 主节点上也有tbl3表[root@test ~]# tcpdump -i ens33 -nn -vv port 3306# 监听3306端口，这时可以看到很多信息，是分离器的ping探测。在两个从节点和主节点上做此操作* 分离器192.168.1.10[root@test ~]# mysql -uadmin -padmin -hlocalhost -S /tmp/proxysql_admin.sock Welcome to the MariaDB monitor. Commands end with ; or \g.Your MySQL connection id is 5Server version: 5.5.30 (ProxySQL Admin Module)MySQL [(none)]&gt; SHOW DATABASES;+-----+---------+-------------------------------+| seq | name | file |+-----+---------+-------------------------------+| 0 | main | || 2 | disk | /var/lib/proxysql/proxysql.db || 3 | stats | || 4 | monitor | |+-----+---------+-------------------------------+MySQL [(none)]&gt; USE monitorMySQL [monitor]&gt; SHOW TABLES;+--------------------------------------+| tables |+--------------------------------------+| global_variables || mysql_collations || mysql_query_rules || mysql_replication_hostgroups || mysql_servers || mysql_users || runtime_global_variables || runtime_mysql_query_rules || runtime_mysql_replication_hostgroups || runtime_mysql_servers || runtime_mysql_users || runtime_scheduler || scheduler |+--------------------------------------+MySQL [monitor]&gt; SELECT * FROM mysql_users;+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+| username | password | active | use_ssl | default_hostgroup | default_schema | schema_locked | transaction_persistent | fast_forward | backend | frontend | max_connections |+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+| myadmin | mypass | 1 | 0 | 0 | mydb | 0 | 0 | 0 | 1 | 1 | 10000 |+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+# 只要向这个表中加入数据，定义好信息，就可以实现运行时修改主从节点的主机了MySQL [monitor]&gt; SELECT * FROM runtime_mysql_replication_hostgroups;+------------------+------------------+-------------+| writer_hostgroup | reader_hostgroup | comment |+------------------+------------------+-------------+| 0 | 1 | test repl 1 |+------------------+------------------+-------------+# 显示读写组的编号MySQL [monitor]&gt; select * from mysql_servers;+--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+| hostgroup_id | hostname | port | status | weight | compression | max_connections | max_replication_lag | use_ssl | max_latency_ms | comment |+--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+| 0 | 192.168.1.14 | 3306 | ONLINE | 1 | 0 | 200 | 0 | 0 | 0 | || 1 | 192.168.1.15 | 3306 | ONLINE | 1 | 0 | 500 | 0 | 0 | 0 | || 1 | 192.168.1.13 | 3306 | ONLINE | 1 | 0 | 500 | 0 | 0 | 0 | |+--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+MySQL [monitor]&gt; UPDATE mysql_servers SET hostgroup_id=0 WHERE hostname='192.168.1.13';# 其他库也支持运行时修改 MHA123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# 当主节点故障时，将从节点提升为主节点# 以上面四台主机为基础，在分离器上安装MHA，一台主节点，两台从节点* 主节点192.168.1.14[root@test ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=1log-bin=master-logrelay_log=relay-log[root@test ~]# systemctl start mariadb* 两个从节点192.168.1.13、192.168.1.15[root@test ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=11log-bin=master-logrelay_log=relay-logrelay_log_purge=0read_only=ON[root@test ~]# systemctl start mariadb* 主节点192.168.1.14[root@test ~]# ssh-keygen -t rsa -P ''[root@test ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.10[root@test ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.13[root@test ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.14[root@test ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.15[root@test ~]# scp -p .ssh/* 192.168.1.10:/root/.ssh[root@test ~]# scp -p .ssh/* 192.168.1.13:/root/.ssh[root@test ~]# scp -p .ssh/* 192.168.1.15:/root/.ssh* 分离器192.168.1.10下载mha4mysql-manager-0.56.0.el6.noarch.rpm mha4mysql-node-0.56-0.el6.noarch.rpm[root@test ~]# yum install mha4mysql-manager-0.56-0.el6.noarch.rpm mha4mysql-node-0.56-0.el6.noarch.rpm[root@test ~]# scp mha4mysql-node-0.56-0.el6.noarch.rpm 192.168.1.13:/root[root@test ~]# scp mha4mysql-node-0.56-0.el6.noarch.rpm 192.168.1.14:/root[root@test ~]# scp mha4mysql-node-0.56-0.el6.noarch.rpm 192.168.1.15:/root* 三个节点192.168.1.13、192.168.1.14、192.168.1.15[root@test ~]# yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm* 主节点192.168.1.14GRANT ALL ON *.* TO 'mhaadmin'@'172.16.0.%' IDENTIFIED BY 'mhapass';# 创建一个mha连接mysql的用户，用上面主从复制中创建的用户也可以FLUSH PRIVILEGES;* 分离器192.168.1.10[root@test ~]# mkdir /etc/masterha[root@test ~]# vim /etc/masterha/app1.cnf[server default]user=mhaadminpassword=mhapassmanager_workdir=/data/masterha/app1manager_log=/data/masterha/app1/manager.logremote_workdir=/data/masterha/app1ssh_user=rootrepl_user=repladmin# 有复制权限的用户名和密码repl_password=replpassping_interval=1[server1]hostname=192.168.1.14candidate_master=1# 是否可以被选为主节点，1为可以[server2]hostname=192.168.1.15candidate_master=1[server3]hostname=192.168.1.13candidate_master=1[root@test ~]# masterha_check_ssh --conf=/etc/masterha/app1.cnf# 测试基于密钥认证是否可以连接主机，后面指明配置文件。如果没问题会显示OK[root@test ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf# 检测主节点和从节点是否正常，这里提示从节点没有repladmin用户，如果提升为主节点会有问题。所以复制时最好看一下主节点(SHOW MASTER STATUS;)日志状态，再创建用户，之后从节点从创建用户之前的日志位置开始复制，就没问题了。* 主节点192.168.1.14GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO 'repladmin'@'172.16.0.%' IDENTIFIED BY 'replpass';FLUSH PRIVILEGES;* 分离器192.168.1.10[root@test ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf# 再检查就OK了。[root@test ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;&gt; /data/masterha/app1/manager.log &amp;# 启动监控，如果主节点故障就切换，切换后这个进程会关闭，需手动启动[root@test ~]# ps aux# 有perl /usr/bin/masterha_manager --conf=/etc/masterha/app1.cnf一条[root@test ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:2793) is running(0:PING_OK), master:192.168.1.14# //检查集群是否有问题，提示主节点是192.168.1.14* 主节点192.168.1.14[root@test ~]# systemctl stop mariadb# 关闭mariadb服务。测试从节点是否会提升为主节点* 分离器192.168.1.10[root@test ~]# ps aux# 上面的nohup启动的masterha_manager进程没有了，完成切换这个进程就会终止。显示：#“[1]+ 完成 nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/data/masterha/app1/manager.log”[root@test ~]# less /data/masterha/app1/manager.log# 查看日志，最后有Failover Report故障转移报告，提示主节点已改为192.168.1.15，并修改了从服务器的配置* 节点192.168.1.15[root@test ~]# mysqldump -uroot -x -R -E --triggers --master-data=2 --all-databases -p &gt; alldb.sql# 完全备份[root@test ~]# scp alldb.sql 192.168.1.14:/root* 节点192.168.1.14[root@test ~]# rm -rf /var/lib/mysql/* [root@test ~]# vim /etc/my.cnf[msyqld]innodb_file_per_table=ONskip_name_resolve=ONserver_id=1relay_log_purge=0read_only=1log-bin=master-logrelay_log=relay-log# 加入两条配置[root@test ~]# systemctl start mariadb[root@test ~]# mysql &lt; alldb.sql[root@test ~]# head -30 alldb.sql# 查看CHANGE MASTER TO一行master-log的文件名和位置[root@test ~]# mysql# 因为是重新初始化的mariadb，所以没有密码，与主节点同步后就会有密码了CHANGE MASTER TO MASTER_HOST='192.168.1.15',MASTER_USER='repladmin',MASTER_PASSWORD='replpass',MASTER_LOG_FILE='master-log.000001',MASTER_LOG_POS=633;START SLAVE;# 启动线程，这样就修复好了。SHOW SLAVE STATUS\G# 查看时有报错，提示"Slave_SQL_Running:No"。解决方法如下：=======================================================================================方法一mysql&gt; stop slave ;mysql&gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;# 在主从库维护中，有时候需要跳过某个无法执行的命令，需要在slave处于stop状态下，执行 set global sql_slave_skip_counter=N以跳过命令。常用的且不易用错的是N=1的情况mysql&gt; start slave ;mysql&gt; SHOW SLAVE STATUS\G方法二mysql&gt; stop slave ;到主服务器上查看主机状态，记录File和Position对应的值mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.15',MASTER_USER='repladmin',MASTER_PASSWORD='replpass',MASTER_LOG_FILE='master-log.000001',MASTER_LOG_POS=633;mysql&gt; start slave ;mysql&gt; SHOW SLAVE STATUS\G=======================================================================================* 分离器192.168.1.10[root@test ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf[root@test ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;&gt; /data/masterha/app1/manager.log &amp;# 地址转移后，这个进程就会关闭，需要手动再启动]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql日志]]></title>
    <url>%2F2019%2F01%2F04%2Fmysql%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[概念錯誤日志 錯誤日志記錄內容 服務器啟動和關閉過程中的信息 服務器運行過程中的錯誤信息 事件調度器運行一個事件時產生的信息 在從服務器上啟動從服務器進程時產生的信息 默認mysql不啟用任何日志功能，一般啟動錯誤日志，默認放在數據目錄中，以當前主機名加.err為後綴名的文件；log_error log_warnings警告信息日志，是否把警告信息記入錯誤日志，服務器上默認是記入的（0是不記，1是記）；mysql中的文件操作要在重啟服務器後生效，我們要把改變內容寫入配置文件。这里的log_warnings改变没有关系 一般查詢日志123456789101112# 一般關閉，記錄每條查詢會產生大量IOgeneral_log # 表示是否啟用查詢日志general_log_file # 日志記錄位置，默認是數據目錄下本機名稱加.log。log # 與查詢日志相關，但在5.6中已廢棄。是否啟用記錄所有語句的日志信息於一般查詢日志中，默認是OFFmysql可以將一般查詢日志保存在表中，只是這個表需要手工創建。啟用此功能還需要啟用log_output，默認輸出是FILE，也可以是TABLE，或是NONE不記錄，這項會控制上面的兩項及其他日志選項。這裡的FILE和TABLE可以同時指定，用逗號隔開即可 慢查詢日志1234567891011121314151617# 慢查詢日志，一般啟用，超過正常查詢的都算慢查詢long_query_time # 超過此項定義時間的查詢就是慢查詢。這裡的語句執行時長為實際的執行時間，而非在CPU上的執行時長。因此，負載較重的服務器上更容易產生慢查詢。其最小值為0，默認值是10，單位是秒。也支持毫秒級的解析度，作用範圍為全局或會話級別，可用於配置文件，屬動態變量log_slow_queries=&#123;YES|NO&#125; # 是否記錄慢查詢。默认是OFFslow_query_log=&#123;ON|OFF&#125; # 設定是否啟用慢查詢日志，0或OFF表示禁用，1或ON表示啟用。日志信息的輸出位置取決於log_output變量的定義，如果其值為NONE，則即便slow_query_log為ON，也不會記錄任何慢查詢信息。作用範圍為全局級別，可用於選項文件，屬動態變量slow_query_log_file # 日志保存位置set global slow_query_log=1 # 開啓慢查日志# 操作函數開關的可以當時生效，如果是文件就要重啓服務了。 二進制日志1234567891011121314151617# 二進制日志，二進制格式，任何引起或可能引起數據庫變化的操作信息都記錄，用於實現mysql復制以及即時點恢復的重要依據。mysql的復制功能就是從服務器不停地從主服務器上把它的二進制日志裡產生的任何操作，它把每個操作通過mysql客戶端、服務器端的每一個操作都讀取過來一份並保存在本地的某個日志中，而後由本地的某一個服務器的mysql線程和IO線程每一次從這個本地文件日志中讀取一行並在本地的服務器上操作一次，其中的某一個線程把日志中的內容讀取出來並在本地執行一次，使兩個數據庫一致，這就是復制。# 本地保存此內容的日志叫中繼日志，中繼日志的格式與二進制的格式一樣，只不過作用並不完全一致，因為中斷日志只是要讓本地服務器執行一次的日志文件。* mysqlbinlog # 用此命令查詢此日志文件。mysqlbinlog的工作很獨特，這一般位於我們的數據目錄中，而且以mysql-bin開頭或以當前主機名開頭。mysql服務器每重啟一次，它都會滾動一次，因為要記錄任何數據庫改變的操作。重放可以生成一模一樣的數據庫在多個位置，它是復制與即時點恢復的重要憑據。在日志文件增長到一定程度就會生成一個新的日志文件，不會讓此文件無限增長的，這就是輪動。不要將此日志與數據庫放在一個磁盤上，這可以在數據丟失時進行重放，指定從某個時間進行還原，這就是即時點恢復# 二進制日志的記錄格式可以是基於語句statement也可基於行row，還有混合方式mixed，由服務器選擇基於語句還是行。# 二進制日志事件，可以是基於行的，也可能是基於語句的，而每一個事件在記錄時的格式是1、事件產生時間；2、每個事件在日志中有一個相對位置。日志文件中有一個文件頭，一般要佔107個字節，記錄日志產生的信息，之後就是事件的內容了，每個事件有一個相對的位置叫position，起始時間starttime，恢復時可指定事件開始時間或位置與結束時間或位置定位。名字一般是mysql-bin.00001之後以此類推，老的文件名是不會改變的# 二進制日志文件組成有索引文件與二進制日志文件，啟動此功能就會有二進制日志文件，mysql-bin.index是索引文件，記錄了已產生的二進制日志文件名，在其中有指針記錄開始與結束文件，結束文件一般是當前使用的。用命令SHOW MASTER STATUS;可查看當前使用的文件，在結果顯示中的Position表示上次事件結束的位置。使用命令SHOW BINLOG EVENTS IN 'mysql-bin.000005';可查看二進制文件中記錄的信息，或SHOW BINLOG EVENTS IN 'mysql-bin.000005' FROM 107;指定從哪個位置開始顯示* 二進制日志相關的幾個選項innodb_support_xa=&#123;TRUE|FLASE&#125; # 定義innodb是否支持分布式事務。存儲引擎事務在存儲引擎內部被賦予了ACID屬性，分布式（XA）事務是一種高層次的事務，它能將InnoDB分爲兩段式提交，它利用“准備”然後“提交”（prepare-then-commit）；現在的存儲引擎都應支持此項功能，建議啓用起來# 兩段式的方式將ACID屬性擴展到存儲引擎外部，甚至是數據庫外部，然而，“准備”階段會導致額外的磁盤刷寫操作，XA需要事務協調員，它會通知所有的參與者准備提交事務（階段1），當協調員從所有參與者那裡收到“就緒”信息時，它會指示所有參與者進行真正的“提交”操作。# 此變量正是用於定義InnoDB是否支持兩段式提交的分布式事務，默認為啟用。事實上，所有啟用了二進制日志的並支持多個線程同時向二進制日志寫入數據的Mysql服務器都需要啟用分佈式事務，否則，多個線程對二進制日誌的寫入操作可能會以與次序不同的方式完成，這將會在基於二進制日誌的恢復操作中或者是從服務器上創建出不同原始數據的結果，因此，除了僅有一個線程可以改變數據以外的其它應用場景都不應該禁用此功能。而在僅有一個線程可以修改數據的應用中，禁用此功能是安全的並可以提升InnoDB表的性能。作用範圍為全局和會話級別，可用於選項文件，屬動態變量。sync_binlog=## 設定多久同步一次二進制日志至磁盤文件中，0表示不同步，任何正數值都表示對二進制每多少次寫操作之後同步一次。當autocommit的值為1時，每條語句的執行都會引起二進制日志同步，否則，每個事務的提交會引起二進制日志同步。一般建議把此項設為1。這樣可使我們在備份時不會有那些正在寫入的事務。打開此項會使二進制日志在寫入的時候以安全的方式進行。FLUSH LOGS執行後會打開一個新的二進制日志執行寫操作，但上面的方法更好一些 事务日志12事務日志是保證給事務提供原子性、一致性的一個重要依據，它能實現將隨機IO轉換為順序IO從而提高性能，並能夠保證事務提交以後不會丟失。只有事務性引擎才會用到事務日志，如InnoDBmysql靠各種服務器變量或服務器啟動的參數來定義各類日志是否啟用， 以及如何啟用，日志文件是什麼。另外事務日志有一個日志組，裡面至少有兩個日志輪替使用 与日志相关的变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051SHOW GLOBAL VARIABLES LIKE '%LOG%';binlog_cache_size # 二進制日志緩存大小，大小取決於下面這條binlog_stmt_cache_size # 與事務相關的二進制日志緩存大小，這兩條取決於binlog_stmt_cache_size的大小而改變，我們只關心這條即可，建議不要調太大，這會加大丟失量# async異步：先在內存中寫，過一會兒再一並寫入磁盤# sync同步：每次操作在內存中完成後直接寫入磁盤，這會使性能降低# 最好是引入異步方式，並提供緩存，寫操作在內存中完成並當作緩存，到一定量再同步到磁盤；可以是按時間，如每一秒與磁盤同步一次；也可以是按語句，如10條語句同步一次；還可以是按事務存儲引擎，只要提交就同步一次。log_bin # 是否啟用二進制日志，與指定文件位置有關sql_ log_bin=&#123;ON|OFF&#125; # 是否真正使用二進制日志取決於此條。用於控制二進制日志信息是否記錄進日志文件，默認為ON，表示啟用記錄功能。用戶可以在會話級別修改此變量的值，但用户必須具有SUPER權限，作用範圍為全局和會話級別，屬動態變量。sql_log_off=&#123;ON|OFF&#125; # 用於控制是否禁止將一般查詢日志類信息記錄進查詢日志文件，默認為OFF，表示不禁止記錄功能。用戶可以在會話級別修改此變量的值，但用户必須具有SUPER權限。作用範圍為全局和會話級別，屬動態變量。與二進制日志無關max_binlog_cache_size max_binlog_stmt_cache_size # 這兩個值一般不用修改，這是控制上限的。最終緩存大小還是取決於binlog_stmt_cache_sizeexpire_logs_days # 日志的過期天數# innodb_file_per_table的值為ON就會給每個表創建一個表空間了，這就可以使用innodb的一些高級功能了。# 中繼日志:從主服務器的二進制日志文件中復制而來的事件，並保存的日志文件。這是從服務器上的信息。# 因爲二進制日志文件只有一個，所以二進制日志文件所在磁盤性能越好，IO能力越強，服務器的整體性能越強。如用一堆SSD盤作RAID。mysql為提高性能會盡可能提高並發能力，如有多個CPU就可以同時多線程操作，但寫入二進制日志文件時，因為日志文件只有一個，故需要此日志文件所在磁盤IO能力更強# IOPS：IO設備每秒執行的IO操作數# 事務日志是確保事務安全性的重要工具。事務性存儲引擎用於保證原子性、一致性、隔離性和持久性innodb_flush_log_at_trx_commit # flush_log的行為，flush_log就是將內存中的日志事件同步到日志文件中的行為。日志文件到磁盤的同步是mysql後台線程自動進行的。這裡的1表示每當有事務提交或每隔1秒都會向磁盤寫一次。2表示每事務提交才同步；0表示每秒同步一次並執行磁盤flush操作（flush操作指告訴內核不在內核中緩存直接寫到磁盤上去）；1表示每事務同步，並執行磁盤flush操作；2表示每事務同步，但不執行磁盤flush操作。innodb_log_buffer_size # 內存緩存大小innodb_log_file_size # 日志文件大小，估計一下五分鍾會產生多少事務操作，有多大數據量，然後給它一個值即可innodb_log_files_in_group # 事務日志組有幾個文件，默認是兩個，一個寫滿就寫另一個，寫滿的將數據同步到磁盤innodb_log_group_home_dir # 日志組所在目錄，叫ib_logfile*，建議給事務日志做一個鏡像。在不同的磁盤上innodb_mirrored_log_groups # 是否給日志組做鏡像 查看1234567891011121314151617# 存放在同一塊磁盤上会使性能降低，更因為數據安全的原因，建議分開存放语法SHOW BINARY LOGS;# 查看當前服務器能識別的二進制日志有哪些SHOW MASTER STATUS; # 查看當前使用的二進制日志SHOW BINLOG EVENTS IN '二進制日志文件' [FROM 'position'];# 查看某個文件中的事件PURGE BINARY LOGS TO '日志文件';# 清除某個日志之前的日志FLUSH LOGS; # 手動滾動二進制日志文件 启动二进制日志功能12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@test ~]# systemctl stop mysql[root@test ~]# vim /etc/my.cnf[mysqld]log_bin = mysql_bin# 加入此项[root@test ~]# systemctl start mysql[root@test ~]# mysqlmysql&gt; SHOW GLOBAL VARIABLES LIKE 'sql_log_bin';+---------------+-------+| Variable_name | Value |+---------------+-------+| sql_log_bin | ON |+---------------+-------+# 如果此项为ON，表示开启了二进制日志mysql&gt; SHOW BINARY LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql_bin.000001 | 120 |+------------------+-----------+[[root@test ~]# mysqlbinlog /var/lib/mysql/mysql_bin.000001/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#190104 15:41:52 server id 1 end_log_pos 120 CRC32 0x2b1c1f39 Start: binlog v 4, server v 5.6.42-log created 190104 15:41:52 at startupROLLBACK/*!*/;BINLOG 'QA4vXA8BAAAAdAAAAHgAAAAAAAQANS42LjQyLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABADi9cEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAATkfHCs='/*!*/;# at 120#190104 15:52:41 server id 1 end_log_pos 167 CRC32 0x7f00ec56 Rotate to mysql_bin.000002 pos: 4DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;# /var/lib/mysql是数据库的路径[root@test ~]# mysqlbinlog --start-position=120 --stop-position=167 /var/lib/mysql/mysql_bin.000001/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#190104 15:41:52 server id 1 end_log_pos 120 CRC32 0x2b1c1f39 Start: binlog v 4, server v 5.6.42-log created 190104 15:41:52 at startupROLLBACK/*!*/;BINLOG 'QA4vXA8BAAAAdAAAAHgAAAAAAAQANS42LjQyLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABADi9cEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAATkfHCs='/*!*/;# at 120#190104 15:52:41 server id 1 end_log_pos 167 CRC32 0x7f00ec56 Rotate to mysql_bin.000002 pos: 4DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;# 查看位置從120到167[root@test ~]# mysqlbinlog --start-datetime='2019-01-04 15:41:52' /var/lib/mysql/mysql_bin.000001/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#190104 15:41:52 server id 1 end_log_pos 120 CRC32 0x2b1c1f39 Start: binlog v 4, server v 5.6.42-log created 190104 15:41:52 at startupROLLBACK/*!*/;BINLOG 'QA4vXA8BAAAAdAAAAHgAAAAAAAQANS42LjQyLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABADi9cEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAATkfHCs='/*!*/;# at 120#190104 15:52:41 server id 1 end_log_pos 167 CRC32 0x7f00ec56 Rotate to mysql_bin.000002 pos: 4DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;# 命令中的日期一定要使用****-**-**这样的格式，不然会报错："Incorrect date and time argument"，日期和时间参数不正确。[root@test ~]# mysqlbinlog --start-datetime='2019-01-04 15:41:52' /var/lib/mysql/mysql_bin.000001 &gt; abc.sql# 將結果重定向到一個.sql文件中，之後可導入mysql執行一次，這就是即時點恢復* 二進制日志的輪動除重啟服務器外還可以用FLUSH LOGS;来實現，這是在主服務器上，如果是從服務器就是中繼服務器才滾動* 二進制日志文件不能手動刪除，會影響mysql服務器啟動。要用mysql命令mysql&gt; PURGE BINARY LOGS TO 'mysql_bin.000002';# 刪除000002以前的二進制文件。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql命令]]></title>
    <url>%2F2019%2F01%2F04%2Fmysql%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[可以在mysql中使用help [command]查看命令的帮助信息 指令12345678910111213\?：查看命令\c：提前终止语句执行，在没写分号前加\c就结束了。如select User from us\c\d：定义语句结束符。例：\d ; //用分号作为语句结束符或用delimiter // //用两个斜线作为语句结束符\r：重新连接服务器\g：无论语句结束符是什么，在结尾加\g直接将此语句送至服务器端执行\G：无论语句结束符是什么，在结尾加\G直接将此语句送至服务器端执行，结果以坚排方式显示\p：顯示當前正在執行的命令\! COMMAND：执行shell命令；例：\! ls /root，在mysql中执行shell命令。也可以使用system COMMAND，效果是一样的，但执行的是本地的shell命令\W：语句执行结束后显示警告信息\w：语句执行结束后不显示警告信息\#：對新建的對象，支持補全功能；或用rehash也可以status：查看数据库状态信息。因为不用将命令发送到服务器端，只在客户端执行，所以不用加语句结束符 SHOW 显示1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556mysql&gt; SHOW ENGINES;# 顯示當前數據庫上的所有存儲引擎mysql&gt; SHOW TABLE STATUS FROM mysql LIKE 'user'\G*************************** 1. row *************************** Name: user Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 138 Data_length: 644Max_data_length: 281474976710655 Index_length: 2048 Data_free: 368 Auto_increment: NULL Create_time: 2019-01-03 23:19:23 Update_time: 2019-01-04 00:02:36 Check_time: NULL Collation: utf8_bin Checksum: NULL Create_options: Comment: Users and global privileges1 row in set (0.00 sec)# 查看表的狀態信息mysql&gt; SHOW CHARACTER SET;+----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 |# 顯示支持的字符集mysql&gt; SHOW COLLATION;+--------------------------+----------+-----+---------+----------+---------+| Collation | Charset | Id | Default | Compiled | Sortlen |+--------------------------+----------+-----+---------+----------+---------+| big5_chinese_ci | big5 | 1 | Yes | Yes | 1 || big5_bin | big5 | 84 | | Yes | 1 |# 顯示字符集排序規則，同一個字符集可能有多個不同的排序規則。如果不指定排序規則，字段從表繼承，表從庫繼承，庫從服務器繼承mysql&gt; SHOW GLOBAL VARIABLES LIKE ''\G# 显示所有变量mysql&gt; SHOW GLOBAL VARIABLES LIKE '%iso%';+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set (0.00 sec)# 查看隔离级别的变量mysql&gt; SHOW CREATE TABLE courses;# 显示创建courses表所用的语句 CREATE 创建创建库1234567891011121314151617语法CREATE &#123;DATABASE | SCHENA&#125; [IF NOT EXISTS] db_name [CHARACTER SET=] [COLLATE] # SCHENA指方案； IF NOT EXISTS指在不存在時才創建數據庫；db_name後的是指定排序的名稱及規則; CHARACTER SET=爲指定字符集，等號可省略；COLLATE爲指定排序規則mysql&gt; CREATE DATABASE test;Query OK, 1 row affected (0.00 sec)# 创建库mysql&gt; CREATE TABLE test.test(ID INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,Name CHAR(20));Query OK, 0 rows affected (0.01 sec)# 创建表。定義為AUTO_INCREMENT時必須是整型，非空，無符號，一定要創建主鍵或唯一鍵索引；AUTO_INCREMENT表示自動增長。PRIMARY KEY表示主鍵mysql&gt; CREATE SCHEMA IF NOT EXISTS students CHARACTER SET 'gbk' COLLATE 'gbk_chinese_ci';Query OK, 1 row affected (0.00 sec)# 創建數據庫後會在/var/lib/mysql數據存儲目錄中生成一個students的庫，其中有db.opt的ASCII文件，可用cat查看此opt文件，此文件中保存了此數據庫的默認字符集和排序規則[root@test ~]# cat /var/lib/mysql/students/db.opt default-character-set=gbkdefault-collation=gbk_chinese_ci 创建表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899创建表的方法有三种1. 直接定義一張空表2. 從其它表中查詢出數據，並以之創建新表3. 以其它表為模板創建一個空表语法CREATE TABLE [IF NOT EXISTS] tb_name (col_name col_defination, CONSTRAINT)# col_name col_defination指字段名稱字段定義，CONSTRAINT 指約束；字段定義有如下：# column_definition: # data_type [NOT NULL | NULL] [DEFAULT default_value]# [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY]# [COMMENT 'string']# [COLUMN_FORMAT &#123;FIXED|DYNAMIC|DEFAULT&#125;]# [STORAGE &#123;DISK|MEMORY|DEFAULT&#125;]# [reference_definition]方法一mysql&gt; CREATE TABLE tab1(id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,Name CHAR(20) NOT NULL,Age TINYINT NOT NULL); Query OK, 0 rows affected (0.01 sec)mysql&gt; CREATE TABLE tab2(id INT UNSIGNED NOT NULL AUTO_INCREMENT,Name CHAR(20) NOT NULL,Age TINYINT NOT NULL,PRIMARY KEY(id,Name),UNIQUE KEY(Name),INDEX(Age));Query OK, 0 rows affected (0.01 sec)# 可以把主鍵寫在最後，用逗號隔開，如果是多個列做主鍵，就一定要單獨寫在最後。# INT 表示整型，UNSIGNED 表示無符號的，AUTO_INCREMENT 表示自動增長，PRIMARY KEY表示主鍵，UNIQUE KEY表示定義唯一鍵，INDEX表示定義索引。这里的PRIMARY KEY, UNIQUE KEY, INDEX的使用方法是一样的，都可以在最后定义多个字段mysql&gt; USE students;Database changedmysql&gt; CREATE TABLE courses(CID TINYINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,Couse VARCHAR(50) NOT NULL) ENGINE=MyISAM;# 最後的ENGINE=MyISAM 是指定存儲引擎的，不加就是數據默認的innodeQuery OK, 0 rows affected (0.00 sec)mysql&gt; SHOW TABLE STATUS FROM students LIKE 'courses'\G*************************** 1. row *************************** Name: courses Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 0 Avg_row_length: 0 Data_length: 0Max_data_length: 281474976710655 Index_length: 1024 Data_free: 0 Auto_increment: 1 Create_time: 2019-01-04 10:59:44 Update_time: 2019-01-04 10:59:44 Check_time: NULL Collation: gbk_chinese_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec)# 命令中可以不加FROM students，那么查看的就是当前的库。mysql&gt; DROP TABLE courses;Query OK, 0 rows affected (0.00 sec)# 删除表方法二mysql&gt; CREATE TABLE testcourses SELECT * FROM courses WHERE CID&lt;=2;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0# 將原表中的CID小於等於2的数据創建一張新表mysql&gt; SHOW TABLES;+--------------------+| Tables_in_students |+--------------------+| courses || testcourses |+--------------------+2 rows in set (0.00 sec)mysql&gt; DESC courses;+-------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+---------------------+------+-----+---------+----------------+| CID | tinyint(3) unsigned | NO | PRI | NULL | auto_increment || Couse | varchar(50) | NO | | NULL | |+-------+---------------------+------+-----+---------+----------------+2 rows in set (0.00 sec)mysql&gt; DESC testcourses;+-------+---------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------------------+------+-----+---------+-------+| CID | tinyint(3) unsigned | NO | | 0 | || Couse | varchar(50) | NO | | NULL | |+-------+---------------------+------+-----+---------+-------+2 rows in set (0.01 sec)# 两个表的结构是不同的，一些屬性不存在了。方法三mysql&gt; CREATE TABLE test LIKE courses;Query OK, 0 rows affected (0.00 sec)mysql&gt; DESC test;+-------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+---------------------+------+-----+---------+----------------+| CID | tinyint(3) unsigned | NO | PRI | NULL | auto_increment || Couse | varchar(50) | NO | | NULL | |+-------+---------------------+------+-----+---------+----------------+2 rows in set (0.00 sec)# 以其它表為模板創建空表，這樣創建的表結構是一樣的 创建索引12345678910111213141516171819# 鍵都是索引，是特殊索引。鍵也稱作約束，可用作索引，屬於特殊索引（有特殊限定），他們存儲下來的都是B+tree索引的結構# BTREE索引主要是為了排序mysql&gt; CREATE INDEX couse_on_test ON test(Couse) USING BTREE;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0# 用 INDEX命令必須指定索引名稱，这里叫couse_on_test ,ON表示在哪個表的哪個字段上創建，一般只能使用BTREE索引， USING表示明確指明是什麼索引。mysql&gt; SHOW INDEXES FROM test;+-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| test | 0 | PRIMARY | 1 | CID | A | 0 | NULL | NULL | | BTREE | | || test | 1 | couse_on_test | 1 | Couse | A | NULL | NULL | NULL | | BTREE | | |+-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+2 rows in set (0.00 sec)# 显示表上的索引mysql&gt; CREATE INDEX couse1_on_test ON test(Couse(5) DESC) USING BTREE;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0# 創建索引同時指定要建索引長度爲5個字符，從左邊開始比較，對TEST類型創建時必須指定長度。並降序排列；ASC表示升序，DESC表示降序 INSERT 插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051语法INSERT INTO tb_name(col1,col2 …) VALUES (vol1, vol2, …)[,(val, val2, …),…] # 字符型要用單引號引起，數值型不需要引號，日期時間型也不需要引號，空值用NULL；''兩個單引號是一個字符串的空串，不是空值；此命令可實現批量插入；VALUES不一定是值，也可以是表達式；SET的用法像UPDATE命令方法一mysql&gt; INSERT INTO courses(Couse) values ('Hamogong'),('pixiejianfa'),('Kuihuabaodian');Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0# 向courses表中的Couse列中插入數據mysql&gt; SELECT * FROM courses;+-----+---------------+| CID | Couse |+-----+---------------+| 1 | Hamogong || 2 | pixiejianfa || 3 | Kuihuabaodian |+-----+---------------+3 rows in set (0.01 sec)方法二mysql&gt; source /root/jiaowu.sql# 导入库mysql&gt; INSERT INTO tutors SET Tname='Tom',Gender='F',Age=30;Query OK, 1 row affected (0.00 sec)mysql&gt; SELECT * FROM tutors ORDER BY TID DESC LIMIT 1;+-----+-------+--------+------+| TID | Tname | Gender | Age |+-----+-------+--------+------+| 10 | Tom | F | 30 |+-----+-------+--------+------+1 row in set (0.00 sec)# 查最後一條輸入的數據，ORDER BY TID DESC表示将TID字段按降序排列，LIMIT 1表示只顯示第一個，因为按降序排列所以这里显示的是最后一条记录mysql&gt; SELECT LAST_INSERT_ID();+------------------+| LAST_INSERT_ID() |+------------------+| 10 |+------------------+1 row in set (0.00 sec)# 這個被查看的函數保存了輸入數據的ID，數據按此ID編號方法三mysql&gt; DESC students;mysql&gt; INSERT INTO tutors (Tname,Gender,Age) SELECT Name,Gender,Age FROM students WHERE Age &gt; 20; Query OK, 4 rows affected (0.01 sec)Records: 4 Duplicates: 0 Warnings: 0# 將從一個表中查詢到的結果插入到指定表中去 ，注意字段要對應；把SELECT查詢到的結果插入到tutors表中，兩個表的字段數量要一致；把學生當中年齡大於20的學生的名字，姓別，年齡插入到tutors表中；前面INTO後的內容是表名與指定插入的字段# 如果INSERT命令在插入時有重復又違反了約束關系會報錯，爲了避免報錯，用如下命令# REPLACE：替換，原表中有就覆蓋，沒有就插入# REPLACE INTO：用法與INSERT INTO相同，有三種方法 DELETE 删除12345678910111213141516171819202122232425262728293031323334语法DELETE…FROM tb_name [WHERE] [ORDER BY] [LIMIT row_xount]; # 如未使用WHERE子句，表就会被清空了，刪除後無法恢復，慎用；TRUNCATE tb_name; # 此命令可以清空表並重置計數器（AUTOINCREMENT）mysql&gt; DELETE FROM students;Query OK, 10 rows affected (0.00 sec)# 清空students表mysql&gt; INSERT INTO students (Name,Age,Gender) VALUES ('Tom','30','F');Query OK, 1 row affected (0.00 sec)# 插入一条数据。mysql&gt; SELECT * FROM students;+------+------+------+--------+------+------+------+---------------------+| SID | Name | Age | Gender | CID1 | CID2 | TID | CreateTime |+------+------+------+--------+------+------+------+---------------------+| 3907 | Tom | 30 | F | NULL | NULL | NULL | 2012-04-06 10:00:00 |+------+------+------+--------+------+------+------+---------------------+1 row in set (0.00 sec)# 插入數據後計數器會繼續向下排號，如上面的3907mysql&gt; TRUNCATE students;Query OK, 0 rows affected (0.01 sec)# 清空表mysql&gt; INSERT INTO students (Name,Age,Gender) VALUES ('Tom',30,'F');Query OK, 1 row affected (0.00 sec)mysql&gt; SELECT * FROM students;+-----+------+------+--------+------+------+------+---------------------+| SID | Name | Age | Gender | CID1 | CID2 | TID | CreateTime |+-----+------+------+--------+------+------+------+---------------------+| 1 | Tom | 30 | F | NULL | NULL | NULL | 2012-04-06 10:00:00 |+-----+------+------+--------+------+------+------+---------------------+1 row in set (0.00 sec)# 使用TRUNCATE清空表后，再次插入数据时就重新计数了。又从1开始了 UPDATE 修改1234567891011121314语法UPDATE tb_name SET col=…,col=… [WHERE][ORDER BY] [LIMIT row_xount];# 一定要使用WHERE條件指明条件mysql&gt; UPDATE tutors SET Age=50 WHERE TID=12;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0# 修改tutors表中TID为12的记录的Age值为50mysql&gt; SELECT * FROM tutors WHERE TID=12;+-----+-------+--------+------+| TID | Tname | Gender | Age |+-----+-------+--------+------+| 12 | HuFei | M | 50 |+-----+-------+--------+------+1 row in set (0.00 sec) ALTER 修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121语法ALTER &#123;DATABASE | SCHEMA &#125; db_name alter_specification… # alter_specification…表示改什麼，能修改的就是字符集與排序規則，偶爾會昇級數據字典名稱，在老版本遷移到新版本數據庫時才用昇級數據字典名稱。用ALTER DATABASE | SCHEMA db_name UPGRADE DATA DIRECTORY NAME就可升級。alter_specification可以是[DEFAULT] CHARACTER SET [=] charset_name或[DEFAULT] COLLATE [=] collation_namemysql&gt; use students;mysql&gt; ALTER TABLE test ADD UNIQUE KEY (Couse);Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0# 添加唯一鍵索引mysql&gt; ALTER TABLE test CHANGE Couse Course VARCHAR(50) NOT NULL;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0# 改變字段名稱mysql&gt; ALTER TABLE test ADD starttime date default '20190105';Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0# 向test表添加字段 starttime，類型是date默認值是default '20190105'mysql&gt; ALTER TABLE test RENAME TO testcourses1;Query OK, 0 rows affected (0.00 sec)# 将test改表名为testcourses1mysql&gt; RENAME TABLE testcourses1 TO test;Query OK, 0 rows affected (0.00 sec)# 使用RENAME TABLE命令将名字改回test。mysql&gt; SHOW TABLES;+--------------------+| Tables_in_students |+--------------------+| courses || test || testcourses |+--------------------+3 rows in set (0.00 sec)例：mysql&gt; CREATE TABLE student (SID INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,Name VARCHAR(30),CID INT NOT NULL);Query OK, 0 rows affected (0.01 sec)mysql&gt; INSERT INTO student (Name,CID) VALUES ('Yue Buqun',2),('Zhang Wuji',1);Query OK, 2 rows affected (0.01 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; SELECT Name,Couse FROM student,courses WHERE student.CID=courses.CID; +------------+-------------+| Name | Couse |+------------+-------------+| Yue Buqun | pixiejianfa || Zhang Wuji | Hamogong |+------------+-------------+2 rows in set (0.00 sec)# 組合查詢/多表查詢；查询student,courses两个表，显示其中student表CID字段等于courses表CID字段的部分mysql&gt; ALTER TABLE student MODIFY CID TINYINT UNSIGNED NOT NULL;Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0# 改字段類型mysql&gt; ALTER TABLE courses ENGINE=InnoDB;Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0# 改存儲引擎mysql&gt; ALTER TABLE student ADD FOREIGN KEY (CID) REFERENCES courses (CID); Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0# 添加外鍵用FOREIGN KEY，外鍵只能在支持事物的存儲引擎上使用，如Inodb，添加外鍵後就有了引用型約束，當插入的信息是關聯表中沒有的信息時是不能插入的。 REFERENCES表示這張表參考哪張表的哪個字段# 添加时两个表的存储引擎应该都是InnoDB，两个字段的属性也应该一样。如下：mysql&gt; desc courses;+-------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+---------------------+------+-----+---------+----------------+| CID | tinyint(3) unsigned | NO | PRI | NULL | auto_increment |mysql&gt; desc student;+-------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+---------------------+------+-----+---------+----------------+| CID | tinyint(3) unsigned | NO | MUL | NULL | |mysql&gt; ALTER TABLE student ADD FOREIGN KEY foreign_cid (CID) REFERENCES courses (CID);Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0# 給外鍵取名叫foreign_cid，就是要添加外键时在FOREIGN KEY后面加入一个名字。与上一条命令相同。mysql&gt; select * from courses;+-----+---------------+| CID | Couse |+-----+---------------+| 1 | Hamogong || 2 | pixiejianfa || 3 | Kuihuabaodian |+-----+---------------+3 rows in set (0.00 sec)mysql&gt; select * from student;+-----+------------+-----+| SID | Name | CID |+-----+------------+-----+| 1 | Yue Buqun | 2 || 2 | Zhang Wuji | 1 |+-----+------------+-----+2 rows in set (0.00 sec)mysql&gt; INSERT INTO student (Name,CID) VALUES ('chenjialuo',1);Query OK, 1 row affected (0.01 sec)# 插入一条数据，因为student表中的CID字段是有外键约束的，依赖于courses表的CID字段。所以添加时，CID的数字一定是courses表中的CID字段有的数字，上面查看表courses表中的CID字段只有1、2、3,所以这里使用了1。如果是courses表中的CID字段中不存在的数字，那么就会报错，"ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`students`.`student`, CONSTRAINT `student_ibfk_1` FOREIGN KEY (`CID`) REFERENCES `courses` (`CID`))"mysql&gt; select * from student;+-----+------------+-----+| SID | Name | CID |+-----+------------+-----+| 1 | Yue Buqun | 2 || 2 | Zhang Wuji | 1 || 4 | chenjialuo | 1 |+-----+------------+-----+3 rows in set (0.00 sec)mysql&gt; DELETE FROM courses WHERE CID=1;ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`students`.`student`, CONSTRAINT `student_ibfk_1` FOREIGN KEY (`CID`) REFERENCES `courses` (`CID`))# 刪表中信息，有外鍵約束時是不能刪的，因为courses表中CID为1的行已经被student表中的CID表引用了，如果将上面的CID改为等于3，就不会有报错了，因为没被引用。外鍵與存儲引擎有關，外鍵約束會極大地消耗資源的 DROP 删除123456语法DROP &#123;DATABASE | SCHEMA&#125; [IF EXISTS] db_name # 一般不會給數據庫重命名。要改數據庫的名稱，可將數據庫停掉，並把數據庫的目錄名稱改一下，重啓服務即可；一般不用重命名DROP INDEX name_on_student ON student# 删除student上叫name_on_student的索引 SELECT 查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223语法SELECT 函數名;例：mysql&gt; SELECT DATABASE();+------------+| DATABASE() |+------------+| jiaowu |+------------+1 row in set (0.00 sec)# 查看默認數據庫是誰mysql&gt; SELECT LAST_INSERT_ID();+------------------+| LAST_INSERT_ID() |+------------------+| 4 |+------------------+1 row in set (0.00 sec)# 查詢上一次生成的ID到幾了mysql&gt; SELECT @@global.sql_mode;+--------------------------------------------+| @@global.sql_mode |+--------------------------------------------+| STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION |+--------------------------------------------+1 row in set (0.00 sec)# @@表示調用服務器變量或內置變量语法SELECT select-list FROM tb WHERE qualificationSELECT * FROM tb_name;# 顯示表中所有字段SELECT field1,field2 FROM tb_name; # 基於投影，只顯示哪些字段例：mysql&gt; SELECT Name,Age FROM students;+------+------+| Name | Age |+------+------+| Tom | 30 |+------+------+1 row in set (0.00 sec)SELECT * FROM tb_name WHERE qualification # 選擇，顯示符合條件的行, qualification表示搜索碼，搜索碼是表中字段即可例：mysql&gt; SELECT * FROM students WHERE Age&gt;=20;+-----+------+------+--------+------+------+------+---------------------+| SID | Name | Age | Gender | CID1 | CID2 | TID | CreateTime |+-----+------+------+--------+------+------+------+---------------------+| 1 | Tom | 30 | F | NULL | NULL | NULL | 2012-04-06 10:00:00 |+-----+------+------+--------+------+------+------+---------------------+1 row in set (0.00 sec)mysql&gt; SELECT Name,Age FROM students WHERE Age&gt;=20; +------+------+| Name | Age |+------+------+| Tom | 30 |+------+------+1 row in set (0.00 sec)SELECT [DISTINCT] * FROM tb_name WHERE qualification # [DISTINCT]表示其後的相同的值只顯示一次，如下面語句中指Gender相同的只顯示一次例：mysql&gt; SELECT DISTINCT Gender FROM students;+--------+| Gender |+--------+| F |+--------+1 row in set (0.00 sec)========================================================*** 规范1. FROM子句後可跟表、多個表、其它SELECT語句，表示要查詢的關系2. WHERE子句指定一個布爾關系表達式，用到的符號有=、&gt;、&lt;、&gt;=、&lt;=、!=、&lt;=&gt;，在做數值比較時，數值不能加引號，條件是字符時必須用’’引號引起，&lt;=&gt;表示就算表中有空值也可以正確比較3. 邏輯表達式 AND、OR、NOT BETWEEN…AND… # 在…之間 LIKE '' # 比較操作，這時要用通配符%和_ %表示任意長度任意字符 _表示一個長度任意字符 REGEXP或RLIKE # 支持正則表達式 IN () # 做離散取值時使用，括號中是符合的條件 IS NULL # 判斷是否為空 IS NOT NULL # 判斷是否不空 ORDER BY field_name (ASC|DESC) # 將查詢後的結果排序，默認是昇序，ASC是昇序，DESC是降序 AS # 字段別名4. LIMIT子句：只显示几行结果或偏移几行显示几行 LIMIT [offset,]Count5. 聚合計算：SUM(), MIN(), MAX(), AVG(),COUNT()6. GROUP BY：分組，目的是將整張表的內容跟據某個標准碼分完組後求聚合函數 HAVING # 條件：分組時用的过滤。与WHERE使用方法一样========================================================例：mysql&gt; source /root/jiaowu.sqlmysql&gt; SELECT Name,Age FROM students WHERE Age&gt;=20;+-------------+------+| Name | Age |+-------------+------+| DingDian | 25 || HuFei | 31 |mysql&gt; SELECT Name,Age FROM students WHERE Gender='M';+-------------+------+| Name | Age |+-------------+------+| GuoJing | 19 || YangGuo | 17 |mysql&gt; SELECT Name,Age FROM students WHERE Age+1&gt;=20;+-------------+------+| Name | Age |+-------------+------+| GuoJing | 19 || DingDian | 25 |# 用表達式做條件，但在字段中這樣用會不能索引mysql&gt; SELECT Name FROM students WHERE Age&gt;20 AND Gender='M';+-------------+| Name |+-------------+| DingDian || HuFei |# 與mysql&gt; SELECT Name FROM students WHERE Age&gt;20 OR Gender='M';+-------------+| Name |+-------------+| GuoJing || YangGuo |# 或mysql&gt; SELECT Name FROM students WHERE NOT Age&gt;20;+--------------+| Name |+--------------+| GuoJing || YangGuo |# 非mysql&gt; SELECT Name,Age,Gender FROM students WHERE NOT Age&gt;20 AND NOT Gender='M';+--------------+------+--------+| Name | Age | Gender |+--------------+------+--------+| HuangRong | 16 | F || YueLingshang | 18 | F |mysql&gt; SELECT Name,Age,Gender FROM students WHERE NOT (Age&gt;20 OR Gender='M');+--------------+------+--------+| Name | Age | Gender |+--------------+------+--------+| HuangRong | 16 | F || YueLingshang | 18 | F |mysql&gt; SELECT Name,Age FROM students WHERE Age&gt;=20 AND Age&lt;=25;+-------------+------+| Name | Age |+-------------+------+| DingDian | 25 || ZhangWuji | 20 |# 年齡在20-25之間的同學mysql&gt; SELECT Name,Age FROM students WHERE Age BETWEEN 20 AND 25;+-------------+------+| Name | Age |+-------------+------+| DingDian | 25 || ZhangWuji | 20 |# 用BETWEEN…AND，与上面效果一样mysql&gt; SELECT Name FROM students WHERE Name LIKE 'y%';+--------------+| Name |+--------------+| YangGuo || YueLingshang |# 找姓名中以y開頭的，用LIKE，表示模糊查找，要用通配符mysql&gt; SELECT Name FROM students WHERE Name LIKE 'y____';+-------+| Name |+-------+| YiLin |+-------+# 找y後跟4個字符的mysql&gt; SELECT Name FROM students WHERE Name LIKE '%ing%';+--------------+| Name |+--------------+| GuoJing || DingDian |# 找包含ing的mysql&gt; SELECT Name FROM students WHERE Name RLIKE '^[DHY].*$';+--------------+| Name |+--------------+| YangGuo || DingDian |# RLIKE或REGEXP表示用正則表達式，找D、H、Y開頭的後面是任意字符，用正則時索引可能不太有用mysql&gt; SELECT Name FROM students WHERE Age IN (18,20,25);+--------------+| Name |+--------------+| DingDian || YueLingshang |# 找年齡爲18、20、25的，用IN來指定一個列表mysql&gt; SELECT Name FROM students WHERE CID2 IS NULL;+-------------+| Name |+-------------+| LingHuchong || YiLin |+-------------+# 找課程2爲空的，用NULL時要用IS，不空用IS NOT NULL 排序查詢後的結果123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt; SELECT Name FROM students WHERE CID2 IS NULL ORDER BY Name;+-------------+| Name |+-------------+| LingHuchong || YiLin |+-------------+# 跟據姓名排序，用ORDER BY field_name &#123;ASC|DESC&#125;指定升序還是降序# 數據存儲在磁盤上有三種格式：堆格式，順序格式，hash格式；建議在經常要排序的場景中應該盡可能選擇一種在存儲時就排好序的方式，而且盡可能和搜索碼保持一致mysql&gt; SELECT Name AS Student_name FROM students;+--------------+| Student_name |+--------------+| GuoJing || YangGuo |# 字段別名，用AS來實現。將字段Name顯示為Student_name；表也支持別名mysql&gt; SELECT 3+1 AS SUM;+-----+| SUM |+-----+| 4 |+-----+# 直接取別名，還可運算mysql&gt; SELECT Name AS Student_name FROM students LIMIT 2;+--------------+| Student_name |+--------------+| GuoJing || YangGuo |+--------------+# 只顯示前兩個mysql&gt; SELECT Name AS Student_name FROM students LIMIT 2,3;+--------------+| Student_name |+--------------+| DingDian || HuFei |# 偏移2個從第三個開始顯示3個 聚合計算1234567891011121314151617181920212223242526272829303132333435363738394041424344454647mysql&gt; SELECT AVG(age) FROM students;+----------+| AVG(Age) |+----------+| 21.3000 |+----------+# AVG表示平均，括號內是字段名mysql&gt; SELECT MAX(Age) FROM students;+----------+| MAX(Age) |+----------+| 31 |+----------+# 最大值mysql&gt; SELECT MIN(Age) FROM students; +----------+| MIN(Age) |+----------+| 16 |+----------+# 最小值mysql&gt; SELECT SUM(Age) FROM students;+----------+| SUM(Age) |+----------+| 213 |+----------+# 总和mysql&gt; SELECT COUNT(Age) FROM students;+------------+| COUNT(Age) |+------------+| 10 |+------------+# 個數之和mysql&gt; SELECT AVG(Age) FROM students WHERE Gender='M';+----------+| AVG(Age) |+----------+| 22.8571 |+----------+# 找男同學的平均年齡 分組12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 分组就是将某一列相同的数据合并为一行显示出来mysql&gt; SELECT Age,Gender FROM students GROUP BY Gender;+------+--------+| Age | Gender |+------+--------+| 16 | F || 19 | M |+------+--------+# 跟據性別分兩組；GROUP BY表示根據什麼分組，这里显示Age是没有意义的，因为这里只是为了根据性别来分组。mysql&gt; SELECT AVG(Age),Gender FROM students GROUP BY Gender;+----------+--------+| AVG(Age) | Gender |+----------+--------+| 17.6667 | F || 22.8571 | M |+----------+--------+# 求不同性别的平均年龄mysql&gt; SELECT COUNT(CID1) FROM students GROUP BY CID1;+-------------+| COUNT(CID1) |+-------------+| 1 || 3 || 1 || 1 |# 根據課程選擇，統計CID1中每門課選修的同學的個數mysql&gt; SELECT COUNT(CID1) AS Persons,CID1 FROM students GROUP BY CID1;+---------+------+| Persons | CID1 |+---------+------+| 1 | 1 || 3 | 2 || 1 | 5 || 1 | 6 || 2 | 8 || 1 | 11 || 1 | 18 |+---------+------+# 將整張表的內容跟據某個標准碼分完組後求聚合函數。显示的结果中，第一列表示每门课程有几个人在学，第二列表示这些课程的ID号也就是统计每门课程的ID有几个人在学mysql&gt; SELECT COUNT(CID1) AS Persons,CID1 FROM students GROUP BY CID1 HAVING persons&gt;=2;+---------+------+| Persons | CID1 |+---------+------+| 3 | 2 || 2 | 8 |+---------+------+# 分組顯示那些選修人數大於等於2個人的，用 HAVING引導過濾條件。 HAVING只能跟 GROUP BY一起用，用於將 GROUP BY的結果再次進行過濾 多表查询123456789101112131415161718192021222324* 交叉連接：笛卡爾乘積，將兩張表連在一起，因為表太大最好不要這樣做* 自然連接：對兩張表做比較將相同字段，只將等值的保留下來mysql&gt; SELECT * FROM students,courses;# 查詢兩張表，顯示为一張表，一般不要這樣做mysql&gt; SELECT * FROM students,courses WHERE students.CID1 = courses.CID;# 顯示每位同學及他所學的第一門課的名稱，條件是 students表中CID1字段等於 courses表中CID字段的，顯示的結果中只有CID1和CID相等的才保留下來mysql&gt; SELECT students.Name,courses.Cname FROM students,courses WHERE students.CID1 = courses.CID;+--------------+------------------+| Name | Cname |+--------------+------------------+| GuoJing | TaiJiquan || YangGuo | TaiJiquan |# 保留要求顯示的字段並做自然連接，如果兩張表中都有name字段，就必須加上表名。或用別名，如下：mysql&gt; SELECT s.Name,c.Cname FROM students AS s,courses AS c WHERE s.CID1 = c.CID;+--------------+------------------+| Name | Cname |+--------------+------------------+| GuoJing | TaiJiquan || YangGuo | TaiJiquan |# 先取別名再過濾，自連接時必須定義別名，不然不能連接。 外連接123456789101112131415161718* 左外連接：左表LEFT JOIN 右表 ON 條件* 右外連接：左表RIGHT JOIN 右表 ON 條件 ；外連接是用ON來指定連接條件mysql&gt; SELECT s.Name,c.Cname FROM students AS s LEFT JOIN courses AS c ON s.CID1=c.CID;+--------------+------------------+| Name | Cname |+--------------+------------------+| GuoJing | TaiJiquan || YangGuo | TaiJiquan |# 顯示每位同學選擇的第一門課，如果有這門課就顯示課程名稱，如果沒有就顯示NULL。这是以左边的列为标准，也就是左边的列的信息会全部显示，右边的列可能有NULLmysql&gt; SELECT s.Name,c.Cname FROM students AS s RIGHT JOIN courses AS c ON s.CID1=c.CID;+--------------+------------------+| Name | Cname |+--------------+------------------+| GuoJing | TaiJiquan || YangGuo | TaiJiquan |# 以右表爲標準，如果課程有人選擇就顯示誰選了，如果沒人選就顯示NULL 自連接1234567mysql&gt; SELECT c.Name AS student,s.Name AS teacher FROM students AS s,students AS c WHERE c.TID=s.SID;+-----------+-------------+| student | teacher |+-----------+-------------+| GuoJing | DingDian || YangGuo | GuoJing |# 顯示每個同學和他的導師，導師是根據導師的編號在同一張表中再查詢對應的人。只有一張表，查詢在一張表中引用兩次 子查詢123456789101112131415161718192021222324252627282930mysql&gt; SELECT Name FROM students WHERE Age &gt; (SELECT AVG(Age) FROM students);+-------------+| Name |+-------------+| DingDian || HuFei || Xuzhu || LingHuchong |+-------------+# 找students表中年齡大於平均年齡的同學# 可在比較操作中使用子查詢，子查詢只能是一個單值，如果是一堆值會報錯# 可在IN()中使用子查詢，這就不需要返回單值了mysql&gt; SELECT Name FROM students WHERE Age IN (SELECT Age FROM tutors);# 不加IN會報錯，因爲老師的年齡有很多。查找同學年齡與老師一樣的mysql&gt; SELECT Name,Age FROM (SELECT Name,Age FROM students) AS t WHERE t.Age&gt;=20;+-------------+------+| Name | Age |+-------------+------+| DingDian | 25 || HuFei | 31 |# 在FROM中使用子查詢# 選擇所有用戶和他的年齡，顯示前面的表中年齡大於20的。mysql&gt; SELECT Name,Age FROM students AS t WHERE t.Age&gt;=20; +-------------+------+| Name | Age |+-------------+------+| DingDian | 25 || HuFei | 31 |# 这条命令与上面执行的结果是一样的。 聯合查詢1234567mysql&gt; (SELECT Name,Age FROM students)UNION(SELECT Tname,Age FROM tutors);+--------------+------+| Name | Age |+--------------+------+| GuoJing | 19 || YangGuo | 17 |# 聯合查詢：这只是简单地將兩個查詢結果聯合起來，上半部分是第一条查询语句的结果，下半部分是第二条查询语句的结果 测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* 挑选出courses表中没有被students中的CID2学习的课程的课程名称；例如：挑选出没有教授任何课程的老师，每个老师及其所教授课程的对应关系在courses表中找出students表中CID1有两个或两个以上同学学习了的同一门课程的课程名称 mysql&gt; SELECT Cname FROM courses WHERE CID NOT IN (SELECT DISTINCT CID2 FROM students WHERE CID2 IS NOT NULL); +------------------+| Cname |+------------------+| TaiJiquan || Qianzhuwandushou |# 挑選出courses表中沒有被students中的CID2學習的課程的課程名稱。括号中查询出的是students表中不为空的CID2的ID号，再从courses表中的CID与后面的结果对比，如果有CID不在后面的CID2中就选出来，最后显示这些选出的CID的名称。mysql&gt; SELECT Tname FROM tutors WHERE TID NOT IN (SELECT DISTINCT TID FROM courses);+-------------+| Tname |+-------------+| NingZhongze |+-------------+# 挑选出没有教授任何课程的老师；找到后面括号中的courses表中的课程ID并且不用重复显示，前面再按条件在后面的结果中筛选，选出tutors表中的课程ID不在后面的结果中的项，最后按这个条件结果显示tutors表中的Tname项。mysql&gt; SELECT Cname FROM courses WHERE CID IN (SELECT CID1 FROM students GROUP BY CID1 HAVING COUNT(CID1) &gt;=2);+-------------+| Cname |+-------------+| TaiJiquan || Wanliduxing |+-------------+# 找出students表中CID1有两个或两个以上同学学习了的同一门课程的课程名称 # 建議將一個復雜查詢改寫成幾個簡單查詢，這樣執行的更快显示每一位老师及其所教授的课程，没有教授的课程的保持为NULLmysql&gt; SELECT t.Tname,c.Cname FROM tutors AS t LEFT JOIN courses AS c ON t.TID=c.TID; +--------------+------------------+| Tname | Cname |+--------------+------------------+| HuangYaoshi | Hamagong || Miejueshitai | TaiJiquan |显示每一个课程及其相关的老师，没有老师教授的课程将其老师显示为空mysql&gt; SELECT t.Tname,c.Cname FROM tutors AS t RIGHT JOIN courses AS c ON t.TID=c.TID; +--------------+------------------+| Tname | Cname |+--------------+------------------+| HuangYaoshi | Hamagong || Miejueshitai | TaiJiquan |显示每位同学的名称，所学CID1课程的课程名及其讲授了相关课程的老师的名称mysql&gt; SELECT Name,Cname,Tname FROM students,courses,tutors WHERE students.CID1=courses.CID AND courses.TID=tutors.TID;+--------------+------------------+--------------+| Name | Cname | Tname |+--------------+------------------+--------------+| GuoJing | TaiJiquan | Miejueshitai || YangGuo | TaiJiquan | Miejueshitai | 視圖12345678910111213141516171819202122232425视图是存儲下來的SELECT語句，基於基表的查詢結果mysql&gt; CREATE VIEW sct AS SELECT Name,Cname,Tname FROM students,courses,tutors WHERE students.CID1=courses.CID AND courses.TID=tutors.TID; Query OK, 0 rows affected (0.00 sec)# 創建視圖，视图的名字叫sctmysql&gt; SHOW TABLES;+------------------+| Tables_in_jiaowu |+------------------+| courses || scores || sct |# 查看發現視圖被當作一張表了mysql&gt; SELECT * FROM sct;+--------------+------------------+--------------+| Name | Cname | Tname |+--------------+------------------+--------------+| GuoJing | TaiJiquan | Miejueshitai || YangGuo | TaiJiquan | Miejueshitai |# 雖然用了*，但還是用了上面的創建視圖的語句中的SELCET部分# 一般不建議向視圖中插入數據，視圖也被稱為虛表，視圖所依賴的表叫基表。視圖上不會有索引mysql&gt; DROP VIEW sct;Query OK, 0 rows affected (0.00 sec)# 刪除sct視圖# 物化視圖：可將查詢結果保存下來。SELECT，mysql上不建議使用視圖 SET 设定1234567891011121314语法SET GLOBAL | SESSION 變量名 = 'value';mysql&gt; SET tx_isolation='READ-UNCOMMITTED';Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT @@tx_isolation;+------------------+| @@tx_isolation |+------------------+| READ-UNCOMMITTED |+------------------+1 row in set (0.00 sec)# 查看某個特定變量的值]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql用户管理]]></title>
    <url>%2F2019%2F01%2F03%2Fmysql%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql用户密码修改方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114方法一[root@test ~]# mysql_secure_installation NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MySQL SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!In order to log into MySQL to secure it, we'll need the currentpassword for the root user. If you've just installed MySQL, andyou haven't set the root password yet, the password will be blank,so you should just press enter here.Enter current password for root (enter for none): OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MySQLroot user without the proper authorisation.Set root password? [Y/n] y New password: Re-enter new password: Password updated successfully!Reloading privilege tables.. ... Success!By default, a MySQL installation has an anonymous user, allowing anyoneto log into MySQL without having to have a user account created forthem. This is intended only for testing, and to make the installationgo a bit smoother. You should remove them before moving into aproduction environment.Remove anonymous users? [Y/n] y ... Success!Normally, root should only be allowed to connect from 'localhost'. Thisensures that someone cannot guess at the root password from the network.Disallow root login remotely? [Y/n] y ... Success!By default, MySQL comes with a database named 'test' that anyone canaccess. This is also intended only for testing, and should be removedbefore moving into a production environment.Remove test database and access to it? [Y/n] y - Dropping test database...ERROR 1008 (HY000) at line 1: Can't drop database 'test'; database doesn't exist ... Failed! Not critical, keep moving... - Removing privileges on test database... ... Success!Reloading the privilege tables will ensure that all changes made so farwill take effect immediately.Reload privilege tables now? [Y/n] y ... Success!All done! If you've completed all of the above steps, your MySQLinstallation should now be secure.Thanks for using MySQL!Cleaning up...# 第一次启动后设置root密码、删除匿名用户、拒绝远程连接、删除测试库、重新加载数据库mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed# 进入mysql库mysql&gt; select Host,User,Password from user;+-----------+------+-------------------------------------------+| Host | User | Password |+-----------+------+-------------------------------------------+| localhost | root | *128977E278358FF80A246B5046F51043A2B1FCED || 127.0.0.1 | root | *128977E278358FF80A246B5046F51043A2B1FCED || ::1 | root | *128977E278358FF80A246B5046F51043A2B1FCED |+-----------+------+-------------------------------------------+3 rows in set (0.00 sec)# 查看用户信息mysql&gt; SET PASSWORD FOR 'root'@'localhost' =password('123456');Query OK, 0 rows affected (0.00 sec)# 改地址为localhost的root密码为123456mysql&gt; select Host,User,Password from user;+-----------+------+-------------------------------------------+| Host | User | Password |+-----------+------+-------------------------------------------+| localhost | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 || 127.0.0.1 | root | *128977E278358FF80A246B5046F51043A2B1FCED || ::1 | root | *128977E278358FF80A246B5046F51043A2B1FCED |+-----------+------+-------------------------------------------+3 rows in set (0.00 sec)# 再次查看密码，localhost的root用户密码和另两个不一样了。方法二mysql&gt; UPDATE mysql.user SET PASSWORD=PASSWORD('123456') WHERE User='root' AND Host='localhost';Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0# 改localhost地址的root用户的密码为123456，如果WHERE后面不指定地址，就是修改所有地址的root用户密码mysql&gt; SELECT Host,User,Password FROM user;+-----------+------+-------------------------------------------+| Host | User | Password |+-----------+------+-------------------------------------------+| localhost | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 || 127.0.0.1 | root | *128977E278358FF80A246B5046F51043A2B1FCED || ::1 | root | *128977E278358FF80A246B5046F51043A2B1FCED |+-----------+------+-------------------------------------------+3 rows in set (0.01 sec)方法三[root@test ~]# mysqladmin -uroot -hlocalhost password 'centos' -p Enter password: Warning: Using a password on the command line interface can be insecure.# 改localhost地址的root用户密码为centos，下面会提示“在命令行使用密码可能不安全” 创建用户12345678910111213141516171819202122232425262728方法一CREATE USER username@host [IDENTIFIED BY ‘password’]mysql&gt; CREATE USER cactiuser@'%' IDENTIFIED BY 'cactiuser';Query OK, 0 rows affected (0.01 sec)mysql&gt; SHOW GRANTS FOR cactiuser@'%';+----------------------------------------------------------------------------------------------------------+| Grants for cactiuser@% |+----------------------------------------------------------------------------------------------------------+| GRANT USAGE ON *.* TO 'cactiuser'@'%' IDENTIFIED BY PASSWORD '*43DD7940383044FBDE5B177730FAD3405BC6DAD7' |+----------------------------------------------------------------------------------------------------------+# 查看用戶權限授權信息[root@test ~]# mysql -ucactiuser -pmysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema |+--------------------+mysql&gt; CREATE DATABASE cactiuser;ERROR 1044 (42000): Access denied for user 'cactiuser'@'%' to database 'cactiuser'# 要用root用户才能创建此库或给cactiuser一个创建的权限方法二INSERT INTO mysql.usermysql&gt;FLUSH PRIVILEGES; # 這條必須執行 创建用户并授权1234567891011121314151617181920212223242526272829303132语法：GRANT ALL PRIVILEGES ON db.* TO username@'%' WITH_OPTION;GRANT EXECUTE ON FUNCTION db.abc TO username@'%';with_option： GRANT OPTION # 可以將自己獲得的權限給別人 MAX_QUERIES_PER_HOUR count # 每小時最多允許發起多少次查詢 MAX_UPDATES_PER_HOUR count # 每小時只允許使用幾次UPDATES MAX_CONNECTIONS_PER_HOUR count # 每小時只允許發起幾個連接請求 MAX_USER_CONNECTIONS count # 同一帳號最多連接多少次mysql&gt; GRANT CREATE ON cactidb.* TO 'cactiuser'@'%' WITH GRANT OPTION;# 給用戶cactiuser創建cactidb庫及在cactidb庫中創建表的權限；CREATE的權限是建庫、表、索引等；WITH GRANT OPTION表示此用户可以将自己的权限给自己创建的用户，但此用户无法操作mysql.user表，所以此项无用。mysql&gt; GRANT INSERT ON cactidb.* TO 'cactiuser'@'%';# 給用戶插入權限，INSERT權限既可以在表級別也可以用在字段級別，這樣寫是用在表級別的，給予此類權限後要重新登陸才能生效，FLUSH PRIVILEGES;是沒有用的，因爲cactiuser沒有此權限。mysql&gt; GRANT SELECT ON cactidb.* TO 'cactiuser'@'%';# 给cactiuser@%用户SELECT查询权限mysql&gt; GRANT SELECT,INSERT,CREATE ON cactidb.* TO 'cactiuser'@'%' IDENTIFIED BY 'centos';# 用一个命令给上面三个权限，并设置密码mysql&gt; GRANT ALTER ON cactidb.* TO 'cactiuser'@'%';# 給用戶ALTER權限，重新登陸生效mysql&gt; RENAME USER cactiuser TO cactiu;# 給用戶重命名 查看用户权限12mysql&gt; SHOW GRANTS FOR 'cactiuser'@'%';# 查看用戶都有哪些權限 取消权限12mysql&gt; REVOKE SELECT ON cactidb.* FROM 'cactiuser'@'%';# 取消某個權限 删除用户123456789101112mysql&gt; DROP USER 'root'@'::1';Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT Host,User,Password FROM mysql.user;+-----------+------+-------------------------------------------+| Host | User | Password |+-----------+------+-------------------------------------------+| localhost | root | *128977E278358FF80A246B5046F51043A2B1FCED || 127.0.0.1 | root | *128977E278358FF80A246B5046F51043A2B1FCED |+-----------+------+-------------------------------------------+2 rows in set (0.00 sec)# 删除IPV6地址的root用户 mysql管理員密碼忘記找回123456789101112131415161718192021222324252627282930313233343536CentOS7[root@test ~]# systemctl stop mysql[root@test ~]# vim /usr/lib/systemd/system/mysqld.serviceExecStart=/usr/bin/mysqld_safe --basedir=/usr --skip-grant-tables --skip-networking# 加入后面两个选项。实现跳过授权表和网络[root@test ~]# systemctl daemon-reload# 重新加载[root@test ~]# systemctl start mysql[root@test ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 2mysql&gt; UPDATE mysql.user SET PASSWORD=PASSWORD('centos') WHERE User='root';Query OK, 1 row affected (0.00 sec)Rows matched: 2 Changed: 1 Warnings: 0# 修改所有地址的root用户密码。从5.7版本开始，user表中不再有PASSWORD字段，改为了authentication_string，所以上面的命令要改为authentication_string=PASSWORD('centos')[root@test ~]# systemctl stop mysql# 一定要先停止mysql服务再修改[root@test ~]# vim /usr/lib/systemd/system/mysqld.serviceExecStart=/usr/bin/mysqld_safe --basedir=/usr[root@test ~]# systemctl daemon-reload[root@test ~]# systemctl start mysql[root@test ~]# mysql -uroot -pcentosWarning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \g.# 使用密码登录CentOS6service mysqld stopvim /etc/init.d/mysqld# 找到start一項，在圖片最下面的那行加入--skip-grant-tables跳過授權表和--skip-networking跳過網絡，這樣改完後只能在本機登錄。通過更新授權表方式直接修改其密碼，而後移除此兩個選項重啓服務即可。service mysqld start mysql UPDATE user SET PASSWORD=PASSWORD(‘12345’) WHERE User=’root’; # 更改root用戶密碼SELECT User,Host,Password FROM user;# 退出mysql服務器，把剛才的配置文件改回來，再啟動服務器，改變的內容才會生效。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql用户管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql安装与配置]]></title>
    <url>%2F2019%2F01%2F03%2Fmysql%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装方法12345# 下载：http://repo.mysql.com/yum/mysql-5.5-community/el/7/x86_64/，到此地址中下载mysql-community-release-el7-5.noarch.rpm，这是mysql的官方rpm源，测试速度非常慢wget http://mirrors.ustc.edu.cn/mysql-repo/yum/mysql-5.7-community/el/7/x86_64/mysql-community-release-el7-7.noarch.rpm# 这是科大的mysql源，速度正常。地址：http://mirrors.ustc.edu.cn/mysql-repo/yum/yum install -y mysql-community-release-el7-7.noarch.rpmyum install -y mysql-community-server 配置1234567891011121314151617vim /etc/my.cnf [mysqld] skip_name_resolve=ON innodb_file_per_table=ON# 加入两项systemctl start mysql* 不输入用户名和密码登录mysql[root@test ~]# vim /root/.my.cnf[client]user='root'password='centos'host='localhost'[root@test ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 21Server version: 5.6.42 MySQL Community Server (GPL)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql安装与配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker资源限制]]></title>
    <url>%2F2018%2F12%2F19%2Fdocker%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[安装配置12345678910[root@test ~]# yum install -y epel-release[root@test ~]# yum install -y docker[root@test ~]# vim /etc/docker/daemon.json &#123; "registry-mirrors":["http://192.168.0.130:8083"], "insecure-registries":["192.168.0.130:8083","192.168.0.130:8082"], "disable-legacy-registry":true &#125;# registry-mirrors表示使用本地仓库，insecure-registries表示可以不使用https协议，disable-legacy-registry定义了关闭"Docker v1 API"，这样就不用在定义nexus3仓库的三种类型时选择启用Docker v1 API了。[root@test ~]# systemctl start docker 测试压测内存1234567891011121314151617181920212223242526272829303132333435[root@test ~]# docker pull lorel/docker-stress-ngUsing default tag: latestTrying to pull repository docker.io/lorel/docker-stress-ng ... latest: Pulling from docker.io/lorel/docker-stress-ngc52e3ed763ff: Pull complete a3ed95caeb02: Pull complete 7f831269c70e: Pull complete Digest: sha256:c8776b750869e274b340f8e8eb9a7d8fb2472edd5b25ff5b7d55728bca681322Status: Downloaded newer image for docker.io/lorel/docker-stress-ng:latest# 下载压测镜像stress[root@test ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/lorel/docker-stress-ng latest 1ae56ccafe55 2 years ago 8.1 MB[root@test ~]# docker run --name stress -it --rm lorel/docker-stress-ng --helpstress-ng, version 0.03.11... ...Example: stress-ng --cpu 8 --io 4 --vm 2 --vm-bytes 128M --fork 4 --timeout 10sNote: Sizes can be suffixed with B,K,M,G and times with s,m,h,d,y# 查看使用帮助[root@test ~]# docker run --name stress -it --rm -m 256m lorel/docker-stress-ng --vm 2stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 2 vm# -m表示给这个容器使用多少内存。--vm表示启动几个进程对内存进行压测，--vm-bytes表示每个进程可以使用的内存数，默认是256m，这里使用默认值，所以没有设置。[root@test ~]# docker top stressUID PID PPID C STIME TTY TIME CMDroot 2389 2375 0 16:21 pts/1 00:00:00 /usr/bin/stress-ng --vm 2root 2413 2389 0 16:21 pts/1 00:00:00 /usr/bin/stress-ng --vm 2root 2415 2389 0 16:21 pts/1 00:00:00 /usr/bin/stress-ng --vm 2root 2440 2415 99 16:21 pts/1 00:00:02 /usr/bin/stress-ng --vm 2# 打开另一终端查看容器启动的进程[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSd07a7a5544ca 6.19% 255.9 MiB / 256 MiB 99.96% 648 B / 648 B 17.1 GB / 49.3 GB 5# 查看容器的实时使用情况，因为设置了容器可用的内存数，所以不会超过256M。 压测CPU123456789101112131415161718192021[root@test ~]# docker run --name stress -it --rm lorel/docker-stress-ng stress --cpu 8stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 使用--cpu选项设置启动8个进程，因没有其他对CPU的设置，所以容器会使用全部CPU[root@test ~]# docker top stressUID PID PPID C STIME TTY TIME CMDroot 2724 2709 0 16:27 pts/1 00:00:00 /usr/bin/stress-ng stress --cpu 8root 2745 2724 24 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2746 2724 25 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2747 2724 25 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2748 2724 24 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2749 2724 24 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2750 2724 25 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2751 2724 25 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8root 2752 2724 25 16:27 pts/1 00:00:14 /usr/bin/stress-ng stress --cpu 8[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSbab5b7de1a68 2.72% 21.23 MiB / 976.3 MiB 2.18% 648 B / 648 B 0 B / 0 B 9CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSbab5b7de1a68 198.59% 21.23 MiB / 976.3 MiB 2.18% 648 B / 648 B 0 B / 0 B 9# 因为是双核CPU，所以容器使用CPU的比例会一直接近200%。 设置容器可使用的CPU核心数123456789101112131415161718192021[root@test ~]# docker run --name stress -it --rm --cpus 1 lorel/docker-stress-ng stress --cpu 8 stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 使用--cpus限制最多使用2核，--cpu表示启用8个进程[root@test ~]# docker top stressUID PID PPID C STIME TTY TIME CMDroot 2854 2840 0 16:30 pts/1 00:00:00 /usr/bin/stress-ng stress --cpu 8root 2877 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2878 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2879 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2880 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2881 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2882 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2883 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8root 2884 2854 12 16:30 pts/1 00:00:06 /usr/bin/stress-ng stress --cpu 8[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSc21d92bb4bc7 1.33% 25.54 MiB / 976.3 MiB 2.62% 648 B / 648 B 0 B / 0 B 9CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSc21d92bb4bc7 107.44% 25.54 MiB / 976.3 MiB 2.62% 648 B / 648 B 0 B / 0 B 9# 因为限制了容器可用CPU的核心数为1，所以容器使用CPU的比例在100% 限制容器在指定的CPU核心上运行1234567891011121314151617181920[root@test ~]# docker run --name stress -it --rm --cpuset-cpus 0 lorel/docker-stress-ng stress --cpu 8stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 使用--cpuset-cpus选项让容器只能在指定的核心上运行。如果有多个核心，可以使用0,2或0-3这样的表达方式[root@test ~]# docker top stress UID PID PPID C STIME TTY TIME CMDroot 2970 2956 0 16:33 pts/1 00:00:00 /usr/bin/stress-ng stress --cpu 8root 2994 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 2995 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 2996 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 2997 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 2998 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 2999 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 3000 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8root 3001 2970 12 16:33 pts/1 00:00:13 /usr/bin/stress-ng stress --cpu 8[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS4ebe403ca83c 2.07% 22.63 MiB / 976.3 MiB 2.32% 648 B / 648 B 0 B / 0 B 9CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS4ebe403ca83c 100.61% 22.63 MiB / 976.3 MiB 2.32% 648 B / 648 B 0 B / 0 B 9 使用权重123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@test ~]# docker run --name stress -it --rm --cpu-shares 1024 lorel/docker-stress-ng stress --cpu 8 stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 使用--cpu-shares选项为容器指定权重[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS6b08823bff45 1.57% 15.84 MiB / 976.3 MiB 1.62% 648 B / 648 B 0 B / 0 B 9CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS6b08823bff45 194.23% 15.84 MiB / 976.3 MiB 1.62% 648 B / 648 B 0 B / 0 B 9# 这时容器会使用全部CPU，所以比例为200%[root@test ~]# docker run --name stress2 -it --rm --cpu-shares 1024 lorel/docker-stress-ng stress --cpu 8 stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 再启动一个容器，并分配相同的权重[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSd8d44395f9fc 100.10% 15.81 MiB / 976.3 MiB 1.62% 578 B / 578 B 0 B / 0 B 96b08823bff45 96.45% 15.84 MiB / 976.3 MiB 1.62% 1.23 kB / 648 B 0 B / 0 B 9# 可以看到两个容器使用CPU的比例相似[root@test ~]# docker run --name stress3 -it --cpu-shares 512 lorel/docker-stress-ng stress --cpu 8 stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 启动第三个容器[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSe1298469a665 39.36% 15.81 MiB / 976.3 MiB 1.62% 648 B / 648 B 0 B / 0 B 9d8d44395f9fc 79.19% 15.81 MiB / 976.3 MiB 1.62% 1.3 kB / 648 B 0 B / 0 B 96b08823bff45 77.88% 15.84 MiB / 976.3 MiB 1.62% 1.94 kB / 648 B 0 B / 0 B 9# CPU被分成了五份，因为是双核，所以一共是200%，一份是40%[root@test ~]# docker run --name stress4 -it --cpu-shares 2048 lorel/docker-stress-ng stress --cpu 8 stress-ng: info: [1] defaulting to a 86400 second run per stressorstress-ng: info: [1] dispatching hogs: 8 cpu# 启动第四个容器[root@test ~]# docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS20d81511c4ad 93.90% 15.81 MiB / 976.3 MiB 1.62% 648 B / 648 B 0 B / 0 B 9e1298469a665 23.74% 15.81 MiB / 976.3 MiB 1.62% 1.3 kB / 648 B 0 B / 0 B 9d8d44395f9fc 41.86% 15.81 MiB / 976.3 MiB 1.62% 1.94 kB / 648 B 0 B / 0 B 96b08823bff45 47.71% 15.84 MiB / 976.3 MiB 1.62% 2.59 kB / 648 B 0 B / 0 B 9# CPU被分成了九份* 测试# 创建一个可以下载文件的web服务器root@ccjd:~/jdycbintest# docker volume create jdycbinroot@ccjd:~/jdycbintest# docker run --name jdycbin --cpus 2 -m 2048m -p 80:80 --mount source=jdycbin,target=/usr/share/nginx/html/ nginx WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.# 创建容器，使用2核CPU，2G内存，暴露80端口，挂载本地数据卷root@ccjd:~/jdycbintest# cp Project_2G.bin /var/lib/docker/volumes/jdycbin/_data/]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[conky简单配置]]></title>
    <url>%2F2018%2F12%2F18%2Fconky%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装123apt install -y conky-all conky-manager到https://www.fontsquirrel.com/fonts/list/find_fonts?q%5Bterm%5D=dreams&amp;q%5Bsearch_check%5D=Y下载CAVIAR DREAMS，解压缩下载的字体包，双击安装字体。安装这个字体是因为conky显示的效果中有方框，因为其他字体没有相应的字符。# ubuntu18.04下没有conky-manager，需要下载，地址：wget --no-check-certificate https://github.com/teejee2008/conky-manager/releases/download/v2.4/conky-manager-v2.4-amd64.run。之后给此文件执行权限，并执行：sudo ./conky-manager-v2.4-amd64.run 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546conky-manager在窗口中选择.conky/Gotham/Gotham，这是会在桌面上显示时间与一些电脑基本信息，再选择配置这个效果，在弹出的窗口中选择Transparency，再选择Transparent，这会有一个透明的效果。vim ~/.conky/Gotham/Gothamuse_xft yes xftfont caviar dreams:size=8# 这里改为caviar dreamsxftalpha 0.1 update_interval 1total_run_times 0own_window yes own_window_type normalown_window_transparent yes own_window_hints undecorated,below,sticky,skip_taskbar,skip_pagerown_window_colour 000000own_window_argb_visual yes own_window_argb_value 0double_buffer yes #minimum_size 250 5#maximum_width 500 draw_shades nodraw_outline nodraw_borders nodraw_graph_borders nodefault_color whitedefault_shade_color red default_outline_color greenalignment top_middlegap_x -50 gap_y 80no_buffers yes uppercase nocpu_avg_samples 2net_avg_samples 1override_utf8_locale yes use_spacer yes minimum_size 0 0 TEXT$&#123;voffset 10&#125;$&#123;color EAEAEA&#125;$&#123;font :pixelsize=120&#125;$&#123;time %H:%M&#125;$&#123;font&#125;$&#123;voffset -84&#125;$&#123;offset 10&#125;$&#123;color FFA300&#125;$&#123;font caviar dreams:pixelsize=42&#125;$&#123;time %d&#125; $&#123;voffset -15&#125;$&#123;color EAEAEA&#125;$&#123;font :pixelsize=22&#125;$&#123;time %B&#125; $&#123;time %Y&#125;$&#123;font&#125;$&#123;voffset 24&#125;$&#123;font :pixelsize=58&#125;$&#123;offset -148&#125;$&#123;time %A&#125;$&#123;font&#125;$&#123;voffset 1&#125;$&#123;offset 12&#125;$&#123;font :pixelsize=12&#125;$&#123;color FFA300&#125;HD $&#123;offset 9&#125;$color$&#123;fs_free /&#125; / $&#123;fs_size /&#125;$&#123;offset 9&#125;$color$&#123;fs_free /home&#125; /home $&#123;fs_size /home&#125;$&#123;offset 30&#125;$&#123;color FFA300&#125;RAM $&#123;offset 9&#125;$color$mem / $memmax$&#123;offset 30&#125;$&#123;color FFA300&#125;# 这里配置了两部分，上面是效果中的日期，下面是电脑的配置如硬盘，内存等的信息。将font后面都改为caviar dreams。这里添加了一个home分区的监测情况，默认只会显示根目录的情况。但测试发现将$&#123;font caviar dreams:pixelsize=22&#125;与$&#123;font caviar dreams:pixelsize=58&#125;两项中的caviar dreams去掉为空时，才能正常显示中文，不然还是一个方框。第二行中的$&#123;font caviar dreams:pixelsize=12&#125;中的caviar dreams也可以去掉，字体会好看一些。 启动命令1234567891011# 在ubuntu中测试时，不会开机启动此程序，可以将下面命令加入ubuntu的“启动应用程序首选项”中。conky -c ~/.conky/Gotham/Gotham -d# 使用-c指定配置文件，-d表示在后台运行。这个方法在ubuntu18.04上测试失败了。# 下面使用另一种方法实现开机启动sudo vim .config/autostart/conky.desktop[Desktop Entry]Name=conkyType=ApplicationExec=conky -c /home/shouyu/.conky/Gotham/Gotham -d # 用户家目录的.config是只有root才有权编辑的，在此目录的autostart目录中加入一个自启动的脚本。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>conky</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用]]></title>
    <url>%2F2018%2F12%2F09%2Fgit%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[git管理安装配置123456yum install -y git# 安装git config --global user.name "Your Name"git config --global user.email "email@example.com"# 每个机器都必须自报家门：你的名字和Email地址。# git config命令的--global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，也可以对某个仓库指定不同的用户名和Email地址。 添加文件并提交12345678910111213141516mkdir learngitcd learngitgit init# 初始化 Initialized empty Git repository in /root/learngit/.git/# 所有的版本控制系统，只能跟踪文本文件的改动vim readme.txt git is a version control system. git is free softwaregit add .# 添加当前目录中的所有文件，也可以只提交某个文件，如：git add readme.txt。可以添加多次文件，最后一并提交。git commit -m "wrote a readme file" [master (root-commit) 8f5d632] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt# 提交，-m后面输入的是本次提交的说明，最好将说明写清楚，方便之后查看。1 file changed：1个文件被改动（我们新添加的readme.txt文件）；2 insertions(+)：插入了两行内容（readme.txt有两行内容） 修改提交1234567891011121314151617181920212223242526272829303132333435363738vim readme.txt git is a distributed version control system. git is free softwaregit status # On branch master # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use "git add" and/or "git commit -a")# git status命令可以让我们时刻掌握仓库当前的状态，上面的命令输出告诉我们，readme.txt被修改过了，但还没有提交修改。 git diff readme.txt diff --git a/readme.txt b/readme.txt index 488642a..1d72fa6 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -git is a version control system. +git is a distributed version control system. git is free software# git diff顾名思义就是查看difference，显示的格式正是Unix通用的diff格式，可以从上面的命令输出看到，我们在第一行添加了一个distributed单词（倒数第二行）。git add readme.txt git status # On branch master # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # modified: readme.txt# git status告诉我们，将要被提交的修改包括readme.txt，下一步，就可以放心地提交了git commit -m "add distributed" [master 5e363b3] add distributed 1 file changed, 1 insertion(+), 1 deletion(-)git status # On branch master nothing to commit, working directory clean# Git告诉我们当前没有需要提交的修改，而且，工作目录是干净（working tree clean）的。 版本回退12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970vim readme.txt git is a distributed version control system. git is free software distributed under the GPL.git add readme.txt git commit -m "append GPL" [master 9976125] append GPL 1 file changed, 1 insertion(+), 1 deletion(-)# 像这样，你不断对文件进行修改，然后不断提交修改到版本库里，就好比玩RPG游戏时，每通过一关就会自动把游戏状态存盘，如果某一关没过去，你还可以选择读取前一关的状态。有些时候，在打Boss之前，你会手动存盘，以便万一打Boss失败了，可以从最近的地方重新开始。Git也是一样，每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作，而不是把几个月的工作成果全部丢失。git log commit 997612519811f1809317db4f6016fe785e9960cf Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Sun Dec 9 13:01:59 2018 +0800 append GPL commit 5e363b39f5a22a8acf7fed8bb0de91952e93d947 Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Sun Dec 9 12:57:05 2018 +0800 add distributed commit 8f5d632912474ae28b5fdeb989e28cabc35b815b Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Sun Dec 9 12:45:26 2018 +0800 wrote a readme file # git log命令显示从最近到最远的提交日志，我们可以看到3次提交，最近的一次是append GPL，上一次是add distributed，最早的一次是wrote a readme file。 git log --pretty=oneline 997612519811f1809317db4f6016fe785e9960cf append GPL 5e363b39f5a22a8acf7fed8bb0de91952e93d947 add distributed 8f5d632912474ae28b5fdeb989e28cabc35b815b wrote a readme file# 如果嫌输出信息太多，可以试试加上--pretty=oneline参数。9976125...是commit id（版本号）。git reset --hard HEAD^ HEAD is now at 5e363b3 add distributed# 在Git中，用HEAD表示当前版本，也就是最新的提交9976125...，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。# 使用git reset命令回退到上一个版本cat readme.txt git is a distributed version control system. git is free software# 回退到了add distributed时的版本git log commit 5e363b39f5a22a8acf7fed8bb0de91952e93d947 Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Sun Dec 9 12:57:05 2018 +0800 add distributed commit 8f5d632912474ae28b5fdeb989e28cabc35b815b Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Sun Dec 9 12:45:26 2018 +0800 wrote a readme file# 最新的那个版本append GPL已经看不到了，如果想回到这个未来的版本，需要知道这个版本的版本号，也就是commit id，在命令行向上找git reset --hard 9976125 HEAD is now at 8f5d632 wrote a readme file# 回到append GPL的版本cat readme.txt git is a distributed version control system. git is free software distributed under the GPL.===========================================================================================# Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL改为指向add distributed。然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。===========================================================================================git reflog 9976125 HEAD@&#123;0&#125;: reset: moving to 9976125 8f5d632 HEAD@&#123;1&#125;: reset: moving to 8f5d63291 5e363b3 HEAD@&#123;2&#125;: reset: moving to HEAD^ 9976125 HEAD@&#123;3&#125;: commit: append GPL 5e363b3 HEAD@&#123;4&#125;: commit: add distributed 8f5d632 HEAD@&#123;5&#125;: commit (initial): wrote a readme file# git reflog用来记录你的每一次提交与回退。可以看到提交append GPL的版本号是9976125，这样就算不知道版本号，也可以这样查找了。当你 (在一个仓库下) 工作时，Git 会在你每次修改了 HEAD 时悄悄地将改动记录下来。当你提交或修改分支时，reflog 就会更新。git update-ref 命令也可以更新 reflog，任何时间运行 git reflog 命令可以查看当前的状态。运行 git log -g 会输出 reflog 的正常日志，从而显示更多有用信息 工作区与暂存区 123456789101112131415161718192021222324252627282930313233343536373839===========================================================================================工作区（Working Directory）：就是你在电脑里能看到的目录，比如我的learngit目录就是一个工作区版本库（Repository）：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。把文件往Git版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。===========================================================================================vim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage.# 修改内容，加一行vim LICENSE add LICENSE# 在工作区再新增一个文件叫LICENSEgit status # On branch master # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # # Untracked files: # (use "git add &lt;file&gt;..." to include in what will be committed) # # LICENSE no changes added to commit (use "git add" and/or "git commit -a")# Git非常清楚地告诉我们，readme.txt被修改了，而LICENSE还从来没有被添加过，所以它的状态是Untracked(未跟踪的)。git add .git status # On branch master # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: LICENSE # modified: readme.txt# 添加两个文件后，查看状态，两个文件被放入了暂存区。git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支 12345678910git commit -m "understand how stage works" [master f21dbee] understand how stage works 2 files changed, 2 insertions(+) create mode 100644 LICENSE# 提交git status # On branch master nothing to commit, working directory clean# 将暂存区的文件提交到主分支，如果你又没有对工作区做任何修改，那么工作区就是“干净”的# 工作区目录中包含版本库，版本库中包括暂存区与分支。在工作区中修改的内容会被添加到暂存区，提交是将暂存区中的内容提交到分支 管理修改12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455vim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes.# 修改，加一行git add readme.txt git status # On branch master # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # modified: readme.txt# 添加并查看状态vim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files.# 再次修改git commit -m "git tracks changes" [master 27975c9] git tracks changes 1 file changed, 1 insertion(+)ed, 1 insertion(+)# 提交git status # On branch master # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use "git add" and/or "git commit -a")# 第二次修改没有被提交。因为第二次修改没有添加到暂存区，也就是没有使用git add 命令git diff HEAD -- readme.txt diff --git a/readme.txt b/readme.txt index 6c29947..b7b0032 100644 --- a/readme.txt +++ b/readme.txt @@ -1,4 +1,4 @@ git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. -git tracks changes. +git tracks changes of files.# 查看工作区和版本库里面最新版本的区别，-git tracks changes.是现在版本库中的内容， +git tracks changes of files.是工作区中的内容。# 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commitgit add readme.txt git commit -m "add of files." [master e49d070] add of files. 1 file changed, 1 insertion(+), 1 deletion(-)git status # On branch master nothing to commit, working directory clean# 添加并提交第二次修改 撤销修改1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677781. 修改了内容，但未放入暂存区vim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files. My stupid boss still prefers SVN.# 修改添加一行内容git status # On branch master # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use "git add" and/or "git commit -a")# 查看状态，提示git checkout -- file可以丢弃工作区的修改git checkout -- readme.txt# 丢弃工作区的修改。git checkout -- file命令中的--很重要，没有--，就变成了“切换到另一个分支”的命令# 命令git checkout -- readme.txt意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况：# 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；上面就是这种情况# 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。# 总之，就是让这个文件回到最近一次git commit或git add时的状态。cat readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files.# 又恢复到修改前的状态2. 修改内容并放入了暂存区vim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files. My stupid boss still prefers SVN.# 修改添加一行内容git add readme.txt git status # On branch master # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # modified: readme.txt# 内容只是被添加到了暂存区，还没有提交，提示使用"git reset HEAD &lt;file&gt;..."可以把暂存区的修改撤销掉（unstage）git reset HEAD readme.txt Unstaged changes after reset: M readme.txt# git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。git status # On branch master # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use "git add" and/or "git commit -a")# 可以看到，这里将修改放回了工作区git checkout -- readme.txt git status # On branch master nothing to commit, working directory cleancat readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files.# 将工作区的内容撤销了# 提交到暂存区后，如果想撤销，就需要两步，先回退到工作区，再将工作区的修改撤销。如果只是在工作区修改了，那么只要撤销工作区的修改即可。==============================================================================================场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD &lt;file&gt;，就回到了场景1，第二步按场景1操作。场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，使用命令"git reset --hard HEAD^ commit id"回退到上个版本或指定版本号，不过前提是没有推送到远程库。============================================================================================== 删除文件1234567891011121314151617181920212223242526272829303132333435363738394041424344451. 从git中删除文件touch test.txtecho "add test.txt" &gt; test.txtgit add test.txtgit commit -m "add test.txt" [master 97669c9] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txt# 添加一个新文件rm test.txt git status # On branch master # Changes not staged for commit: # (use "git add/rm &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # deleted: test.txt # no changes added to commit (use "git add" and/or "git commit -a")# 状态显示删除了文件git rm test.txt rm 'test.txt'# 从git版本库中删除test.txt文件，这样删除后就不能恢复了git commit -m "remove test.txt" [master 1e50e5e] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt# 提交，删除文件。现在，文件就从版本库中被删除了。2. 在git中误删除了文件echo "add test.txt" &gt; test.txt# 创建一个test.txt文件ls LICENSE readme.txt test.txtgit add test.txt git commit -m "add test.txt" [master 83de0e9] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txtrm -rf test.txt git checkout -- test.txt# 上面不小心删除了文件，这里可以使用git checkout -- file命令将文件从版本库中恢复ls LICENSE readme.txt test.txt# git rm用于从版本库中删除一个文件，这样操作会删除工作区与版本库中的文件，之后也不能恢复。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 远程仓库123456789101112131415161718192021222324252627282930ssh-keygen -t rsa -C "abc@gmail.com"# -t指定加密方法，-C提供一个新的注释cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDc2tIjUTdNkfGKQanXQmRrxenLU54zzgjqojmiWSNpgWLR2a2/F001GBCQsj6MargtS9kbrUhjAuD6y7rGTIyVqZA+cLZs1WB3F3kq2nMhhohNJi6tdH792iyxBXy9C8pRXp5i/pD8PIv3MksGFruIeZtbwVzIIvBIByWZPX52Nro6+njQEaKRxtRwdoG1s45PMjcbWt2UiuqyOZbSvdJX+fzMiYnViLu6W61OeNvF8ySX/hniy8kJ6rfawetn0/A/8DRwHDzI/31aXNntCoF+rER3KzyUwJl4LN/4IFgfhOdmm0JzZaBiCCUS4kM/A4zi2fsUiLWupL/cEG1CtVj abc@gmail.com将公钥添加到github# GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。git remote add origin git@github.com:ruopu89/test.git# 关联远程仓库，远程库的名字就是origin，这是Git默认的叫法。git@github.com:ruopu89/test.git是项目的地址，在github上可以查看到git push -u origin master The authenticity of host 'github.com (52.74.223.119)' can't be established. RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8. RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'github.com,52.74.223.119' (RSA) to the list of known hosts. Counting objects: 27, done. Compressing objects: 100% (21/21), done. Writing objects: 100% (27/27), 2.14 KiB | 0 bytes/s, done. Total 27 (delta 8), reused 0 (delta 0) remote: Resolving deltas: 100% (8/8), done. remote: remote: Create a pull request for 'master' on GitHub by visiting: remote: https://github.com/ruopu89/test/pull/new/master remote: To git@github.com:ruopu89/test.git * [new branch] master -&gt; master Branch master set up to track remote branch master from origin.# git push命令是把当前分支master推送到远程。# 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。git push origin master# 之后在本地提交后，可以把本地master分支的最新修改推送至GitHub 分支管理 在git中，开始只有一个master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。开始master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点。每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上。从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变。假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并。合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支。 分支创建与提交、合并123456789101112131415161718192021222324252627282930313233343536git checkout -b dev Switched to a new branch 'dev'# git checkout命令加上-b参数表示创建并切换，相当于git branch dev &amp;&amp; git checkout dev两条命令git branch * dev master# 列出所有分支，当前分支前面会标一个*号。vim readme.txt ... Creating a new branch is quick.# 在最下方追加一行内容git add readme.txtgit commit -m "branch test"# 在dev分支上添加并提交git checkout master# 切换回master分支cat readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files.# 在master分支上文件并没有变化。因为那个提交是在dev分支上，而master分支此刻的提交点并没有变git merge dev Updating 83de0e9..39ca38a Fast-forward readme.txt | 1 + test.txt | 1 - 2 files changed, 1 insertion(+), 1 deletion(-) delete mode 100644 test.txt# 合并指定分支到当前分支。上面的Fast-forward信息告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。但并不是总可以使用此模式git branch -d dev Deleted branch dev (was 39ca38a).# 删除dev分支git branch * master# 再查看，只有master分支了。 解决冲突12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394git checkout -b featurel witched to a new branch 'featurel'# 创建并切换分支git branch * featurel master# 查看现在的分支vim readme.txt ... Creating a new branch is quick and simple.# 在最后一行添加一些内容git add readme.txt# 添加到暂存区git commit -m "and simple" [featurel 5119ca1] and simple 1 file changed, 1 insertion(+), 1 deletion(-)# 提交git checkout master Switched to branch 'master' Your branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)# 切换到master分支，提示当前master分支比远程的master分支超前一个提交vim readme.txt ... Creating a new branch is quick &amp; simple.# 修改最后一行git add readme.txt# 添加到暂存区git commit -m "&amp; simple" [master 91b537a] &amp; simple 1 file changed, 1 insertion(+), 1 deletion(-)# 提交。现在，master分支和feature1分支各自都分别有新的提交git merge featurel Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result.# 合并featurel分支到master分支。这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并可能会有冲突。Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交。git status # On branch master # Your branch is ahead of 'origin/master' by 2 commits. # (use "git push" to publish your local commits) # # You have unmerged paths. # (fix conflicts and run "git commit") # # Unmerged paths: # (use "git add &lt;file&gt;..." to mark resolution) # # both modified: readme.txt # no changes added to commit (use "git add" and/or "git commit -a")# git status也可以告诉我们冲突的文件cat readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Creating a new branch is quick &amp; simple. ======= Creating a new branch is quick and simple. &gt;&gt;&gt;&gt;&gt;&gt;&gt; featurel# 查看文件，Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容vim readme.txt ... Creating a new branch is quick AND simple.# 将文件修改为一个新的样子git add readme.txt# 添加git commit -m "conflict fixed" [master c0051d2] conflict fixed# 解决冲突后提交git log --graph --pretty=oneline --abbrev-commit * c0051d2 conflict fixed |\ | * 5119ca1 and simple * | 91b537a &amp; simple |/ * 39ca38a branch test * 83de0e9 add test.txt * 1e50e5e remove test.txt * 97669c9 add test.txt * 1ef2c96 add test.txt * e49d070 add of files. * 27975c9 git tracks changes * f21dbee understand how stage works * 9976125 append GPL * 5e363b3 add distributed * 8f5d632 wrote a readme file# 查看日志，显示5119ca1 and simple和91b537a &amp; simple合并成了c0051d2 conflict fixed。--graph选项可以看到分支合并图。git branch -d featurel Deleted branch featurel (was 5119ca1).# 删除分支# 当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。 Bug分支123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# 软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。git checkout -b dev Switched to a new branch 'dev'# 创建并切换到dev分支git branch * dev master# 查看分支touch hello.txtecho "hello" &gt; hello.txt git status # On branch dev # Untracked files: # (use "git add &lt;file&gt;..." to include in what will be committed) # # hello.txt nothing added to commit but untracked files present (use "git add" to track)git add hello.txtgit status # On branch dev # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: hello.txtvim readme.txt git is a distributed version control system. git is free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files. Creating a new branch is quick AND simple. bug test# 修改文件内容git add .git status # On branch dev # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: hello.txt # modified: readme.txt# 添加并查看状态git stash Saved working directory and index state WIP on dev: c0051d2 conflict fixed HEAD is now at c0051d2 conflict fixed# 因为不想提交，所以使用stash命令把当前dev分支的工作现场“储藏”起来，等以后恢复现场后继续工作git status # On branch dev nothing to commit, working directory clean# 查看状态，现在工作区是干净的git checkout master Switched to branch 'master' Your branch is ahead of 'origin/master' by 4 commits. (use "git push" to publish your local commits)# 切换到master分支git checkout -b issue Switched to a new branch 'issue'# 创建并切换到issue分支git branch dev * issue master# 查看分支vim readme.txt git is a distributed version control system. git is a free software distributed under the GPL. git has a mutable index called stage. git tracks changes of files. Creating a new branch is quick AND simple.# 修改第二行内容git add readme.txtgit commit -m "fix bug" [issue 305a5d8] fix bug 1 file changed, 1 insertion(+), 1 deletion(-)git checkout master Switched to branch 'master' Your branch is ahead of 'origin/master' by 4 commits. (use "git push" to publish your local commits)git merge --no-ff -m "merged bug fix" issue Merge made by the 'recursive' strategy. readme.txt | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-)# 在issue分支添加并提交修改内容，之后回到master分支，并将issue分支合并到master分支，--no-ff指的是强行关闭fast-forward方式，保留分支的commit历史git checkout dev Switched to branch 'dev'git status # On branch dev nothing to commit, working directory clean# 切换回dev分支，查看工作区还是干净的git stash list stash@&#123;0&#125;: WIP on dev: c0051d2 conflict fixed# 查看stash list中储存了一个分支工作现场，恢复有两种方法：一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除；另一种方式是用git stash pop，恢复的同时把stash内容也删了git stash pop # On branch dev # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: hello.txt # # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt # Dropped refs/stash@&#123;0&#125; (515e010252f11e7fa154494d4717eaa66af07784)git stash list# 再用git stash list查看，就看不到任何stash内容了# 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令git stash apply stash@&#123;0&#125;git stash Saved working directory and index state WIP on dev: c0051d2 conflict fixed HEAD is now at c0051d2 conflict fixed# 再次保存现场git stash list stash@&#123;0&#125;: WIP on dev: c0051d2 conflict fixedgit stash apply stash@&#123;0&#125; # On branch dev # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: hello.txt # # Changes not staged for commit: # (use "git add &lt;file&gt;..." to update what will be committed) # (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) # # modified: readme.txt ## 恢复stash@&#123;0&#125;的工作git stash list stash@&#123;0&#125;: WIP on dev: c0051d2 conflict fixed# 因为使用了git stash apply命令，所以还是可以查看到保存的工作现场git stash drop stash@&#123;0&#125; Dropped stash@&#123;0&#125; (cd2bfebbef6aed8d05fc79e91ef5d4acc883cd5a)# 删除保存的工作现场git stash list# 再查看时就没有了# 修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。 Feature分支123456789101112131415161718192021222324252627# 软件开发中，总有无穷无尽的新的功能要不断添加进来。添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。git checkout -b feature Switched to a new branch 'feature'# 创建并切换分支echo vulcan &gt; vulcan.txtgit add vulcan.txtgit status # On branch feature # Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: vulcan.txt #git commit -m "add feature vulcan" [feature f098cc4] add feature vulcan 1 file changed, 1 insertion(+) create mode 100644 vulcan.txt# 创建、添加、提交文件git checkout dev Switched to branch 'dev'git branch -d feature error: The branch 'feature' is not fully merged. If you are sure you want to delete it, run 'git branch -D feature'.# 这时如果使用-d选项删除刚创建的分支会提示feature分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用大写的-D参数git branch -D feature Deleted branch feature (was f098cc4).# 使用-D选项强行删除分支成功。 多人协作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162git remote origin# 当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin===========================================================================================多人协作的工作模式通常是这样：1. 首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改；2. 如果推送失败，则因为远程分支比你本地的内容更新，需要先用git pull试图合并；3. 如果合并有冲突，则解决冲突，并在本地提交；4. 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！5. 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。===========================================================================================git remote -v origin git@github.com:ruopu89/test.git (fetch) origin git@github.com:ruopu89/test.git (push)# 用git remote -v显示更详细的信息git push origin master Warning: Permanently added the RSA host key for IP address '13.250.177.223' to the list of known hosts. Counting objects: 18, done. Compressing objects: 100% (16/16), done. Writing objects: 100% (16/16), 1.38 KiB | 0 bytes/s, done. Total 16 (delta 7), reused 0 (delta 0) remote: Resolving deltas: 100% (7/7), completed with 1 local object. To git@github.com:ruopu89/test.git 83de0e9..5f4464a master -&gt; master# 推送本地的master分支到远程的origin中，创建一个叫master的分支git push origin dev Counting objects: 9, done. Compressing objects: 100% (5/5), done. Writing objects: 100% (7/7), 554 bytes | 0 bytes/s, done. Total 7 (delta 2), reused 0 (delta 0) remote: Resolving deltas: 100% (2/2), completed with 1 local object. remote: remote: Create a pull request for 'dev' on GitHub by visiting: remote: https://github.com/ruopu89/test/pull/new/dev remote: To git@github.com:ruopu89/test.git * [new branch] dev -&gt; dev# 推送本地的dev分支到远程的origin上，创建一个叫dev的分支。这样远程就有了两个分支，一个master，一个devmkdir learngit2cd learngit2git clone git@github.com:ruopu89/test.git Cloning into 'test'... Warning: Permanently added the RSA host key for IP address '13.229.188.59' to the list of known hosts. remote: Enumerating objects: 50, done. remote: Counting objects: 100% (50/50), done. remote: Compressing objects: 100% (25/25), done. remote: Total 50 (delta 17), reused 50 (delta 17), pack-reused 0 Receiving objects: 100% (50/50), done. Resolving deltas: 100% (17/17), done.cd test/# 进入克隆下来的目录ls -a . .. .git LICENSE readme.txt# 查看master分支中的文件git branch * master# 查看现在的分支是mastergit checkout -b dev origin/dev Branch dev set up to track remote branch dev from origin. Switched to a new branch 'dev'# 创建远程origin的dev分支到本地git branch * dev masterlshello.txt LICENSE readme.txt# dev分支中的文件echo env &gt; env.txt# 在dev分支中创建文件git add env.txtgit commit -m "add env" [dev afff0e7] add env 1 file changed, 1 insertion(+) create mode 100644 env.txtgit push origin dev Counting objects: 4, done. Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 329 bytes | 0 bytes/s, done. Total 3 (delta 0), reused 0 (delta 0) To git@github.com:ruopu89/test.git a285424..afff0e7 dev -&gt; dev# 推送到远程的dev分支中cd ../learngit# 到之前的目录ls hello.txt LICENSE readme.txt# 这里并没有env文件git branch * dev issue master # 现在也在dev分支上cp ../learngit2/test/env.txt ./# 将克隆下来的目录中的env.txt文件复制到当前目录中ls env.txt hello.txt LICENSE readme.txtecho abc &gt;&gt; env.txt # 修改env.txt文件git add env.txtgit commit -m "add new env" [dev c997d7c] add new env 1 file changed, 2 insertions(+) create mode 100644 env.txtgit push origin dev To git@github.com:ruopu89/test.git ! [rejected] dev -&gt; dev (fetch first) error: failed to push some refs to 'git@github.com:ruopu89/test.git' hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first merge the remote changes (e.g., hint: 'git pull') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.# 推送失败。因为刚才最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送git pull remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. From github.com:ruopu89/test a285424..afff0e7 dev -&gt; origin/dev There is no tracking information for the current branch. Please specify which branch you want to merge with. See git-pull(1) for details git pull &lt;remote&gt; &lt;branch&gt; If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; dev# git pull也失败了，有两种方法解决。一是git pull 远程地址/分支，二是git branch --set-upstream-to=origin/&lt;branch&gt; devgit pull git@github.com:ruopu89/test.git dev From github.com:ruopu89/test * branch dev -&gt; FETCH_HEAD Auto-merging env.txt CONFLICT (add/add): Merge conflict in env.txt Automatic merge failed; fix conflicts and then commit the result.# 使用第一种方法pull下来文件git branch --set-upstream-to=origin/dev dev Branch dev set up to track remote branch dev from origin.git pull U env.txt Pull is not possible because you have unmerged files. Please, fix them up in the work tree, and then use 'git add/rm &lt;file&gt;' as appropriate to mark resolution, or use 'git commit -a'.# 使用第二种方法pull文件，只是提示不能合并文件，因为上面已经拉过一次了vim env.txt env abcgit add env.txtgit commit -m "fix env" [dev 59a0059] fix envgit push origin dev Counting objects: 7, done. Compressing objects: 100% (3/3), done. Writing objects: 100% (4/4), 451 bytes | 0 bytes/s, done. Total 4 (delta 1), reused 0 (delta 0) remote: Resolving deltas: 100% (1/1), done. To git@github.com:ruopu89/test.git afff0e7..59a0059 dev -&gt; dev # 修改文件后再添加、提交、推送就没问题了。 变基12345678910111213141516171819git log --graph --pretty=oneline --abbrev-commit * 59a0059 fix env |\ | * afff0e7 add env * | c997d7c add new env |/ * a285424 test2 * 15e9ec8 test1 * c0051d2 conflict fixed |\ | * 5119ca1 and simple * | 91b537a &amp; simple |/ * 39ca38a branch test# --graph表示查看分支合并图；--pretty=oneline表示将信息在一行显示；--abbrev-commit表示仅显示SHA-1的前几个字符，而非全部字符（这个SHA-1字符就是指的校验和）# Git用(HEAD -&gt; master)和(origin/master)标识出当前分支的HEAD和远程origin的位置git rebase# rebase操作的特点：把分叉的提交历史“整理”成一条直线，看上去更直观。缺点是本地的分叉提交已经被修改过了。# rebase操作可以把本地未push的分叉提交历史整理成直线；rebase的目的是使得我们在查看历史提交的变化时更容易，因为分叉的提交需要三方对比。 标签管理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374发布一个版本时，我们通常先在版本库中打一个标签（tag），这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。git tag v1.0# 打标签，默认标签是打在最新提交的commit上的git tag v1.0# 查看标签git log --pretty=oneline --abbrev-commit 59a0059 fix env c997d7c add new env afff0e7 add env a285424 test2 15e9ec8 test1# 查看日志git tag v1.1 c997d7c# 给指定的提交打标签git tag v1.0 v1.1git show v1.1 commit c997d7c8f10561e1176ff24c7dd6f3c6468c467f Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Tue Dec 11 15:59:14 2018 +0800 add new env diff --git a/env.txt b/env.txt new file mode 100644 index 0000000..f981a8f --- /dev/null +++ b/env.txt @@ -0,0 +1,2 @@ +env +abc # 查看标签打在哪个提交上了git tag -a v1.2 -m "test" afff0e7# 使用-a选项指定标签名，-m指定说明文字。-a选项在要添加说明信息时使用git show v1.2 tag v1.2 Tagger: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Tue Dec 11 16:33:49 2018 +0800 test commit afff0e76e4e904da31f58bd046667eaac3ce5d5f Author: ruopu89 &lt;ruopu1989@hotmail.com&gt; Date: Tue Dec 11 15:56:21 2018 +0800 add env diff --git a/env.txt b/env.txt new file mode 100644 index 0000000..0a764a4 --- /dev/null +++ b/env.txt @@ -0,0 +1 @@ +envgit tag -d v1.2 Deleted tag 'v1.2' (was 5c1f2b9) # 删除标签git push origin v1.1 Total 0 (delta 0), reused 0 (delta 0) To git@github.com:ruopu89/test.git * [new tag] v1.1 -&gt; v1.1# 推送标签到远程git push origin --tags Total 0 (delta 0), reused 0 (delta 0) To git@github.com:ruopu89/test.git * [new tag] v1.0 -&gt; v1.0# 一次性推送全部尚未推送到远程的本地标签git push origin :refs/tags/v1.1 To git@github.com:ruopu89/test.git - [deleted] v1.1# 从远程删除。 :refs/tags/v1.1是标签在.git目录中的路径 查看配置信息1234567# config配置有system(系统级别)、global(用户级别)和local(当前仓库)三种级别，生效级别为local-&gt;global-&gt;systemgit config --system --list# 查看系统configgit config --global --list# 查看当前用户（global）配置git config --local --list# 查看当前仓库配置信息 忽略特殊文件1234567创建.gitignore文件可以忽略不想上传的文件，.gitignore文件不需要从头创建，可在https://github.com/github/gitignore下载。忽略文件的原则是：1. 忽略操作系统自动生成的文件，比如缩略图等；2. 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；3. 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。git add -f abc.txt# 使用-f选项可以强制添加文件 github个人博客多电脑使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cd /home/GitHub/ruopu.github.iossh-keygen -t rsa -C "ruopu19@hotmail.com"# -C后的是一些描述信息cat .ssh/id_rsa.pub# 将密钥复制到github上ssh -T git@github.com# 测试与github连接是否成功git config --global user.name "ruopu1989"git config --global user.email "ruopu1989@hotmail.com"# 自报家门git init给源文件目录初始化git，虽然目录中已有内容，但这也不会报错的git remote add origin https://github.com/abc/abc.github.io.git# 与远程的origin分支关联，最后的地址是github上项目的地址。使用git push时如果提示需要输入用户名和密码，可以删除远程地址，再试。命令：git remote remove origin。另外，这里也可以使用git@github.com:abc/abc.github.io.git地址。git checkout -b source# 创建并切换分支，使用-b选择就是为了创建并切换。这与git branch source &amp;&amp; git checkout source两条命令的执行结果是一样的。git branch# 现在本地只有一个source分支，这也就是主分支git add .# 添加所有内容到暂存区git commit -m 'add source'# 提交git push origin source# 将本地的source分支推送到远程的origin分支上在github上将source设置为主分支，这样之后clone的就都是这个source分支上的内容了。** 上传中会有一个问题，就是theme目录中的主题文件上传后可能是灰色的，这是因为获得主题文件时就是从另一个库clone来的，所以主题文件目录中也有.git文件。如果上传了目录，解决方法如下：1. 将主题文件目录剪切到另一个不相干的目录中2. git add .3. git commit -m 'delete theme'4. git push# 以上几步是为了将没有主题文件目录的信息再次提交，之后推送到远程库，也就删除了远程库上的主题文件目录5. 将主题文件目录中的.git、.gitignore、.gitattributes三个文件删除，之后将主题文件目录再剪切回github的theme目录中6. git add .7. git commit -m 'new theme'8. git push# 再次将没有.git文件的主题推送到远程库就没有问题了。==============================================================================================推送时出现问题，原因是想将本地的文件推送到远程，但与远程有很多不同。可以使用下面命令强行推送。但本地的文件可能丢失。推送前将文件备份，推送后将丢失的文再复制到相应目录，再推送就可以了。git push -f origin source另外还涉及一些常用命令git branch# 查看当前分支git checkout master# 切换分支。加-b选项是创建并切换分支git merge source# 将source分支内容合并到当前分支git add .git commit -m "abc"git push origin sourcegit diffgit statusgit loggit remote add origin https://github.com/abc/rab.github.io.gitgit reset --hard HEAD^# 回退到上一个版本git reflog# 查看提交与回退历史 问题解决123* 克隆远程分支git clone -b dev https://git.oschina.net/oschina/android-app.git# 使用-b选项指定远程分支的名称，这里叫dev]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShellScript练习]]></title>
    <url>%2F2018%2F12%2F05%2FShellScript%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[查看日志1234567891011121314151617181920# 因没办法得到日志，所以只能用tcpdump来抓包，之后将抓到的包中的设备编号取出并排序。这里只取数字tcpdump -i em1 -w netty.capvim enginenumber.sh #!/bin/bash # for i in `tcpdump -X -r $1 | grep stamc | awk '&#123;print $10&#125;'`;do # tcpdump -X表示以ASCII码的方式显示，-r表示读取，$1是要输入的cap文件名，解析cap文件后从中找到有stamc的行，最后打印出每10列 first=`echo $&#123;i##*stamc&#125;` # 截取结果中stamc后面的部分，并将结果给first变量。因为结果都是stamc****ve这样的结果 for j in $first;do # 将$first变量的值给j echo $&#123;j%ve*&#125; &gt;&gt; ./test.txt # 截取结果中ve前面的部分，这时的结果是****ve这样的编号，将结果重定向到当前目录下的test.txt文件中 done done sort -n -u test.txt &gt;&gt; $2 # 将test.txt中的数字以从小到大的顺序排列，并去除重复的数字，最后输出到一个文件，输出的文件需要执行命令时手工输入 rm -rf ./test.txt # 最后删除test.txt文件 查询设备编号1234567891011121314151617# 每日有大量日志文件，每500M打包一个，需要从众多日志文件中查找设备编号，并查看日志结果vim netty.sh #!/bin/bash # read -p "please input month: " -t 10 month # 输入月份 read -p "please input day: " day # 输入日期 read -p "please input engine number: " engine # 输入设备编号 read -p "please input logs path: " path # 输入日志路径 for i in `ls $path/netty.log-2018-$&#123;month&#125;-$&#123;day&#125;.*.log`;do # 遍历当天的所有日志 grep -a "stamc$&#123;engine&#125;ve" $i &gt;&gt; new.txt # 从每个日志中查找相应的设备编号，并重定向到new.txt文件中。使用-a选项是因为日志中多是二进制文件，直接打开或查找会显示乱码。 done 备份日志12345678910111213141516生产服务器ssh-keygen -t rsa -P ''# 生成密钥ssh-copy-id -i ~/.ssh/id_rsa.pub '-p 39999 ccjd@126.38.38.85'# 传输公钥到远程备份服务器。如果不是默认的端口，要用单引号括起远程的端口与地址，端口使用-p选项指定。ssh ccjd@106.38.38.85 -p 39999# 连接测试vim logbackup.sh #!/bin/bash # cd /usr/local/logs/ tar -zcf netty.log-`date -d "yesterday" +"%F"`.log.tar.gz ./netty.log-`date -d "yesterday" +"%F"`.*.log # 使用date -d "yesterday" +"%F"获取昨天的日期 scp -P 39999 netty.log-`date -d "yesterday" +"%F"`.log.tar.gz ccjd@106.38.38.85:/home/logsbackup/ # 这里指定端口使用-P选项且要将选项放在前面。 rm -rf netty.log-`date -d "yesterday" +"%F"`.*.log netty.log-`date -d "yesterday" +"%F"`.log.tar.gz 安装软件123456789101112131415161718192021222324252627#!/bin/bash#hn=`hostname`listen=`ss -tln4 | grep 10050 | awk '&#123;print $4&#125;' | cut -d':' -f2`rpm -q zabbix-agentif [ $? -eq 0 ];then while [ "$listen" != "10050" ];do# 这里使用字符串来判断数字，因为测试中如果没有启动服务listen变量就是空，比较时会报错，脚本不会向下执行。 systemctl start zabbix-agent listen=`ss -tln4 | grep 10050 | awk '&#123;print $4&#125;' | cut -d':' -f2`# 启动之后一定要再检查一次端口是否启动，并赋值给listen doneelse yum install -y /netdisk/soft/zabbix/zabbix-agent-3.4.3-1.el7.x86_64.rpmcat &gt; /etc/zabbix/zabbix_agentd.conf &lt;&lt; EOFPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0EnableRemoteCommands=1Server=172.16.201.2ServerActive=127.0.0.1Hostname=$hnInclude=/etc/zabbix/zabbix_agentd.d/*.confEOF# 从cat命令到这里的内容最好都顶头写，尤其最后的EOF，如果不顶头写会报语法错误。中间要输入的内容如果不顶头写，在写入配置文件后也会在内容前有空格。 systemctl start zabbix-agentfi 跳板机1234567891011121314151617181920212223242526272829303132333435[root@template sh]# vim /etc/profile.d/tiaoban.sh [ $UID -ne 0 ] &amp;&amp; . /tmp/tiaoban.sh# 判断用户是否为root用户，如果不是就加载tiaoban.sh脚本[root@template sh]# vim /tmp/tiaoban.sh# 这个脚本要放在一个登录的普通用户可以进入执行的路径 trapper() &#123; trap ':' INT EXIT TSTP TERM HUP&#125;# 测试发现，这里使用trap ':'或trap ''都是一样的。如果不使用trap命令，普通用户登录后，在菜单中使用ctrl+c可以退出到命令行界面while :;do trapper clear cat &lt;&lt; menu 1. web a 2. web b 3. exitmenu read -p "pls select: " num case "$num" in 1) echo 1 ssh root@192.168.1.14 # 这里如果不指定用户登录，会使用当前的用户登录 ;; 2) echo 2 ssh root@192.168.1.15 ;; 3|*) exit ;; esacdone# 用户以普通用户的身份登录后只会显示菜单，再传输跳板机中普通用户的密钥到目标主机，最后禁止使用密码登录跳板机或禁止root用户登录即可# 跳板机的实现，就是通过一个脚本，提供菜单，实现登录远程主机与退出功能，另外，添加一个环境变量，判断只要不是root用户登录，就加载这个跳板机脚本，给用户提供菜单，最后给创建一个普通用户的权限，可以连接跳板机，这样在用户登录时就可以看到菜单，但用户无法连接到这台跳板机服务器的命令行。可否添加高可用keepalived？ 批量卸载rpm包123456789#!/bin/bash#for i in `find ./ -name *.rpm`;do# 搜索当前目录下的所有rpm包，路径最好写绝对路径 test=`basename $i | cut -d'.' -f1 | awk -F"-" 'OFS="-"&#123;$NF=""&#125;END&#123;sub(/-$/,"");print&#125;'`# 先取包名，如：drbd84-utils-8.4.1-2.el6.elrepo.x86_64.rpm，因为不想加包的版本号，所以继续取包名，使用cut命令按点来分隔，取出第一段，这时是这样的：drbd84-utils-8，再使用awk命令，指定分隔符为"-"，之后再指定输出分隔符为"-"，$NF表示最后一列，如果只写到这里，取出的值是：drbd84-utils-，只去除了以"-"为分隔符后的最后一段，但最后还有一个"-"，这样就使用END命令，在最后再处理一次，sub是内置函数，/-$/是指尾部的"-"，sub(/-$/,"")表示将尾部的"-"改为空，最后打印出来，就成了：drbd84-utils rpm -e --nodeps $test# 使用rpm -e --nodeps可以只卸载指定的包，而不卸载依赖包done 提取JSON文件中的指定值1234567891011121314151617181920212223有JSON格式文件都在一行中，需要从中提取指定的值，需要从中提取"ChannelName"后的值，如"BTV文艺"，JSON文件内容如下：&#123;"count": 460, "data": [&#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"ADID":"16512_1_102","Advtype":2,"RandomSeq":"dce3db2d-8331-43e8-8dab-fc42d4bdff4b","LocalTime":"2019-02-01 00:00:00","CACardID":"8100103913276261","EventtypeId":"AdvDataCollect","IsLeave":"1","ServiceID":102,"DeviceType":"DVBIP-1004","CollectManufacturer":"inspur","ChannelName":"BTV文艺","SerialNumber":"10081807030091806","ADPositionID":6,"RegionId":"11132"&#125;", "AdvDataCollect": &#123;"ADPositionID": "6", "Advtype": "2", "ServiceID": "102", "ADID": "16512_1_102", "IsLeave": "1", "ChannelName": "BTV文艺", "LocalTime": "2019-02-01 00:00:00.000+0800"&#125;, "RegionId": "11132", "RandomSeq": "dce3db2d-8331-43e8-8dab-fc42d4bdff4b", "DeviceType": "DVBIP-1004", "time": "2019-02-01 00:00:00.000+0800", "EventtypeId": "AdvDataCollect", "_id": "LsulpGgBnh2vjNXwpHy3", "_collect_time": "2019-02-01 00:02:25.064+0800"&#125;, &#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"ADID":"16512_1_102","Advtype":2,"RandomSeq":"653c618f-4282-452a-b680-d4050ec6b567","LocalTime":"2019-02-01 .........23:59:11","CACardID":"8100103913276261","EventtypeId":"LockingDataCollect","DeviceType":"DVBIP-1004","Locked":"true","CollectManufacturer":"inspur","SerialNumber":"10081807030091806","SymbolRate":6875000,"Modulation":"QAM64","Quality":37,"CurrentFrequency":331,"Level":60,"RegionId":"11132"&#125;", "RegionId": "11132", "RandomSeq": "e2c61503-7d9d-47dc-979d-a17cd4db5a30", "DeviceType": "DVBIP-1004", "time": "2019-02-01 23:59:11.000+0800", "EventtypeId": "LockingDataCollect", "_id": "kDTIqWgBNUKkFfMOVTGX", "_collect_time": "2019-02-01 23:58:24.179+0800", "LockingDataCollect": &#123;"Locked": "true", "Level": "60", "Modulation": "QAM64", "SymbolRate": "6875000", "CurrentFrequency": "331", "Quality": "37", "LocalTime": "2019-02-01 23:59:11.000+0800"&#125;&#125;, &#123;"CACardID": "8100103913276261", "SerialNumber": "10081807030091806", "log": "&#123;"DeviceType":"DVBIP-1004","CollectManufacturer":"inspur","RandomSeq":"b7b7896b-c293-425a-ae7c-40675f22252f","SerialNumber":"10081807030091806","LocalTime":"2019-02-01 23:59:11","Idle":91,"SystemRunTime":23475,"RegionId":"11132","FlashRest":4823449,"CACardID":"8100103913276261","EventtypeId":"ResourceDataCollect","RAMRest":638&#125;", "ResourceDataCollect": &#123;"SystemRunTime": 23475.0, "FlashRest": 4823449.0, "Idle": "91", "RAMRest": 638.0, "LocalTime": "2019-02-01 23:59:11.000+0800"&#125;, "RegionId": "11132", "RandomSeq": "b7b7896b-c293-425a-ae7c-40675f22252f", "DeviceType": "DVBIP-1004", "time": "2019-02-01 23:59:11.000+0800", "EventtypeId": "ResourceDataCollect", "_id": "B8TIqWgBnh2vjNXwVauX", "_collect_time": "2019-02-01 23:58:24.602+0800"&#125;], "timed_out": false, "take_time": 5475&#125;root@ruopu64:2019-03-07#cat 8100103913276261_2019-02-01.json | tr "," "\n" | grep "ChannelName"# 使用tr命令将文件中的逗号都转为新行，之后再查找指定值即可。# 这样的JSON文件每天会产生一个root@ruopu64:2019-03-07#cat *.json &gt; all.json# 将所有文件输出到一个文件中root@ruopu64:2019-03-07#cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n &gt; allOK.txt# 再将统计结果输出到一个文件中。通过这两步就可以统计所有频道点播的次数了root@ruopu64:2019-03-07#vim all.sh#!/bin/bash#count=$(cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n)counta=$(cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n|awk '&#123;print $1&#125;')a=0for i in `cat all.json | tr "," "\n" | grep "ChannelName" | cut -d":" -f2 | grep -v "^[[:space:]]"|sort -n |uniq -c|sort -n|awk '&#123;print $1&#125;'`;do let a=$a+$i doneecho $a 自动添加策略路由12345678910111213141516171819202122232425262728#!/bin/bash#mbm - 04/16/2012 - add additional routestablenum=100for int_name in &#123;eno2,ens1f0,ens1f1,enp96s0f1,enp24s0f0,enp24s0f1,enp216s0f0,enp216s0f1&#125; ;do if [ -f /etc/sysconfig/network-scripts/ifcfg-$&#123;int_name&#125; ]; then . /etc/sysconfig/network-scripts/ifcfg-$&#123;int_name&#125; network=$(ipcalc -n $&#123;IPADDR&#125; $&#123;NETMASK&#125; | awk -F= '&#123;print $2&#125;') IFS=. read -r i1 i2 i3 i4 &lt;&lt;&lt; $&#123;network&#125; ROUTER=$&#123;i1&#125;.$&#123;i2&#125;.$&#123;i3&#125;.$((i4+1)) prefix=$(ipcalc -p $&#123;IPADDR&#125; $&#123;NETMASK&#125; | awk -F= '&#123;print $2&#125;') tablenum=$((tablenum+1)) else continue fi if [ $&#123;ONBOOT&#125; != 'yes' ] ;then continue fi if ! grep "^$&#123;tablenum&#125; $&#123;DEVICE&#125;$" /etc/iproute2/rt_tables &gt;/dev/null ;then echo "$&#123;tablenum&#125; $&#123;DEVICE&#125;" #&gt;&gt;/etc/iproute2/rt_tables fi echo "ip route add $&#123;network&#125;/$&#123;prefix&#125; dev $&#123;DEVICE&#125; src $&#123;IPADDR&#125; table $&#123;DEVICE&#125;" echo "ip route add default via $&#123;ROUTER&#125; dev $&#123;DEVICE&#125; table $&#123;DEVICE&#125;" echo "ip rule add from $&#123;IPADDR&#125;/32 table $&#123;DEVICE&#125;" echo "ip rule add to $&#123;IPADDR&#125;/32 table $&#123;DEVICE&#125;"done]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL证书生成]]></title>
    <url>%2F2018%2F12%2F05%2FSSL%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[概念 SSL也就是Secure Socket Layer，叫做安全套接字协议，是一种应用层协议，主要用于传输数据的加密。SSL证书通过在客户端浏览器和Web服务器之间建立一条SSL安全通道，SSL安全协议主要用来提供对用户和服务器的认证；对传送的数据进行加密和隐藏；确保数据在传送中不被改变，即数据的完整性，现已成为该领域中全球化的标准。 x509证书一般会用到三类文件：key、csr、crt key是私钥，openssl格式，通常使用rsa算法 csr是证书请求文件 ，用于申请证书。在制作csr文件的时候，必须使用自己的私钥来签署申请。 crt是CA认证后的证书文件，签署人用自己的key给申请人签署的凭证。 先要有CA根证书，之后用CA根证书来签发用户证书。用户申请证书时，先生成一个私钥，之后用私钥生成证书请求，证书中含有公钥信息，再利用证书服务器的CA根证书来签发证书。根证书是CA认证中心给自己颁发的证书，任何安装CA根证书的服务器都意味着对这个CA认证中心是信任的。数字证书则是由证书认证机构（CA）对证书申请者真实身份验证之后，用CA的根证书对申请人的一些基本信息以及申请人的公钥进行签名后形成的一个数字文件。数字证书包含证书中所标识的实体的公钥，由于证书将公钥与特定的个人匹配，并且该证书的真实性由颁发机构保证，因此，数字证书为如何找到用户的公钥并知道它是否有效这一问题提供了解决方案。 openssl中文件的后缀名 .key格式：私有的密钥 .csr格式：证书签名请求，含有公钥信息，csr是certificate signing request的缩写 .crt格式：证书文件，crt是certificate的缩写 .crl格式：证书文件，crl是certificate的缩写 .pem格式：用于导出，导入证书时候的证书的格式，有证书开头，结尾的格式 证书生成步骤： 这里有三个角色，CA根服务器、RA派出服务器、客户端 根证书：生成CA私钥（.key）–&gt;生成CA证书请求（.csr）–&gt;自签名得到根证书（.crt）（CA给自已颁发的证书）。（这里的CA服务器） 派出服务器证书：派出服务器的证书也是自己先生成私钥和请求，再由CA根服务器使用根证书签署后，派出服务器才能使用 客户端证书：客户端证书由客户端生成私钥与请求后，由派出服务器签署生效 个人理解，这里的CA服务器就是操作系统中集成的根证书机构，RA就是可以从出售证书的机构，如阿里等，客户端指需要使用SSL功能的机构，如网站等。用户在电脑上浏览某个https网站时，会下载网站的证书，证书的有效性靠操作系统中集成的根证书来识别。 通信过程：A要与B进行通信，A将自己的公钥发给了B，那B就需要知道A发过来的公钥是否为正规的CA颁发的，A在获得CA给其颁发的证书时CA会在证书上面盖一个戳，因此我们需要通过验证戳的真实性来验证A的公钥的合法性，所以上面的问题关键点就在于验证CA所盖的戳的真实性。通过验证CA自身的证书就可以验证CA盖的戳的真实性。CA证书是从操作系统上获得的，也就是系统发行厂商会把这些CA证书做进操作系统里。在需要的时候可以直接比对，如果操作系统中没有固化的这些CA证书，那么这个证书就不合法。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>SSL证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShellScript_概念]]></title>
    <url>%2F2018%2F12%2F02%2FShellScript-%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概念 shell是外殼，用戶連接计算機用的外殼；shell也是一種程序；包括： GUI:Gnome, KDE, Xfce 圖形 CLI:sh, csh, ksh, bash, tcsh, zsh 命令行 shell在什麼時候被啓動？用戶登陸時要給用戶提供一個輸入命令的地方，這時就打開了一個shell。如果同時登陸兩個用戶，用的shell是一個嗎？因shell是一種程序，所以程序只能有一個，但進程是程序的副本，誰用的時候就拿來復制一個，可以有多個，哪怕是同一個用戶登陸三次也會打開三個進程。三個進程間彼此各不相幹，這是linux的特性；在每個進程看來，當前主機上只存在內核和當前進程，運行的只是自己，它不知道別的進程的存在。因爲系統識別進程是靠進程號識別的，所以進程號不同，就是不同的程序；進程是程序的副本，進程也是程序執行的實例（就是程序運行起來才是進程）；進程是有生命周期的，從啓動那一刻到終止那一刻結束，這個過程由內核來管理。bash是一個外部命令，但啓動後它還有很多內置命令 bash特性： 命令歷史，上下箭頭可查看之前的命令、命令補全 支持管道、重定向 支持命令別名 支持命令行編輯 支持命令行展開 支持文件名通配 支持使用變量 支持編程 注：可以讀一下bash的幫助文檔，man bash 環境變量：定義用戶的工作環境 PATH：命令搜索路徑 HISTSIZE：命令歷史緩沖區大小，默認是1000條； 例：echo $HISTSIZE(用echo $變量名 可以查看變量名) SHELL的類型 登錄式shell（站在用戶登錄的角度） 正常通過某終端登錄 su – username或su –l username 非登錄式shell su username 圖形終端下打開命令窗口 自動執行的shell腳本 bash的配置文件 全局配置；全局生效 ​ /etc/profile /etc/profile.d/*.sh /etc/bashrc 個人配置；當前用戶生效 ​ ~/.bash_profile ~/.bashrc profile類的文件 設定環境變量，比如將環境變量放在/etc/profile或/etc/profile.d目錄下（全局和個人都配置了，以個人為準，作用範圍越小的最終先生效） 運行命令或腳本（登陸前的準備工作可以在此類文件中定義） bashrc類的文件 設定本地變量 定義命令別名 登陸式shell如何讀取配置文件 ​ 讀取過程 ​ /etc/profile → /etc/profile.d/*.sh →~/.bash_profile → ~/.bashrc → /etc/bashrc 非登陸式shell如何讀取配置文件 ​ ~/.bashrc → /etc/bashrc → /etc/profile.d/*.sh (因為不讀取/etc/profile和/.bash_profile所以使用兩種方式su過去的用戶是不同的，所以su – 是完成切換，不加-是半切換) 例：用hive用戶登陸，並alias cls=clear會設置別名，但登出後會失效，但可在~/.bashrc定義別名的地方，在其中加入一行如：alias cls=’clear’即可在當前用戶下次登陸時生效，或使用. ~/.bashrc命令当时生效 ~/.bash_profile定義登陸時的提醒信息，在其中加入一行如：echo “Hello,hive.Welcome to our system. It is date”；加入 umask 027 可使umask一直是027，默認是002是在/etc/profile中定義好的 輸入輸出重定向與管道 bash：是腳本解釋器 默認輸出設備：也叫標準輸出或STDOUT，文件描述符是1；只輸出正常的數據；如果沒指定輸入輸出設備就從默認的設備裏進行； 默認輸入設備：也叫標準輸入或STDIN，文件描述符是0 標准錯誤輸出：STDERR，描述符2 標準輸入：鍵盤 標准輸出和錯誤輸出：默認都輸出到顯示器 I/O重定向：改變輸入輸出來源 1234567891011\&gt;：輸出重定向，覆蓋輸出\&gt;&gt;：追加輸出set -C：禁止對已經存在文件使用覆蓋重定向；強制覆蓋輸出，則使用&gt;|set +C：關閉上述功能2&gt;：重定向錯誤輸出2&gt;&gt;：追加方式 例：ls /varr &gt; /tmp/var.out 2&gt; /tmp/err.out&amp;&gt;：重定向標準輸出或錯誤輸出至同一個文件&lt;：輸入重定向 例：tr ‘a-z’ ‘A-Z’ &lt; /etc/fstab&lt;&lt;：在此處生成文檔(Here Document ) 例：cat &lt;&lt; END 之後可以一直輸入文字，直到輸入END為止，END可以自己定義；cat &gt;&gt; /tmp/myfile.txt &lt;&lt; EOF，系統會等待用戶輸入數據直到輸入EOF為止，這種方式可以腳本中生成文件的 管道：前一個命令的輸出，作為後一個命令的輸入 12345678910语法：命令1 ｜ 命令2 ｜ 命令3 ｜ …例：echo “redhat” | passwd --stdin hivecut -d: -f1 /etc/passwd | sort | tr ‘a-z’ ‘A-Z’echo “hello” | tee /tmp/hello.out # tee命令是從標准輸入數據讀取並保存一份文檔並輸出到顯示器，這裏顯示器上的結果是tee輸出的不是echo輸出的wc –l /etc/passwd | cut –d' ' -f1 # 其中-d選項要指定分隔符為空格 編譯器或解釋器是一種軟件，它是一個翻譯官，轉換人與機器所用的語言。shell就是這樣的翻譯官 編程語言：機器語言（01代碼）、匯編語言（人和機器都可以理解）、高級語言（接近人的語言） 高級語言分爲靜態與動態語言 靜態語言屬於編譯型語言，有自己的程序開發環境，不需要借助額外的二進制程序就可以直接寫代碼，寫完後需要一個編譯器將其直接轉換成二進制代碼後可以獨立運行的就是靜態語言。它們是強類型（變量）語言，我們在使用編程的時候，無論哪種語言都提供一些控制語句或關鍵字，這些關鍵字最後能夠被我們的解釋器或編譯器轉換成能夠被機器識別的機器代碼或機器指令。編譯語言需要在程序編譯之前或轉換之前事先完成的，只有轉換完成以後，我們才能運行這個程序 態語言屬於解釋型語言是弱類型的語言。不需要事先完成轉換以後才運行這個程序，代碼寫完後不需要轉換成二進制格式，而是有解釋器解釋一條執行一條，也就是程序在執行的時候才需要轉換。執行特性是on the fly；動態語言的解釋器是靜態語言開發的 面向過程：把編程着眼點放在問題解決過程本身。適合開發小型程序。linux內核是用C開發的；shell, C 面向對象：把整個要實現的項目抽象成一個個的對象並且定義對象之間的動作。更適合開發大型程序；Java, python, perl, c++ 變量是內存空間，定義變量是命名內存的過程，空間用完後可回收 內存：編址的存儲單元 進程：數據、指令在內存，臨時存儲在內存；在進程中有一個字符串，人看它的是變量名，機器看是內存地址，機器通過此地址到內存中提取變量，變量被提取後內存空間會被回收 變量類型：決定變量的存儲格式；事先定義好數據的存儲格式和長度，保存不下會溢出 強類型編程語言：變量在使用前，必須事先聲明，甚至還需要初始化，就是給一個值；默認數值型是0,字符串型是空 弱類型編程語言：變量用時聲明，甚至不區分類型；默認是字符串類型 bash變量類型： 環境變量：作用域為當前shell進程及其子進程 本地變量（局部變量）：作用域為整個bash進程，啓動後可從shell中聲明變量，與bash進程相關，bash進程結束時變量也就都沒了。變量是進程的變量。局部變量的作用域為當前代碼段 位置變量：$1, $2, … 特殊變量:bash內置，保存特殊數據的 程序執行，可能有兩類返回值： 程序執行結果就是顯示的結果 程序狀態返回代碼（0－255） ​ 0：正確執行；1－255：錯誤執行，1，2，127系統預留； 對shell來講默認所有變量值都是字符串所以默認不能作算術運算 腳本是命令的堆砌，按實際需要，結合命令流程控制機制實現的源程序 shebang：魔數，須以#!開頭之後寫出可執行文件的所在位置，#號注釋行，不執行；命令沒給路徑會到PATH環境變量中查找，要執行命令可以將當前路徑加入PATH環境變量中或用./指明當前路徑，也可以是其他路徑；腳本沒有執行權限時可用bash SCRIPTNAME來執行，這是明確告訴程序用bash解釋器來執行腳本。 腳本在執行時會啟動一個子shell進程： 命令行中啟動的腳本會繼承當前shell環境變量 系統自動執行的腳本（非命令行啟動）就需要自我定義需要的各環境變量 shell是能夠實現接收用戶指令理解用戶接令的命令，並將它傳輸給內核，由內核指揮某個應用程序啓動的一個界面。Shell會提供一個用戶能夠和它交互的界面，其次將用戶的指揮行翻譯爲內核能夠理解的命令。 函數：函數就是功能（function），必須被調用才能執行。函數的主要作用是代碼重用]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShellScript_正则表达式]]></title>
    <url>%2F2018%2F12%2F02%2FShellScript-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本正则表达式元字符转义字符1234567\r: 回车\n: 换行符\t: 制表符\\: “\” 本身\^: 匹配^符号本身\$: 匹配$符号本身\.: 匹配小数点. 本身 多种字符匹配1234\d：任意一个数字，0~9 中的任意一个\w：任意一个字母或数字或下划线，也就是 A~Z,a~z,0~9,_ 中任意一个\s：包括空格、制表符、换页符等空白字符的其中任意一个.：小数点可以匹配除了换行符以外的任意一个字符 字符匹配1234567891011.: 匹配任意单个字符[]:匹配指定范围内的任意单个字符[^]:匹配指定范围外的任意单个字符# 以上[]当中的范围有以下几种表示方法：[:alnum:]:表示所有的字母和数字[:alpha:]:表示所有字母（不区分大小写）[:digit:]:表示所有的数字[:lower:]:表示所有的小写字母[:punct:]:表示所有的标点符号[:space:]:表示所有的空白字符[:upper:]:表示所有的大写字母 次数匹配123456789用于在要指定次数的字符后面或用于指定前面的字符要出现的次数：*:匹配前面的字符任意次.*:任意长度的任意字符?:匹配其前面的字符0次或1次，即前面的可有可无+:匹配其前面的字符至少1次\&#123;m\&#125;:匹配前面的字符m次\&#123;m,n\&#125;:匹配前面的字符至少m次，至多n次\&#123;,n\&#125;:匹配前面的字符至多n次\&#123;m,\&#125;:区配前面的字符至少m次 位置锚定123456789对特定位置进行定位^:行首锚定：用于模式的最左侧$:行尾锚定：用于模式的最右侧^PATTERN$: 用于模式匹配整行 ^$:空行，不包含有空格的行 ^[[:space:]]*$:空行，但包含有空格的行\&lt;或\b:词首锚定，用于单词模式的左侧\&gt;或\b:词尾锚定，用于单词模式的右侧\&lt;PATTERN\&gt;:匹配整个单词 分组1234567分组是指将一个或多个字符捆绑在一起，当作一个整体进行处理，其符号为：\(\):例：\(xy\)*ab表示xy这个整体可以出现任意次注意：1. 分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为：\1, \2, \3, ...。 \1:从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符；如：\(ab\+\(xy\)*\)中\1表示：ab\+\(xy\)*，\2表示：xy2. 后向引用：引用前面的分组括号中的模式所匹配的字符，而非模式本身 扩展正则表达式元字符字符匹配12[]:匹配指定范围内的任意单个字符[^]:匹配指定范围外的任意单个字符 次数匹配1234567*:任意次?:0次或1次+:至少1次&#123;m&#125;:精确匹配m次&#123;m,n&#125;:至少m次，至多n次&#123;m,&#125;:到少m次&#123;0,n&#125;:至多n次 锚定1扩展正则表达式的位置锚定和其本正则表达式相同 分组1234():用括号括起来表示要引用的内容，不需要转义后向引用：\1, \2, \3或a|b:a或者b 概念贪婪与非贪婪匹配​ 在使用修饰匹配次数的特殊符号时，有几种表示方法可以使同一个表达式能够匹配不同的次数，比如：“{m,n}”, “{m,}”, “?”, “”, “+”，*具体匹配的次数随被匹配的字符串而定。这种重复匹配不定次数的表达式在匹配过程中，总是尽可能多的匹配。 ​ 比如，文本 “axxxaxxxa”，”(a)(\w+)“，其中”\w+“会匹配”xxxaxxxa”，”(a)(\w+)(a)“则会匹配”xxxaxxx”。由此可见，”\w+“ 在匹配的时候，总是尽可能多的匹配符合它规则的字符。 ​ 虽然第二个举例中，它没有匹配最后一个 “a”，但那也是为了让整个表达式能够匹配成功。同样的，带 ”“ 和 ”{m,n}“ 的表达式都是尽可能地多匹配，带 ”?“ 的表达式在可匹配可不匹配的时候，也是尽可能的匹配。这种匹配原则就叫作”贪婪”模式。 ​ 非贪婪模式则是指的在修饰匹配次数的特殊符号后再加上一个 “?” 号，可以使匹配次数不定的表达式尽可能少的匹配，使可匹配可不匹配的表达式，尽可能的不匹配。 ​ 这种匹配原则也叫作 “勉强” 模式。如果少匹配就会导致整个表达式匹配失败的时候，与贪婪模式类似，非贪婪模式会最小限度的再匹配一些，以使整个表达式匹配成功。如，文本 “axxxaxxxa” ，“(a)(\w+?)”，其中”\w+“只会匹配一个“x”。 反向引用​ 表达式在匹配时，表达式引擎会将小括号 “()” 包含的表达式所匹配到的字符串记录下来。在获取匹配结果的时候，小括号包含的表达式所匹配到的字符串可以单独获取。当用某种边界来查找，而所要获取的内容又不包含边界时，必须使用小括号来指定所要的范围。如：“(.*?)“即获取div标签内部的内容。 ​ 这里小括号包含的正则表达式所匹配到的字符串不仅仅是在匹配结束后才可以使用，在匹配过程中也可以使用。表达式后边的部分，可以引用前面括号内的子匹配已经匹配到的字符串。引用方法是 “\” 加上一个数字。”\1” 引用第1对括号内匹配到的字符串，”\2” 引用第2对括号内匹配到的字符串，以此类推，而如果一对括号内包含另一对括号，则外层的括号先排序号。换句话说，哪一对的左括号 “(” 在前，那这一对就先排序号。 ​ 例如：表达式 “(‘|’)(.*?)(\1)“ 在匹配 ” ‘Hello’, “World” “ 时，匹配结果是：成功；匹配到的内容是：” ‘Hello’ “。再次匹配下一个时，可以匹配到 ” “World” “。 预搜索​ 如前面所讲”^“、”$“、”\b”字符有一个共同点，就是：它们本身不匹配任何字符，只是对 “字符串的两头” 或者 “字符之间的缝隙” 附加了一个条件。同样的，正则中提供了其他基于此原理的机制，来实现预搜索。 正向预搜索：”(?=xxxxx)“，”(?!xxxxx)” 格式：”(?=xxxxx)“，在被匹配的字符串中，它对所处的 “缝隙” 或者 “两头” 附加的条件是：所在缝隙的右侧，必须能够匹配上xxxxx这部分的表达式，不影响后边的表达式去真正匹配这个缝隙之后的字符。如：“Mac (?=book|air)” 在匹配 “Mac pro, Mac air” 时，将只匹配 “Mac air” 中的 “Mac”。 格式：“(?!xxxxx)”，所在缝隙的右侧，必须不能匹配 xxxxx 这部分表达式。如：“hello(?!\w)” 在匹配字符串 “hello,helloworld”时，匹配 hello”。这里使用 “(?!\w)” 和使用 “\b” 效果一样。 反向预搜索：“(?&lt;=xxxxx)”，“(?&lt;!xxxxx)” 和正向预搜索类似，反向预搜索要求的条件是：所在缝隙的 “左侧”，两种格式分别要求必须能够匹配和必须不能够匹配指定表达式，而不是去判断右侧。与 “正向预搜索” 一样的是：它们都是对所在缝隙的一种附加条件，本身都不匹配任何字符。 其他通用规则 可以使用 “\xXX” 和 “\uXXXX” 表示一个字符（”X” 表示一个十六进制数） \xXX: 编号在 0-255 范围的字符，如：空格可以使用 “\x20” 表示 \uXXXX: 任何字符可以使用 “\u” 再加上其编号的4位十六进制数表示，比如：“\u4E2D” 在表达式 “\s”，”\d”，”\w”，”\b” 表示特殊意义的同时，对应的大写字母表示相反的意义 \S: 匹配所有非空白字符 \D: 匹配所有的非数字字符 \W: 匹配所有的字母、数字、下划线以外的字符 \B: 匹配非单词边界，即左右两边都是 “\w” 范围或者左右两边都不是 “\w” 范围时的字符缝隙 括号“()”内的子表达式，如果希望匹配结果不进行记录供以后使用，可以使用 “(?:xxxxx)”格式。如：表达式 “(?:(\w)\1)+” 匹配 “a bbccdd efg” 时，结果是 “bbccdd”。括号 “(?:)” 范围的匹配结果不进行记录，因此 “(\w)” 使用 “\1” 来引用。 常用的表达式属性设置包括：Ignorecase、Singleline、Multiline、Global Ignorecase: 默认情况下，表达式中的字母是要区分大小写的。配置为 Ignorecase 可使匹配时不区分大小写。有的表达式引擎，把 “大小写” 概念延伸至 UNICODE 范围的大小写。 Singleline: 默认情况下，小数点 “.” 匹配除了换行符（\n）以外的字符。配置为Singleline可使小数点可匹配包括换行符在内的所有字符。 Multiline: 默认情况下，表达式 “^” 和 “$” 只匹配字符串的开始1和结尾4位置。如：1xxxxxxxxx2\n 3xxxxxxxxx4 配置为 Multiline 可以使 “^” 匹配1外，还可以匹配换行符之后，下一行开始前3的位置，”$“ 匹配4外，还可以匹配换行符之前，一行结束2的位置。使用(?m)可以设置为Multiline模式。如”(?m)^\n +“。 Global: 主要在将表达式用来替换时起作用，配置为Global表示替换所有的匹配。 提示 如果要求表达式所匹配的内容是整个字符串，而不是其中的一部分，可以在表达式的首尾使用 “^” 和 ““ 要求整个字符串只有数字。 如果要求匹配的内容是一个完整的单词，而不会是单词的一部分，那么在表达式首尾使用 “\b”，如：使用 “\b(if|while|…)\b” 来匹配程序中的关键字。 表达式不要匹配空字符串。否则会一直得到匹配成功，而结果什么都没有匹配到。 能匹配空字符串的子匹配不要循环无限次。如果括号内的子表达式中的每一部分都可以匹配0次，而这个括号整体又可以匹配无限次，那么匹配过程中可能死循环。 “|” 的左右两边，对某个字符应该只有一边可以匹配，以防止”|“两边的表达式因为交换位置而有所不同。 要合理选择贪婪模式与非贪婪模式，如. 与 .?的区别使用。]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker部署-Dockerfile使用]]></title>
    <url>%2F2018%2F11%2F29%2Fdocker%E9%83%A8%E7%BD%B2-Dockerfile%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Dockerfile测试定制基础镜像1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586* 测试一mkdir -p /root/apache_centoscd /root/apache_centosvim run.sh #!/bin/bash /usr/sbin/sshd &amp; /usr/local/apache2/bin/httpd -D FOREGROUNDvim Dockerfile FROM centos RUN yum install -y wget WORKDIR /usr/local/src # 使用WORKDIR是为了切换目录 RUN wget http://apache.fayea.com/httpd/httpd-2.4.37.tar.gz RUN tar -zxvf httpd-2.4.37.tar.gz WORKDIR httpd-2.4.37 RUN yum install -y gcc make apr-devel apr apr-util apr-util-devel pcre-devel RUN ./configure --prefix=/usr/local/apache2 --enable-mods-shared=most --enable-so RUN make RUN make install RUN sed -i 's/#ServerName www.example.com:80/ServerName localhost:80/g' /usr/local/apache2/conf/httpd.conf RUN /usr/local/apache2/bin/httpd ADD run.sh /usr/local/sbin/run.sh RUN chmod 755 /usr/local/sbin/run.sh EXPOSE 80 CMD ["/usr/local/sbin/run.sh"]docker build -t apache_dockerfile:centos .# 生成镜像。生成的镜像仓库是apache_dockerfile，标签是centos，以centos镜像为基础。这样创建镜像的问题就是使用了太多的RUN命令，Dockerfile 中每一个指令都会建立一层，RUN也不例外。每一个RUN的行为都会新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。这样创建镜像大概需要十多层* 测试二# 使用Dockerfile文件，简化RUN命令vim Dockerfile FROM centos RUN buildDeps='wget gcc make apr-devel apr apr-util apr-util-devel pcre-devel' \ # 这一步非常重要，如果不将要安装的包定义在变量中，下面的yum命令将无法进行，yum会将之后的所有命令都当作要安装的包。 &amp;&amp; yum install -y $buildDeps \ &amp;&amp; cd /usr/local/src \ &amp;&amp; wget http://apache.fayea.com/httpd/httpd-2.4.37.tar.gz \ &amp;&amp; tar -zxvf httpd-2.4.37.tar.gz \ &amp;&amp; cd httpd-2.4.37 \ &amp;&amp; ./configure --prefix=/usr/local/apache2 --enable-mods-shared=most --enable-so \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; sed -i 's/#ServerName www.example.com:80/ServerName localhost:80/g' /usr/local/apache2/conf/httpd.conf \ &amp;&amp; /usr/local/apache2/bin/httpd COPY run.sh /usr/local/sbin/run.sh RUN chmod 755 /usr/local/sbin/run.sh EXPOSE 80 CMD ["/usr/local/sbin/run.sh"]docker build -t apache_dockerfile1:centos .* 测试三# 加入构建后的清除动作vim Dockerfile FROM centos RUN buildDeps='wget gcc make apr-devel apr apr-util apr-util-devel pcre-devel' \ &amp;&amp; yum install -y $buildDeps \ &amp;&amp; cd /usr/local/src \ &amp;&amp; wget http://apache.fayea.com/httpd/httpd-2.4.37.tar.gz \ &amp;&amp; tar -zxvf httpd-2.4.37.tar.gz \ &amp;&amp; cd httpd-2.4.37 \ &amp;&amp; ./configure --prefix=/usr/local/apache2 --enable-mods-shared=most --enable-so \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; yum clean all \ # 清除所有yum缓存 &amp;&amp; rm -rf /usr/local/src/httpd-2.4.37.tar.gz \ &amp;&amp; rm -rf /usr/local/src/httpd-2.4.37 \ # 删除下载的包 &amp;&amp; sed -i 's/#ServerName www.example.com:80/ServerName localhost:80/g' /usr/local/apache2/conf/httpd.conf \ &amp;&amp; /usr/local/apache2/bin/httpd COPY run.sh /usr/local/sbin/run.sh RUN chmod 755 /usr/local/sbin/run.sh EXPOSE 80 CMD ["/usr/local/sbin/run.sh"]docker build -t apache_dockerfile2:centos .docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEapache_dockerfile2 centos ad579e67578a 23 minutes ago 304MBapache_dockerfile1 centos cce4dadd883f 41 minutes ago 446MBapache_dockerfile centos de4da4d57f3e About an hour ago 545MBcentos latest 75835a67d134 7 weeks ago 200MB# 可以看到，基础镜像centos只有200M，第一次构建后有545M，减少RUN命令使用后的构建较第一次少了近100M，如果删除缓存与安装包后，镜像较第一次构建少了200多M。root@test:~/apache_centos# docker run -d -p 8000:80 apache_dockerfile2:centos /usr/local/sbin/run.sh09e9cc066eaf250ea4fa18e8a7755c666d308267dcc3f2e4c40f9d4941fb94c5# 创建镜像，可以不使用最后的命令，因为与镜像中的命令重复了root@test:~/apache_centos# curl localhost:8000&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;# 访问测试 创建mysql镜像123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187# 测试一* 准备Dockerfile文件mkdir /root/mysqlcd /root/mysqlvim Dockerfile FROM mysql:5.7 ENV MYSQL_ALLOW_ENPTY_PASSWORD yes COPY setup.sh schema.sql privileges.sql /mysql/ # 这里最后要复制到mysql目录中，mysql后面的斜线一定不能少。 CMD ["sh", "/mysql/setup.sh"]# 下载mysql:5.7镜像；ENV MYSQL_ALLOW_ENPTY_PASSWORD yes表示可以免密码登录，这是为了方便导入数据，导入后会再设置密码；复制脚本与sql脚本到容器；最后启动容器。这个mysql:5.7是安装在Debian9系统中的* 准备脚本vim setup.sh #!/bin/bash # set -e echo `service mysql status` echo '1. startup mysql...' service mysql start sleep 3 echo `service mysql status` echo '2. inputing...' mysql &lt; /mysql/schema.sql echo '3. input OK' sleep 3 echo `service mysql status` echo '4. setpassword' mysql &lt; /mysql/privileges.sql echo '5. setpasswordOK' sleep 3 echo `service mysql status` echo 'mysql_container_OK'# 启动mysql与导入数据。set -e表示如果任何语句的执行结果不是true则应该退出。写这些echo是为了之后使用此镜像创建容器时使用docker logs可以查看到相关日志，便于排错。chmod +x setup.sh # 一定不能忘记给脚本执行权限* 准备sql脚本vim schema.sql CREATE database `docker_mysql` default character set utf8 collate utf8_general_ci; USE docker_mysql; DROP TABLE IF EXISTS `user`; CREATE TABLE `user` ( `id` bigint(20) NOT NULL, `created_at` bigint(40) DEFAULT NULL, `last_modified` bigint(40) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `first_name` varchar(255) DEFAULT NULL, `last_name` varchar(255) DEFAULT NULL, `username` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1; INSERT INTO `user` (`id`, `created_at`, `last_modified`, `email`, `first_name`, `last_name`, `username`) VALUES (0,1490257904,1490257904,'john.doe@example.com','John','Doe','user');# 创建一个docker_mysql库、user表，加入一条测试数据vim privileges.sql USE mysql; SELECT host, user from user; CREATE user docker identified by '123456'; GRANT all on docker_mysql.* to docker@'%' identified by '123456' with grant option; flush privileges;# 创建用户并设置密码及权限。with grant option表示它具有grant权限* 构建镜像、启动容器docker build -t mysqltest:test .# 构建镜像docker imagesdocker run -d -p 13306:3306 --name testmysql mysqltest:test# 创建容器，创建容器时最好把库名与标签名都写全docker logs -t 7f78ca1# 查看日志docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' 7f78ca1# 查看容器IP地址docker exec -it 7f78ca1 bash# 进入容器mysql -udocker -p123456# 到容器中再进入容器中的mysqlSHOW DATABASES;use docker_mysqlSHOW TABLES;SELECT * FROM user;# 测试二mkdir /root/jdycmysqlcd /root/jdycmysqlvim Dockerfile FROM mysql:5.7 ENV MYSQL_ALLOW_ENPTY_PASSWORD yes COPY setup.sh echarging.sql user.sql /mysql/ COPY my.cnf /etc/mysql/ CMD ["sh", "/mysql/setup.sh"]# 容器中的mysql配置文件在/etc/mysql中，echarging.sql是要用的数据库，user.sql是改密码与权限所用vim setup.sh #!/bin/bash # #set -e echo `service mysql status` echo '1. startup mysql...' service mysql start sleep 3 echo '1.1 createing...' /usr/bin/mysql -e "create database echarging" echo 'create OK!!!!!!!' sleep 3 echo `service mysql status` echo '2. inputing...' mysql echarging &lt; /mysql/echarging.sql echo '3. input OK' sleep 3 echo `service mysql status` echo '4. setpassword' mysql &lt; /mysql/user.sql echo '5. setpasswordOK' sleep 3 echo `service mysql status` echo 'mysql_container_OK'# 因为set -e在返回错误代码时就会退出脚本，所以这里注释了，因为导入数据库时可能会有报错。因为echarging.sql中没有创建数据库的命令，所以这里加入了创建数据库的命令，并且在导入时也指定了数据库，如果不写明这两项，在导入数据库时都会报找不到数据库的错误。vim my.cnf [client] default-character-set = utf8mb4 [mysqld] init-connect = 'SET NAMES utf8mb4' character-set-server = utf8mb4vim user.sql USE mysql GRANT all on *.* to echarge@'%' identified by 'CCjd1rj@com' with grant option; GRANT all on *.* to root@'%' identified by 'CCjd1rj@com' with grant option; flush privileges;# 新建一个用户并设置root用户与新建用户的密码与权限。docker build -t jdycm:Jmysql .docker run -d -p 3306:3306 --name jdycmysql jdycm:Jmysqlwatch 'docker logs -t jdycmysql' 2018-11-30T08:57:34.924250376Z MySQL Community Server 5.7.24 is not running. 2018-11-30T08:57:34.924304852Z 1. startup mysql... 2018-11-30T08:57:35.082746075Z 2018-11-30T08:57:35.078891Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timesta mp server option (see documentation for more details). 2018-11-30T08:57:35.281231444Z 2018-11-30T08:57:35.280868Z 0 [Warning] InnoDB: New log files created, LSN=45790 2018-11-30T08:57:35.330693896Z 2018-11-30T08:57:35.330333Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2018-11-30T08:57:35.390385937Z 2018-11-30T08:57:35.389987Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: fafeea4e-f47d-11e8-87e6-0242ac110003. 2018-11-30T08:57:35.391824469Z 2018-11-30T08:57:35.391529Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened. 2018-11-30T08:57:35.393019043Z 2018-11-30T08:57:35.392585Z 1 [Warning] root@localhost is created with an empty password ! Please consider switching off the --initiali ze-insecure option. 2018-11-30T08:57:41.396343436Z .. 2018-11-30T08:57:41.396406084Z MySQL Community Server 5.7.24 is started. 2018-11-30T08:57:44.399015302Z 1.1 createing... 2018-11-30T08:57:44.410619098Z create OK!!!!!!! 2018-11-30T08:57:47.486484333Z MySQL Community Server 5.7.24 is running. 2018-11-30T08:57:47.486554105Z 2. inputing... 2018-11-30T09:05:59.990855328Z 3. input OK 2018-11-30T09:06:03.065787206Z MySQL Community Server 5.7.24 is running. 2018-11-30T09:06:03.065853836Z 4. setpassword 2018-11-30T09:06:03.077077343Z 5. setpasswordOK 2018-11-30T09:06:06.151459148Z MySQL Community Server 5.7.24 is running. 2018-11-30T09:06:06.151902503Z /mysql/setup.sh: 1: /mysql/setup.sh: mysql_container_OK: not found 2018-11-30T09:06:06.151989387Z# docker logs的-t选项是显示时间戳的。docker exec -it 901fc12e6e48 bashmysqlmysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || echarging || mysql || performance_schema || sys |+--------------------+5 rows in set (0.01 sec)mysql&gt; use echargingReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+-----------------------------+| Tables_in_echarging |+-----------------------------+| area_dictionary || assistant_user || charge_record || communication_board_version |]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker部署-Nexus3.x使用]]></title>
    <url>%2F2018%2F11%2F27%2Fdocker%E9%83%A8%E7%BD%B2-Nexus3-x%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[安装12345root@ccjd:~# docker run -d --name nexus3 --restart=always -p 8081:8081 -p 8082:8082 --mount src=nexus-data,target=/nexus-data sonatype/nexus3# 在后台运行容器，名字叫nexus3，运行了一个restart策略为always的nexus3容器，暴露docker的8081端口为服务器的8081端口，挂载本地的nexus-data目录到容器的/nexus-data目录（这会在本地的/var/lib/docker/volumes中自动创建一个nexus-data目录，在容器中自动创建/nexus-data目录），镜像使用sonatype/nexus3。root@ccjd:~# docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' 48b7fb09c1f8172.17.0.2# 使用此命令获取docker的IP地址 docker命令的–restart选项1234567891011121314151617181920212223242526# 运行容器时使用--restart参数可以指定一个restart策略，来指示在退出时容器应该如何重启或不应该重启。# 当容器启用restart策略时，将会在docker ps显示Up或者Restarting状态。也可以使用docker events命令来生效restart策略。docker支持如下restart策略：* no – 容器退出时不要自动重启。这个是默认值。* on-failure[:max-retries] – 只在容器以非0状态码退出时重启。可选的，可以退出docker daemon尝试重启容器的次数。* always – 不管退出状态码是什么始终重启容器。当指定always时，docker daemon将无限次数地重启容器。容器也会在daemon启动时尝试重启，不管容器当时的状态如何。* unless-stopped – 不管退出状态码是什么始终重启容器，不过当daemon启动时，如果容器之前已经为停止状态，不要尝试启动它。# 在每次重启容器之前，不断地增加重启延迟[上一次重启的双倍延迟，从100毫秒开始]来防止影响服务器。这意味着daemon将等待100ms,然后200 ms, 400, 800, 1600等等，直到超过on-failure限制，或执行docker stop或docker rm -f。# 如果容器重启成功[容器启动后并运行至少10秒]，然后delay重置为默认的100ms。# 你可以使用on-failure策略指定docker尝试重启容器的最大次数。默认下docker将无限次数重启容器。可以通过docker inspect来查看已经尝试重启容器了多少次。例如，获取容器“my-container”的重启次数:$ docker inspect -f "&#123;&#123; .RestartCount &#125;&#125;" my-container# 2或者获取上一次容器重启时间：$ docker inspect -f "&#123;&#123; .State.StartedAt &#125;&#125;" my-container# 2015-03-04T23:47:07.691840179Z* 示例$ docker run --restart=always redis这运行了一个restart策略为always的redis容器，以使得容器退出时,docker将重启它。$ docker run --restart=on-failure:10 redis这个运行了一个restart策略为on-failure,最大重启次数为10的redis容器。如果redis以非0状态退出连续退出超过10次，那么docker将中断尝试重启这个容器。只有on-failure策略支持设置最大重启次数限制。 配置docker仓库 Nexus3 提供了的3种类型的Docker仓库，前两者都可以创建多个仓库，最后一个则可以将他们全部聚合到一个URL来访问。 docker (hosted): 自托管 docker (proxy): 代理 docker (group): 聚合 hosted类型1234567891011121314151617181920212223242526272829301. 用浏览器打开192.168.0.198:8081--&gt;点击右上角登录--&gt;点击页面上方的齿轮标志--&gt;点击左侧的Repository中的Bolb Stores创建一个存储块--&gt;点击左侧Repositories--&gt;Create repository--&gt;docker(hosted)--&gt;输入名称；勾选Online，这个开关可以设置这个Docker repo是在线还是离线；选择HTTP并设置创建时用到的8082端口，这是在命令行连接时要用到的端口；勾选Force basic authentication，这样的话就不允许匿名访问了，执行docker pull或 docker push之前，都要先登录：docker login；勾选Docker Registry API Support，Docker registry默认使用的是API v2, 但是为了兼容性，我们可以勾选启用API v1。Storage选择之前创建的存储块设备；Hosted使用默认的Allow redeploy；选择左侧的Security中的Realms，将Docker Bearer Token Realm加入到右侧的Active框中2. 使用本机的ubuntu16.04测试root@ccjd:~# vim /lib/systemd/system/docker.service [Service] ... ExecStart=/usr/bin/dockerd --insecure-registry 192.168.0.198:8082 -H unix:// ... # 加入--insecure-registry 192.168.0.198:8082，这里加入的地址必须是宿主机的地址，测试发现如果添加的是docker容器的172地址，在认证时还是会提示"Error response from daemon: Get https://172.17.0.2:8082/v2/: http: server gave HTTP response to HTTPS client"root@ccjd:~# systemctl daemon-reload root@ccjd:~# systemctl restart dockerroot@ccjd:~# docker login 192.168.0.198:8082 -u admin -p admin123WARNING! Using --password via the CLI is insecure. Use --password-stdin.WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded# 出现Login Succeeded就表示成功了root@ccjd:~# docker tag centos 192.168.0.198:8082/centos# 给现有的centos镜像打一个标签叫192.168.0.198:8082/centosroot@ccjd:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE192.168.0.198:8082/centos latest 75835a67d134 6 weeks ago 200MBcentos latest 75835a67d134 6 weeks ago 200MB# 查看已有了新的镜像root@ccjd:~# docker push 192.168.0.198:8082/centosThe push refers to repository [192.168.0.198:8082/centos]f972d139738d: Pushed latest: digest: sha256:dc29e2bcceac52af0f01300402f5e756cc8c44a310867f6b94f5f7271d4f3fec size: 529# 将镜像推送到本地仓库 proxy类型12345678910111213141. 用浏览器打开192.168.0.198:8081--&gt;点击右上角登录--&gt;点击页面上方的齿轮标志--&gt;点击左侧的Repository中的Bolb Stores创建一个存储块。2. 打开左侧的Repositories--&gt;Create replsitory--&gt;docker(proxy)--&gt;自定义Name；勾选Online；设置http端口；不勾选Force basic authentication；勾选Docker Registry API Support；Remote Storage使用阿里云的加速器地址；Docker Index使用Use proxy registry(specified above)；Storage使用创建的存储块# 勾选Force basic authentication后，proxy仓库的状态会显示在线-正在连接。但下载镜像后状态也不会改变。如果不勾选，下载镜像后会显示在线-远程可用3. 配置root@ccjd:~# vim /etc/docker/daemon.json &#123; "registry-mirrors":[ "http://192.168.0.198:8083" ] &#125;# 改为内部仓库的地址4. 测试root@ccjd:~# docker pull debian5. 用浏览器打开192.168.0.198:8081后，点击上面的盒子图标，在左侧的Browse中选择创建的proxy存储块，可以看到我们下载的镜像，这是将镜像持久化存储在块中了。之后如果下载相同的镜像，可以从私有仓库中直接下载。 group类型12345678910111213141516171. 创建存储块--&gt;创建group类型库2. 这里需要注意，在三种类型中都不再选择"Docker Registry API支持"，并修改配置文件，如下：root@ccjd:~# vim /etc/docker/daemon.json &#123; "registry-mirrors":["http://192.168.0.130:8083"], "insecure-registries":["192.168.0.130:8083","192.168.0.130:8082"], "disable-legacy-registry":true &#125;# 这里第一行定义了group类型的仓库，第二行定义了两个地址为安全地址，可以不用https连接，最后一行定义了关闭"Docker v1 API"，这样就不用在定义三种类型时选择启用Docker v1 API了。3. 测试发现，如果在group类型中一次性加入hosted和proxy类型的两个存储库，那么pull镜像时，proxy类型的库中就不会有反应，去除了hosted类型的库后就可以了。之后再将hosted类型的库加上也没有问题。4. 官方推荐配置两个Connectors端口，一个配置在docker(group)用来访问所有库，搜索和下载images(group下包含proxy，所以创建proxy仓库的时候可以不设置Connectors-https端口)，另一个配置在docker(hosted)用来push自己的images，使用docker(group)实现搜索和下载images。The recommended minimal configuration requires one port for a Docker repository group used for read access to all repositories and one port for each hosted Docker repository that will receive push events from your users.5. 测试docker login 192.168.0.130:8083 -u admin -p admin123docker pull centos再次查看nexus3页面时，在proxy存储块中应该有centos镜像，之后再下载时就可以从私有库中下载了。# 下面为三种类型库的配置截图 配置yum仓库123456使用nexus3来管理yum仓库相对简单，首先创建存储块，这里共创建了6个，有5个是给每个不同的库使用的，1个是给组用的。之后创建5个不同的proxy类型库，每个库都指向不同的yum源，最后创建一个组来管理这5个库。yum源地址如下：http://mirrors.aliyun.com/centos/7/os/x86_64http://mirrors.aliyun.com/centos/7/updates/x86_64http://mirrors.aliyun.com/centos/7/extras/x86_64http://mirrors.aliyun.com/centos/7/centosplus/x86_64http://mirrors.aliyun.com/centos/7/contrib/x86_64]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu16.04配置IP地址]]></title>
    <url>%2F2018%2F11%2F26%2Fubuntu16-04%E9%85%8D%E7%BD%AEIP%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[配置IP12345678910111213141516171819202122232425vim /etc/network/interfaces auto eno1 iface eno1 inet static address 10.5.5.198/24 auto eno2 iface eno2 inet static address 192.168.0.198/24 gateway 192.168.0.1# 配置网卡时，如果有两块网卡，只指定一个网关，不然重启网卡时会报错:# RTNETLINK answers: File exists# Failed to bring up eth2.# 如果两块网卡都是dhcp获得地址，就不会有报错的问题# auto enp7s0 // 使用的网络接口，之前查询接口是为了这里# iface enp7s0 inet static // enp7s0这个接口，使用静态ip设置# address 10.0.208.222 // 设置ip地址# netmask 255.255.240.0 // 设置子网掩码# gateway 10.0.208.1 // 设置网关# dns-nameservers 10.0.208.1 // 设置dns服务器地址。nameserver也可以写在resolve.conf文件中/etc/init.d/networking restart# 重启网卡生效ip addr flush dev eno2 &amp;&amp; /etc/init.d/networking restart# 如果重启网卡不能生效，需要使用ip addr flush清除一下网卡的配置，再重启网卡就没问题了。# 参考：https://my.oschina.net/zhaomengit/blog/375360# 参考：https://www.jianshu.com/p/d69a95aa1ed7]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu16.04</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习七：网络]]></title>
    <url>%2F2018%2F11%2F23%2Fdocker%E5%AD%A6%E4%B9%A0%E4%B8%83%EF%BC%9A%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[网络功能介绍 Docker 允许通过外部访问容器或容器互联的方式来提供网络服务。 外部访问容器映射随机端口12345678910111213root@ruopu:~# docker run -d -P --name web1 nginxe962c7424359a76bb7c185de8acd401616f1854fee9a7768596a020b214aeebf# 使用-P选项可以随机选择一个端口映射到容器中的打开的端口root@ruopu:~# docker container ls -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES58ef89a43297 nginx "nginx -g 'daemon of…" About an hour ago Up About an hour 0.0.0.0:32778-&gt;80/tcp web1# 使用-l选项只会显示最上面一条运行的容器的信息。可以看到，本地主机的32778端口被映射到了容器的80端口，此时访问本机的32778端口即可访问容器内的80端口root@ruopu:~# docker logs -f web192.168.0.89 - - [23/Nov/2018:04:51:29 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36" "-"192.168.0.89 - - [23/Nov/2018:04:51:29 +0000] "GET /favicon.ico HTTP/1.1" 404 555 "http://192.168.0.132:32778/" "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36" "-"2018/11/23 04:51:29 [error] 8#8: *1 open() "/usr/share/nginx/html/favicon.ico" failed (2: No such file or directory), client: 192.168.0.89, server: localhost, request: "GET /favicon.ico HTTP/1.1", host: "192.168.0.132:32778", referrer: "http://192.168.0.132:32778/"# 使用此命令后，会监听容器的log日志，如果有人访问本机的32778端口，日志就会有显示。-f选项表示Follow log output，跟踪日志输出。 映射所有接口地址123456root@ruopu:~# docker run -d -p 5000:5000 nginx74a78539f3ae4befc1a272a92432f547ab0476b7a3bcf1800451be292c7ba690root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES74a78539f3ae nginx "nginx -g 'daemon of…" 51 seconds ago Up 51 seconds 80/tcp, 0.0.0.0:5000-&gt;5000/tcp hungry_leakey# 使用-p选项，可以指定本地的某端口映射到容器中的某个端口，上面就是映射了本地的5000端口到容器的5000端口。这样定义会监听本地的所有地址。 映射到指定地址的指定端口123456root@ruopu:~# docker run -d -p 127.0.0.1:6000:5000 nginx 13221c9107420a3c71a04ae2c6d4bcba8e4ea4c6616863ab085712c38b4821d6root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES13221c910742 nginx "nginx -g 'daemon of…" 5 seconds ago Up 5 seconds 80/tcp, 127.0.0.1:6000-&gt;5000/tcp frosty_agnesi# 将本地的回环地址的6000端口映射到容器的5000端口 映射到指定地址的任意端口123456root@ruopu:~# docker run -d -p 127.0.0.1::5000 nginx762d1752599817dc0052080ecdb29543522a0f321bdaaee4ee2495516f92bfe2root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES762d17525998 nginx "nginx -g 'daemon of…" 25 seconds ago Up 25 seconds 80/tcp, 127.0.0.1:32768-&gt;5000/tcp loving_borg# 将本地的任意端口映射到容器的5000端口，可以看到本地的端口用了32768 映射UDP端口12345root@ruopu:~# docker run -d -p 127.0.0.1:4000:5000/udp nginx1258d3b29d3de4aa8cdf4cced7c2575855d04dc5c53edd6c894bd5670f336e75root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1258d3b29d3d nginx "nginx -g 'daemon of…" 6 seconds ago Up 5 seconds 80/tcp, 127.0.0.1:4000-&gt;5000/udp infallible_aryabhata 查看映射端口配置12345678910root@ruopu:~# docker port web1 800.0.0.0:32783# 使用port指令可以查看容器内的端口映射到了本地的哪个地址和端口root@ruopu:~# docker container port web 800.0.0.0:32771root@ruopu:~# docker container port web80/tcp -&gt; 0.0.0.0:32771# 使用上面命令也可以显示容器端口的映射情况root@ruopu:~# docker inspect web1# 使用inspect指令可以获取容器所有的变量 绑定多个端口123456root@ruopu:~# docker run -d -p 5001:5000 -p 5002:80 nginx85ef456480e7bcc0180a07e705a0d8d48c4f4d618ed7fffa5c7474a322dbee98root@ruopu:~# docker container ls -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES85ef456480e7 nginx "nginx -g 'daemon of…" 9 seconds ago Up 8 seconds 0.0.0.0:5002-&gt;80/tcp, 0.0.0.0:5001-&gt;5000/tcp affectionate_bell# 可以多次使用-p选项来绑定多个端口 容器互联新建网络123root@ruopu:~# docker network create -d bridge my-netc2bf630de56e2dc260eef74f0b9afc1e913f97fcef36d37d61025970a081c891# 使用-d参数指定docker网络类型，有bridge和overlay。其中overlay网络类型用于swarm mode 连接容器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748root@ruopu:~# docker run -it --rm --name busybox1 --network my-net busybox shUnable to find image 'busybox:latest' locallylatest: Pulling from library/busybox90e01955edcd: Pull complete Digest: sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812Status: Downloaded newer image for busybox:latest# 运行一个容器连接到新建的my-net网络ruopu@ruopu:~$ docker run -it --rm --name busybox2 --network my-net busybox sh/ # # 打开一个新终端再创建一个连接my-net网络的容器root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5097ae5dbbc2 busybox "sh" About a minute ago Up About a minute busybox2c71c2f7646a6 busybox "sh" 2 minutes ago Up 2 minutes busybox1# 打开一个新终端查看容器信息* busybox1/ # ping busybox2PING busybox2 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.068 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.074 ms# 在busybox1上ping busybox2，可以ping通，并可以看到busybox2的IP地址/ # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.18.0.2 711b0a48b174# 在自己的hosts文件中有对本机地址的解析条目* busybox2/ # ping busybox1PING busybox1 (172.18.0.2): 56 data bytes64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.048 ms64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.029 ms# 在busybox2上ping busybox1，可以ping通，并可以看到busybox1的IP地址# 这样,busybox1容器和busybox2容器建立了互联关系。/ # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.18.0.3 0871d29cd3b4/ # Docker Compose 如果你有多个容器之间需要互相连接，推荐使用Docker Compose 配置DNS1234567/ # mount.../dev/mapper/ubuntu--vg-ubuntu--lv on /etc/resolv.conf type ext4 (rw,relatime,data=ordered)/dev/mapper/ubuntu--vg-ubuntu--lv on /etc/hostname type ext4 (rw,relatime,data=ordered)/dev/mapper/ubuntu--vg-ubuntu--lv on /etc/hosts type ext4 (rw,relatime,data=ordered)...# 在容器中使用mount命令可以查看到挂载信息，其中有上面三条，挂载了宿主机的三个文件到容器，当宿主机信息发生改变时，所有Docker容器的配置通过这些文件也随之改变。 高级网络配置 当 Docker 启动时，会自动在主机上创建一个docker0虚拟网桥，实际上是 Linux 的一个bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。同时，Docker 随机分配一个本地未占用的私有网段(在 RFC1918 中定义)中的一个地址给docker0接口。比如典型的172.17.42.1，掩码为255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段(172.17.0.0/16)的地址。当创建一个 Docker 容器的时候，同时会创建了一对veth pair接口(当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包)。这对接口一端在容器内，即eth0；另一端在本地并被挂载到docker0网桥，名称以veth开头(例如vethAQI2QT)。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 快速配置 下面是一个跟 Docker 网络相关的命令列表。其中有些命令选项只有在 Docker 服务启动的时候才能配置，而且不能马上生效。 -b BRIDGE 或 –bridge=BRIDGE：指定容器挂载的网桥 –bip=CIDR：定制 docker0 的掩码 -H SOCKET… 或 –host=SOCKET…：Docker 服务端接收命令的通道 –icc=true|false：是否支持容器之间进行通信 –ip-forward=true|false：转发，请看下文容器之间的通信 –iptables=true|false：是否允许 Docker 添加 iptables 规则 –mtu=BYTES：容器网络中的 MTU 下面2个命令选项既可以在启动服务时指定，也可以在启动容器时指定。在 Docker 服务启动的时候指定则会成为默认值，后面执行 docker run 时可以覆盖设置的默认值。 –dns=IP_ADDRESS…：使用指定的DNS服务器 –dns-search=DOMAIN…：指定DNS搜索域 最后这些选项只有在 docker run 执行时使用，因为它是针对容器的特性内容。 -h HOSTNAME 或 –hostname=HOSTNAME：配置容器主机名 –link=CONTAINER_NAME:ALIAS：添加到另一个容器的连接 –net=bridge|none|container:NAME_or_ID|host：配置容器的桥接模式 -p SPEC 或 –publish=SPEC：映射容器端口到宿主主机 -P or –publish-all=true|false：映射容器所有端口到宿主主机 容器访问控制 容器的访问控制，主要通过 Linux 上的iptables防火墙来进行管理和实现。iptables是Linux 上默认的防火墙软件，在大部分发行版中都自带。 容器访问外部网络 容器要想访问外部网络，需要本地系统的转发支持。在Linux 系统中，检查转发是否打开。 12345$sysctl net.ipv4.ip_forwardnet.ipv4.ip_forward = 1# 如果为 0，说明没有开启转发，则需要手动打开。$sysctl -w net.ipv4.ip_forward=1# 如果在启动 Docker 服务的时候设定ip_forward，Docker 就会自动设定系统的--ip-forward=true参数为 1。 容器之间访问 容器之间相互访问，需要两方面的支持。 容器的网络拓扑是否已经互联。默认情况下，所有容器都会被连接到docker0网桥上。 本地系统的防火墙软件 – iptables是否允许通过。 访问所有端口 当启动 Docker 服务时候，默认会添加一条转发策略到 iptables 的 FORWARD 链上。策略为通过(ACCEPT)还是禁止(DROP)取决于配置 –icc=true (缺省值)还是 –icc=false。当然，如果手动指定 –iptables=false 则不会添加iptables规则。可见，默认情况下，不同容器之间是允许网络互通的。如果为了安全考虑，可以在 /etc/default/docker 文件中配置 DOCKER_OPTS=–icc=false 来禁止它。 访问指定端口 在通过 -icc=false 关闭网络访问后，还可以通过 –link=CONTAINER_NAME:ALIAS 选项来访问容器的开放端口。 例如，在启动 Docker 服务时，可以同时使用 icc=false –iptables=true 参数来关闭允许相互的网络访问，并让 Docker 可以修改系统中的 iptables 规则。此时，系统中的 iptables 规则可能是类似 12345678$ sudo iptables -nL...Chain FORWARD (policy ACCEPT)target prot opt source destinationDROP all 0.0.0.0/0--0.0.0.0/0... 之后，启动容器( docker run )时使用 –link=CONTAINER_NAME:ALIAS 选项。Docker 会在 iptable 中为两个容器分别添加一条 ACCEPT 规则，允许相互访问开放的端口(取决于 Dockerfile 中的 EXPOSE 指令)。当添加了 –link=CONTAINER_NAME:ALIAS 选项后，添加了 iptables 规则。 123456$ sudo iptables -nL...Chain FORWARD (policy ACCEPT)target prot opt source destination ACCEPT tcp -- 172.17.0.2 172.17.0.3 tcp spt:80ACCEPT tcp -- 172.17.0.3 172.17.0.2 tcp dpt:80DROP all -- 0.0.0.0/0 0.0.0.0/0 注意: –link=CONTAINER_NAME:ALIAS 中的 CONTAINER_NAME 目前必须是 Docker 分配的名字, 或使用 –name 参数指定的名字。主机名则不会被识别。 映射容器端口到宿主主机的实现 默认情况下，容器可以主动访问到外部网络的连接，但是外部网络无法访问到容器。 容器访问外部实现 容器所有到外部网络的连接，源地址都会被 NAT 成本地系统的 IP 地址。这是使用 iptables 的源地址伪装操作实现的。查看主机的 NAT 规则。 123456$ sudo iptables -t nat -nL...Chain POSTROUTING (policy ACCEPT)target prot opt source destinationMASQUERADE all -- 172.17.0.0/16 !172.17.0.0/16... 其中，上述规则将所有源地址在 172.17.0.0/16 网段，目标地址为其他网段(外部网络)的流量动态伪装为从系统网卡发出。MASQUERADE 跟传统 SNAT相比的好处是它能动态从网卡获取地址。 外部访问容器实现 容器允许外部访问，可以在 docker run 时候通过 -p 或 -P参数来启用。不管用那种办法，其实也是在本地的 iptables 的 nat 表中添加相应的规则。 1234567891011121314* 使用 -P 时:$ iptables -t nat -nL...Chain DOCKER (2 references)target prot opt source destinationDNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:49153 to:172.17.0.2:80* 使用 -p 80:80 时:$ iptables -t nat -nLChain DOCKER (2 references)target prot opt source destinationDNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80 注意: 这里的规则映射了 0.0.0.0，意味着将接受主机来自所有接口的流量。用户可以通过 -p IP:hostPort:containerPort 或 -p IP::port 来指定允许访问容器的主机上的 IP、接口等，以制定更严格的规则。 如果希望永久绑定到某个固定的 IP 地址，可以在 Docker 配置文件 /etc/docker/daemon.json 中添加如下内容。{“ip”: “0.0.0.0”} 配置 docker0 网桥 Docker 服务默认会创建一个 docker0 网桥(其上有一个 docker0 内部接口)，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信，它还给出了 MTU(接口允许接收的最大传输单元)，通常是 1500 Bytes，或宿主主机网络路由上支持的默认值。这些值都可以在服务启动的时候进行配置。 –bip=CIDR：IP 地址加掩码格式，例如 192.168.1.5/24 –mtu=BYTES：覆盖默认的 Docker mtu 配置 也可以在配置文件中配置 DOCKER_OPTS，然后重启服务。 由于目前 Docker 网桥是 Linux 网桥，用户可以使用 brctl show 来查看网桥和端口连接信息。 1234$ sudo brctl showbridge name bridge id STP enabled interfacesdocker0 8000.3a1d7362b4ee no veth65f9 vethdda6 *注: brctl 命令在 Debian、Ubuntu 中可以使用 sudo apt-get install bridge-utils 来安装。每次创建一个新容器的时候，Docker 从可用的地址段中选择一个空闲的 IP 地址分配给容器的 eth0 端口。使用本地主机上 docker0 接口的 IP 作为所有容器的默认网关。 123456789101112$ sudo docker run -i -t --rm busybox sh$ ip addr show eth024: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 32:6f:e0:35:57:91 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::306f:e0ff:fe35:5791/64 scope link valid_lft forever preferred_lft forever$ ip routedefault via 172.17.42.1 dev eth0172.17.0.0/16 dev eth0 proto kernel scope link src 172.17.0.3 自定义网桥 除了默认的 docker0 网桥，用户也可以指定网桥来连接各个容器。在启动 Docker 服务的时候，使用 -b BRIDGE 或 –bridge=BRIDGE 来指定使用的网桥。如果服务已经运行，那需要先停止服务，并删除旧的网桥。 123456789101112131415161718$ sudo systemctl stop docker$ sudo apt install bridge-utils$ sudo ip link set dev docker0 down$ sudo brctl delbr docker0# 然后创建一个网桥bridge0。$ sudo brctl addbr bridge0$ sudo ip addr add 192.168.5.1/24 dev bridge0$ sudo ip link set dev bridge0 up# 查看确认网桥创建并启动。$ ip addr show bridge04: bridge0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state UP group default link/ether 66:38:d0:0d:76:18 brd ff:ff:ff:ff:ff:ff inet 192.168.5.1/24 scope global bridge0 valid_lft forever preferred_lft forever# 在 Docker 配置文件 /etc/docker/daemon.json 中添加如下内容，即可将 Docker 默认桥接到创建的网桥上。&#123;"bridge": "bridge0",&#125; 启动 Docker 服务。新建一个容器，可以看到它已经桥接到了 bridge0 上。可以继续用 brctl show 命令查看桥接的信息。另外，在容器中可以使用 ip addr 和 ip route 命令来查看 IP 地址配置和路由信息。 工具和示例 在介绍自定义网络拓扑之前，你可能会对一些外部工具和例子感兴趣: pipework Jérôme Petazzoni 编写了一个叫 pipework 的 shell 脚本，可以帮助用户在比较复杂的场景中完成容器的连接。 playground Brandon Rhodes 创建了一个提供完整的 Docker 容器网络拓扑管理的 Python库，包括路由、NAT 防火墙；以及一些提供 HTTP， SMTP，POP，IMAP，Telnet，SSH，FTP 的服务器。 编辑网络配置文件 Docker 1.2.0 开始支持在运行中的容器里编辑 /etc/hosts , /etc/hostname 和 /etc/resolv.conf文件。但是这些修改是临时的，只在运行的容器中保留，容器终止或重启后并不会被保存下来，也不会被docker commit提交。 示例：创建一个点到点连接 默认情况下，Docker 会将所有容器连接到由docker0提供的虚拟子网中。用户有时候需要两个容器之间可以直连通信，而不用通过主机网桥进行桥接。解决办法很简单：创建一对接口，分别放到两个容器中，配置成点到点链路类型即可。 1234567891011121314151617181920212223* 首先启动 2 个容器:$ docker run -i -t --rm --net=none base /bin/bashroot@1f1f4c1f931a:/#$ docker run -i -t --rm --net=none base /bin/bashroot@12e343489d2f:/## 找到进程号，然后创建网络命名空间的跟踪文件。$ docker inspect -f '&#123;&#123;.State.Pid&#125;&#125;' 1f1f4c1f931a2989$ docker inspect -f '&#123;&#123;.State.Pid&#125;&#125;' 12e343489d2f3004$ sudo mkdir -p /var/run/netns$ sudo ln -s /proc/2989/ns/net /var/run/netns/2989$ sudo ln -s /proc/3004/ns/net /var/run/netns/3004# 创建一对 peer 接口，然后配置路由$ sudo ip link add A type veth peer name B$ sudo ip link set A netns 2989$ sudo ip netns exec 2989 ip addr add 10.1.1.1/32 dev A$ sudo ip netns exec 2989 ip link set A up$ sudo ip netns exec 2989 ip route add 10.1.1.2/32 dev A$ sudo ip link set B netns 3004$ sudo ip netns exec 3004 ip addr add 10.1.1.2/32 dev B$ sudo ip netns exec 3004 ip link set B up$ sudo ip netns exec 3004 ip route add 10.1.1.1/32 dev B]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习六：数据管理]]></title>
    <url>%2F2018%2F11%2F23%2Fdocker%E5%AD%A6%E4%B9%A0%E5%85%AD%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[数据管理数据卷(Volumes) 数据卷是一个可供一个或多个容器使用的特殊目录，它绕过UFS，可以提供很多有用的特性： 数据卷可以在容器之间共享和重用 对数据卷的修改会立即生效 对数据卷的更新，不会影响镜像 数据卷默认会一直存在，即使容器被删除 数据卷的使用，类似于Linux下对目录或文件进行mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示的是挂载的数据卷 创建1234567891011121314151617181920212223242526ruopu@ruopu:~$ docker volume create my-volmy-vol# 创建一个叫my-vol的卷ruopu@ruopu:~$ docker volume ls DRIVER VOLUME NAMElocal my-vol# 查看所有的数据卷ruopu@ruopu:~$ docker volume inspect my-vol [ &#123; "CreatedAt": "2018-11-23T01:46:21Z", "Driver": "local", "Labels": &#123;&#125;, "Mountpoint": "/var/lib/docker/volumes/my-vol/_data", "Name": "my-vol", "Options": &#123;&#125;, "Scope": "local" &#125;]# 查看指定数据卷的信息。inspect[inˈspekt]：检查；point[pɔint]：点；mountpoint：挂载点；scope[skəup]：范围root@ruopu:~# ll -h /var/lib/docker/volumes/total 36Kdrwx------ 3 root root 4.0K Nov 23 01:46 ./drwx--x--x 14 root root 4.0K Nov 21 03:40 ../-rw------- 1 root root 32K Nov 23 01:46 metadata.dbdrwxr-xr-x 3 root root 4.0K Nov 23 01:46 my-vol/ 启动一个挂载数据卷的容器123456789101112131415161718192021222324252627282930313233ruopu@ruopu:~$ docker run -d -P --name web --mount source=my-vol,target=/webapp nginx cb192c96fc3232d42e6a33440945e152cd3dd3a20fce95e0a12440b489a822fe# 创建容器，-P选项表示让Docker随机映射一个 49000~49900 的端口到内部容器开放的网络端口。source指定为外部的数据卷名，target指定容器内的路径，如果容器内没有这个路径，在创建时会自动创建。之后指定从哪个镜像创建。root@ruopu:~# docker exec -it web bash# 进入容器root@fc042722e238:/# ls -l / total 72.......drwxr-xr-x 1 root root 4096 Nov 12 00:00 usrdrwxr-xr-x 1 root root 4096 Nov 12 00:00 vardrwxr-xr-x 2 root root 4096 Nov 23 01:46 webapp# 可以看到容器内根下的webapp目录root@ruopu:~# cp /etc/fstab /var/lib/docker/volumes/my-vol/_data# 在数据卷中还有一个_data目录，要将文件放在这个目录中，这样在容器内的挂载点上就能看到这个文件了。这里将fstab文件放到了_data目录中。root@fc042722e238:/# ls /webapp/fstab# 在容器内也可以看到这个文件了root@ruopu:~# docker inspect web..."Mounts": [ &#123; "Type": "volume", "Name": "my-vol", "Source": "/var/lib/docker/volumes/my-vol/_data", "Destination": "/webapp", "Driver": "local", "Mode": "z", "RW": true, "Propagation": "" &#125; ],...# 使用inspect命令检查web容器的信息，在输出中的Mounts中有数据卷的信息 删除数据卷123456789101112131415161718192021222324252627282930313233343536373839404142434445464748root@ruopu:~# docker volume rm my-vol Error response from daemon: remove my-vol: volume is in use - [cb192c96fc3232d42e6a33440945e152cd3dd3a20fce95e0a12440b489a822fe, fc042722e2380b62651271fe36a7d4388a50cff2ea2321550ad2953ea46cf4b0]# 直接删除数据卷会有一个错误提示，告知数据卷正在被哪些容器使用，也就是后面中括号中的容器ID。不删除容器，是不能删除数据卷的root@ruopu:~# docker container stop web1web1root@ruopu:~# docker container rm web1web1root@ruopu:~# docker container rm webwebroot@ruopu:~# docker volume rm my-vol my-volroot@ruopu:~# ls /var/lib/docker/volumes/metadata.db# 删除占用数据卷的容器后再删除数据卷就没问题了，再查看本地的相应位置也没有数据卷了root@ruopu:~# docker -vDocker version 18.09.0, build 4d60db4root@ruopu:~# docker rm -v webwebroot@ruopu:~# ls /var/lib/docker/volumes/mmetadata.db my-vol/ # 在18.09.0版本中测试发现，使用"docker rm -v 容器ID"命令并不会删除数据卷。* 删除无主的数据卷root@ruopu:~# docker volume create my-volmy-volroot@ruopu:~# docker volume inspect my-vol [ &#123; "CreatedAt": "2018-11-23T03:36:38Z", "Driver": "local", "Labels": &#123;&#125;, "Mountpoint": "/var/lib/docker/volumes/my-vol/_data", "Name": "my-vol", "Options": &#123;&#125;, "Scope": "local" &#125;]root@ruopu:~# docker volume pruneWARNING! This will remove all local volumes not used by at least one container.Are you sure you want to continue? [y/N] yDeleted Volumes:my-volTotal reclaimed space: 0B# prune[pru:n]：修剪root@ruopu:~# docker volume ls DRIVER VOLUME NAME# 先创建一个数据卷，再删除。 挂载主机目录(Bind mounts)1234567891011121314151617181920212223242526272829303132root@ruopu:~# docker run -d -P --name web --mount type=bind,source=/etc/init.d,target=/opt/webapp nginx58ef89a432971bcec8ca0031a69960549d85766b5f42cc40d09e65a662f027c9# 使用type=bind将本地的目录挂载到容器中，但用source指定的本地目录一定要使用绝对路径，如果本地目录不存在，Docker会报错。* 以只读方式挂载本地目录root@ruopu:~# docker run -d -P --name web1 --mount type=bind,source=/etc/init.d,target=/opt/webapp,readonly nginx f59500a342675873413040fa09dea6f626df2215430640830fde9e46c1195fc5# 创建时加入readonly，使用户对目录只有只读权限root@10c115755312:/# cd /opt/webapp/root@10c115755312:/opt/webapp# mkdir amkdir: cannot create directory 'a': Read-only file system# 创建目录时会有不能创建的提示root@ruopu:~# docker inspect web1|grep Mounts -A 10 "Mounts": [ &#123; "Type": "bind", "Source": "/etc/init.d", "Target": "/opt/webapp", "ReadOnly": true &#125; ], "Mounts": [ &#123; "Type": "bind", "Source": "/etc/init.d", "Destination": "/opt/webapp", "Mode": "", "RW": false, "Propagation": "rprivate" &#125; ],# 可以看到，上面的ReadOnly是true，下面的RW是false 挂载一个本地主机文件作为数据卷123456789101112131415root@ruopu:~# docker run --rm -it --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history ubuntu:14.04 bashroot@4e18204505bf:/# history 1 apt update 2 ping www.baidu.com 3 ip a 4 ping 192.168.0.1 5 vim /etc/resolv.conf 6 ping www.baidu.com 7 ping 192.168.0.55 8 vim /etc/network/interfaces 9 ip a 10 vim /etc/network/interfaces 11 systemctl restart networking ...# 用--mount标记从主机挂载单个文件到容器中，这样就可以记录在容器输入过的命令了，也可以看到本地执行过的命令了]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习五：访问Docker仓库]]></title>
    <url>%2F2018%2F11%2F22%2Fdocker%E5%AD%A6%E4%B9%A0%E4%BA%94%EF%BC%9A%E8%AE%BF%E9%97%AEDocker%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[访问仓库 仓库(Repository)是集中存放镜像的地方。一个容易混淆的概念是注册服务器(Registry)。实际上注册服务器是管理仓库的具体服务器，每个服务器上可以有多个仓库，而每个仓库下面有多个镜像。从这方面来说，仓库可以被认为是一个具体的项目或目录。例如对于仓库地址 dl.dockerpool.com/ubuntu来说， dl.dockerpool.com是注册服务器地址，ubuntu是仓库名。 大部分时候，并不需要严格区分这两者的概念。 Docker Hub注册 你可以在 https://cloud.docker.com 免费注册一个 Docker 账号 登录 可以通过执行docker login命令交互式的输入用户名及密码来完成在命令行界面登录Docker Hub 拉取镜像12345678910111213141516root@ruopu:~# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 4939 [OK] ansible/centos7-ansible Ansible on Centos7 119 [OK]# 使用search搜索镜像。可以看到返回了很多包含关键字的镜像，其中包括镜像名字、描述、收藏数(表示该镜像的受关注程度)、是否官方创建、是否自动创建。官方的镜像说明是官方项目组创建和维护的，automated 资源允许用户验证镜像的来源和内容。# 根据是否是官方提供，可将镜像资源分为两类。# 一种是类似centos这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。# 还有一种类型，比如ansible/centos7-ansible镜像，它是由 Docker 的用户创建并维护的，往往带有用户名称前缀。可以通过前缀username/来指定使用某个用户提供的镜像，比如 ansible 用户。# 另外，在查找的时候通过--filter=stars=N参数可以指定仅显示收藏数量为N以上的镜像。root@ruopu:~# docker pull centosUsing default tag: latestlatest: Pulling from library/centosaeb7866da422: Pull complete Digest: sha256:67dad89757a55bfdfabec8abd0e22f8c7c12a1856514726470228063ed86593bStatus: Downloaded newer image for centos:latest# 使用pull命令下载镜像 推送镜像123456789101112131415161718192021222324252627root@ruopu:~# docker login Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: testPassword: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded# 登录dockerroot@ruopu:~# docker tag ubuntu:14.04 test/ubuntu:14.04# 准备要推送的镜像，一定要写为自己docker的usernameroot@ruopu:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEtest/ubuntu 14.04 f17b6a61de28 2 days ago 188MB# 查看在本地有了要推送的镜像root@ruopu:~# docker push test/ubuntu:14.04The push refers to repository [docker.io/test/ubuntu]85a0d9a0e38e: Mounted from library/ubuntu fe72fc94fa1a: Mounted from library/ubuntu ea213108ab36: Mounted from library/ubuntu 960c7c5516b2: Mounted from library/ubuntu 14.04: digest: sha256:296c2904734ac0f13f3ab7265eeafb2efc33f085eeb87c875d28c360cec18700 size: 1152# 推送镜像ruopu@ruopu:~$ docker search testNAME DESCRIPTION STARS OFFICIAL AUTOMATED# 查询自己上传的镜像，没有结果。可能是因为上传的速度较慢，所以暂时看不到，并且再次上传时提示文件已存在。但登录docker hub后，发现镜像已经上传了。 自动创建 自动创建(Automated Builds)功能对于需要经常升级镜像内程序来说，十分方便。 有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站(目前支持 GitHub 或BitBucket)上的项目，一旦项目发生新的提交或者创建新的标签(tag)，Docker Hub 会自动构建镜像并推送到 Docker Hub 中。 要配置自动创建,包括如下的步骤: 创建并登录 Docker Hub，以及目标网站； 在目标网站中连接帐户到 Docker Hub； 在 Docker Hub 中 配置一个自动创建； 选取一个目标网站中的项目(需要含Dockerfile)和分支； 指定Dockerfile的位置，并提交创建。 之后，可以在 Docker Hub 的自动创建页面中跟踪每次创建的状态。 私有仓库私有仓库高级配置Nexus3]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dns配置使用]]></title>
    <url>%2F2018%2F11%2F22%2Fdns%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概念 DNS即域名解析；一般網絡上都是用bind（Berkeley Internet Name Domain）軟件實現的 域名：www.magedu.com是主機名或叫FQDN（ Full Qualified Domain Name）,譯為完全限定域名，這不能被稱為域名。magedu.com才是域名，com也是域名，因爲它下面包含了magedu等域。 DNS：名稱解析（Name Resolving）；名稱解析就是名稱轉換（背後有查詢過程，所以叫解析，依賴數據庫） ​ FQDN到 IP之間的雙向轉換，DNS提供的是兩者之間的雙向轉換 ​ 172.16.0.1 www.magedu.com. nsswitch：為多種需要提供名稱解析的機制，可以讓別人完成名稱解析。它是提供名稱解析的平台，應用程序到這個框架上找名稱解析的店鋪即可。將DNS解析成IP地址的有兩個，一個是libnss_files和libnss_dns，調用這兩個庫即可。對我們展現的就是一個配置文件，配置文件/etc/nsswitch.conf。服務（如web，telnet，ssh）只需要到nsswitch這個框架上找對應的名稱解析服務就可以了。基於名稱轉換的機制還有NIS 配置文件：nsswitch.conf 格式：hosts : files dns 根據/etc/hosts文件來完成主機名稱到IP地址的轉換的。files指/etc/hosts文件，dns指dns服務，stub resolver被解釋爲最根本的最原始的名稱解析器，它是一個程序，它會根據某個庫調用來完成找nsswitch.conf中的配置，根據nsswitch.conf中的次序先去找files:/etc/hosts裡的文件，查一下有沒有主機名對應的IP，如PING命令在執行時會靠本地的stub resolver完成名稱解析，stub resolver會根據files:/etc/hosts文件找是否有主機名對應的IP，如沒有就找DNS，這就是stub resolver的作用。 轉換的機制叫stub resolver：名稱解析器，它是一個軟件或程序 ​ libnss_files.so libnss_dns.so 早期用hosts文件實現解析 hosts: ​ IP FQDN Ailases（主機別名） 172.16.0.1 www.magedu.com www a、周期性任務下載hosts文件 b、之後出現了IANA（互聯網地址名稱分配機構）建的服務器server，由服務器負責轉換地址。互聯網地址名稱分配機構，之後轉由ICANN管理，它管理頂級域。IA在nsswitch中有： hosts: files dns NA就負責維護IP與FQDN之間的對應關系的數據庫 c、分布式數據庫，把DNS從集中的數據庫轉換成分布式數據庫，從最高開始找，主機名是從小到大寫www.magedu.com.，最後的點就是根域，也就是最上層的域，主機名結構從下向上，授權是自上向下的。下級是不知道上級的，但上級是知道直接下級的，但每個人都知道根在哪裡。.net這樣的才叫頂級域或TLD(top level domain)。為了節省流量可以將IP與主機名緩存下來。別人是不能用自己的緩存的，這就需要建立一個DNS緩存服務器，第一次由根來查找，由緩存服務器發起一次請求，之後被請求的服務器查找，一級一級地向下傳遞，緩存服務器等待結果，這就是遞歸查找，這會加大根服務器的壓力，但根是不與任何服務器遞歸的；緩存服務器根據提示發起多次請求就是迭代查找，但對於客戶端來講是遞歸查找，對於服務器來講是迭代查找。因為客戶端只向服務器發起一次請求。緩存下來的結果也是非權威答案，只有服務器的上一級給的答案才是權威答案（也就是管理域名的服務器給的答案才是權威答案），緩存時間由上一級來規定，也就是上一級不僅返回答案還返回超時時間，超過時間要重新發起請求，緩存時間的長短會影響主機的性能，時間越長服務器的壓力越小；緩存服務器既要接受本域內的請求，還要接受其他域的查找請求。也就是來自外部的請求查找內部的主機或來自內部的主機查找外部的主機，內部的主機請求查找內部的主機就直接返回結果，而且是權威答案。 一台服務器可以給多個域進行解析的。那麼它的授權過程是：在根服務器上有一個下級域的數據庫，管理域的是NS（NS（Name Server）记录是域名服务器记录，用来指定该域名由哪个DNS服务器来进行解析。），在數據庫中有下級域對應的服務器ns名稱及IP，當向根域發起請求後，根域會根據數據庫返回對應的頂級域的IP，如要找.com，根據這個IP找到.com，.com也會根據自己的數據庫返回用戶請求的域的管理主機的IP，這臺管理主機一般也叫NS，如ruopu，這樣再找ruopu這個域的NS服務器，請求查找www主機，如果有就返回IP。這裏NS查找的數據庫就叫授權數據庫，要實現一台服務器管理多個域就需要在授權數據庫中記錄多個域的信息，但不同的域有不同的數據庫，這樣一個IP可以有多個主機名，一個主機名也可以有多個IP，但每次只返回一個，是把多個IP輪流返回的，這就是負載均衡，是DNS的高級功能，但效果較差，他們之間是多對多的關系。 注：德魯克的扁平化管理 TLD譯為頂級域分三類，頂級域也叫一級域 ​ a、組織域：.com, .org, .net, .cc ​ b、國家域：.cn, .tw, .hk, .iq, ​ c、反向域：IP轉主機名FQDN專用 ​ 反向：IP –&gt; FQDN ​ 正向：FQDN –&gt; IP 正反向用的不是一個數據庫 查詢有兩種方式 ​ 遞歸：只發出一次請求 ​ 迭代：可能發出多次請求 解析： ​ 反向：IP –&gt; FQDN ​ 正向：FQDN –&gt; IP 這兩種用的不是一個數據庫 兩段式：第一段是遞歸（客戶端發起），第二段是迭代（服務器查找） DNS服務器工作 ​ a、接受本地客戶端查詢請求（遞歸） ​ b、外部客戶端請求：請求權威答案，如果有就返回肯定答復，沒有就返回一個否定答復，且也有緩存時長（TTL），如果外部客戶端請求非權威答案，這需要設置，但一般不會給外部客戶端遞歸查找的。互聯網上的根、com等是不與任何主機遞歸的，這是為了安全，/etc/resolv.conf（DNS配置文件）文件中填的一定是遞歸的服務器IP，不能給出答案的是沒有用的，一般運營商給的DNS服務器都是遞歸的，不然沒法上網。一般NS只給自己負責的域名遞歸，給權威答案，請求其他的主機都是不給遞歸的 ​ 肯定答案：TTL值（TTL：存活時間） ​ 否定答案：TTL值（存活時間） 根服務器：從a.root-server.net 到m.root-server.net 根服務器掛掉會使世界混亂，要保證絕對的安全。全球共有13台根服務器，13個根是一樣的，任何一台域名服務器數據改變都要多台服務器數據同步，這是自動修改的。如果域內的主機不在線，服務器也會返回相應的結果，只是不能訪問，但如果DNS服務器上沒有記錄的話無論如何也無法訪問。如果DNS服務器掛了，其下的域名是不能訪問的，除非用IP。如果有緩存也可以訪問，但緩存過期就不能訪問。要有兩台服務器保證可以解析，一個出問題，其他可以頂上，這就是主從結構。NS中的數據庫內的信息與信息對應的主機沒有關系，即使主機不在線，NS服務器也會返回查詢結果，只是請求方無法與查詢到的結果建立聯系。但如果NS的數據庫上沒有相關記錄，就算有主機在線，也不能與其聯系。所以服務器與數據庫內的信息應該對應起來。 DNS服務器類型 DNS服務器主從結構 ​ 主DNS服務器：在此服務器上完成數據修改 ​ 輔助DNS服務器：請求數據同步，同步是客戶端請求的，也就是拉取的模式。這是定期同步的，如果改了就同步改了的，沒有就下次再同步 ​ 主DNS服務器如果掛掉，輔助服務器會定期檢查是否可以同步，如果超時還未恢復，輔助服務器也會掛掉，自殺 12345678serial number版本號/序列號 # 定義版本號是為了在同步時如果主DNS與從DNS序列號不一致就證明數據有改變，就同步refresh：檢查時間週期/刷新時期 # 多長時間檢查一次，如果沒有響應，就進入重試時間再檢查，之後如果到了過期時間就認為主DNS掛了retry：重試時間；應小於refreshexpire：重試多久過期negative ansver TTL：否定答案的緩存時長# 主從服務器要定義這五種屬性 緩存DNS服務器，只負責緩存，不負責解析或說不提供任何權威答案；另一種是轉發器，去掉緩存功能就是轉發器，這台服務器可以上互聯網並返回結果，但客戶端不能上互聯網時，或到達某服務器時，可由這台服務器幫助轉發出去 哪台服務器負責解析，由上級指定IP由誰解析，也就是上級授權 數據庫中的每一個條目稱作一個資源記錄（Resource Record簡寫爲RR），靠此記錄來標明服務器的用途，如是DNS服務器還是郵件服務器 主DNS要通知從DNS服務器數據有變更，保證主從一致，這就是區域傳送 區域傳送類型：在未到時間同步時，主服務器通知從DNS服務器來同步 ​ 完全區域傳送：axfr # 這是完全同步的 ​ 增量區域傳送：ixfr # 只傳送改變的內容 區域類型（傳輸數據時） ​ 主區域: master # 主DNS服務器 ​ 從區域：slave ​ 提示區域：hint # 定義根在什麼地方 ​ 轉發區域：forward # 不找根，直接告訴域在什麼地方，並轉出的 資源記錄 123456789101112131415# 資源記錄的格式，是橫著寫的，這裡為看清竪寫NAME：名稱TTL：（可省，如果都一樣的話可在全局定義即可）IN : internetRRT：資源記錄類型VALUE：數據*例：NAME [TTL] IN RRT VALUEwww.magedu.com. IN A 1.1.1.1 # 在此條第一項中，www.magedu.com. 最後的點一定要寫，不然會有問題1.1.1.1 IN PTR www.magedu.com. # 條爲反向解析，其中的PTR指主機名類型 SOA123456789101112131415161718192021# SOA(Start Of Authority)起始授權記錄，用於標明一個區域內部主從服務器之間如何同步數據，以及起始授權對象是誰的；數據中的第一條記錄必須是此條，用於標明本區域內多個DNS服務器之間是如何完成數據同步的ZONE NAME TTL IN SOA FQDN ADMINISTRATOR_MAILBOX ( serial namber # ADMINISTRATOR_MAILBOX指郵箱地址；上面的FQDN是起始授權主機，一般是主DNS服務器地址；serial namber指版本號 refresh retry expire na ttl) # 時間單位可以使用：M（分鍾）、H（小時）、D（天）、W（周）、默認單位是秒# 郵箱格式：admin@magedu.com應寫為admin.magedu.com，不能用@，在此@表示當前區域的區域名稱* 例:magedu.com. 600 IN SOA ns1.magedu.com. admin.magedu.com.(# 上面的ZONE NAME寫成@也可，@就表示區域名稱，區域名稱是在配置文件(/etc/named.conf)中定義的；郵件地址不能用@，因@有特殊含義，故用admin.magedu.com. 2013040101； # 2013年4月1日第一版，最長10個數 1H # 一小時刷新一次 5M # 5分鍾重試 1W # 重試一週過期 1D) # 否定回答的TTL值# 這些內容可以不換行，之間用空格隔開即可，也不用加括號了，但不提倡。可以加分號，分號後是注釋，換行才需注釋，一般不用 NS12345678# NS: (Name Server)：ZONE NAME（區域名稱） --&gt; FQDN，這是說明哪個區域，它的區域的NS是哪個主機，這裏給的是主機名而非IP，另外還要加一條主機名的IP地址記錄* 例: magedu.com. 600 IN NS ns1.magedu.com. magedu.com. 600 IN NS ns2.magedu.com. ns1.magedu.com. 600 IN A 1.1.1.2 # 還要給一個IP，雖然用不上，因爲上級已指定了此域，但有人要查詢時這裏要能返回結果，所以還是要添加此條A記錄；NS服務器的主從在區域文件內定義 ns2.magedu.com. 600 IN A 1.1.1.5 MX12345# MX(Mail eXchanger): ZONE NAME --&gt; FQDN（郵件服務器的主機名），格式如下： ZONE NAME TTL IN MX pri VALUE magedu.com. 600 IN MX 10 mail.magedu.com. mail.magedu.com. 600 IN A 1.1.1.3# pri優先級從0－99，數字越小級別越高；在多台服務器找高優先級的服務器；郵件服務器也要有A記錄 A1# A(address)：FQDN--&gt;IPV4 從FQDN（名稱）转换到IPV4（地址）的，主機名轉IP地址的都用A記錄，這是一種最常用的記錄；另一種是AAAA: FQDN --&gt; IPV6 PTR12# PTR(pointer指針記錄)：IP --&gt; FQDN，常用# DNS服務器的主從一般是在配置文件的區域內部定義的，定義區域時指明 CNAME1234567# CNAME(Canonical NAME)正式名稱，此名叫別名記錄：FQDN --&gt; FQDN，標示別名是誰www2.magedu.com. IN CNAME www.magedu.com# www2是後面www的別名，www是www2的正式名稱# 以下三種是其他的記錄格式，可查詢其意思TXT CHAOSSRV 域和區域12345678910111213141516171819202122232425262728域：Domain，邏輯概念區域：Zone，物理概念# 解析有正向與反向，使用不同的數據庫，這就有了正向區域與反向區域，兩個區域在一起組成了域，域不是存儲的，區域才是。區域與域沒有必然的包含關系，一個域中包含區域，但域的授權又是來自上級的區域所以沒法分清，但正反向的授權是從上級不同的區域而來。* 例:以magedu.com. 192.168.0.0/24為例.com # 舉例在.com中已得到授權，下面兩條是授權記錄magedu.com. IN NS ns.magedu.com.ns.magedu.com. IN A 192.168.0.10 www 192.168.0.1 # 這是要在DNS服務器上做的記錄mail 192.168.0.2 MX * 建立兩個區域文件：按規化手動寫入* 正向區域文件（主機名可寫成@） magedu.com. (@) IN SOA # 無論正反向第一條都要是此條 www.magedu.com. IN A 192.168.0.1# 可以簡寫為(簡寫主機名不加點，全寫一定要加點) www IN A 192.168.0.1 * 反向區域文件 0.168.192.in-addr.arpa.（這裡要寫網段地址，反寫，後面是特定後綴）IN SOA 0.168.192.in-addr.arpa.最後的點不能少 * PTR記錄格式 1. 0.168.192.in-addr.arpa. IN PTR www.magedu.com.(這個主機名不能簡寫，因爲簡寫時補的是區域名，這裏的區域名是0.168.192.in-addr.arpa.) 1 IN PTR www.magedu.com. (這是上一條的簡寫，因為1後面沒有點，所以會補全上面0.168.192開頭的格式)# 正反向的格式除了區域名稱外，都是相同的# MX記錄只定義在正向區域中，反向不需要；NS記錄正反向都要；A記錄只能定義在正向；PTR只能定義在反向 安装与使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207* 例：測試---------------------------------------------------------------------------------------有域magedu.com. 172.16.100.0/24有如下服務器ns 172.16.100.1 # ns指的就是DNS服務器www 172.16.100.1, 172.16.100.3mail 172.16.100.2ftp是www主機的別名--------------------------------------------------------------------------------------- DNS軟件:BIND Berkeley（博客利） Internet Name Domain，互聯網上用的最多的DNS軟件www.isc.org 互聯網系統協會，在此下載BIND軟件，是一個源碼包，紅帽上也有rpm包 bind-libs包是庫文件包，軟件需要依賴此包運行；bind-utils包是工具包，一般要用utils包就需要libs包。bind-utils中有dig host nslookup nsupdate等常用工具 A. bind97(服務器版)1. bind主配置文件/etc/named.conf，主要用於定義BIND進程的工作屬性，區域的定義； 2. /etc/rndc.key（rndc: Remote Name Domain Controller）這是遠程名稱服務控制器，是遠程控制DNS服務器進程可以啟動、關閉、重新裝載等功能的常用命令，rndc.key是讓rndc可以遠程工作的密鑰文件，bind用的是/etc/rndc.conf文件；key中只是密鑰，而conf中還有配置信息，.key和.conf文件一般有一個就可以工作。 3. 還要有區域數據文件，用來查詢主機名與IP之間轉換的規則。默認是自己創建的，在/var/named下，名字自己定義 4. 還有一個服務腳本/etc/rc.d/init.d/named &#123;start|stop|restart|status|reload|configtest&#125;# reload 重讀配置文件和數據文件但不用重啟服務；configtest測試語法錯誤，97版本不支持# bind的二進制程序（启动脚本）叫named，只是軟件包的名字叫bind 5. devel包是在創建開發環境時使用，一般運維不需要安裝，除非創建開發環境。可以不裝# 用yum info bind97-devel查看此軟件包的信息。 6. bind-chroot包： 默認情況bind運行在根/下，有人劫持服務器named進程時，任何運行這個進程的用戶的權限攻擊者都可獲取。運行此進程的用戶是named組也是named，這個用戶和組雖不能登陸系統，但這個用戶named能到達的位置，攻擊者也能到達了。這很不安全。 這可以把運行named依賴的文件搬到一個假的根下，這樣就可防止上述問題了。如下，很多服務都可以通過這種方式提高安全性，但之後的路徑都要以/var/named/chroot/為根，配置會復雜一些，在這裡不要輕易使用chroot,建議不要裝此包，因爲不熟悉，會改變目錄結構 /var/named/chroot/ etc/named.conf etc/rdnc.key sbin/named var/named 7. caching-nameserver包，能讓DNS成為緩存DNS服務器，這是一個快速建立緩存服務器的工具。這裏不安裝。8. 配置DNS服務器過程：先配置成緩存服務器 --&gt; 然後是主服務器 --&gt; 從服務器B、安裝配置過程1. 安裝bind97rpm -ql bind97/etc/rc.d/init.d/named # 服務腳本/etc/rndc.conf # rndc的配置文件/etc/rndc.key /etc/sysconfig/named # 服務腳本的配置文件，這裏還有很多服務腳本配置文件，gen表示generation，生成之意/usr/sbin/named # 主程序 /usr/sbin/named-checkconf # 檢查配置文件中的語法錯誤 /usr/sbin/named-checkzone # 檢查區域文件中的語法錯誤 /usr/sbin/named-compilezone # 編譯區域文件/usr/sbin/rndc # 遠程控制工具 /usr/sbin/rndc-confgen # 幫助生成/etc/rndc.conf配置文件的，gen表示生成/var/named/named.ca # 這些是var下的區域數據文件/var/named/named.empty/var/named/named.localhost/var/named/named.loopback C. 配置文件1. /etc/named.conf中的內容，這是官方的示例 options # 全局選項，對下面的設置都生效 logging # 定義如何生成與保存日志 zone # 定義區域 include # 把其他文件包含進來，這意味著這個文件分成片了，而且還有文件在/etc/named.rfc1912.zones中，這個文件中都是區域的定義，這些定議可以與named.conf寫在一個文件中，需要用include包含進去 2. /var/named/named.ca中定義了根服務器的地址13個，有些主機有多個地址，如果沒有這個文件也可自己生成，用dig (Domain information gropher)命令，用dig -t NS .命令查找根域的NS記錄，也就是根域的所有DNS服務器，這時的前提是可以訪問互聯網或可以修改/etc/resolv.conf中的nameserver爲內網中可上網的DNS服務器。-t是指定資源記錄類型，並指明通過哪個服務器來查詢就能得到結果。還可以dig -t NS . @a.root-servers.net，指明通過哪台主機來找，這表示不借助本地服務器，而是通過根服務器來找，但也要可以聯網。3. /var/named/named.localhost是本地主機，將localhost解析成127.0.0.1的，為了必免DNS服務器配置錯誤，將localhost解析成一個正常地址，使每個主機可以通過localhost訪問本機，這是特別定義的。4. /var/named/named.loopback用於將127.0.0.1解析成localhost# 上述兩配置文件是本地主機名的正反向解析。 5. service named start # 啓動6. DNS監聽的協議及端口：53/udp,53/tcp。除同步數據時用tcp傳輸，默認查詢時都通過UDP的53號端口，速度快。 953/tcp是rndc監聽的 7. 配置文件/etc/named.conf options &#123; listen-on port 53 &#123; 127.0.0.1; &#125;; # 監聽在哪個地址的哪個端口，這裏監聽的是127.0.0.1，所以不能接受遠程主機的查詢請求 listen-on-v6 port 53 &#123; ::1; &#125;; # 是否監聽IPv6端口 directory "/var/named"; # 數據文件位置 dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; localhost; &#125;; # 只允許誰來查詢 recursion yes; # 是否遞歸 dnssec-enable yes; dnssec-validation yes; dnssec-lookaside auto; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; &#125;; 8. SOCKET：套接字就是IP加端口號 IP:PORT 套接字的主要目的就是通過此機制讓位於兩個主機上的不同進程能夠通信的。很多軟件是C/S架框的，套接字就是讓客戶端知道到哪去請求服務器端服務的，因此每個服務器只要想讓位於兩個不同主機端可以通訊，服務器端就要監聽在某個位置，這個位置就是套接字，服務器端監聽在套接字上作為訪問入口。127.0.0.1:53是回環地址，如果監聽在此套接字上，訪問的只能是127的地址，也就是本機。要監聽在外網的地址上才能接受來自其他主機的請求，端口如果沒有監聽是不能響應的。如果有多個地址也可以把每個地址與端口寫清或用0.0.0.0:53代表所有IP的53號端口，或可以不寫地址。這是named.conf文件中options中listen-on中指定的監聽的IP，options中的內容是bind服務器配置文件中選項中可使用的指令加對應的值，或參數和對應值。zone會受其控制，全局選項中最重要的是directory一項，它定義了數據文件目錄，只要告訴DNS服務器到哪找數據即可，其他都可不定義。這裡我們自己建一個。此文件權限是640 D. 創建配置文件1. mv /etc/named.conf /etc/named.conf.orig2. vim /etc/named.conf# 此文件的語法是每一個完整的語句要用分號結尾，花括號前後要有空格，只要不在同一行中，如果花括號後沒有內容或為分號沒關系 options &#123; directory “/var/named”; &#125;； # 區域的定義方法：任何時候DNS服務器只要能夠解析除了自己權威的或負責的區域以外的其他區域，都必須能夠提交給根的；解析其他區域要給根；type指區域類型，指明是什麼區域 zone “ZONE NAME” IN &#123; type &#123;master主|slave從|hint根|forward轉發&#125; &#125;; a、主區域如果是主區域還要定義路徑 file “區域數據文件”# 用file定義區域文件位置，可以使用相對路徑，是相對上面定義的directory的路徑而言 b. 從區域如果是從區域還要定義路徑，只是數據文件是同步來的，不用建立 file “區域數據文件”； masters &#123; master1_ip; &#125;； # 定義主DNS服務器地址，最後要加分號，外面結尾要加分號，master1_ip指主DNS服務器地址，可以是多個 c. 根區域根區域與主區域一樣，只是類型是hint zone “.” IN &#123; type hint; file “named.ca”; # 這個文件是自動生成的 &#125;; zone “localhost” IN &#123; type master; file “named.localhost”; # 本地正向 &#125;; zone “0.0.127.in-addr.arpa” IN &#123; type master; file “named.loopback”; # 本地反向 &#125; 注：上述內容就可創建一個緩存服務器了 3. chown root.named /etc/named.conf # 改變所屬用戶與所屬組4. chmod 640 /etc/named.conf # 改權限5. named-checkconf # 檢查主配置文件語法，不報信息表示沒問題6. named-checkzone "." /var/named/named.ca# 檢查區域文件是否有問題，在命令後指定區域是根，再指明根區域的配置文件路徑。結果提示zone ./IN: not loaded due to errors.也沒有問題7. named-checkzone "localhost" /var/named/named.localhost8. named-checkzone "0.0.127.in-addr.arpa" /var/named/named.loopback# 或可用service named configtest代替上面的三條命令，在bind97中沒有此命令9. service named start# 啓動# 可以查看/var/log/messages文件，看一下服務器啟動的日志# 另外要確保selinux不要啓動---------------------------------------------------------------------------------------在mint8安裝並配置了bind9成緩存服務器，運行正常1. apt install bind92. vim /etc/bind/named.*** # 配置文件都在這裏，但是分幾個文件寫的3. /etc/init.d/bind9 start # 啓動bind94. vim /etc/bind/named.conf.options allow-recursion &#123;192.168.1.0/24; 192.168.5.2; &#125;;# 打開全局設置，加入上面一行，表示可以給1.0網絡遞歸，這時1.0網段主機就可用此DNS緩存服務器了。如果要給本機遞歸，要加上自己所在的網段或給127.0.0.1放行，但這裏測試127網段失敗）---------------------------------------------------------------------------------------10. /etc/init.d/bind9 reload 11. netstat -tlunp # 查看是否有53號端口被監聽12. 測試上面建立的緩存服務器# 將DNS改成本服務器# 啟動DNS服務器 dig -t NS . @a.root-servers.net. # 測試能否找到根 13. chkconfig --list named14. chkconfig named on 配置文件与正向区域配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657* 實現互聯網上的DNS服務器功能1. vim /etc/named.conf options &#123; directory "/var/named"; &#125;; zone "." IN &#123; type hint; file "named.ca"; &#125;; zone "localhost" IN &#123; type master; file "named.localhost"; &#125;; zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.loopback"; &#125;; zone "mageedu.com" IN &#123; type master; file "mageedu.com.zone"; # 自定义文件mageedu.com.zone &#125;; # &#125;與；間沒有空格named-checkconf # 此命令只能檢查語法錯誤，不能查邏輯錯誤 2. vim /var/named/mageedu.com.zone $TTL 600 # 因為是定義全局的值所以要加$號 mageedu.com. IN SOA ns1.mageedu.com. admin.mageedu.com. ( # 上面的域名可用@代替，因爲在主配置文件中已定義了；主DNS服務器的名字是ns1.mageedu.com. 一個IP可以有多個主機名，一個主機名也可有多個IP 2016061301 1H 5M 2D 6H)mageedu.com. IN NS ns1 # 第一個區域名稱如果與上面一樣可不寫 IN MX 10 mailns1 IN A 192.168.5.4mail IN A 192.168.5.5www IN A 192.168.5.4www IN A 192.168.5.6# 這裏只寫www，是因爲省略了域名ftp IN CNAME www # 別名這裏指的一定是名字，而不是地址 3. chmod 640 mageedu.com.zone4. chown root:named mageedu.com.zone5. named-checkzone “mageedu.com” /var/named/mageedu.com.zone# 将DNS改为当前的主机，vim /etc/resolv.conf --&gt; nameserver 192.168.1.107 dig命令123456789101112131415161718192021222324252627282930313233343536373839401. 用dig命令測試* 语法：dig -t RT NAME # NAME與RT要配合起來，這是根據RT的類型找NAME對應的值dig -x IP# 根據IP查FQDN（主機名）* 例：dig -t A www.mageedu.com# 找A記錄，對應的就是相應類型如A記錄一行中的IP的值，這就是根據屬性的名稱找對應的值，也就是取IP地址的dig -t NS mageedu.com# 查這個域的DNS服務器是誰的，最後一定是一個名稱，而不能是IP地址dig -t RT NAME @IP# 加@表示直接到DNS服務器上查找，@IP就是指明DNS服務器地址的 2. dig命令返回的結果dig -t A www.mageedu.com返回結果如下： QUESTION SECTION: # 提出的問題是什麼 ANSWER SECTION: # 答案 AUTHORITY SECTION # 誰是提出問題的主機名的權威服務器 ADDITIONAL SECTION # 補充段，與上一項（權威服務器）NS記錄對應的A記錄# 因爲給web服務配置了兩個地址，所以返回的兩個值每次都會對調，這就是負載均衡了dig -t CNAME ftp.mageedu.com # 查別名dig -t NS mageedu.com # 查NS記錄dig -t MX mageedu.com# 上面是正向解析的方法；dig -t SOA mageedu.com3. 跟踪vim /etc/resolv.conf nameserver 114.114.114.114# 这里一定要改为公网的DNS，默认这里是127.0.0.53,虽然也可以访问公网，但使用下面命令时就不行了，因为dig会不断访问公网的DNS询问答案。dig +trace www.sina.com# dig会一直询问公网DNS，之后再到根域，一级域，二级域不断询问要查找的地址。 host命令123456* 语法：host -t RT NAME # 用-t指定資源類型；查詢名稱的解析結果，但不能用@host -t A www.mageedu.comhost -t MX mageedu.comhost -t SOA mageedu.com nslookup命令12345678910# nslookup：交互式命令，也可工作在命令行模式下；這裏只介紹交互式模式，用window測試nslookupnslookup&gt; server 192.168.5.4 # 在windows中操作，切換DNS；通過server命令指明用5.4DNS服務器來查詢，如果不指或指的服務器不是負責的域，會給出非權威答案nslookup&gt; set q=A # 用set q=命令設定資源類型nslookup&gt; NAME # 要查的域名，如www.mageedu.comset q=NSmageedu.com 反向区域配置123456789101112131415161718192021222324252627282930313233343536373839404142* 反向區域的配置1. vim /etc/named.conf zone "100.16.172.in-addr.arpa" IN &#123; type master; file "172.16.100.zone"; &#125;; 2. cp mageedu.com.zone 172.16.100.zone -p # 包括權限完全復制3. vim 172.16.100.zone $TTL 600 @ IN SOA ns1.mageedu.com. admin.mageedu.com. ( # 這裡的DNS主機名不可簡寫 2016061301 1H 5M 2D 6H) IN NS ns1.mageedu.com. # 反向區域裡DNS域名必須寫完整 1 IN PTR ns1.mageedu.com. 1 IN PTR www.mageedu.com. 2 IN PTR mail.mageedu.com. 3 IN PTR www.mageedu.com.# 反向配置文件中不需要A記錄 4. named-chechconf5. named-chechzone “5.168.192.in-addr.arpa” 192.168.5.zone # 在/var/named目錄中執行此條6. service named restart7. windows測試 set q=PTR 192.168.5.2 set q=NS 5.168.192.in-addr.arpa8. dig -x 192.168.5.4 # 在linux中解析IP，-x選項是解析，將DNS指向自建的DNS後才可使用此命令 泛域名解析、递归、传送123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778* 泛域名解析：如果想不管输入什麼，都轉到主頁。实际上应该是错误页面，這要通過url重定向來處理。1. 在mageedu.com.zone中添加如下，以實現泛域名解析 *.mageedu.com. IN A IP 2. 设置给谁遞歸，（不是自己負責的域才有遞歸的概念） vim /etc/named.conf # 在全局選項中加入 options &#123; recursion yes; # 定義是否给所有人開啟遞歸，默認遞歸的客戶端個數是有限制的，這會使DNS服務器不會掛掉，默認也是開啟，不太好這種方式，所以去掉此項用下面的選項。 allow-recursion &#123; 172.16.0.0/16; &#125;; # 說明只給哪個網段的用戶遞歸，定義遞歸對象；可加入本機回環地址，但用dig -t A IP時後面要加@127.0.0.1才能給遞歸，這應該是本機的DNS指向了本機IP。測試發現不是同一網段地址默認不給遞歸。如DNS是1網段，主機是5網段。這就要在DNS的配置文件中此項加入5網段才能使用。 allow-query # 只允許誰來查詢，用的不多 allow-transfer &#123;172.16.100.2; &#125;; # 只允許172…2這台主機來傳送 notify yes; # 啟動同步通知 recursion no; # 不與任何人遞歸 &#125; 3. 測試遞歸：dig +[no]tcp# 加號 表示以某種方式工作，+no表示不以某種方式工作dig +recurse -t A www.sohu.com @192.168.5.4 # recurse表示遞歸查詢，這是用本機5.4解析sohu的A記錄dig -t A www.sohu.com @192.168.5.4# 默認都是遞歸的，加不加recurse也一樣dig +norecurse -t A www.sina.com @192.168.5.4 # 明確表示不遞歸，返回結果會讓去找.com域dig +norecurse -t A www.sina.com @m.gtld-servers.net.# 再到.com服務器查詢dig +norecurse -t A www.sina.com @dns.baidu.com# 經過三次測試才找到網址的A記錄，不遞歸就只會返回一個參考答案dig +trace -t A www.baidu.com @192.168.5.4 # +trace是跟蹤DNS的解析過程，但是不顯示IP地址的在配置文件中加入recursion no;不與任何人遞歸後再試dig +recurse -t A www.baidu.com @192.168.5.4 # 不會返回結果dig +recurse -t A www.mageedu.com @192.168.5.4# 因是自己負責的域會返回權威答案# 不遞歸就不能設為DNS服務器，因為不能解析就沒有意義vim /etc/named.conf options &#123; ... allow-recursion &#123; 192.168.5.0/24; &#125;; ... &#125;; # 添加上面一条dig -t A www.baidu.com @192.168.5.4dig -t A www.baidu.com @127.0.0.1 # 因為只給192.168.5網段遞歸，所以本機也遞歸不了# 添加allow-recursion &#123; 192.168.5.0/24;127.0.0.1; &#125;;即可給本機遞歸 4. 傳送# axfr：完全區域傳送# ixfr：增量區域傳送dig -t axfr mageedu.com @192.168.5.4# 得到一個區域的完全傳送，得到對方區域內的所有數據 5. vim mageedu.com.zone # 在mageedu.com.zone中加入 pop IN A 192.168.5.7 # 在每次改完此文件後加把版本號加1，改成2016061302 6. service named reload7. dig -t IXFR=2016061301 mageedu.com # 2016061301版本以後發生的變化，如果改成2016061302，結果中只會有XFR size: 1 records (messages 1, bytes 75)一條，說明了有幾條變化，但不會有更詳細的結果。所以可以手動完成區域傳送。###有主從服務器才會有區域傳送，是从主服務器傳送給從服務器，但像剛才的操作並不安全，應只讓從服務傳送才行，也就是添加allow-transfer &#123; 192.168.5.8; &#125;; 只允許誰來傳送，也可將此條寫在zone區域內，也就是某個區域只允許誰來傳送，如果寫在options中就會使全部區域都生效。不讓傳送就將IP地址改成none，如allow-transfer &#123; none; &#125;;dig -t axfr mageedu.com # 測試改爲allow-transfer &#123; none; &#125;;還能否傳送8. 改另一臺主機地址爲允許傳送的地址dig -t axfr mageedu.com @192.168.1.4 # 測試是否可以傳送，最後一定指向對方主機，因爲自己不是DNS服務器 主从配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586871. vim /etc/named.conf options &#123; directory "/var/named"; allow-recursion &#123; 192.168.5.0/24;127.0.0.1; &#125;; # recursion no; &#125;; zone "." IN &#123; type hint; file "named.ca"; &#125;; zone "localhost" IN &#123; type master; file "named.localhost"; allow-transfer &#123; none; &#125;; &#125;; zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.loopback"; allow-transfer &#123; none; &#125;; &#125;; zone "mageedu.com" IN &#123; type master; file "mageedu.com.zone"; allow-transfer &#123; 192.168.5.8; &#125;; &#125;; zone "5.168.192.in-addr.arpa" IN &#123; type master; file "192.168.5.zone"; allow-transfer &#123; 192.168.5.8; &#125;; &#125;;# 只允許5.8這個地址來傳送mageedu.com中的正反向數據，但根區域不用寫allow-transfer，寫了會報錯2. service named reload3. dig -t axfr mageedu.com @192.168.5.4 # 因為5.4不在指定範圍內，所以不能傳送* 新開一台主機，配置地址為192.168.5.8dig -t axfr mageedu.com @192.168.5.8 # 用此命令模擬傳送，因是指定主機所以可以傳送 1. 從服務器配置，在5.8上# 在/var/named目錄中有slaves文件，屬主與屬組都是named，且都有寫權限，但/var/named屬組是named，且沒有寫權限，屬主是root。如果讓從服務器同步數據保存在此目錄中，因是以named身份訪問所以沒有寫權限不能保存，所以要將數據放在slaves中2. setenforce 03. mv /etc/named.conf /etc/named.conf.orig4. scp 192.168.5.4:/etc/named.conf /etc/ # 將5.4的.conf文件下載回來放在/etc下5. vim /etc/named.conf# 僅修改下面內容 zone "mageedu.com" IN &#123; type slave; file "slaves/mageedu.com.zone"; # 將文件放在/var/named/slaves/中 masters &#123; 192.168.5.4; &#125;; # 指定主服務器 allow-transfer &#123; none; &#125;; # 不允許同步數據，試驗時可先去掉主從區域中的此條，以免出問題 &#125;; zone "5.168.192.in-addr.arpa" IN &#123; type slave; file "slaves/192.168.5.zone"; masters &#123; 192.168.5.4; &#125;; allow-transfer &#123; none; &#125;; &#125;; # 將一個服務器設為正向的主服務器反向的從服務器，另一個設為正向的從服務器，反向的主服務器。 6. named-checkconf7. chgrp named /etc/named.conf8. service named start # 視頻中出現問題，是因爲主服务器的配置文件的屬組是root且其他權限是0,改爲named組再試。查看日志可找到錯誤信息9. tail /var/log/messages# 在兩台主機上運行此條命令，結果會顯示完全傳送啓動與結束的信息10. cd /slaves # 查看傳送過來的信息# ORIGIN . 與 TTL 都可以聲明多次的 增量传送1234567891011121314151617181920212223242526272829303132333435363738* 在主服務器5.4中1. vim /var/named/mageedu.com imap IN A 192.168.5.9 # 加入 2016061303 # 改序列號 2. service named reload3. tail /var/log/messages# 查看兩服務器的日志因視頻中的同步沒有發生，所以在主服務器的named.conf中的options中加入了notify yes; 一條讓服務器啟動同步通知，沒有發生同步的真正原因是在主服務器的mageedu.com.zone中沒有定義另一台服務器的IP地址，所以域服務器只知道有一台服務器。4. 在主服務器的mageedu.com.zone加入兩條 mageedu.com. IN NS ns2 ns2 IN A 192.168.5.8# 這是正向的NS和A記錄，反向也要有192.168.5.zone中加入 IN NS ns2.mageedu.com. 8 IN PTR ns2.mageedu.com.5. service named reload # 重新讀取主服務器配置文件6. 將從服務器上slaves中的文件都刪除，讓從服務器再完全同步一次7. 到主服務器上vim mageedu.com，加入 hello IN A 192.168.5.9 改序列號 8. service named reload9. tail /var/log/messages# 加入一台NS服務器時一定也要加入ns記錄，放在本區域中所支持的DNS服務器中10. 在主服務器的反向文件192.168.5.zone中加入 10 IN PTR hello.mageedu.com. 11. service named reload12. 查看日志 rndc12345678910111213141516171819202122232425262728293031323334353637383940414243* 用rndc控制DNS服務器1. rndc-confgen &gt; /etc/rndc.conf # 生成配置文件2. cat /etc/rndc.conf# start of rndc.conf與end of rndc.conf中間的段才是生效的，文件中下面還有這樣的一段內容，但注釋掉了，並要求將注釋的內容放到named.conf中3. vim /etc/rndc.conf 輸入:.,$-1w &gt;&gt; /etc/named.conf # 定位光標所在行到倒數第二行追加到/etc/named.conf中 4. vim /etc/named.conf :.,$s/^# //g # 從光標所在行到最後一行，查找行首的#號且後面有空白，替換為什麼也沒有，之後可以看到rndc-key的保存位置，並標明了是密鑰 5. vim /etc/rndc.conf# 這裡也定義了rndc-key6. rm /etc/rndc.key # 這是bind軟件提供的，刪除即可7. service named restart8. rndc -c /etc/rndc.conf status # 使用-c選項控制服務器，查看服務器狀態9. rm -rf /etc/rndc.key # 刪除這個文件，不然上面一條命令會報錯？？？ 10. rndc -c /etc/rndc.conf notify “mageedu.com” # 手動發送通知11. rndc -c /etc/rndc.conf flush # 清除緩存12. rndc -c /etc/rndc.conf stop # 停止服務器，啟動必須用service命令啟動named13. netstat -tlunp # 查看14. service named start# rndc命令用於控制與查看服務器，在控制本地主機時較常用 控制遠程服務器需注意12345678910111213141516171. named.conf中controls一項中的監聽地址要改，如：controls &#123; inet 192.168.5.4 port 953 # 監聽的地址 allow &#123; 192.168.5.8; &#125; keys &#123; “rndc-key”; &#125;; # 允許控制的地址，用什麼控制&#125;service named restart2. scp /etc/rndc.conf 192.168.5.8:/root # 把密鑰文件拷到控制主機上，並放在root目錄下，如果放在etc下會覆蓋別人的相同文件3. vim rndc.conf # 編輯拷過來的文件 改options中的default-server地址為要控制的服務器地址 4. 這裡還要同步時間，一般不用開啟遠程控制，不安全。一般只在本機上使用。 测试DNS服务器123456789101112131415161718192021222324252627282930* 例：公司在mageedu.com域下，網站是www.mageedu.com。現兩個部門有各自的網址，分別為www.mageedu.com/fin（財務）和www.mageedu.com/market（市場），現兩個網站有不同的地址，如www.fin.mageedu.com和www.market.mageedu.com，現在就有三個域要管理，也就是mageedu.com域要有DNS服務器管理，新分出的www.fin.mageedu.com和www.market.mageedu.com也要有兩個DNS服務器管理，這就是一個父域和兩個子域，子域要有父域的授權，下面為正向的設置。反向設置比較麻煩 正向區域設置SUB_ZONE_NAME IN NS NSSERVER_SUB_ZONE_NAMENSSERVER_SUB_ZONE_NAME IN A IP A記錄 SUB_ZONE_NAME # 指子域的區域名稱NSSERVER_SUB_ZONE_NAME # 指管理這個子域的域名服務器，且一定是當前域的子片# A記錄是管理這個子域的域名服務器的IP地址# 如在.com域下注冊了mageedu.com，那麼在.com上要用如上方法建立mageedu.com IN NS ns1.mageedu.com. IN NS ns2.mageedu.com.ns1.mageedu.com. IN A 192.168.5.38ns2.mageedu.com. IN A 192.168.5.41# 如果有輔助服務器是192.168.5.8，在互聯網上是不能用的，因為.com域中沒有記錄。也就是子域中有幾個名稱服務器，在父域中也要建幾條記錄。這裏再次回顧解析過程，如下：dig +trace -t A www.baidu.com @192.168.5.38# 因爲5.38是負責mageedu.com.域的，不負責解析baidu.com域，所以要去找根，根會返回.com域的信息，再找.com域，.com域會根據自己的A記錄再返回baidu.com域的A記錄信息。baidu.com域再根據自己的A記錄返回要查找的內容。所以，如果在baidu.com.域中沒有相關記錄，即使建了從服務器，也不會被找到。如果在父域中有多條記錄，會被輪流使用。#如上。如自建了兩臺NS服務器，在網上注冊了域名，要在域名提供商提供的頁面中將ns記錄改為自己的服務器，並建兩個記錄指向自己的兩臺NS服務器。 * 例：現在mageedu.com域已屬我們自己管理，且建好了一主一從兩臺名稱服務器，現在希望授權子域，一個叫fin，一個叫market，並且讓兩個子域可以自我管理。如何實現？建立兩個子域，授權子域可自我管理在父域上授權子域，這應該是在域名提供網的頁面上做的fin.mageedu.com. IN NS ns1.fin.mageedu.com.fin.mageedu.com. IN NS ns2.fin.mageedu.com. # 這是從服務器ns1.fin.mageedu.com. IN A 192.168.5.10 # 子域IP也就是子域與父域不一定在同一網段，但要能與父域通訊ns2.fin.mageedu.com. IN A 192.168.5.7 # 子域2的服務器一定要能通信，如果解析返回子域2的IP地址，但不在線，這就不能通信了。從服務器如果不在線也會影響解析工作market.mageedu.com. IN NS ns1.market.mageedu.com.ns1.market.mageedu.com. IN A 192.168.5.11 fin子域服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869* 建立fin子域服務器方法：只建一個1. 在父域上授權，編輯父服務器中的主服務器，加入如下vim /var/named/mageedu.com.zone fin IN NS ns1.fin ns1.fin IN A 192.168.5.10 market IN NS ns1.marketns1.market IN A 192.168.5.11最後修改序列號，不然從服務器得不到此數據 2. service named restart --&gt; tail /var/log/messages # 重啓，看日志cd /var/named/slaves # 查看從服務器是否同步了數據cat mageedu.com.zone # 其中用$ORIGIN聲明變量3. dig -t NS fin.mageedu.com @192.168.5.4 # 雖然NS服務器不存在，但記錄已有。因為沒建立子域，聯系不上子域服務器所以不會返回結果 dig -t A ns1.fin.mageedu.com @192.168.5.4 # 查看A記錄是否能找到4. 在另一臺服務器上建子域服務器，修改IP地址。DNS服務器改爲自己（也就是子域服務器地址），搜索的子域，也就是search一項改爲fin.mageedu.com。重啓網絡服務，ping主DNS服務器，再試 在/etc/named.conf中加入，並刪除之前所有自定義的域 zone “fin.mageedu.com” IN &#123; type master; file “fin.mageedu.com.zone”; &#125;; 5. 在主DNS中操作cd /var/named--&gt;復制mageedu.com.zone爲fin.mageedu.com.zone並修改:%s@mageedu.com@fin.mageedu.com@g# 上面的%表示全文搜索，將mageedu.com改爲fin.mageedu.com$TTL 86400@ IN SOA ns1.fin.mageedu.com. admin.fin.mageedu.com. 2016110101 2H 10M 7D 2D) IN NS ns1 IN MX 10 mailns1 IN A 192.168.5.41mail IN A 192.168.5.42www IN A 192.168.5.43上面就建立了子域的名稱服務器，保存退出並啓動6. 到子域再試dig -t NS fin.mageedu.com @192.168.5.41dig -t A fin.mageedu.com @192.168.5.41 7. 到父域再試dig -t NS fin.mageedu.com @192.168.5.38dig -t A fin.mageedu.com @192.168.5.38# 只要子域存在就沒問題了。在子域解析時，顯示的flags一行有aa字樣，應該是權威答案。8. 用windows的nslookup試server 192.168.5.38 # 指向父域set q=Awww.mageedu.comwww.fin.mageedu.com server 192.168.5.41 # 指向子域set q=Awww.mageedu.com # 因爲互聯網上沒有這個域，所有不會返回結果www.fin.mageedu.com# 將發送到子域的請求都轉發給父域 子域轉發123456789101112131415161718192021222324252627282930313233343536# 讓子域可以找到互聯網上沒有的父域，定義轉發即可。將子域所有的請求都轉發給父域。* 在子域中1. vim /etc/named.conf# 在options中加入forward &#123; only|first &#125;，only指把自己解析不了的都轉給指定的服務器，如果指定的服務器不能給答案就算了；first指轉發給指定的服務器如果不能給答案，子域就去找根了。 forward first; # forward表示轉發，這樣設備會報錯 forwarders &#123; 192.168.5.4; &#125;; # 指定轉發器的位置，也就是轉發給誰。但這是對全局的設定，所有請求都會轉發 2. service named restart3. windows中測試效果 nslookup set q=A www.fin.mageedu.com www.mageedu.com 4. dig +trace -t A www.baidu.com # 這裏的請求實際是轉發給父域了，但父域不負責百度，這樣做的意義並不大。我們也可以轉發父域負責的，其他自己去查設置轉發域，在/etc/named.conf中追加新建區域 zone “mageedu.com” IN &#123; type forward; # 說明是轉發域 forward first; # 將此兩條寫在這裡，說明只有請求的是mageedu.com域時才轉發 forwarders &#123; 192.168.5.4; &#125;; # 測試這裏不能用acl訪問控制列表 &#125; 5. named-checkconf6. 在windows中測試 set q=A www.mageedu.com# 試一下將所有對.com的請求都轉發給.comdig -t NS com --&gt; 找到.com的A記錄，把A記錄填入forwarders中 acl1234567891011121314151617181920212223242526ACL的使用（訪問控制列表）allow-recursion &#123;&#125;; # 能被遞歸的客戶端來源allow-query &#123;&#125;; # 允許查詢的客戶端allow-transfer &#123;&#125;; # 允許傳送的客戶端在named.conf也可使用變量這種機制，但叫acl（訪問控制列表），假如要在上面三個條目中定義主機，可用acl定義並放在前面，並取名，以後可隨時使用 1. 用法：acl在主配置文件named.conf中的options之上定義 acl innet &#123; 192.168.5.0/24; 127.0.0.0/8; &#125;;# innet是ACL_NAME（acl的名字），可以隨便起 allow-query &#123; innet; &#125;; # 再用此項時，可不寫地址，直接寫innet即可 none；# 是內置的常用列表，表示什麼都沒有 any；# 同none一樣是內置的常用列表，表示任意的* acl一定要先定義才能使用，所以一般對主配置文件來說，acl是寫在最上方的。例： acl innet &#123; 192.168.5.0/24; 127.0.0.0/8; &#125;;# 可參考書&lt;&lt;bind97 Manual&gt;&gt;，另外講的大多數內容在&lt;&lt;OReily DNS and BIND 5th&gt;&gt; 智能DNS123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118 * 能夠根據客戶端來源所屬的網絡進行判斷，並且返回給一個我們事先定義好的IP地址，這就是智能DNS。 * 它是怎麼實現智能的？DNS在自己的內部做視圖（view），DNS服務器試圖解析一個域名，我們把所有客戶端來源分爲兩類，一類是來自聯通網的，一類是電信網的。我們希望位於聯通網的解析爲一個聯通的IP地址，電信的返回電信機房的IP地址。這就要將數據文件分成兩部分，來自聯通的就查找聯通的數據文件，電信的查找電信的數據文件。用兩個文件分別應對來自不同網絡的請求。這樣對一個域名的請求就可以一分為二，叫做split brain(腦裂)的結果，這裏不只能分爲兩個，要看有多少個數據文件，就能分幾個。（在各地機房都有服務器，這個服務器可能是緩存服務器，而不是源服務器。）這裡不僅限分成兩個，要看劃分區域多少。實現上可能是建一個服務器集群，之後在各地建緩存服務器，在客戶端請求時，緩存服務器向服務器集群發請求，將web內容緩存到本地，之後客戶端就可從本地緩存服務器上得到請求的結果，這種能判斷客戶端來源並返回最近的服務器內容的網絡，而且這個網絡本身能夠根據原始服務器取得內容以後緩存在本地，它就叫做CDN (Content Delivery Network)內容分發網絡。這裏緩存的一般是靜態內容，只有動態內容才從原始服務器獲取。而很多動態內容也可通過策略靜態化，並緩存在本地。CDN比較重要的前提是可以判斷客戶端來源。而且要能根據客戶端來源返回離他最近的服務器地址。 * 測試：分兩個網絡172.16.0.0/16和127.0.0.0/8的是電信網，其他都是聯通網。這要使用view功能，只能一臺服務器實現智能解析。方法： route 查看網關爲172.16的網絡再找一臺主機，改成192.168的網絡，網關指向192.168.0.254，192與172在同一臺主機上是允許路由數據的。這臺主機只是用來做客戶端，停止named服務。例：vim /etc/named.conf# 要想實現智能解析，就要使用view視圖。用man named.conf可查看視圖的幫助。 view VIEW_NAME &#123; # 對option使用的所有指令對視圖都可用。除了directory外。 &#125;# options中的指令在view中幾乎都可使用。一旦使用了視圖，所有區域都必須定義在view中，根區域只需定義在需要遞歸的view中即可。用man named.conf可查看幫助 * 定義三個視圖，一個叫內網，一個叫電信，一個叫聯通。來自電信和聯通的都不用做遞歸，只要不遞歸就不用提供根的解析。如果此情況在互聯網上是不用聲明根區域的，但一般還是提供根區域的1. cp /etc/named.conf /rootvim /etc/named.conf acl telecom &#123; 172.16.0.0/16; 127.0.0.0/8; &#125;； options &#123; directory “/var/named”； allow-recursion &#123; telecom; &#125;; &#125;; view telecom &#123; match-clients &#123; telecom; &#125;; # match-clients是view中最常用的指令，判斷是來自哪兒的客戶端的 zone “mageedu.com” IN &#123; type master; file “telecom.magedu.com.zone”; # 每個視圖對應一個區域數據文件，只要區域在不同的區域中都提供了，就要給不同的區域文件。 &#125;; &#125;; view unicom &#123; match-clients &#123; any; &#125;; # 這裡的any代表除上面定義的telecom網絡外的其他網絡，只要匹配不上上面的就都會匹配這個 zone “mageedu.com” IN &#123; type master; file “unicom.magedu.com.zone”; &#125;; &#125;;# 到這裏測試了一下，named-checkconf --&gt; service named restart 2. 建立正向解析文件vim /var/named/telecom.mageedu.com.zone $TTL 43200 @ IN SOA ns1.mageedu.com. admin.mageedu.com. ( 2016061301 1H 10M 7D 1D) IN NS ns1 IN MX 10 mail ns1 IN A 192.168.5.4 mail IN A 192.168.5.5 www IN A 192.168.5.6 3. chgrp named telecom.mageedu.com.zone4. chmod 640 telecom.mageedu.com.zone5. cp -p telecom.mageedu.com.zone unicom.mageedu.com.zone6. vim unicom.mageedu.com.zone $TTL 43200 @ IN SOA ns1.mageedu.com. admin.mageedu.com. ( 2016061301 1H 10M 7D 1D) IN NS ns1 IN MX 10 mail ns1 IN A 192.168.5.4 # 此條IP是不會變的 mail IN A 172.16.100.2 www IN A 172.16.100.3 7. 測試，在客戶端上和服務器上分別做一次dig -t A www.mageedu.com @172.16.100.1在windows上測試server 172.16.100.1set q=Awww.mageedu.com * 一臺DNS服務器可爲多個域解析，加入a.net網絡，且a.net不用區分網絡。來自a.net的無論哪個網絡都解析一個IP8. 在主配置文件的兩個view中加入下面內容，這樣才能保證來自不同網絡的客戶端訪問同一個地址。 zone “a.net” IN &#123; type master; file “a.net.zone”; &#125;;這就可以實現如果同時解析多個域，但有些域裡不想使用不同的結果，之後如下vim a.net.zone $TTL 43200 @ IN SOA ns1.a.net. admin.a.net. ( 2016061301 1H 10M 7D 1D) IN NS ns1 ns1 IN A 172.16.100.1 mail IN A 172.16.100.2 www IN A 172.16.100.3 9. chgrp named a.net.zone10. chmod 640 a.net.zone11. service named restart12. dig -t A www.a.net @172.16.100.1 # 在兩臺主機上測試# DNS服務啟動後會將數據文件載入內存，解析與查找過程是在內存中完成的，所以很快。但如果修改了數據文件就要重新載入，如果數據文件較大就比較慢了。所以將區域的定義內容可以寫在數據庫中，不再載入內存，不用重新讀取，每次都查數據庫，所以管理方便了，但速度慢了。智能DNS服務器提供商：dnspod、www.dns.la。推薦文檔《利用bind DLZ MySQL構建智能DNS》，DLZ是能將DNS數據放入MySQL中的一種機制。還有一種是bind-sdb，這也是一種將數據放在數據庫中的機制 DNS日志功能12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758在互聯網上使用不建議開日志功能，會產生大量磁盤I/O寫日志，影響服務器性能1. vim /etc/named.conf 在options中加入 querylog yes; 2. service named restart3. dig -t A www.baidu.com @192.168.5.384. tail /var/log/messages# 这种方法添加的日志功能，日志文件在messages中# bind提供的日志系統要定義兩個子系統，一個category，一個channel5. category：DNS產生子系統在什麼地方，定義產生日志的源，可以是與查詢相關的，也可以是與區域傳送相關的等。可以通過category自定義日志來源；日志源一共只有15個 6. channel：定義日志保存位置 一個category可以定義到多個channel，但一個channel只能保存到一個category。也就是一个日志查询的源可以保存在多个地方，但一个地方只能保存一种日志源。 7. 日志記錄的地方有兩種：syslog和file syslog：由syslog定義，存在/var/log/messages中 file：自定義保存日志信息的文件 日志級別有：critical error warning notice info debug[level] dynamic（動態級別）；默認是info級別 * 方法1. vim /etc/named.conf logging &#123; 用logging括起來 channel querylog &#123; # 定義通道，querylog是保存的名字，名字隨便 file “/var/log/named/bind_query.log” versions 5 size 10M; # 類型是file，格式，達到10M後滾動，保存5個版本。另外named用戶要對保存位置有寫權限 severity dynamic; # 日志級別 print-category yes; # 由哪個category產生的信息 print-time yes; # 什麼時間產生的信息；但在發往syslog時不用，因爲syslog會自動記錄 print-severity yes; # 記錄日志時把當前的級別也寫下來 &#125;; channel xfer_log &#123; file “/var/log/named/transfer.log” versions 3 size 10k; severity debug 3; print-time yes; &#125;; category querise &#123; querylog; &#125;; # 來自category類別的日志與query（查詢）相關的，記錄到querylog中 category xfer-out &#123; xfer_log &#125;; &#125;; 2. mkdir /var/log/named3. chown named:named /var/log/named4. chmod 770 /var/log/named# 每重啓服務日志都會自動滾動；# 參考: http://www.ahlinux.com/server/dns/6291.html** 一般查詢與安全日志不開，更新日志開啟 ** DNS服務器性能測試12345678910111213141516171819202122* dnstop軟件是監控DNS服務器每秒能接受多少查詢的，對哪個域名發起查詢請求的；bind原碼軟件包中有queryperf命令可以對服務器做壓力測試用queryperf命令1. 先建一個文件在裡面寫明要查詢的內容vim test www.mageedu.com A mageedu.com NS mageedu.com NX mail.mageedu.com A ns1.mageedu.com A pop. mageedu.com A imap. mageedu.com A# 將內容復制了多次達到200000行時測試，:1,$y從第一行到最後一行復制；這時用top命令查看cpu佔用率；用兩臺不同的主機測試 2. queryperf -d test -s 172.16.100.1# 測試中可能會卡住，這時可用top命令查看一下CPU的壓力；另外這是本機測試，沒有考慮帶寬問題，可用其他主機測試一下，把test文件和queryperf文件拷到其他主機 * 再用dnstop工具監控DNS狀態，編譯安裝此軟件需要安裝libpcap-devel包。這是一個抓包工具dnstop -4 -Q -R eth0# -4指監聽IPv4地址，-Q指記錄查詢數，-R指記錄響應數，最後是網卡名稱。之後用dig命令查詢，這條命令會有結果顯示 # 多行注釋方法：/*開頭*/結尾# 本節介紹的書籍dns and bind、bind97 Manual、利用bind DLZ Mysql構建智能DNS]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习四：操作容器]]></title>
    <url>%2F2018%2F11%2F22%2Fdocker%E5%AD%A6%E4%B9%A0%E5%9B%9B%EF%BC%9A%E6%93%8D%E4%BD%9C%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[操作Docker容器 容器是 Docker 又一核心概念。 简单的说，容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统(提供了运行态环境和其他系统环境)和跑在上面的应用。 启动容器 启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态(stopped)的容器重新启动。 新建并启动容器12345678910111213141516171819202122232425262728293031323334root@ruopu:~# docker run ubuntu:14.04 /bin/echo 'Hello World'Unable to find image 'ubuntu:14.04' locally14.04: Pulling from library/ubuntuaa1a66b8583a: Pull complete aaccc2e362b2: Pull complete a53116a2808f: Pull complete b3a7298e318c: Pull complete Digest: sha256:f961d3d101e66017fc6f0a63ecc0ff15d3e7b53b6a0ac500cd1619ded4771bd6Status: Downloaded newer image for ubuntu:14.04Hello World# 新建并启动一个容器，因为本地没有ubuntu14.04的镜像，所以会先下载镜像并启动容器，并输出一个"Hello World"。运行完命令后这个容器就会终止。root@ruopu:~# docker run ubuntu:14.04 /bin/echo 'Hello World'Hello World# 再次执行相同命令时就不会再下载了root@ruopu:~# docker run -t -i ubuntu:14.04 /bin/bashroot@eb5dd3071f75:/## -t选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。root@f55cb4d1089e:/# pwd/root@f55cb4d1089e:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var# 在交互模式下，用户可以通过所创建的终端来输入命令============================================================================================当利用docker run来创建容器时，Docker 在后台运行的标准操作包括：* 检查本地是否存在指定的镜像，不存在就从公有仓库下载* 利用镜像创建并启动一个容器* 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层* 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去* 从地址池配置一个 ip 地址给容器* 执行用户指定的应用程序* 执行完毕后容器被终止============================================================================================ 启动已终止容器12345678910111213141516root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf55cb4d1089e ubuntu:14.04 "/bin/bash" 6 hours ago Up 6 hours competent_feistel54b6e4618182 nginx:v2 "nginx -g 'daemon of…" 27 hours ago Up 27 hours 0.0.0.0:81-&gt;80/tcp web24fc2b542c0de nginx "nginx -g 'daemon of…" 28 hours ago Exited 28 hours 0.0.0.0:80-&gt;# 查看正在运行的已有容器，如果要查看全部容器，要在命令最后加-a选项root@ruopu:~# docker start f55cf55c# 启动已终止的容器，重启可以使用restartroot@ruopu:~# docker exec -it f55c bash # 进入正在运行的容器root@f55cb4d1089e:/# ps PID TTY TIME CMD 36 pts/1 00:00:00 bash 52 pts/1 00:00:00 ps# 可见，容器中仅运行了指定的 bash 应用。这种特点使得 Docker 对资源的利用率极高，是货真价实的轻量级虚拟化。 后台运行1234567891011121314151617181920212223242526272829root@ruopu:~# docker run ubuntu:14.04 /bin/sh -c "while true; do echo 'hello world'; sleep 1; done"hello worldhello worldhello worldhello worldhello world# 如果不使用-d参数运行容器，容器会把输出的结果 (STDOUT) 打印到宿主机上面root@ruopu:~# docker run -d ubuntu:14.04 /bin/sh -c "while true; do echo 'hello world'; sleep 1; done" 299d22cbda4f6d648095732350572999aa6937cad2d0d20db5ab37f09340c19e# 如果使用了-d参数运行容器，此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面。root@ruopu:~# docker logs 299d22hello worldhello worldhello world# 输出结果可以用"docker logs 容器ID"查看。容器是否会长久运行是和docker run指定的命令有关，和-d参数无关。使用-d参数启动后会返回一个唯一的ID。root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES299d22cbda4f ubuntu:14.04 "/bin/sh -c 'while t…" 2 minutes ago Up 2 minutes sharp_boothf55cb4d1089e ubuntu:14.04 "/bin/bash" 6 hours ago Up 6 hours competent_feistel54b6e4618182 nginx:v2 "nginx -g 'daemon of…" 27 hours ago Up 27 hours 0.0.0.0:81-&gt;80/tcp web24fc2b542c0de nginx "nginx -g 'daemon of…" 28 hours ago Up 28 hours 0.0.0.0:80-&gt;80/tcp webserver# 使用此命令可以查看容器的信息。root@ruopu:~# docker container logs 299dhello worldhello worldhello worldhello world# 使用此命令也可以看到容器中输出的内容。logs后可以使用容器ID或容器NAMES。语法：docker container logs [container ID or NAMES]# 当使用对容器操作的指令时，docker命令可以默认对容器进行操作，所以不加container也可以。 终止容器123456789101112131415161718192021root@ruopu:~# docker container stop sharp_boothsharp_booth# 可以使用stop命令终止容器，容器可以用NAMES或ID指明root@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES299d22cbda4f ubuntu:14.04 "/bin/sh -c 'while t…" 7 minutes ago Exited (137) 11 seconds ago sharp_boothe06be3875296 ubuntu:14.04 "/bin/sh -c 'while t…" 9 minutes ago Exited (0) 9 minutes ago recursing_vaughan2d025ef6aa4c ubuntu:14.04 "/bin/sh -c 'while t…" 9 minutes ago Exited (0) 9 minutes ago jolly_merklef2e9d5847f7f ubuntu:14.04 "/bin/sh -c 'while t…" 9 minutes ago Exited (2) 9 minutes ago keen_johnsonf55cb4d1089e ubuntu:14.04 "/bin/bash" 6 hours ago Up 6 hours competent_feisteleb5dd3071f75 ubuntu:14.04 "/bin/bash" 7 hours ago Exited (0) 6 hours ago flamboyant_edisonc43e0c0c2836 ubuntu:14.04 "/bin/echo 'Hello Wo…" 7 hours ago Exited (0) 7 hours ago mystifying_nobel9a4c0b5b979b ubuntu:14.04 "/bin/echo 'Hello Wo…" 7 hours ago Exited (0) 7 hours ago focused_stallman54b6e4618182 nginx:v2 "nginx -g 'daemon of…" 27 hours ago Up 27 hours 0.0.0.0:81-&gt;80/tcp web24fc2b542c0de nginx "nginx -g 'daemon of…" 28 hours ago Up 28 hours 0.0.0.0:80-&gt;80/tcp webserverc17f952574b5 hello-world "/hello" 28 hours ago Exited (0) 28 hours ago clever_bell# 可以使用此命令查看到所有的容器，包括已停止的容器，在信息中会被标记为"Exited"。仍在运行的容器被标记为"Up"# 如果是只启动了一个终端的容器，用户可以在容器中使用exit命令或Ctrl+d来退出终端，退出时创建的容器立刻终止。root@ruopu:~# docker container restart f55cf55c# 使用restart命令可以重启容器，容器可以使用ID或NAMES指定 进入容器attach命令（不建议使用）12345678910111213141516root@ruopu:~# docker run -dit ubuntu:14.0464dda1b25fac61f165a0c7ab7c7807f9adf7ac173cdbdc907b0815d796ae0473# 在后台启动一个容器root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES64dda1b25fac ubuntu:14.04 "/bin/bash" About a minute ago Up About a minute gifted_swartz# 查看已启动的容器root@ruopu:~# docker attach 64ddroot@64dda1b25fac:/## 使用attach进入容器。此时如果使用exit退出容器，那么会导致容器的停止。root@64dda1b25fac:/# exitexitroot@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES64dda1b25fac ubuntu:14.04 "/bin/bash" 5 minutes ago Exited (0) 13 seconds ago gifted_swartz# 查看显示容器已停止 exec命令（建议使用）12345678910111213141516171819202122root@ruopu:~# docker run -dit ubuntu:14.04c063d378b1191193d70d44c8fcb7a81e3e5bf0ab8a2f2cb1db4d526b6b510005root@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 15 seconds ago Up 15 seconds agitated_hopperroot@ruopu:~# docker exec -i c063 bashlsbinbootdev...# 只用-i参数时，由于没有分配伪终端，界面没有我们熟悉的Linux命令提示符，但命令执行结果仍然可以返回。直接输入命令就会返回结果。root@ruopu:~# docker exec -it c063 bashroot@c063d378b119:/## 当-i、-t参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。root@c063d378b119:/# exitexitroot@ruopu:~# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 4 minutes ago Up 4 minutes agitated_hopper# 如果使用exit退出容器，不会导致容器的停止。 导出、导入容器导出容器12345root@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9a4c0b5b979b ubuntu:14.04 "/bin/echo 'Hello Wo…" 7 hours ago Exited (0) 7 hours ago focused_stallmanroot@ruopu:~# docker export 9a4c0b5b979b &gt; ubuntu.tar# 这样就将容器快照导出到本地文件 导入容器快照12345678910root@ruopu:~# cat ubuntu.tar | docker import - test/ubuntu:v1.0sha256:34a66c78f8af873bd07ab5b53073b4b2fbfd0a53cece350b54be9ef9910925adroot@ruopu:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEtest/ubuntu v1.0 34a66c78f8af 11 seconds ago 175MB# 导入容器，容器的REPOSITORY是test/ubuntu，TAG是v1.0root@ruopu:~# docker import http://example.com/exampleimage.tgz example/imagerepo# 也可以通过指定URL或某个目录来导入# 用户既可以使用docker import来导入镜像存储文件到本地镜像库，也可以使用docker load来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态)，而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 删除容器删除已停止的容器1234567891011root@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 14 minutes ago Up 14 minutes agitated_hopper64dda1b25fac ubuntu:14.04 "/bin/bash" 20 minutes ago Exited (0) 15 minutes ago gifted_swartz299d22cbda4f ubuntu:14.04 "/bin/sh -c 'while tb" 34 minutes ago Exited (137) 27 minutes agoroot@ruopu:~# docker container rm gifted_swartzgifted_swartzroot@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 14 minutes ago Up 14 minutes agitated_hopper299d22cbda4f ubuntu:14.04 "/bin/sh -c 'while tb" 34 minutes ago Exited (137) 27 minutes ago 删除运行中的容器12345678root@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 14 minutes ago Up 14 minutes agitated_hopperroot@ruopu:~# docker container rm -f f55cf55c# 使用-f选项强制删除运行中的容器，Docker 会发送SIGKILL信号给容器。通过容器ID删除容器root@ruopu:~# docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 清理所有处于终止状态的容器1234567891011121314151617root@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 21 minutes ago Up 21 minutes ........root@ruopu:~# docker container prune WARNING! This will remove all stopped containers.Are you sure you want to continue? [y/N] yDeleted Containers:299d22cbda4f6d648095732350572999aa6937cad2d0d20db5ab37f09340c19ee06be3875296e3f0beaea61f8f48517c4e2ac39ee8852eef24bb2d6c871b0e12........Total reclaimed space: 5Broot@ruopu:~# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc063d378b119 ubuntu:14.04 "/bin/bash" 21 minutes ago Up 21 minutes agitated_hopper54b6e4618182 nginx:v2 "nginx -g 'daemon ofb........]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu18.04Server配置IP地址]]></title>
    <url>%2F2018%2F11%2F21%2Fubuntu18-04Server%E9%85%8D%E7%BD%AEIP%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[配置IP地址1234567891011121314151617vim /etc/netplay/50-cloud-init.yaml# ubuntu18.04Server中调整了网络地址配置方式。如果没有此配置文件，需要手动创建。每个网络端口对应一个配置文件 network: ethernets: ens33: addresses: [192.168.1.90/24] dhcp4: false gateway4: 192.168.1.1 nameservers: addresses: - 114.114.114.114 search: [] version: 2 netplan apply # 配置地址后使用此命令让配置生效 netplan --debug apply # 使用此命令会给出错误提示]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu18.04Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark使用]]></title>
    <url>%2F2018%2F11%2F19%2FWireshark%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[基本使用打开软件后，要选择对哪块网卡抓包，双击即可进入。或点击前头指向的图标 方框部分表示启用混杂模式，然后点击start即可。如果不选择混杂模式，那么抓到的包就都是从选择的网卡进或出的包，也就是只抓取与本机相关的包。如果选择混杂模式，那么经过本机网卡的包都会被抓取。 下面方框部分是抓包筛选器，可以通过筛选器过滤掉不想要的数据包 点击方框部分可以创建一个新的抓包筛选器 比如只想抓IP地址是192.168.2.1的数据包，就可以选择下面方框部分 也可以只抓IP的包（方框部分），或管理筛选器规则（箭头部分） 下面是管理筛选器页面，可以自定义或删除规则 也可以手动输入，这里表示只抓取与本机IP相关的包，用host引导 这时可以看到页面中标明只抓取本机的包 中间部分是包的分层，从方框中的信息可以看到目标地址是本机。 先要停止抓包，才能保存 可以选择保存类型，建议使用pcap的格式，这种格式使用更广泛，也就是下图中的第二种格式，在保存时还可以选择Compress with gzip来进行压缩保存 首选项 调整结构 调整后的效果，这里取消了16进制信息的显示 还可以对包的显示信息列进行调整，也可以添加或删除 方框中是wireshark可以解码的所有协议类型 数据会先经过抓包筛选器进行过滤，之后再对抓到的包进行显示筛选 方框部分就是显示筛选器 只想查看到DNS相关的包，输入好后按右面的箭头进行应用。 这里想创建一个组合的显示条件，输入udp，之后在包分层中按红框选择，在Source上右键，选择Apply as Filter中的and not selected。之后就会在显示筛选器中出现一条筛选语句。这条语句表示，即是udp的包，但来源不是192.168.0.20地址的包 也可以把规则改为目的地址ip.dst，或地址ip.addr。筛选完成后可再按上面步骤进一步筛选，一定要选择and not selected，这样规则就会叠加。 Wireshark信息统计统计功能基本都在Statistics菜单下]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump命令使用]]></title>
    <url>%2F2018%2F11%2F19%2Ftcpdump%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[tcpdump命令使用123456789101112131415161718192021222324252627282930313233343536* tcpdump如果不指定字节大小，默认只抓每个包的前68个字节。通常是把tcp、ip、还有包头可以抓完整的例：root@kali:~# tcpdump -i eth0 -s 0 -w a.cap# -i指定网卡；-s指定数据包的大小，如果用0就表示全部包，这里应该指定的是多少字节；-w指定将结果保存到一个文件中。这会抓取到所有经过eth0端口的包。70900 packets captured表示抓到了70900个包ping 172.16.0.108# 用另一台主机ping这台kali，产生一些数据包tcpdump -r a.cap# 读取刚才生成的包文件tcpdump -A -r a.cap# 使用ASCII码的格式显示包tcpdump -X -r a.cap# 使用16进制的格式显示包tcpdump -i eth0 tcp port 22# 抓取eth0上的tcp协议端口22的包，这叫抓包筛选器nc -nv 172.16.0.108 22# 使用nc命令连接地址的端口nc -nv 172.16.0.108 80# 连接80端口，但这时是不会抓取包的，因为只监听了网络的22端口例：显示筛选器tcpdump -n -r http.cap | awk '&#123;print $3&#125;' | sort -u# 显示筛选器。-n表示不对包内的地址做名称解析。sort的-u选项是去除重复的项tcpdump -n src host 172.16.0.108 -r a.cap# src host表示源地址，这是只显示源地址是172.16.0.108的包tcpdump -n dst host 172.16.0.108 -r a.cap# 显示目标地址tcpdump -n port 53 -r http.cap# 显示端口为53的包tcpdump -n tcp port 53 -r http.cap# 显示tcp的包，也可以显示udp协议的包tcpdump -nX port 80 -r http.cap# 可以加上X选项，以16进制显示* 高级筛选可以筛选包头里其他部分。图中是TCP的包头结构，以8个位为一个字节，每一行的内容表示4个字节，0-7是一个字节，8-16又是一个字节。一共是32个位。源端口占用了前面的16个位，也就是两个字节。目的端口占用后面的2个位（16个字节）。之后的Sequence Number和Acknowledgment Number都是占用32个位的，也就是4个字节。下面一个字节被分成了两个部分，第一部分是数据的偏移量，如果这时包被分段了，那么就会有数据的偏移量，保留了几个位之后，后面的就是tcp的flag，也就是标签位，表示当前这个包是什么类型的包，如是SYN包，还是回的ACK+SYN包，每一个位表示一个包的类型，如FIN是1，就表示FIN的flag标签的包，也就是哪位是1，就表示是那个位对应的类型的包有效。三次握手后，客户端发送的就是ACK+PSH包，这时这两个会标记为1，表示这是数据传输最起始的步骤。使用筛选时，如果不想看握手的包，就可以指定ACK+PSH为1的数据包。在图中，类型有8个，每个占用一个位，一共8位，我们要筛选的就是ACK+PSH是1，其他位都是0的包，计算成十进制就是24，二进制是00011000，所以转换为十进制是24。另外在表示类型的行上面有三行，共占12个字节。在类型前面的Data Offset和Res.还占用了一个字节，所以tcp的flag位是tcp包头时的每14个字节。（因为tcp包头的字节是从0开始的，这里只筛选tcp包头里第14个字节，但从表达式来说，应该是第13号。也就是第13号字节，实际就是第14个字节）转换为十进制是24的这些数据包，表达式命令如果tcpdump -A -n 'tcp[13] = 24' -r http.cap 简介用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182* 默认启动tcpdump# 普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包。* 监视指定网络接口的数据包tcpdump -i eth1# 使用-i选项指定网卡。如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0 * 监视指定主机的数据包tcpdump host sundown# 打印所有进入或离开sundown的数据包.tcpdump host 210.27.48.1 # 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包tcpdump host helios and \( hot or ace \)# 打印helios 与 hot 或者与 ace 之间通信的数据包tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 \) # 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信tcpdump ip host ace and not helios# 打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.tcpdump ip host 210.27.48.1 and ! 210.27.48.2# 获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包tcpdump -i eth0 src host hostname# 截获主机hostname发送的所有数据tcpdump -i eth0 dst host hostname# 监视所有发送到主机hostname的数据包 * 监视指定主机和端口的数据包tcpdump tcp port 23 and host 210.27.48.1# 获取主机210.27.48.1接收或发出的telnet包tcpdump udp port 123 # 对本机的udp 123 端口进行监视，123为ntp的服务端口 * 监视指定网络的数据包tcpdump net ucb-ether# 打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为'Berkeley网络'的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包)tcpdump 'gateway snup and (port ftp or ftp-data)'# 打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析)tcpdump ip and not net localnet# 打印所有源地址或目标地址是本地主机的IP数据包(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字) * 监视指定协议的数据包tcpdump 'tcp[tcpflags] &amp; (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'# 打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字)tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)'# 打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习)(nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&amp;0xf)&lt;&lt;2)表示ip数据包包头的长度(ip[0]&amp;0xf代表包中的IHL域, 而此域的单位为32bit, 要换算成字节数需要乘以4, 即左移2. (tcp[12]&amp;0xf0)&gt;&gt;4 表示tcp头的长度, 此域的单位也是32bit, 换算成比特数为 ((tcp[12]&amp;0xf0) &gt;&gt; 4) &lt;&lt; ２, 即 ((tcp[12]&amp;0xf0)&gt;&gt;2). ((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0 表示: 整个ip数据包的长度减去ip头的长度,再减去 tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的'Payload Length' 与 'tcp头的长度'的差值, 并且其中表达方式'ip[]'需换成'ip6[]'.)tcpdump 'gateway snup and ip[2:2] &gt; 576'# 打印长度超过576字节, 并且网关地址是snup的IP数据包tcpdump 'ether[0] &amp; 1 = 0 and ip[16] &gt;= 224'# 打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply'# 打印除'echo request'或者'echo reply'类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 . (nt: 'echo reuqest' 与 'echo reply' 这两种类型的ICMP数据包通常由ping程序产生))tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap# tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型# -i eth1 : 只抓经过接口eth1的包 # -t : 不显示时间戳 # -s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包 # -c 100 : 只抓取100个数据包 # -dst port ! 22 : 不抓取目标端口是22的数据包 # -src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24 # -w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析* 使用tcpdump抓取HTTP包tcpdump -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854# 0x4745 为"GET"前两个字母"GE",0x4854 为"HTTP"前两个字母"HT"。 # tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。 tcpdump的简单选项介绍12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061tcpdump采用命令行方式，它的命令格式为： tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ] [ -i 网络接口 ] [ -r 文件名] [ -s snaplen ] [ -T 类型 ] [ -w 文件名 ] [表达式 ]-a # 将网络地址和广播地址转变成名字；-A # 以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages).-c count # tcpdump将在接受到count个数据包后退出.-C file-size (nt: 此选项用于配合-w file 选项使用) # 该选项使得tcpdump在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)-d # 以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充)-dd # 以C语言的形式打印出包匹配码.-ddd # 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的'count'前缀).-D # 打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口.此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用. 如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数.-e # 每行的打印输出中将包括数据包的数据链路层头部信息-E spi@ipaddr algo:secret,...# 可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充).# 需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）.# 可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入.# 该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到.# 除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,... 中...换成一个语法文件名). 此文件在接受到第一个ESP 包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害).-f # 显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环). 由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 'any' 网络接口就不需要设置地址和掩码, 不过此'any'接口可以收到系统中所有接口的数据包), 该选项不能正常工作.-F file #使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.-i interface# 指定tcpdump 需要监听的接口. 如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束.# 在采用2.2版本或之后版本内核的Linux 操作系统上, 'any' 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包.# 如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数.-l # 对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的: ``tcpdump -l | tee dat'' 或者 ``tcpdump -l &gt; dat &amp; tail -f dat''.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作'&gt;', 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中)-L # 列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定)-m module # 通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充). 此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块.-M # secret 如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret.-n # 不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换.-nn： # 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示-N # 不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印'nic' 而不是 'nic.ddn.mil'.-O # 不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用.-p # 一般情况下, 把网络接口设置为非'混杂'模式. 但必须注意 , 在特殊情况下此网络接口还是会以'混杂'模式来工作； 从而, '-p' 的设与不设, 不能当做以下选现的代名词:'ether host &#123;local-hw-add&#125;' 或 'ether broadcast'(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包).-q # 快速(也许用'安静'更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短.-R # 设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出'禁止中继'域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号.-r file # 从文件file 中读取包数据. 如果file 字段为 '-' 符号, 则tcpdump 会从标准输入中读取包数据.-S # 打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325).-s snaplen # 设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索'网络接口分接头'关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现''[|proto]''的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包.-T type # 强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包. 目前已知的type 可取的协议为: aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用), cnfp (Cisco NetFlow protocol), rpc(Remote Procedure Call), rtp (Real-Time Applications protocol), rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol), tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电 视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议).-t # 在每行输出中不打印时间戳-tt # 不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315)-ttt # tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位)-tttt # 在每行打印的时间戳之前添加日期的打印-u # 打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件)-U # 使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件)。-U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数.-v # 当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.-vv # 产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.-vvv # 产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面, 其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).-w # 把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印.-W filecount # 此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序.-x # 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link layers that pad, 未能衔接理解和翻译, 需补充 )-xx # tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部.-X # 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便.-XX # 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便.-y # datalinktype 设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包-Z user # 使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程)。此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充) 命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283tcpdump –i eth0 ‘port 1111’ -X -c 3# -i 是interface的含义，是指我们有义务告诉tcpdump希望他去监听哪一个网卡,# -X告诉tcpdump命令，需要把协议头和包内容都原原本本的显示出来（tcpdump会以16进制和ASCII的形式显示），这在进行协议分析时是绝对的利器。port 1111我们只关心源端口或目的端口是1111的数据包.# -c 是Count的含义，这设置了我们希望tcpdump帮我们抓几个包。tcpdump -i eth0 port 1111 -l | awk '&#123;print $1&#125;'# 提取包的每一行的第一个域(时间域)，这种情况下我们就需要-l将默认的全缓冲变为行缓冲了。# -l选项的作用就是将tcpdump的输出变为“行缓冲”方式，这样可以确保tcpdump遇到的内容一旦是换行符即将缓冲的内容输出到标准输出，以便于利用管道或重定向方式来进行后续处理。# Linux/UNIX的标准I/O提供了全缓冲、行缓冲和无缓冲三种缓冲方式。# 标准错误是不带缓冲的，终端设备常为行缓冲，而其他情况默认都是全缓冲的。tcpdump -i eth0 port 1111 -c 3 -w cp.pcap# -w 直接将包写入文件中(即原始包，如果使用 重定向 &gt; 则只是保存显示的结果，而不是原始文件)，即所谓的“流量保存”---就是把抓到的网络包能存储到磁盘上，保存下来，为后续使用。参数-r 达到“流量回放”---就是把历史上的某一时间段的流量，重新模拟回放出来，用于流量分析。tcpdump i- eth0 'port 1111' -c 3 -r cp.pcap # 通过-w选项将流量都存储在cp.pcap(二进制格式)文件中了.可以通过 –r 读取raw packets文件 cp.pcap. tcpdump -i eth0 -e -nn -X -c 2 'port1111'# -n不把网络地址转换成名字ruopu@ruopu-PC:~$ sudo tcpdump -i enp0s25 -e -nnvv -X -c 2 'port 80'tcpdump: listening on enp0s25, link-type EN10MB (Ethernet), capture size 262144 bytes14:09:31.285330 50:7b:9d:65:f9:ff &gt; 8c:a6:df:ec:9e:52, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 64, id 15932, offset 0, flags [DF], proto TCP (6), length 60) 192.168.0.89.43174 &gt; 101.37.97.51.80: Flags [S], cksum 0x8788 (incorrect -&gt; 0xa52d), seq 1891133781, win 29200, options [mss 1460,sackOK,TS val 4099617288 ecr 0,nop,wscale 7], length 0 0x0000: 4500 003c 3e3c 4000 4006 7526 c0a8 0059 E..&lt;&gt;&lt;@.@.u&amp;...Y 0x0010: 6525 6133 a8a6 0050 70b8 6955 0000 0000 e%a3...Pp.iU.... 0x0020: a002 7210 8788 0000 0204 05b4 0402 080a ..r............. 0x0030: f45b 3208 0000 0000 0103 0307 .[2.........14:09:31.320699 8c:a6:df:ec:9e:52 &gt; 50:7b:9d:65:f9:ff, ethertype IPv4 (0x0800), length 66: (tos 0x0, ttl 51, id 0, offset 0, flags [DF], proto TCP (6), length 52) 101.37.97.51.80 &gt; 192.168.0.89.43174: Flags [S.], cksum 0x9a5b (correct), seq 1054611816, ack 1891133782, win 29200, options [mss 1444,nop,nop,sackOK,nop,wscale 9], length 0 0x0000: 4500 0034 0000 4000 3306 c06a 6525 6133 E..4..@.3..je%a3 0x0010: c0a8 0059 0050 a8a6 3edc 1968 70b8 6956 ...Y.P..&gt;..hp.iV 0x0020: 8012 7210 9a5b 0000 0204 05a4 0101 0402 ..r..[.......... 0x0030: 0103 0309 ....2 packets captured3 packets received by filter0 packets dropped by kernel# tcpdump: verbose output suppressed, use -v or -vv for full protocol decode表示使用选项-v和-vv可以看到更完全的输出信息# listening on enp0s25, link-type EN10MB (Ethernet), capture size 262144 bytes表示监听enp0s25网卡，它的链路层是基于以太网的，要抓的包大小限制为262144字节。包大小限制值可以通过-s选项来设置。# 14:09:31.285330 表示这个包被抓到的“时”、“分”、“秒”、“微秒”# 50:7b:9d:65:f9:ff &gt; 8c:a6:df:ec:9e:52表示从哪个MAC地址发往哪个MAC地址# ethertype IPv4 (0x0800)表示Ethernet帧的协议类型为ipv4，代码为0x0800# length 74表示以太帧长度为74# 192.168.0.89.43174 &gt; 101.37.97.51.80表示源IP192.168.0.89，端口43174向101.37.97.51的80号端口传输数据。# Flags [S]表示是syn建立连接包(即三次握手的第一次握手)# seq 1891133781 表示序号为1891133781# win 29200 表示窗口大小为29200* tcpdump过滤语句# 过滤表达式大体可以分成三种过滤条件，“类型”、“方向”和“协议”，这三种条件的搭配组合就构成了我们的过滤表达式。# 关于类型的关键字，主要包括host，net，port, 例如 host 210.45.114.211，指定主机210.45.114.211，net 210.11.0.0 指明210.11.0.0是一个网络地址，port 21 指明端口号是21。如果没有指定类型，缺省的类型是host.# 关于传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,这些关键字指明了传输的方向。例：src 210.45.114.211 ,指明ip包中源地址是210.45.114.211, dst net 210.11.0.0 指明目的网络地址是210.11.0.0。如果没有指明方向关键字，则缺省是src or dst关键字。# 关于协议的关键字，主要包括 ether,ip,ip6,arp,rarp,tcp,udp等类型。这几个的包的协议内容。如果没有指定任何协议，则tcpdump将会监听所有协议的信息包。 tcpdump -i eth0 -nn -c 1 'tcp' # 只抓tcp的包 # 除了这三种类型的关键字之外，其他重要的关键字：gateway, broadcast,less,greater。还有三种逻辑运算，取非运算是 'not ','! ', 与运算是'and','&amp;&amp;';或运算是'or','||'；sudo tcpdump -i eth0 -c 10 'dst port 21 or dst port 80'# 只想查目标机器端口是21或80的网络包，其他端口的我不关注sudo tcpdump -i eth0 -c 3 'host 172.16.0.11 and (210.45.123.249 or 210.45.123.248)'# 想要截获主机172.16.0.11 和主机210.45.123.249或 210.45.123.248的通信，使用命令(注意括号的使用)sudo tcpdump 'port ftp or ftp-data'# 想获取使用ftp端口和ftp数据端口的网络包这里 ftp、ftp-data到底对应哪个端口？ linux系统下 /etc/services这个文件里面，就存储着所有知名服务和传输层端口的对应关系。如果你直接把/etc/services里的ftp对应的端口值从21改为了3333，那么tcpdump就会去抓端口含有3333的网络包了。sudo tcpdump ip ‘host 172.16.0.11 and ! 210.45.123.249’# 如果想要获取主机172.16.0.11除了和主机210.45.123.249之外所有主机通信的ip包sudo tcpdump -i eth0 ‘host 172.16.0.11 and ! port 80 and ! port 25 and ! port 110’# 抓172.16.0.11的80端口和110和25以外的其他端口的包sudo tcpdump -i eth0 'host 172.16.0.11 and host google.com and tcp[tcpflags]&amp;tcp-syn!=0' -c 3 -nn# 获取172.16.10.11和google.com之间建立TCP三次握手中带有SYN标记位的网络包proto [expr : size]# Proto即protocol的缩写，它表示这里要指定的是某种协议名称，如ip,tcp,udp等。总之可以指定的协议有十多种，如链路层协议 ether,fddi,tr,wlan,ppp,slip,link,网络层协议ip,ip6,arp,rarp,icmp传输层协议tcp,udp等。expr用来指定数据报字节单位的偏移量，该偏移量相对于指定的协议层，默认的起始位置是0；而size表示从偏移量的位置开始提取多少个字节，可以设置为1、2、4,默认为1字节。如果只设置了expr，而没有设置size，则默认提取1个字节。比如ip[2:2]，就表示提取出第3、4个字节；而ip[0]则表示提取ip协议头的第一个字节。在我们提取了特定内容之后，我们就需要设置我们的过滤条件了，我们可用的“比较操作符”包括：&gt;，&lt;，&gt;=，&lt;=，=，!=，总共有6个。sudo tcpdump 'tcp[13] &amp; 3 != 0 and not(src and dst net 172.16.0.0)' -nn# 截取每个TCP会话的起始和结束报文(SYN 和 FIN 报文), 而且会话方中有一个远程主机.# tcp偏移13字节的位置为2位保留位和6位标志位(URG,ACK,PSH,RST,SYN,FIN), 所以与3相与就可以得出SYN,FIN其中是否一个置位1. 从上面可以看到在写过滤表达式时，需要我们对协议格式比较理解才能把表达式写对。为了让tcpdump工具更人性化一些，有一些常用的偏移量，可以通过一些名称来代替，比如icmptype表示ICMP协议的类型域、icmpcode表示ICMP的code域，tcpflags则表示TCP协议的标志字段域。更进一步的，对于ICMP的类型域，可以用这些名称具体指代：icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect,icmp-echo, icmp-routeradvert, icmp-routersolicit, icmp-timxceed, icmp-paramprob,icmp-tstamp, icmp-tstampreply, icmp-ireq, icmp-ireqreply, icmp-maskreq,icmp-maskreply。而对于TCP协议的标志字段域，则可以细分为tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nc命令使用]]></title>
    <url>%2F2018%2F11%2F19%2Fnc%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[nc命令使用方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101* 将nc命令当telnet使用语法：nc -nv IP PORT例：mtr 202.106.0.20# 使用mtr命令追踪一下路由nc -nv 123.125.50.29 110# -n表示不使用DNS解析(不建议在nc后使用域名)；-v表示显示详细信息。连接163邮箱服务器。进入后可以使用一些命令，但识别的都是base64加密后的数据base64 zheng.yao@ccgoldenet.com# 输入base64命令后按回车，之后等待输入数据，输入完成后按回车再按Ctrl+d结束，就会产生一个base64编码后的数据nc -vn 123.125.50.138 25# 连接163的smtp服务器。nc -vn 1.1.1.1 80# 连接后都会提示端口的状态，如open表示打开状态 head /# 进入后，可以用head请求头信息* 使用NC传输文本信息A：nc -l -p 333# -l(listen)表示要监听端口，-p指定端口号。这可以起到一个服务端的功能B：nc -nv 1.1.1.1 333# 连接后，这两台主机就可以聊天了。# 这个功能不为聊天，实际是为电子取证所用A：nc -l -p 333B：ls -l | nc -nv 1.1.1.1 333# 将本机ls -l显示的信息传到nc服务器上。这是远程电子审计的标准方法A：nc -l -p 333 &gt; ps.txt# 将结果重定向到一个文件中B：ps aux|nc -nv 1.1.1.1 333 -q 1# 收集进程信息。-q表示标准结果输出后，delay（延迟）一定时间就退出。1就是延迟的时间，表示1秒A： cat ps.txtA：nc -l -p 333 &gt; lsof.txtB：lsof | nc -nv 1.1.1.1 333 -q 1A： cat lsof.txt* 使用NC传输文件/目录** 传输文件A：nc -lp 333 &gt; 1.mp4# 接收端打开333端口，接收到的内容输入到一个文件名B：nc -nv 1.1.1.1 333 &lt; 1.mp4 -q 1# 发送文件到接收端。在windows上使用上面的命令会报错，可能是安装的是netcat软件。需要使用下面命令nc -w 1 1.1.1.1 333 &lt; 1.mp4或A：nc -q 1 -lp 333 &lt; a.mp4# 从服务器向客户端收送文件，这就成了发送端。这像是一个下载的过程。连接完成后1秒断开B：nc -nv 1.1.1.1 333 &gt; 2.mp4# 客户端成了接收端。** 传输目录A：tar -cvf - music/ | nc -lp 333 -q 1# 打包目录，通过管道入到nc中。视频中强调，cvf后面的横线不能少，少了就不能打包成tar文件了。在 GNU 指令中，如果单独使用 - 符号，不加任何该加的文件名称时，代表"标准输入"的意思。这是 GNU指令的共通选项。如：tar xpvf -，这里的 - 符号，既代表从标准输入读取资料。不过，在 cd 指令中则比较特别，cd -，这代表变更工作目录到"上一次"工作目录。B：nc -nv 1.1.1.1 333 |tar -xvf -# 连接到nc，将打包的目录解压到本地# 也可以反方向传输。** 加密传文件A：nc -lp 333 | mcrypt --flush -Fbqd -a rijindael-256 -m ecb &gt; 1.mp4# A端先监听端口，等待别人给其传文件。收到文件后给后面的解密命令解密，之后重新输出一个文件。接收到文件后会提示输入密码B：mcrypt --flush -Fbq -a rijindael-256 -m ecb &lt; a.mp4 | nc -nv 1.1.1.1 333 -q 1# 将加密文件转给A主机。两边的加密方式应该一致。加密时需要输入两次密码* 使用NC做流媒体服务A： cat 1.mp4 | nc -lp 333# mp4文件也可以用cat打开B：nc -nv 1.1.1.1 333 | mplayer -vo x11 -cache 3000 -# mplayer是一个播放器，其他支持命令行的播放器也可以* 使用NC做端口扫描nc -nvz 1.1.1.1 1-65535nc -nvzu 1.1.1.1 1-1024# -z表示使用0输入/输出模式，只在扫描通信端口时使用。默认使用tcp端口，-u表示扫描udp的端口。每一个扫描器扫描的结果都不是完全准确的，可能被防火墙拦截。建议使用多个工具进行扫描* 使用NC做远程克隆硬盘A：nc -lp 333 | dd of=/dev/sdaB：dd if=/dev/sda | nc -nv 1.1.1.1 333 -q 1# 远程电子取证，可以将目标服务器硬盘远程复制，或者内存。这是块级别的备份。不会只拷贝文件，它会将磁盘扇区上的所有数据都拷贝过来。dd命令就是块级别的复制。if表示input file* 使用NC做远程控制** 正向A： nc -lp 333 -c bashB： nc -nv 1.1.1.1 333# 客户端控制服务器。连接后可以使用bash命令** 反向A：nc -lp 333B：nc -nv 1.1.1.1 333 -c bash# 服务器控制客户端注：windows用户把bash改成cmd* NC-NCATNC缺乏加密和身份验证的能力NCAT包含于nmap工具包中。NCAT与NC是不一样的A：ncat -c bash --allow 1.1.1.1 -vnl 333 --ssl# --allow表示允许哪个IP地址来连接本服务器B：ncat -nv 1.1.1.1 333 --ssl；监听的是333端口，--ssl表示ssl加密# 不同系统/平台的NC参数功能不尽相同 mtr命令mtr命令可以结合ping nslookup tracert 来判断网络的相关特性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273* 参数mtr -r# 以报告模式显示mtr -s # 用来指定ping数据包的大小mtr -c # 设置每秒发送数据包的数量mtr -n # no-dns不对IP地址做域名解析mtr -a # 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的mtr -i # 使用这个参数来设置ICMP返回之间的要求默认是1秒mtr -4 # IPv4mtr -6 # IPv6ruopu@ruopu-PC:~$ mtr -r 202.108.33.94Start: 2018-11-19T11:09:25+0800HOST: ruopu-PC Loss% Snt Last Avg Best Wrst StDev 1.|-- _gateway 0.0% 10 0.3 0.4 0.3 0.5 0.1 2.|-- 106.38.38.81 0.0% 10 3.2 8.7 3.1 54.0 15.9 3.|-- 237.235.120.106.static.bj 10.0% 10 2.8 3.0 2.8 4.4 0.5 4.|-- 202.97.57.201 0.0% 10 3.3 3.4 3.2 3.8 0.2 5.|-- 202.97.88.246 60.0% 10 3.2 3.2 3.1 3.3 0.1 6.|-- 219.158.44.133 0.0% 10 10.7 8.2 3.5 12.7 2.7 7.|-- 219.158.3.77 0.0% 10 9.3 7.7 4.8 10.3 2.2 8.|-- 124.65.194.174 40.0% 10 3.5 3.6 3.4 3.7 0.1 9.|-- 61.148.143.30 0.0% 10 3.2 3.9 3.2 5.9 0.8 10.|-- 210.74.176.138 0.0% 10 3.5 4.1 3.1 8.6 1.6 11.|-- ??? 100.0 10 0.0 0.0 0.0 0.0 0.0# ruopu-PC一列显示的是IP地址或本机域名；Snt一列显示的是设置每秒发送数据包的数量，默认值是10，可以通过参数-c来指定。ruopu@ruopu-PC:~$ mtr -r -c 15 202.108.33.94Start: 2018-11-19T11:12:54+0800HOST: ruopu-PC Loss% Snt Last Avg Best Wrst StDev 1.|-- _gateway 0.0% 15 0.4 0.4 0.3 0.5 0.1 2.|-- 106.38.38.81 0.0% 15 187.6 65.7 3.7 187.6 59.1 3.|-- 237.235.120.106.static.bj 0.0% 15 3.0 3.9 2.6 12.4 2.8 4.|-- 202.97.57.237 0.0% 15 4.4 6.5 4.0 14.6 3.0 5.|-- 202.97.57.114 0.0% 15 35.1 17.8 2.9 50.9 17.5 6.|-- 219.158.44.129 0.0% 15 12.5 7.9 3.3 20.7 4.4 7.|-- 219.158.3.77 0.0% 15 4.4 6.6 3.1 9.9 2.3 8.|-- 124.65.194.118 66.7% 15 3.9 12.1 3.7 43.0 17.3 9.|-- 61.148.143.22 0.0% 15 3.2 7.3 3.2 35.8 9.1 10.|-- 210.74.178.198 0.0% 15 3.9 4.2 3.5 10.8 1.8 11.|-- ??? 100.0 15 0.0 0.0 0.0 0.0 0.0# HOST:ruopu-PC一列显示的是途经的IP地址或本机域名；Loss%列显示的是每个对应IP的丢包率，只有最后的目标丢包才算是真正的丢包；Snt一列显示的是设置每秒发送数据包的数量，默认值是10，可以通过参数-c来指定；Last列显示的是最近一次的返回时延，按毫秒计算；Avg列显示的是发送ping包的平均时延；Best烈显示的是最好或时延最短的；Wrst列显示的是最差或时延最长的；StDev列显示的是标准偏差。ruopu@ruopu-PC:~$ sudo mtr -i 0.1 -n -c 100 202.108.33.94# 对不标IP不做解析，ping100次，每0.1秒返回一次结果ruopu@ruopu-PC:~$ mtr -r -n -c 30 -s 1024 www.baidu.comStart: 2018-11-19T11:28:06+0800HOST: ruopu-PC Loss% Snt Last Avg Best Wrst StDev 1.|-- 192.168.0.1 0.0% 30 0.6 0.6 0.5 0.7 0.1 2.|-- 106.38.38.81 0.0% 30 16.8 56.8 11.6 160.8 36.0 3.|-- ??? 100.0 30 0.0 0.0 0.0 0.0 0.0 4.|-- 220.181.0.234 83.3% 30 6.1 5.6 4.6 6.1 0.6 5.|-- 218.30.112.130 60.0% 30 5.0 5.7 4.9 10.3 1.6 6.|-- 180.149.128.138 26.7% 30 10.6 270.4 6.8 1008. 355.7 7.|-- 180.149.129.6 0.0% 30 5.3 5.8 4.7 16.9 2.8 8.|-- ??? 100.0 30 0.0 0.0 0.0 0.0 0.0 9.|-- ??? 100.0 30 0.0 0.0 0.0 0.0 0.0 10.|-- 180.149.132.151 0.0% 30 5.8 6.8 5.7 16.6 2.8]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>nc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdyc备份服务器搭建]]></title>
    <url>%2F2018%2F11%2F18%2Fjdyc%E5%A4%87%E4%BB%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[搭建服务器过程12345678910111213141516171819* Server1. 创建CentOS7服务器2. 创建备份目录mkdir /home/logsbackup3. 将本地地址映射出去* Clientssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub 1.1.1.1vim /root/sh/logsbackup.sh #!/bin/bash # cd /usr/local/logs tar -zcf netty.log-$(date -d yesterday +%Y-%m-%d).tar.gz netty.log-$(date -d yesterday +%Y-%m-%d).*.log scp -P 3999 netty.log-$(date -d yesterday +%Y-%m-%d).tar.gz 1.1.1.1:/home/logsbackup rm -rf netty.log-$(date -d yesterday +%Y-%m-%d).*.log echo $(date +%Y-%m-%d-%T) &gt;&gt; /root/sh/logsbackup.txt crontab -e 0 1 * * * /bin/bash /root/sh/logsbackup.sh]]></content>
      <categories>
        <category>jdbc</category>
      </categories>
      <tags>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习一：基本概念]]></title>
    <url>%2F2018%2F11%2F16%2Fdocker%E5%AD%A6%E4%B9%A0%E4%B8%80%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[基本概念 Docker 和传统虚拟化方式的不同之处在于传统虚拟机技术是虚拟出一套硬件后,在其上运行一个完整操作系统,在该系统上再运行所需应用进程;而容器内的应用进程直接运行于宿主的内核,容器内没有自己的内核,而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 Docker 镜像(Image),就相当于是一个root文件系统。Docker 镜像是一个特殊的文件系统,除了提供容器运行时所需的程序、库、资源、配置等文件外,还包含了一些为运行时准备的一些配置参数(如匿名卷、环境变量、用户等)。镜像不包含任何动态数据,其内容在构建之后也不会被改变。 因为镜像包含操作系统完整的root文件系统,其体积往往是庞大的,因此在 Docker 设计时,就充分利用 Union FS 的技术,将其设计为分层存储的架构。所以严格来说,镜像并非是像一个 ISO 那样的打包文件,镜像只是一个虚拟的概念,其实际体现并非由一个文件组成,而是由一组文件系统组成,或者说,由多层文件系统联合组成。镜像构建时,会一层层构建,前一层是后一层的基础。每一层构建完就不会再发生改变,后一层上的任何改变只发生在自己这一层。比如,删除前一层文件的操作,实际不是真的删除前一层的文件,而是仅在当前层标记为该文件已删除。在最终容器运行的时候,虽然不会看到这个文件,但是实际上该文件会一直跟随镜像。因此,在构建镜像的时候,需要额外小心,每一层尽量只包含该层需要添加的东西,任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层,然后进一步添加新的层,以定制自己所需的内容,构建新的镜像。 镜像(Image)和容器(Container)的关系,就像是面向对象程序设计中的类和实例一样,镜像是静态的定义,容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器的实质是进程,但与直接在宿主执行的进程不同,容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、自己的网络配置、自己的进程空间,甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里,使用起来,就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。前面讲过镜像使用的是分层存储,容器也是如此。每一个容器运行时,是以镜像为基础层,在其上创建一个当前容器的存储层,我们可以称这个为容器运行时读写而准备的存储层为容器存储层。容器存储层的生存周期和容器一样,容器消亡时,容器存储层也随之消亡。因此,任何保存于容器存储层的信息都会随容器删除而丢失。按照 Docker 最佳实践的要求,容器不应该向其存储层内写入任何数据,容器存储层要保持无状态化。所有的文件写入操作,都应该使用 数据卷(Volume)、或者绑定宿主目录,在这些位置的读写会跳过容器存储层,直接对宿主(或网络存储)发生读写,其性能和稳定性更高。数据卷的生存周期独立于容器,容器消亡,数据卷不会消亡。因此,使用数据卷后,容器删除或者重新运行之后,数据却不会丢失。 Docker Registry 镜像构建完成后,可以很容易的在当前宿主机上运行,但是,如果需要在其它服务器上使用这个镜像,我们就需要一个集中的存储、分发镜像的服务,Docker Registry 就是这样的服务。一个 Docker Registry 中可以包含多个仓库(Repository);每个仓库可以包含多个标签(Tag);每个标签对应一个镜像。通常,一个仓库会包含同一个软件不同版本的镜像,而标签就常用于对应该软件的各个版本。我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签,将以latest作为默认标签。以 Ubuntu 镜像为例,ubuntu是仓库的名字,其内包含有不同的版本标签,如,14.04、16.04。我们可以通过 ubuntu:14.04,或者ubuntu:16.04。来具体指定所需哪个版本的镜像。如果忽略了标签,比如ubuntu,那将视为ubuntu:latest。仓库名经常以两段式路径形式出现,比如jwilder/nginx-proxy,前者往往意味着 Docker Registry 多用户环境下的用户名,后者则往往是对应的软件名。但这并非绝对,取决于所使用的具体 Docker Registry 的软件或服务。 Docker Registry 公开服务Docker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务。一般这类公开服务允许用户免费上传、下载公开的镜像,并可能提供收费服务供用户管理私有镜像。最常使用的 Registry 公开服务是官方的 Docker Hub,这也是默认的 Registry,并拥有大量的高质量的官方镜像。除此以外,还有 CoreOS 的 Quay.io,CoreOS 相关的镜像存储在这里;Google 的 Google Container Registry,Kubernetes 的镜像使用的就是这个服务。由于某些原因,在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对 Docker Hub 的镜像服务(Registry Mirror),这些镜像服务被称为加速器。常见的有 阿里云加速器、DaoCloud 加速器等。使用加速器会直接从国内的地址下载 Docker Hub 的镜像,比直接从 Docker Hub 下载速度会提高很多。国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如时速云镜像仓库、网易云镜像服务、DaoCloud 镜像市场、阿里云镜像库等。 私有 Docker Registry除了使用公开服务外,用户还可以在本地搭建私有Docker Registry。Docker 官方提供了Docker Registry 镜像,可以直接使用做为私有Registry服务。开源的 Docker Registry 镜像只提供了 Docker Registry API 的服务端实现,足以支持docker命令,不影响使用。但不包含图形界面,以及镜像维护、用户管理、访问控制等高级功能。在官方的商业化版本 Docker Trusted Registry 中,提供了这些高级功能。 除了官方的 Docker Registry 外,还有第三方软件实现了 Docker Registry API,甚至提供了用户界面以及一些高级功能。比如,VMWare Harbor 和 Sonatype Nexus。]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云调整]]></title>
    <url>%2F2018%2F11%2F15%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[报警可以先创建报警人组与报警人，这里只是对硬件的资源的基本监控。 创建交换机建议将所有ECS虚拟机放在一个交换机中，这样便于管理，也可以避免不同交换机间通信需要进行一次路由的问题。 共享带宽购买NAT网关，设置DNAT，将需要外网访问的内网地址加入DNAT。SNAT中要匹配现有的所有交换机 内网负载均衡主要为RabbitMQ使用。在监听中定义要监听的端口，在默认服务器组中加入两台服务器，这样就会监听两个服务器的这些定义了的端口]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[KVM使用]]></title>
    <url>%2F2018%2F11%2F15%2FKVM%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[KVM安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798安装环境在CentOS6.6_x64* 方法一1. 查看是否支持虚拟化egrep '(vmx|svm)' /proc/cpuinfo2. 关闭SELinux和防火墙setenforce 0getenforcesystemctl stop firewalldsystemctl disable firewalld3. 加载kvm模块modprobe kvm4. 查看是否加载kvmlsmod | grep kvm5. 安装KVM软件yum -y install qemu-kvm qemu-kvm-tools6. 因为安装后qemu-kvm命令不在环境变量中，所以要添加ln -sv /usr/libexec/qemu-kvm /usr/sbin7. qemu-kvm查看帮助、支持模拟的PC、可模拟的CPU架构qemu-kvm -hqemu-kvm -M ?qemu-kvm -cpu ?8. 安装VNC服务端yum -y install tigervnc-server9. 将系统镜像文件复制到服务器10. 创建虚拟机的镜像文件目录并创建镜像文件mkdir /images/vm1 -pvqemu-img create -f qcow2 -o size=100G /images/vm1/ubuntu.qcow2# 创建虚拟机前，需要先有一个虚拟磁盘文件，不然无法创建虚拟机11. 创建虚拟机qemu-kvm -name "ubuntu10" -m 1024 -smp 2 -hda /images/vm1/ubuntu.qcow2 -cdrom ubuntu-10.01.***.iso -vnc :0 -boot order=dc# -name是取一个虚拟机的名字；-m指定内存大小；-smp指定CPU的颗数，但不要超过物理核心数；-hda是指定磁盘镜像，因为是本地第一个分区所以用-hda；-cdrom是指定光盘镜像；-boot是指定启动次序，这里的d指使用一次；-net nic是指定网卡的，指定nic会向某个接口进行桥连接，如果不能连接会报错，所以这里不用此选项；-vnc :0是为了避免vnc连接失败。启动后提示在5900上启动了vnc# 发现在ubuntu18.04中找不到qemu-kvm命令，即使安装了qemu-kvm包。12. 在CentOS上安装vnc客户端测试yum -y install tigervnc13. 连接VNC服务器进行安装vncviewer :590014. windows上安装VNC-viewer软件，连接时输入IP:5900，NAME输入在qemu-kvm创建时用-name创建的虚拟机名字15. 安装xp系统qemu-img create -f qcow2 -o size=100G /images/vm1/xp.qcow2# 创建虚拟磁盘qemu-kvm -name "winxp" -m 768 -smp 4 -drive file=/images/vm1/xp.qcow2,if=ide,index=0,media=disk,format=qcow2 -drive file=/root/winxp_ghost.iso,media=cdrom,index=1 -vnc :0 -boot order=dc# -drive中的第一個file指定磁盤映像文件，if指定磁盤接口類型，index表示爲第幾個設備，0爲第一個設備，從0開始編號，media=disk表示是一個磁盤設備，format=qcow2是指定映像文件的格式。第二個file指定光盤映像文件，media=cdrom是指明是一個光盤。啓動成功。16. 安装openSUSEqemu-kvm -m 2048 -name opensuse -drive file=/home/ruopu/private1/VirtaulOS/openSUSE/openSUSE.qcow2,media=disk,format=qcow2,if=ide -net nic -boot c* 方法二1. 查看是否支持虚拟化egrep '(vmx|svm)' /proc/cpuinfo2. 关闭SELinux和防火墙setenforce 0getenforcesystemctl stop firewalldsystemctl disable firewalld3. 加载kvm模块modprobe kvm4. 查看是否加载kvmlsmod | grep kvm5. 安装依赖软件yum install -y qemu-kvm libvirt virt-install bridge-utils tigervnc tigervnc-server virt-manager# virt-manager是一个图形管理页面6. 开启kvm服务，并且设置其开机自动启动systemctl start libvirtdsystemctl enable libvirtdsystemctl status libvirtdsystemctl is-enabled libvirtd7. 配置网桥模式。配置好之后会有br0和virbr0两个网卡cd /etc/sysconfig/network-scriptscp ifcfg-eno16777736 ifcfg-eno16777736.bakvim ifcfg-br0 BOOTPROTO=static DEVICE=br0 TYPE=Bridge NM_CONTROLLED=no IPADDR=192.168.1.90 NETMASK=255.255.255.0 GATEWAY=192.168.1.1 DNS1=192.168.1.1vim ifcfg-eno16777736 BOOTPROTO=none DEVICE=enp0s25 NM_CONTROLLED=no # 此条必须配置。这是NetworkManager的参数，如果是yes，那么会实时生效，修改后无需要重启网卡立即生效。通常不使用NetworkManager管理网络 ONBOOT=yes BRIDGE=br0systemctl restart network# 可按此方法配置多个网桥设备8. 复制系统镜像文件到服务器9. 创建虚拟磁盘，这里创建的镜像文件格式建议用.img格式。qemu-img create -f qcow2 -o size=50G centos7.img# 需要事先创建磁盘文件，不然下面的命令会报错“ERROR Format cannot be specified for unmanaged storage.”，这应该是virt-manager 没有找到存储池的问题qemu-img create -f qcow2 -opreallocation=metadata RHEL7.img 40G# 这样创建磁盘也可以，重要的是-opreallocation=metadata选项，可以预分配磁盘，硬盘空间不会立即分配出去10. 创建虚拟机 virt-install -n xp -r 1024 --vcpus 2 --disk /images/xp.img,format=qcow2,size=50 --network bridge=br0 --os-type=windows --cdrom /images/vm1/xp.iso --vnc --vncport=5900 --vnclisten=0.0.0.0 --acceleratevirt-install -n centos6 -r 1024 --vcpus 2 --disk /images/centos.img,format=qcow2,size=30 --network bridge=br0 --network bridge=br1 --os-type=linux --cdrom /images/vm1/centos6.iso --vnc --vncport=5900 --vnclisten=0.0.0.0 --accelerate # --accelerate表示KVM或KQEMU内核加速,这个选项是推荐最好加上。如果KVM和KQEMU都支持，KVM加速器优先使用。--vncport指定端口，--vnclisten很重要，0.0.0.0表示监听在所有端口，不指定的话会监听在本地回环地址，用vncviewer是不能连接的。另外，不能两个VNC软件同时连接虚拟机；--disk /images/centos.img,format=qcow2,size=30是一定要定义的，这与上面创建的磁盘大小没有关系，如果这里不指定磁盘大小，在安装时会显示磁盘大小是0# 在启动KVM时，提示"ioctl(KVM_CREATE_VM) failed: 16 Device or resource busy"。这是因为有另一个虚拟程序在运行，它锁定了虚拟化功能。如VirtualBox在运行时，就不能启动KVM虚拟机了。 查看虚拟机状态1virsh list --all 虚拟机的启动、停止与删除1234567891011121314151617181920212223242526272829303132333435* 启动virsh start xp# 启动虚拟机virsh create /etc/libvirt/qemu/C7.xml# 通过配置文件启动虚拟机virsh autostart RHEL# 配置开机自启动虚拟机* 关闭virsh shutdown xp# 关闭虚拟机systemctl start acpidsystemctl enable acpidvirsh shutdown RHEL# 默认情况下virsh工具不能对linux虚拟机进行关机操作，linux操作系统需要开启与启动acpid服务。在安装KVM linux虚拟机必须配置此服务。virsh destroy RHEL# 强制关闭虚拟机RHEL* 删除virsh undefine RHEL# 删除虚拟机，前提条件是这个虚拟机没有快照文件，如果有就要先删除快照再删除虚拟机。该命令只是删除RHEL虚拟机的配置文件，并不删除虚拟磁盘文件。* 挂起服务器virsh suspend RHEL* 恢复服务器virsh resume RHEL* 导出KVM虚拟机配置文件virsh dumpxml RHEL &gt; /etc/libvirt/qemu/wintest02.xml* 重新定义虚拟机配置文件mv /etc/libvirt/qemu/C7_1.xml /etc/libvirt/qemu/C7.xmlvirsh define /etc/libvirt/qemu/C7.xml# 通过导出备份的配置文件恢复原KVM虚拟机的定义，并重新定义虚拟机。 修改现有虚拟机配置1234virsh edit RHEL# 这会打开虚拟机的配置文件，在虚拟机关机状态下修改后保存并启动虚拟机就会生效。如果用vim修改/etc/libvirt/qemu/目录中的虚拟机的xml文件是不能生效的virsh dominfo RHEL# 修改完以后用此命令查看现在的虚拟机的配置 添加、删除网卡12345678910111213141516171819202122232425262728293031323334353637383940414243[root@ccjd shaosong]# virsh domiflist SScentos7Interface Type Source Model MAC-------------------------------------------------------vnet0 bridge br0 - 52:54:00:7e:7b:7e# 查看网卡信息[root@ccjd shaosong]# virsh attach-interface SScentos7 --type bridge --source br1Interface attached successfully# 给SScentos7虚拟机临时添加一块叫br1的网卡[root@ccjd shaosong]# virsh domiflist SScentos7Interface Type Source Model MAC-------------------------------------------------------vnet0 bridge br0 - 52:54:00:7e:7b:7evnet1 bridge br1 - 52:54:00:b9:a1:e2# 再查看时已多了一块网卡，在虚拟机中也可以看到此网卡，并且可以使用。[root@ccjd shaosong]# virsh attach-interface SScentos7 --type bridge --source br1 --config# 永久添加网卡，使用--config选项Interface attached successfully[root@ccjd shaosong]# virsh edit SScentos7Domain SScentos7 XML configuration not changed.# 查看虚拟机的配置文件，可以看到多了一个新网卡的配置信息 &lt;interface type='bridge'&gt; &lt;mac address='52:54:00:7e:7b:7e'/&gt; &lt;source bridge='br0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/&gt; &lt;/interface&gt; &lt;interface type='bridge'&gt; &lt;mac address='52:54:00:5a:89:15'/&gt; &lt;source bridge='br1'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/&gt; &lt;/interface&gt;[root@ccjd shaosong]# virsh shutdown SScentos7Domain SScentos7 is being shutdown[root@ccjd shaosong]# virsh start SScentos7Domain SScentos7 started[root@ccjd shaosong]# virsh domiflist SScentos7Interface Type Source Model MAC-------------------------------------------------------vnet0 bridge br0 - 52:54:00:7e:7b:7evnet1 bridge br1 - 52:54:00:5a:89:15# 重启虚拟机可以看到网卡被永久添加上了[root@ccjd shaosong]# virsh detach-interface SScentos7 --type bridge --mac 52:54:00:5a:89:15 --configInterface attached successfully# 删除虚拟机网卡 克隆虚拟机123virt-clone -o C7 -n C7-1 -f /data/c7_1.img -f /data/c7_2.img# C7是现有的域名(虚拟机名)，C7-1是要创建的域名，c7_1.img是要创建的镜像文件，这里不需要事先创建虚拟磁盘。这条命令是说将C7域克隆一个叫C7-1的域，创建的镜像文件在/data目录下，叫c7_1.img。克隆时要关闭虚拟机。如果有多个磁盘，要用多个-f选项指定。这里不需要指定原来的*.img镜像文件# 克隆的问题是都会使用同样的VNC端口，这样就不能将所有克隆虚拟机都启动，需要使用"virsh edit 虚拟机名"，打开虚拟机的配置文件，找到VNC的端口号并修改。之后保存退出才能启动。 快照12345678910111213141516171819202122* 创建virsh snapshot-create C7# 创建域名叫C7的快照；快照配置文件在/var/lib/libvirt/qemu/snapshot/虚拟机名称/下virsh snapshot-list C7# 查看C7域的快照virsh snapshot-current C7# 查看当前虚拟机镜像快照的版本virsh snapshot-create-as C7 centos_install_ftp# 为虚拟机C7创建快照，快照名称为centos_install_ftp* 恢复虚拟机快照# 恢复虚拟机快照必须关闭虚拟机。virsh domstate winxp# 确认虚拟机状态virsh snapshot-revert winxp 1515577720# 恢复快照。1515577720是winxp快照的名字，如果有多个快照，要先用virsh snapshot-list winxp查看快照名字qemu-img info winxp.img# 查看镜像的快照名字，可能有多个* 删除virsh snapshot-delete winxp 1515577720# 删除winxp的叫1515577720的快照 重命名虚拟机1234567891011121314151617181920212223242526271. 关闭虚拟机2. 导出虚拟机配置文件cd /etc/libvirt/qemu/# 到虚拟机配置文件目录virsh dumpxml Ytest &gt; openvpn.xml# 导出Ytest虚拟机的配置文件，叫openvpn.xmlvirsh snapshot-delete Ytest 1540542652# 先删除之前的虚拟机快照，如果不删除快照是不能删除虚拟机的virsh undefine Ytest# 删除虚拟机vim openvpn.xml &lt;domain type='kvm'&gt; &lt;name&gt;openvpn&lt;/name&gt; # 修改虚拟机的名字 ....... &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2' cache='none'/&gt; &lt;source file='/home/IOS/openvpn/openvpn.img'/&gt; # 修改虚拟机磁盘的路径cd /home/IOSmv Ytest/ openvpnmv Ytest.img openvpn.img# 修改之前的虚拟机的目录名称与磁盘文件名称virsh define openvpn.xml# 再加载新命名的虚拟机的配置文件virsh list --all# 查看是否有新命名的虚拟机virsh start openvpn# 启动新命名的虚拟机 修改虚拟机硬件配置123456789[root@ccjd qemu]# virsh edit gitlab# 修改虚拟机配置文件 &lt;domain type='kvm'&gt; &lt;name&gt;gitlab&lt;/name&gt; &lt;uuid&gt;77890890-312b-bfed-83ed-c53665cf86d1&lt;/uuid&gt; &lt;memory unit='KiB'&gt;8192000&lt;/memory&gt; &lt;currentMemory unit='KiB'&gt;8192000&lt;/currentMemory&gt; &lt;vcpu placement='static'&gt;4&lt;/vcpu&gt;# 8192000为内存大小，4为CPU核心数。修改后保存，再启动虚拟机即可。 给KVM虚拟机添加磁盘123456789101112131415161718191. cd /home/IOS/RHEL72. qemu-img create -f raw RHEL7_1.img 10G# 创建一个磁盘，格式是raw3. virsh edit RHEL7 &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='raw' cache='none'/&gt; &lt;source file='/home/IOS/RHEL/RHEL7_1.img'/&gt; &lt;target dev='sda' bus='scsi'/&gt; &lt;address type='drive' controller='0' bus='0' target='0' unit='0'/&gt; &lt;/disk&gt; &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='raw' cache='none'/&gt; &lt;source file='/home/IOS/RHEL/RHEL7_2.img'/&gt; &lt;target dev='hda' bus='ide'/&gt; &lt;address type='drive' controller='0' bus='0' target='0' unit='1'/&gt; &lt;/disk&gt;# 原来的硬盘是hda，bus是ide，如果新磁盘与原磁盘一样是ide的，那么要改下面的unit的数字，不一样就可以，不然无法启动。如果磁盘类型不一样，可以直接改类型即可，如上面的类型就是 &lt;target dev='sda' bus='scsi'/&gt;，unit是按类型向下编号的，不一样就可以。4. tail -100 /var/log/libvirt/qemu/RHEL7.log# 如果不能启动，可以查看此日志，寻找原因。日志是以虚拟机名命名的。 kvm开启虚拟化123456789101112131415161718192021222324# 先检查 KVM host（宿主机/母机）上的kvm_intel模块是否打开了嵌套虚拟机功能（默认是开启的）：1. modinfo kvm_intel | grep nested parm: nested:bool2. cat /sys/module/kvm_intel/parameters/nested Y3. 如果上面的显示结果不是 Y 的话需要开启 nested：modprobe -r kvm-intelmodprobe kvm-intel nested=1cat /sys/module/kvm_intel/parameters/nested Y4. 如果使用libvirt管理虚拟机,需要修改虚拟机xml文件中CPU的定义,下面定义方法都可以:* 方法一virsh edit debian9.3 &lt;cpu mode='custom' match='exact'&gt; &lt;model fallback='allow'&gt;core2duo&lt;/model&gt; &lt;feature policy='require' name='vmx'/&gt; # 添加这一行 &lt;/cpu&gt;#这种方式为虚拟机定义需要模拟的CPU类型"core2duo",并且为虚拟机添加"vmx"特性* 方法二 &lt;cpu mode='host-model'&gt; &lt;model fallback='allow'/&gt; &lt;/cpu&gt;# 参考：https://www.cnblogs.com/chimeiwangliang/p/7862229.html 虚拟机静态迁移1234567891011121314151617* 静态迁移就是虚拟机在关机状态下，拷贝虚拟机虚拟磁盘文件与配置文件到目标虚拟主机中，实现的迁移。# 虚拟主机各自使用本地存储存放虚拟机磁盘文件。本文实现基于本地磁盘存储虚拟机磁盘文件的迁移方式。虚拟主机之间使用共享存储存放虚拟机磁盘文件，该方式只是在目标虚拟主机上重新定义虚拟机就可以了。1. 先确定虚拟机关机virsh list --all2. 准备迁移winxp虚拟机，查看此虚拟机配置的磁盘文件virsh domblklist winxp3. 导出虚拟机配置文件virsh dumpxml winxp &gt; /root/winxp.xml4. 拷贝配置文件到目标虚拟主机上scp /root/winxp.xml root@192.168.1.11:/etc/libvirt/qemu/5. 拷贝虚拟机磁盘文件到目标虚拟机scp winxp.img root@192.168.1.11:/data6. 到目标主机上查看。目标主机的目录结构要与源虚拟主机一致7. 定义注册虚拟主机virsh define /etc/libvirt/qemu/winxp.xml8. 启动虚拟机virsh start winxp 配置文件1234/etc/libvirt# qemu配置文件位置 /etc/libvirt/qemu# 虚拟机配置文件位置 问题解决VNC软件无法正常连接 在windows主机上安装VNC Viewer，使用此软件打开虚拟机。另外，用此工具连接后可能会有错误提示“ZlibInStream:Inflate Failed”，并且不断刷新页面，无法正常进入。如下： 设置图像，从高到低试，测试时选择High就可以正常连接了。 virt-manager键盘输入错乱 需要在Details中的VNC中选择en-us 从远程打开KVM的图形管理页面12345678* CentOS6.6系统yum groupinstall "X 窗口系统"# 远程连接服务器，使用ssh -X IPvirt-manager错误提示： ”process 63345: D-Bus library appears to be incorrectly set up; failed to read machine uuid: Failed to open "/var/lib/dbus/machine-id": 没有那个文件或目录 See the manual page for dbus-uuidgen to correct this issue. D-Bus not built with -rdynamic so unable to print a backtrace“ 123456解决办法：dbus-uuidgen &gt; /var/lib/dbus/machine-id# 执行此命令后就可以远程打开virt-manager了，但是乱码yum groupinstall "中文支持"# 安装完中文后，乱码就解决了。 报错error: unsupported configuration: Unable to find security driver for label selinux12virsh edit 虚拟机名# 删除最后有selinux的行，再启动就没问题了。]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>KVM虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openvpn搭建]]></title>
    <url>%2F2018%2F10%2F27%2Fopenvpn%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110* ServerIP: 10.5.5.27、192.168.0.181yum install -y epel-releaseyum install -y openvpn easy-rsa# 安装openvpncp /usr/share/doc/openvpn-2.4.6/sample/sample-config-files/server.conf /etc/openvpn/# 拷贝该示例配置文件到配置目录vim /etc/openvpn/server.conf local 10.5.5.27 port 1194 # 定义openvpn使用端口 proto tcp # 通过udp协议连接，也可以使用tcp协议。建议使用TCP协议，这样更稳定。 dev tun # 定义openvpn运行模式，openvpn有两种运行模式一种是tap模式的以太网通道，一种是tun模式的路由 IP 通道。 ca /etc/openvpn/easy-rsa/pki/ca.crt # openvpn使用的CA证书文件，CA证书主要用于验证客户证书的合法性，存放位置请依据实际情况自行改动 cert /etc/openvpn/easy-rsa/pki/issued/server.crt # openvpn服务器端使用的证书文件，存放位置请依据实际情况自行改动 key /etc/openvpn/easy-rsa/pki/private/server.key # This file should be kept secret # 服务器密钥存放位置，请依据实际情况自行改动 dh /etc/openvpn/easy-rsa/pki/dh.pem # Diffie hellman文件，存放位置请依据实际情况自行改动 server 10.8.0.0 255.255.255.0 # openvpn在使用tun路由模式时，分配给client端分配的IP地址段，虚拟局域网网段设置，请依据须要自行改动，不支持和拔号网卡位于同一网段 ifconfig-pool-persist ipp.txt # 在openvpn重新启动时,再次连接的client将依旧被分配和曾经一样的IP地址 push "route 192.168.0.0 255.255.255.0" # 为客户端创建对应的路由,以另其与公司网内部服务器通信,但记住，公司网内部服务器也需要有可用路由返回到客户端 ;push "redirect-gateway def1 bypass-dhcp" # 测试发现，不加此条，在客户端连接openvpn后，可以连通外网，加此条无法解析外网地址。 push "dhcp-option DNS 114.114.114.114" push "dhcp-option DNS 114.114.115.115" # 向客户端推送的DNS信息，DNS配置，依据实际情况配置 keepalive 10 120 # 活动连接保时期限 tls-auth ta.key 0 # This file is secret cipher AES-256-CBC comp-lzo max-clients 10 user nobody group nobody persist-key persist-tun status openvpn-status.log log-append openvpn.log verb 3mkdir -p /etc/openvpn/easy-rsa/keyscp -rf /usr/share/easy-rsa/3.0.3/* /etc/openvpn/easy-rsa/cp /usr/share/doc/easy-rsa-3.0.3/vars.example /etc/openvpn/easy-rsa/varscd /etc/openvpn/easy-rsa/vim vars set_var EASYRSA "$PWD" set_var EASYRSA_PKI "$EASYRSA/pki" # 定义key的生成目录 set_var EASYRSA_DN "cn_only" set_var EASYRSA_REQ_COUNTRY "CN" # 定义所在的国家 set_var EASYRSA_REQ_PROVINCE "BJ" # 定义所在的省 set_var EASYRSA_REQ_CITY "BeiJing" # 定义所在的城市 set_var EASYRSA_REQ_ORG "ccjd" # 定义所在的组织 set_var EASYRSA_REQ_EMAIL "ccjd@goldenet.com" # 定义邮箱 set_var EASYRSA_REQ_OU "IT" # 定义所在单位 set_var EASYRSA_KEY_SIZE 2048 # 定义生成私钥的大小，一般为1024或2048，默认为2048位。这个就是我们在执行build-dh命令生成dh2048文件的依据。 set_var EASYRSA_ALGO rsa set_var EASYRSA_CA_EXPIRE 3650 # ca证书有效期，默认为3650天，即十年 set_var EASYRSA_CERT_EXPIRE 3650 # 定义秘钥的有效期，默认为3650天，即十年 set_var EASYRSA_NS_SUPPORT "no" set_var EASYRSA_NS_COMMENT "Easy-RSA Generated Certificate" set_var EASYRSA_EXT_DIR "$EASYRSA/x509-types" set_var EASYRSA_SSL_CONF "$EASYRSA/openssl-1.0.cnf" set_var EASYRSA_DIGEST "sha256"# 配置证书文件，修改上面的行./easyrsa init-pki# 到easy-rsa目录下，初始化，会在当前目录创建PKI目录，用于存储一些中间变量及最终生成的证书 ./easyrsa build-ca nopass# 创建根证书，nopass表示不设置密码，一直回车即可。会生成根证书：ca.crt，文件在：/etc/openvpn/easy-rsa/pki/ca.crt./easyrsa gen-dhopenvpn --genkey --secret ta.key# 创建ta.keycp -r ta.key /etc/openvpn/./easyrsa gen-req server# 创建服务端证书，生成请求，使用gen-req来生成req，创建server端证书和private key。也可以在之后使用nopass，或设置密码。生成服务器证书：/etc/openvpn/easy-rsa/pki/private/server.key、/etc/openvpn/easy-rsa/pki/reqs/server.req./easyrsa sign-req server server# 签发证书,签约服务端证书，给server端证书做签名，首先是对一些信息的确认，可以输入yes，然后输入build-ca时设置的那个密码，因上面没有设置密码，所以会直接通过。生成服务端签名证书：/etc/openvpn/easy-rsa/pki/issued/server.crt./easyrsa build-client-full ccjd# 生成客户端用户证书，ccjd是用户名，需要输入客户端密码与ca密码（上面没有设置）。生成客户端用户签名证书：/etc/openvpn/easy-rsa/pki/issued/ccjdname.crt、/etc/openvpn/easy-rsa/pki/private/ccjdname.key、/etc/openvpn/easy-rsa/pki/reqs/ccjdname.reqsystemctl start openvpn@server# 启动服务，启动时输入创建服务端证书时输入的密码，第一次启动可能不成功，可以再使用此命令启动，直到需要输入密码为止 systemd-tty-ask-password-agent # 启动后输入上面命令，再输入密码ss -tlnu# 查看是否监听了udp的1194端口，如果没有监听，可以再执行启动命令，直到监听端口为止echo 1 &gt; /proc/sys/net/ipv4/ip_forward# 添加路由转发功能vim /etc/sysctl.conf net.ipv4.ip_forward = 1sysctl -p# 这种方法也可以开启转发功能，sysctl -p是使用配置文件生效iptables -t nat -I POSTROUTING -s 10.8.0.0/24 -j SNAT --to-source 192.168.0.181# 设置完生效可能有此慢，需要等半分钟# 因为是固定IP，只是想让连接openvpn的主机可以访问另一个网段的主机，所以这里用了源地址转换，所有连接openvpn的主机会使用openvpn服务器的192地址与192.168.0.0/24网段的主机通信。如果是动态IP，也可以使用命令：iptables -t nat -I POSTROUTING -s 10.8.0.0/24 -j MASQUERADEtcpdump -i tun0 -nn windows Client 下载安装openvpn-install-2.3.3-I002-i686，安装时选中所有选项 将安装目录中的sample-config目录中的Client.ovpn文件放入安装目录中的config目录中。将服务器端的ccjd.key、ca.crt、ta.key、ccjd.crt四个文件也放入config目录中 设置客户端配置文件 123456789101112131415161718192021clientdev tunproto tcpremote 10.5.5.27 1194resolv-retry infinitenobindremote-cert-tls serverca ca.crtcert ccjd.crtkey ccjd.keytls-auth ta.key 1persist-keypersist-tunpush dhcp-option DNS 114.114.114.114push dhcp-option DNS 8.8.8.8cipher AES-256-CBClog-append ccjd.log# 定义此条后，启动软件后在config目录中会有ccjd.log文件，其中记录了启动失败的原因。status ccjd-status.logcomp-lzoverb 3 使用管理者权限启动OpenVPN GUI，在屏幕右下角会有一个加锁的窗口的标志，如果连接成功，这个标志会变为绿色。因为要添加路由表，所以使用管理员权限打开客户端，如果用普通用户启动客户端是没法添加路由条目的，连接后也无法使用。 启动失败，可以查看config目录中的ccjd.log文件 注意客户端主机的系统时间，时间不对也会影响连接 调整客户端网卡配置到，一定要重新连接openvpn。可以在任务管理器中杀死两个openvpn的进程。 连接后，在客户端查看路由表，应该有加红框的两条路由 CentOS7_Client12345678910111213141516171819202122232425262728293031323334yum install -y epel-releaseyum install -y openvpnvim /etc/openvpn/client/ccjd.ovpn client dev tun proto tcp remote 10.5.5.27 1194 resolv-retry infinite nobind remote-cert-tls server ca ca.crt cert ccjd.crt key ccjd.key tls-auth ta.key 1 persist-key persist-tun comp-lzo verb 3# 客户端配置文件apt install -y openssl libssl-dev lzop# 安装openssl和lzo，lzo用于压缩通讯数据加快传输速度* 将ca.crt、ta.key、ccjd.crt、ccjd.key四个文件放入/etc/openvpn目录下openvpn --daemon --cd /etc/openvpn --config /etc/openvpn/client/ccjd.ovpn --log-append /var/log/openvpn.log# 启动客户端# --daemon：openvpn以daemon方式启动。# --cd dir：配置文件的目录，openvpn初始化前，先切换到此目录。# --config file：客户端配置文件的路径。# --log-append file：日志文件路径，如果文件不存在会自动创建。# **测试发现，如果是ubuntu18.04系统，在启动客户端时，不能加入--daemon选项，如果加入此选项，就无法输入密码。不加此选项才可以输入密码。直接在后台运行会停止程序，可以在启动后使用Ctrl+z让程序在后台运行，之后用```bg 运行号```，让后台程序运行。运行号是用jobs命令查看到的**tail -f /var/log/openvpn.log# 查看启动日志ip a# 查看是否有openvpn分配的IP地址# 连接后的问题是，有时ping192.168.0.1不通，以为是多个客户端同时使用了一个帐号，但只有一个客户端使用此帐号连接时也会有此问题。要等上一会儿才有反应。测试发现，长ping时，一段时间后就会停下来，再过2－3分钟后又可以ping了]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>openvpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins安装与部署]]></title>
    <url>%2F2018%2F10%2F22%2FJenkins%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Jenkins简单部署rpm包安装启动12345678910111213141516171819202122232425262728============================================================================================环境准备两台主机node1：地址：192.168.1.63node2：地址：192.168.1.64============================================================================================------------ jenkins------------ [root@jenkins ~]# yum install -y java-1.8.0-openjdk-devel[root@jenkins ~]# yum install -y jenkins-2.60.3-1.1.noarch.rpm[root@jenkins ~]# systemctl start jenkins[root@jenkins ~]# ss -tlnState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::111 :::* LISTEN 0 50 :::8080# 可以看到监控了8080端口[root@jenkins ~]# vim /etc/sysconfig/jenkinsJENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"# 调整jenkins的使用内存，默认此项是-Djava.awt.headless=true# -Xms：初始堆内存Heap大小，使用的最小内存，cpu性能高时此值应设的大一些# -Xmx：初始堆内存heap最大值，使用的最大内存# -XX:MaxPermSize:设定最大内存的永久保存区域# -Xms与-Xmx设置相同的值，需要根据实际情况设置，增大内存可以提高读写性能访问http://192.168.1.63:8080 tomcat启动1234567891011121314151617------------ jenkins------------ [root@jenkins ~]# yum install -y tomcat[root@jenkins ~]# cp /usr/lib/jenkins/jenkins.war /usr/share/tomcat/webapps/# 将上面安装的jenkins的war包复制到tomcat的部署目录下，也可以直接下载jenkins的war包[root@jenkins ~]# vim /etc/sysconfig/tomcatJAVA_OPTS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"# 调整tomcat使用jvm内存[root@jenkins ~]# systemctl start tomcat[root@jenkins ~]# ps aux|grep tomcattomcat 2242 17.4 40.8 3718460 763224 ? Ssl 19:27 0:21 /usr/lib/jvm/jre/bin/java -Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m -classpath /usr/share/tomcat/bin/bootstrap.jar:/usr/share/tomcat/bin/tomcat-juli.jar:/usr/share/java/commons-daemon.jar -Dcatalina.base=/usr/share/tomcat -Dcatalina.home=/usr/share/tomcat -Djava.endorsed.dirs= -Djava.io.tmpdir=/var/cache/tomcat/temp -Djava.util.logging.config.file=/usr/share/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager org.apache.catalina.startup.Bootstrap start访问http://192.168.1.63:8080/jenkins[root@jenkins ~]# cat /usr/share/tomcat/.jenkins/secrets/initialAdminPassword cdc0bfcfa03e4d2da4f7232b213c50c1# 查看登录jenkins的默认密码 安装maven1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768------------ maven------------[root@maven ~]# yum install -y java-1.8.0-openjdk-devel tomcat tomcat-admin-webapps# 在当前主机上安装一个tomcat，稍后测试maven构建的包是否可以正常运行[root@maven ~]# yum install -y maven git[root@maven ~]# git clone https://github.com/mageedu/spring-boot-web-jsp.git# 克隆一个java代码测试。# 对maven来说最重要的是pom.xml文件，它描述了这个代码是如何构建的[root@maven ~]# cd spring-boot-web-jsp/[root@maven ~]# vim /etc/maven/settings.xml&lt;mirrors&gt;&lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt;# mirrors段添加国内源地址。&lt;profile&gt; &lt;id&gt;jdk-1.4&lt;/id&gt; &lt;activation&gt; &lt;jdk&gt;1.4&lt;/jdk&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/profile&gt;# Maven 还需要安装一些插件包，这些插件包的下载地址也让其指向 oschina.net 的 Maven 地址。在&lt;profiles&gt;中插入# 一定要修改为国内源，不然构建速度将非常慢。尤其是在jenkins中[root@maven spring-boot-web-jsp]# mvn package# 开始构建。[root@maven ~]# vim /etc/tomcat/tomcat-users.xml&lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt;&lt;user name="tomcat" password="tomcat" roles="manager-gui,manager-script" /&gt;[root@maven ~]# vim /etc/sysconfig/tomcatJAVA_OPTS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"[root@maven ~]# systemctl start tomcat[root@maven spring-boot-web-jsp]# ls target/classes maven-archiver spring-boot-web-jsp-1.0 spring-boot-web-jsp-1.0.war.originalgenerated-sources maven-status spring-boot-web-jsp-1.0.war# 可以看到构建后有了war包[root@maven spring-boot-web-jsp]# cp target/spring-boot-web-jsp-1.0.war /usr/share/tomcat/webapps/访问http://192.168.1.64:8080/spring-boot-web-jsp-1.0/，可以看到部署的结果了 测试jenkins1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586------------ jenkins------------ [root@jenkins ~]# scp jenkins.war 192.168.1.64:/usr/share/tomcat/webapps/# jenkins.war包的属主属组应该是tomcat，权限是644------------ maven------------[root@maven webapps]# cat /usr/share/tomcat/.jenkins/secrets/initialAdminPassword 083cbf58aefd411b89558aea505f3e94[root@maven webapps]# vim /etc/tomcat/server.xml&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8"/&gt;# 让tomcat可以使用UTF-8编码。这是为了让jenkins不再报需要使用UTF-8编码的错误[root@maven webapps]# systemctl restart tomcat访问http://192.168.1.64:8080/jenkins/ --&gt; 输入密码 --&gt; 选择默认插件 --&gt; 创建新用户 --&gt; 在系统管理中配置jenkins的环境 --&gt; 到系统管理中的global tool configuration中配置JDK的别名和路径，取消自动安装，路径写/usr即可 --&gt; git工具被默认配置了，因为git包已经安装了。Gradle是java的新的构建工具 --&gt; 配置Mave，使用mvn -v查看版本，将版本号输入到Name中，如maven-3.0.5，路径写/usr新建一个任务，叫spring-boot-web-jsp。一般构建选择两种，一是自由风格，一是pipeline（流水线），这里选自由风格。选择github project，输入https://github.com/mageedu/spring-boot-web-jsp.git，这是给定一个代码路径，点击高级可显示Display name输入spring-boot-web，这是自定义的。源码管理中的Git是指如果要推送到远程服务器上，在这里要输入地址，用户名和密码或密钥，在这里还是输入https://github.com/mageedu/spring-boot-web-jsp.git，源码管理不做配置也可以，但测试中发现一定要配置源码管理的地址，不然会提示找不到pom.xml文件。构建触发器是指如果代码更新了要怎么办或什么条件下进行构建。第一可以自定义脚本来触发，build after other projects are built指在其他项目构建完触发，build pericxfically是周期性构建，每隔一段时间就看一下源代码是否有变化，有变化就构建，GitHub hook trigger for GITScrn polling是如果GitHub上注册的hook有变化，就会发送通知，下载代码构建，Poll SCM是不断向github轮询，有符合条件的就构建，这里可以在日程表中写入H/5 * * * *，表示每5分钟轮询一次。在构建中可以选择Invoke top-level Maven targets，表示一个顶级的maven构建，在Maven Version中选择安装的maven版本，Goals中输入构建的路径，这种方式易出错。选择Execute shell表示脚本构建，在Command中写入/usr/bin/mvn package即可，它会自动切换到构建目录下构建。构建后操作就是要发布了。视频中这里没有选择。直接点击项目中的立即构建了，在构建中可以选择console一项，可以打开一个窗口查看构建的过程。[root@maven webapps]# cd /usr/share/tomcat/.jenkins/# 构建完成后进入此目录[root@maven .jenkins]# ls workspace/spring-boot-web-jsp/# 在workspace目录中有构建完的程序------------ jenkins------------ [root@jenkins ~]# rm -rf /usr/share/tomcat/webapps/jenkins*[root@jenkins ~]# cd /etc/tomcat/[root@jenkins tomcat]# vim tomcat-users.xml&lt;role rolename="manager-script"/&gt; &lt;user name="admin" password="admin" roles="manager-script" /&gt;# 我们要将maven上构建的结果在 jenkins上的tomcat上运行，所以需要这里打开manager-script功能。[root@jenkins tomcat]# systemctl restart tomcat[root@jenkins tomcat]# ss -tln------------ maven------------选择系统管理中的管理插件，在可选插件中选择安装Deploy to container，选择安装完成后重启Jenkins。进入spring-boot-web-jsp项目中，点击配置，选择构建后操作中的Deploy war/ear to a container，这是刚安装的插件，WAR/EAR files输入**target/*.war，（**表示任意个路径下的target目录中的.war文件。也可以写为**/*.war或*.war）。Context path可以不改，使用默认，这里使用/test-spring（这是部署到node1的tomcat上的目录的名称）。Containers选择Tomcat7.*，用户名和密码就是上面配置的manager-script的用户名和密码，输入两次tomcat。Tomcat URL输入http://IP:8080/，这是tomcat的访问路径。如果要构建多个tomcat，可以再添加Add Container就可以了。最后保存。点击项目中的立即构建。构建中出了问题，一直提示没有权限部署。因为node1上没有安装tomcat-admin-webapps------------ jenkins------------ [root@jenkins tomcat]# yum install -y tomcat-admin-webapps[root@jenkins tomcat]# ls webapps/host-manager manager test-spring test-spring.war# 在此目录下有刚部署的test-spring.war文件访问http://192.168.1.63:8080/test-spring/------------ maven------------[root@maven .jenkins]# rm -rf workspace/spring-boot-web-jsp/# 删除代码，测试重新构建[root@maven .jenkins]# cd[root@maven ~]# lsanaconda-ks.cfg netty-new.jar spring-boot-web-jsp[root@maven ~]# vim spring-boot-web-jsp/src/main/resources/application.propertiesspring.mvc.view.prefix: /WEB-INF/jsp/spring.mvc.view.suffix: .jspwelcome.message: Hi Jenkins, Test.com, iunx.io.# 修改这个文件中的显示内容，再保存，这里修改了Test.com, iunx.io.[root@maven ~]# vim spring-boot-web-jsp/src/main/resources/static/css/main.cssh1&#123; color:#FFFF00;&#125;h2&#123; color:#0000FF;&#125;# 修改颜色cd spring-boot-web-jspgit add .git commit -m "version 4.2.0"git push 点击自动构建如果是灰度发布，可以使用脚本，脚本可实现将指定文件发送到服务器并部署回滚到之前的版本，可以在构建时指定构建的版本就可以了，使用git克隆时就克隆指定的版本就可以了。在ganneral最上方的一栏中可以选择参数化构建过程。参考：blog.ramanshalupau.com/parameterized-jenkins-build-for-rollback-purposes，实现滚动发布与回滚 Jenkins&amp;GitlabJenkins依赖环境准备1234567891011121314151617181920212223242526272829303132333435363738394041424344454647* 安装java环境[root@jenkins ~]# lltotal 83356-rw-------. 1 root root 1292 Oct 24 05:42 anaconda-ks.cfg-rwxr-xr-x 1 root root 9621331 Feb 1 12:51 apache-tomcat-8.5.33.tar.gz-rwxr-xr-x 1 root root 75728164 Feb 1 12:51 jenkins.war[root@jenkins ~]# yum install -y java-1.8.0-openjdk-devel[root@jenkins ~]# vim /etc/profile.d/java.sh export JAVA_HOME=/usr[root@jenkins ~]# . /etc/profile.d/java.sh[root@jenkins ~]# java -versionopenjdk version "1.8.0_181"OpenJDK Runtime Environment (build 1.8.0_181-b13)OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)* tomcat环境[root@jenkins ~]# tar xf apache-tomcat-8.5.33.tar.gz -C /usr/local/[root@jenkins ~]# cd /usr/local/[root@jenkins local]# ln -sv apache-tomcat-8.5.33/ tomcat'tomcat' -&gt; 'apache-tomcat-8.5.33/'[root@jenkins local]# cp /root/jenkins.war tomcat/webapps/# 上传Jenkins.war文件到tomcat服务器，放入webapps目录中[root@jenkins tomcat]# vim /usr/local/tomcat/conf/tomcat-users.xml &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="tomcat_user" password="tomcat" roles="manager-gui,manager-script,manager-jmx,manager-status"/&gt;[root@jenkins tomcat]# vim /usr/local/tomcat/conf/server.xml &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8" /&gt;# 加入URIEncoding="UTF-8"地址的编码解码字符集[root@jenkins local]# vim /usr/local/tomcat/bin/catalina.sh JAVA_OPTS="-Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m"# 调整tomcat使用jvm内存[root@jenkins tomcat]# /usr/local/tomcat/bin/startup.sh[root@jenkins tomcat]# tail -f /usr/local/tomcat/logs/catalina.out# 查看启动过程[root@jenkins local]# ps aux|grep tomcatroot 3101 33.7 38.4 3704844 717556 pts/0 Sl 13:02 0:17 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.awt.headless=true -Xms1024m -Xmx1024m -XX:MaxNewSize=512m -XX:MaxPermSize=512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start[root@jenkins tomcat]# cat /root/.jenkins/secrets/initialAdminPassword 2296380bbe5e4753bc970240aca8ae2d# 这是打开jenkins页面时要输入的密码，这也是Jenkins的admin管理员的登录密码* 安装git[root@jenkins ~]# yum install -y git 下面访问10.5.5.250:8080/jenkins 选择安装推荐的插件。如果有软件安装失败，可在安装完后点Retry，再次安装。安装成功进入jenkins后，还要重启一次jenkins服务才能正常访问 创建用户，或使用admin用户登录 确认 完成上述步骤后可以正常登录，但测试发现chrome浏览器访问时显示空白页面，使用firefox浏览器没有问题 更换火狐浏览器后可以到登录页面，但输入用户名和密码后还是空白页面。解决方法如下： 123456789101112131415161718[root@jenkins tomcat]# tail -f /var/log/messages Oct 21 22:30:35 jenkins systemd: Stopped IPv4 firewall with iptables.Oct 21 22:30:35 jenkins systemd: Unit iptables.service entered failed state.Oct 21 22:30:35 jenkins systemd: iptables.service failed.Oct 21 22:43:01 jenkins systemd: Started Session 4057 of user root.Oct 21 22:43:01 jenkins systemd: Starting Session 4057 of user root.Oct 21 22:57:11 jenkins systemd: Stopping The Apache HTTP Server...Oct 21 22:57:13 jenkins systemd: Stopped The Apache HTTP Server.Oct 21 22:57:18 jenkins systemd: Reloading.Oct 21 22:57:18 jenkins systemd: [/usr/lib/systemd/system/vzfifo.service:19] Support for option SysVStartPriority= has been removed and it is ignoredOct 21 23:15:06 jenkins systemd: Configuration file /usr/lib/systemd/system/ebtables.service is marked executable. Please remove executable permission bits. Proceeding anyway.# 查看系统日志发现，要求取消/usr/lib/systemd/system/ebtables.service的可执行权限。[root@jenkins tomcat]# chmod 744 /usr/lib/systemd/system/ebtables.service# 取消属组和其他人的执行权限[root@jenkins tomcat]# lsof -i:8080[root@jenkins tomcat]# kill -9 1181[root@jenkins tomcat]# /usr/local/tomcat/bin/startup.sh# 关闭tomcat并重新启动 可以正常访问了，使用chrome浏览器也没有问题了。但因为chrome浏览器的语言的繁体中文，所以Jenkins登录后也是繁体中文 配置JDK和Maven并安装Deploy插件 登录Jenkins 选择全局安全配置 选择允许用户注册。授权策略可以先任何用户可以做任何事，方便测试使用。也可以是默认的登录用户可以做任何事。最后保存 选全局工具配置 上面两项都选择文件系统中的settings文件，之后需要输入maven的settings文件路径。JDK也一样要输入JAVA_HOME的路径，同时自定义一个别名。取消自动安装。下面的Git因为还没有，所以可以删除。Maven同JDK，需要自定义名称并输入MAVEN_HOME Maven的安装 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455到http://mirrors.shu.edu.cn/apache//maven/maven-3/3.5.4/binaries/下载Maven的二进制包，保存到/root目录下[root@jenkins ~]# tar xf apache-maven-3.5.4-bin.tar.gz -C /usr/local/[root@jenkins ~]# vim /etc/profile.d/maven.sh export PATH=$PATH:/usr/local/apache-maven-3.5.4/bin export MAVEN_HOME=/usr/local/apache-maven-3.5.4[root@jenkins ~]# . /etc/profile.d/maven.sh[root@jenkins ~]# mvn -versionApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z)Maven home: /usr/local/apache-maven-3.5.4Java version: 1.8.0_181, vendor: Oracle Corporation, runtime: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64/jreDefault locale: en_US, platform encoding: ANSI_X3.4-1968OS name: "linux", version: "4.15.17-1-pve", arch: "amd64", family: "unix"[root@jenkins local]# vim /usr/local/apache-maven-3.5.4/conf/settings.xml&lt;mirrors&gt;&lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt;# mirrors段添加国内源地址。&lt;profile&gt; &lt;id&gt;jdk-1.4&lt;/id&gt; &lt;activation&gt; &lt;jdk&gt;1.4&lt;/jdk&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/profile&gt;# Maven 还需要安装一些插件包，这些插件包的下载地址也让其指向 oschina.net 的 Maven 地址。在&lt;profiles&gt;中插入# 一定要修改为国内源，不然构建速度将非常慢。尤其是在jenkins中 选择插件管理 安装插件deploy to container，这个插件是让jenkins成功构建后可以部署war包到tomcat的 gitlab安装1234567891011下载gitlab-ce-10.6.1-ce.0.el7.x86_64.rpm到/root目录[root@localhost ~]# yum install -y gitlab-ce-10.6.1-ce.0.el7.x86_64.rpm[root@localhost ~]# vim /etc/gitlab/gitlab.rb external_url 'http://10.5.5.199'# 设置服务地址[root@localhost ~]# gitlab-ctl reconfigure# 这是一个初始化的过程访问IP，要求设置root密码，需要是一个复杂的密码，之后就可以正常登录了# 如果访问出现502错误，可以查看是否之前安装并启动过web服务或tomcat服务，卸载服务并重启gitlab后就可以正常访问了。# [root@gitlab ~]# gitlab-ctl restart # 重启gitlab命令# 另外也可以查看一下内存是否不足 获取gitlab的token 使用root用户登录 选择左下角的settings，并勾选最下方的“Allow requests to the local network from hooks and services”并保存。此项非常关键，如果不勾选此项，之后测试连接jenkins时会报500错误 登出root用户，重新注册一个新用户 选择用户的settings，并选择左侧的”Access Tokens” 创建Token 得到一个Token，这个很重要，需要记录，如果关闭此页面，之后就找不到这个Token了 创建一个git项目 使用普通用户登录，到首页创建项目 这两条命令在设置jenkins时有用 生成访问Gitlab的ssh秘钥。 从gitlab以SSH方式拉取或提交代码需要用到这个SSH 秘钥，哪台机器需要从gitlab上拉取代码，就在哪台机器上生成一次SSH Key，因此，在jenkins服务器上，以及你的开发PC上，都需要生成SSH密钥。 在jenkins与要部署代码的服务器上执行生成秘钥的命令 1234567891011121314151617181920212223[root@jenkins conf]# ssh-keygen -t rsa -P ''Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Created directory '/root/.ssh'.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:69:1e:73:2b:de:c8:e8:23:79:9a:0a:96:6f:e8:8a:b8 root@jenkinsThe key's randomart image is:+--[ RSA 2048]----+| || || || . || S . || . o + . ||.o. . o . ||+o..o.o+ + ||Eoooo=o.+ . |+-----------------+[root@jenkins conf]# cat /root/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDZS8mV9dyi2kOCnhe3o5V/bc8EEln6cVpNXQ16P4lKvAYSdcmrRTYdWapsssJAzjWnA5Pa/u32n/OWKTZDq+qmV3IxlQwuOVI7AeB5TJTuawk90f/1fj7aN1963yOvlZthS8dRUvEcrq+HHpekmAH+mLDeQGYcZEoNsovl1Cvp3TVNDC/7sKds7yoYmHupknyn5d7tgGID8Up02DJlgUQK6V7ZvivjRxAaYAjsWSEktIZK0jv0uWqo6cSddC/rLERGL4spjdwqErFKDQ8SVhArD5zR7L5Lpf9McbxFLFpMMN0I2U+udCXa8n7vwbzHTyaFU+ZvUkX80ykDpMJIW5ot root@jenkins# 将此公钥放入gitlab中 jenkins中安装gitlab插件 需要的插件： GitLab Hook：使 gitlab web 挂钩能够用于触发 gitlab 项目上的 smc 轮询 GitLab：这个插件允许 gitlab 触发 jenkins 构建, 并在 gitlab ui 中显示它们的结果。 Gitlab Authentication：这是使用 gitlab oauth 的身份验证插件。 Git Parameter：增加了从项目中配置的 git 存储库中选择分支、标记或修订的功能。 Build Authorization Token Root：即使匿名用户看不到 jenkins, 也可以访问生成和相关的 rest 生成触发器 Publish Over SSH：通过 ssh 发送生成项目 jenkins中设置token jenkins可以通过从gitlab上得到的token，与gitlab协同工作 Connection name可以自定义；Gitlab host URL是gitlab的访问地址；最后设置Credentials 在弹出的窗口中选择类型为GitLab API token，之后输入在gitlab中取得的项目的token，最后添加 选择刚创建的”GitLab API token”，然后点击”Test Connection”测试是否连接正常，如果没有问题就保存。这里的配置会在创建任务后的第一个General页面的”GitLab Connection”中自动引用 jenkins中设置Publish over SSH 进入设置 输入jenkins服务器的私钥，也就是用户家目录中.ssh中的id_rsa文件的内容（这是为了可以通过jenkins的公钥与私钥进行配对，使jenkins可以在远程主机上操作，当然也需要jenkins将公钥传到远程主机），SSH Servers中设置自定义Name，Hostname是要部署代码的服务器地址，Username是登录用的用户名，Remote Directory这里设置为了/usr/share/nginx/html，之后jenkins就可以向这个目录部署网页文件了 配置git插件 打开系统管理中的系统设置 选择Git plugin 设置Git插件的全局配置，然后点击“apply”——“save”。全局配置就是上面“Gitlab创建项目”部分中的global setting ，也就是git的用户名和邮箱地址。在项目第一次commit前，这些信息都可以在GitLab的项目的首页里找到 创建一个Jenkins Job 在jenkins里，一个任务叫做一个job。一般我们的项目会有多个分支，比如开发分支和产品分支，我们可以对每一个分支都新建一个job，比如，我们对开发分支创建一个测试的job，每次有代码提交就自动运行一次测试，对产品分支创建一个打包的job，每次有代码提交就运行打包任务。 在系统设置中设置的项就是为了可以在任务中得到引用。 创建的job最好与gitlab中的项目名一致 配置Job 在源码管理里，选择Git，并输入路径，路径可以在gitlab的项目首页上看到 添加用户，类型选“SSH Username with private key”；Username填root；选择PrivateKey中的Enter directly，在下面的key中输入jenkins服务器的私钥，可以用命令cat /root/.ssh/id_rsa查看。也里是指使用jenkins服务器上root用户的私钥访问gitlab上的项目，与gitlab上的jenkins服务器的root用户的公钥进行验证。 在Repository URL下面的红字提示“Failed to connect to repository : Error performing command: git ls-remote -h git@10.5.5.11:test/ccjdtest.git HEAD”是因为jenkins服务器上没有安装git，安装后解决。 jenkins job默认对master分支进行构建，你也可以自定义分支。这要求你的Gitlab代码仓库中要存在这个分支，一般来说，就是要向代码仓库提交一次更改，请 自行完成（Gitlab项目刚创建时是空的，一个分支也没有，这样的话，自动构建时会出错） 配置构建触发器，选择Build一行，后面的地址就是jenkins上放项目的路径，再选择下面的高级 选择Filter branches by regex，表示要触发自动部署的分支，在下面的Target Branch Regex中输入”.*master”，这是正则表达式，表示分支名。最后点击Generate，生成gitlab webhook的安全令牌，在配置gitlab时有用。 构建，选择新增中的send files or … over SSH 这里的Name中会有在Jenkins的设置中设置的Publish over SSH的服务器名字，下面的Source files中输入“**/**”，Remote directory中要部署到远程服务器的路径，Exec command是在远程服务器部署完代码后要执行的命令 gitlab上设置webhook 到gitlab的项目中设置集成 URL与Secret Token都是在Jenkins中的项目配置中取得的，取消SSL的勾选，最后添加 添加后在下面的Webhooks中就会有添加的项，点Test中的Push events测试。这里一定要在gitlab的项目中有一个文件，如果没有，测试时会提示“Hook execution failed: Ensure the project has at least one commit.”。可以在gitlab项目中创建一个README文件 如果测试正常，在页面最上方会有HTTP 200的提示 webhook就是为了在有人上传代码时，就会触发上面设置的地址，只要触发这个地址，jenkins就会自动部署 测试 到要部署代码的服务器上，安装nginx。 到jenkins服务器上安装git，准备拉取代码 12345678910111213141516------------- jenkins-------------ssh-copy-id -i /root/.ssh/id_rsa.pub 10.5.5.22# 要与部署代码的服务器实现密钥通讯git clone git@10.5.5.11:test/ccjdtest.gitcd ccjdtest/echo "test Jenkins" &gt; index.html# 创建一个文件git config --global user.email "test@ccjd.com"git config --global user.name "test"# 这两项是在gitlab中创建项目时设置的git add .git commit -m 'add index.html'git push# 推送到gitlab服务器 到jenkins中查看项目情况，如果配置正确，推送代码到gitlab后，这里会有提示 到部署代码的服务器上查看，index.html文件已放入了/usr/share/nginx/html目录中，并且服务已重新启动。访问页面变成了我们设置的内容。 测试maven手动部署部署流程 注册gitlab帐号 创建git项目 将上传代码的主机、Jenkins服务器、与部署代码的服务器的公钥上传到gitlab 将项目clone到本地 将本地代码push到gitlab 在Jenkins中创建Job 设置Job中的git地址，Jenkins登录git的用户名与私钥。新建构建“调用顶层Maven目标” 第一次构建，要到Job中点击“立即构建” 构建后操作 设置Job 设置Job，输入git地址，设置jenkins服务器登录gitlib时用的用户名与私钥，这样私钥与jenkins上传到gitlab上的公钥就可以配对了 设置构建，选择调用顶层Maven目标 Maven版本是在jenkins设置中设置好的，目标是一条Maven命令：“clean install -Dmaven.test.skip=true” 设置构建后操作。WAR/EAR files是一个相对路径，相对/root/.jenkins/workspace/echarging/而言，echarging是项目的名称，项目下的target中有war文件，这里输入c-rest/target表示在项目目录下还有一层。Context path是访问的名称，之后就可以使用IP:8080/rest访问了。再选择下面的Containers为Tomcat8.x，这要根据实际情况选择，然后添加一个可以访问tomcat的manager_webapp页面的用户名和密码，这是在部署代码的tomcat中设置的。下面就是Tomcat的访问地址。都输入正确后保存即可。这样，在Maven处理完代码后，就会自动部署到部署代码的tomcat服务器上了。 在部署代码的服务器上设置tomcat 1234567891011121314[root@bogon local]# yum install -y java-1.8.0-openjdk-devel[root@bogon ~]# vim /etc/profile.d/java.sh export JAVA_HOME=/usr[root@bogon tomcat]# vim /usr/local/tomcat/conf/tomcat-users.xml &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="tomcat_user" password="tomcat" roles="manager-gui,manager-script,manager-jmx,manager-status"/&gt;[root@bogon tomcat]# vim webapps/manager/META-INF/context.xml &lt;Context antiResourceLocking="false" privileged="true" &gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1|10.5.5.90|10.5.5.9" /&gt;# 这里加入两个地址，一个是本地的地址，为了测试页面是否可以打开。一个是jenkins的地址。如果不加jenkins的地址，jenkins的部署会报错。 到Job中，点击立即构建 总结1234567891011121314151617181920------------- jenkins-------------1. 全局安全设置，可以用户注册2. 系统设置中设置maven和java的家目录3. 安装deploy to container及gitlib相关插件4. jenkins中设置token，使jenkins与gitlab可以联合工作5. 配置publish over ssh，使jenkins可以使用ssh方法发送文件到远程服务器，或在远程服务器上执行命令。当然还需要将jenkins的公钥传输到远程主机6. 配置git，使用jenkins可以到远程的gitlab上进行验证7. 配置JOB7.1 源码管理中使用git，创建一个带有jenkins服务器上私钥的用户名，让jenkins可以使用私钥与github上的jenkins的公钥配对。让gitlab可以将代码推送到jenkins。7.2 构建触发器选择Build when a change is pushed to GitLab. (当更改推送到 gitlab 时生成。)，这是为了让gitlab可以向jenkins发送POST请求的。之后设置自动触发的分支，生成一个webhook安全令牌。7.3 构建，选择Send files or execute commands over SSH，也就是在构建期间通过ssh作为构建步骤发送文件或执行命令的方法，之后可以设置要部署的服务器，这个服务器是在publish over ssh中设置好的某台服务器，还可以设置代码的源路径，要部署的远程服务器的路径，要在远程服务器上执行的命令等。----------- gitlab-----------1. 生成token，给jenkins使用2. 为某个项目设置webhook。设置jenkins的URL与jenkins中生成的webhook安全令牌，使gitlab知道如何通知jenkins3. 当项目中的代码发生变化时，gitlab会将代码推送到jenkins主机进行部署]]></content>
      <categories>
        <category>持续集成与部署</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ基本命令与配置]]></title>
    <url>%2F2018%2F10%2F19%2FRabbitMQ%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[命令rabbitmq server命令12345678910systemctl start rabbitmq-serversystemctl stop rabbitmq-serversystemctl status rabbitmq-serversystemctl rotate-logs rabbitmq-serversystemctl restart rabbitmq-serversystemctl condrestart rabbitmq-serversystemctl try-restart rabbitmq-serversystemctl reload rabbitmq-serversystemctl force-reload rabbitmq-server# rabbitmq默认监听5672端口，网页管理页面监听15672端口 插件1234567* 语法** 开启插件rabbitmq-plugins enable 插件名** 关闭插件rabbitmq-plugins disable 插件名rabbitmq-plugins enable rabbitmq_management# 开启rabbitmq web管理页面插件 rabbitmqctl命令123456789101112131415161718192021222324252627282930* 创建用户，设置密码rabbitmqctl add_user username password* 分配用户标签-设置为管理用户。默认用户名密码为guestrabbitmqctl set_user_tags username tag# Tag可以为：administrator,monitoring, management等* 查看现有用户信息rabbitmqctl list_users* 删除用户rabbitmqctl delete_user username* 修改用户密码rabbitmqctl change_password username password* 查看所有队列消息rabbitmqctl list_queues* 清除所有队列rabbitmqctl reset* 新建虚拟机rabbitmqctl add_vhost 虚拟机名* 撤销虚拟机rabbitmqctl delete_vhost 虚拟机名* 服务器状态rabbitmqctl status 防火墙设置12345iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 15672 -j ACCEPTiptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 25672 -j ACCEPTiptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 5672 -j ACCEPTiptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 4369 -j ACCEPTiptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 5671 -j ACCEPT rabbitmq配置RabbitMQ支持三种配置方式： 读取环境变量中配置， 这包括shell中环境变量和rabbitmq-env.conf/rabbitmq-env-conf.bat文件中配置的环境变量 &emsp;&emsp;可配置如端口、配置文件指定自定义位置、节点名字等信息。 读取配置文件rabbitmq.config &emsp;&emsp;可配置权限、集群、插件设置等高级信息， 当然也可配置端口等简单信息 通过运行命令时指定参数 &emsp;&emsp;通常用来配置集群范围信息， 用来运行时动态传入 环境变量读取优先级 读取shell中环境变量 读取rabbitmq-env.conf/rabbitmq-env-conf.bat中的 读取默认的 rabbitmq-env.conf/rabbitmq-env-conf.bat 详解（颜色标注的为常用配置） 变量名称 默认值 描述 RABBITMQ_NODE_IP_ADDRESS 默认为空字符串， 即绑定所有网络接口 如果想绑定到一个固定的IP可以使用此变量. 如果要绑定到两个或两个以上只能通过rabbitmq.config中的tcp_listeners来设置。 RABBITMQ_NODE_PORT 5672 供客户端建立连接端口 RABBITMQ_DIST_PORT RABBITMQ_NODE_PORT + 20000 用于节点和CLI工具连接的端口， 如果rabbitmq.config中配置了kernel.inet_dist_listen_min 或 kernel.inet_dist_listen_max该参数将被忽略 RABBITMQ_NODENAME Unix*: rabbit@$HOSTNAMEWindows: rabbit@%COMPUTERNAME% 节点名字， 必须唯一 RABBITMQ_CONF_ENV_FILE Generic UNIX - $RABBITMQ_HOME/etc/rabbitmq/Debian - /etc/rabbitmq/RPM - /etc/rabbitmq/Mac OS X (Homebrew) - ${install_prefix}/etc/rabbitmq/, the Homebrew prefix is usually /usr/localWindows - %APPDATA%\RabbitMQ\ rabbitmq-env.conf/rabbitmq-env-conf.bat 默认位置， 不同系统不同安装方式位置也不同， 如果默认位置没找到则需在该位置手动创建一个 RABBITMQ_CONFIG_FILE 同上 rabbitmq.config 默认位置。 如果默认位置没找到则需在该位置手动创建一个 RABBITMQ_USE_LONGNAME 官网没说。。。。应该是false。。。 取值： true 或 false。 如果配置为true， 这将导致RabbitMQ使用完全限定的名称来标识节点 RABBITMQ_SERVICENAME Windows Service: RabbitMQ 服务名称 RABBITMQ_CONSOLE_LOG 只在控制台输出日志， 日志不会持久化到文件 取值： new 或 reuse。两种取值都是将控制台输出从服务器重定向到名为%rabbitmqservicename%（上面那个变量）的文件。 1）默认： 不设置， 控制台的日志不会被持久化到文件 2）new： 每次启动时都会创建一个新的文件 3）reuse： 每次启动服务器都会重用该日志文件 RABBITMQ_CTL_ERL_ARGS None 在调用rabbitmqctl时使用的erl命令的参数。应该仅用于调试目的。 RABBITMQ_SERVER_ERL_ARGS Unix*:”+K true +A30 +P 1048576 -kernel inet_default_connect_options [{nodelay,true}]”Windows: None 在调用RabbitMQ服务器时使用的erl命令的标准参数， 应该仅用于调试目的 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS Unix*: NoneWindows: None 在调用RabbitMQ服务器时使用的erl命令的附加参数。这个变量的值被附加到参数的默认列表(RABBITMQ_SERVER_ERL_ARGS). RABBITMQ_SERVER_START_ARGS None 在调用RabbitMQ服务器时使用的erl命令的额外参数。这不会覆盖RABBITMQ_SERVER_ERL_ARGS. HOSTNAME Unix, Linux: env hostnameMacOSX: env hostname -s 当前机器名称 COMPUTERNAME Windows: localhost 当前机器名称， windows使用该变量 ERLANG_SERVICE_MANAGER_PATH Windows Service: %ERLANG_HOME%\erts-x.x.x\bin erlsrv.exe的路径， erlsrv.exe这个是erlang服务的包装脚本 rabbitmq.config详解（核心配置）&emsp;&emsp;该配置文件使用的是Erlang标准配置文件，语法请参照这里 1234例： [ &#123;rabbit, [&#123;tcp_listeners, [5673]&#125;]&#125; ]. key 描述 tcp_listeners 监听AMQP连接的端口或主机/对。 Default: [5672] num_tcp_acceptors Erlang进程的数量，接受TCP监听器的连接数。 Default: 10 handshake_timeout 对AMQP 0-8/0-9/0-9-1握手的最大时间(在套接字连接和SSL握手之后)，以毫秒为间隔 Default: 10000 ssl_listeners 如上所述，用于SSL连接。 Default: [] num_ssl_acceptors 用于接受SSL监听连接的Erlang进程的数量。 Default: 1 ssl_options SSL配置参数. 详情请看 SSL documentation.Default: [] ssl_handshake_timeout SSL握手超时，以毫秒为间隔。 Default: 5000 vm_memory_high_watermark 触发流控制的内存阈值。详情请看 memory-based flow control.Default: 0.4 vm_memory_high_watermark_paging_ratio 设置当内存使用超过总内存百分比多少时，队列开始将消息持久化到磁盘以释放内存。 详情请看 memory-based flow control.Default: 0.5 disk_free_limit RabbitMQ存储数据的分区的磁盘空间限制。当可用的磁盘空间低于这个限制时，就会触发流控制。值可以相对于RAM的总数设置(例如，内存比例，1.0)。该值也可以设置为整数的字节数。或者，单位(例如“50 mb”)。默认情况下，空闲磁盘空间必须超过50MB。详情请看 Disk Alarms.Default: 50000000 log_levels 控制日志的粒度。该值是一个日志事件类别和日志级别对的列表。 可设置级别： ‘none’ ‘error’ ‘warning’ ‘info’ ‘debug’ 以上下一层级别的日志输出均包含上层级别日志输出（如： warning包含warning和error）, none为不输出日志 另外，当前未分类的事件总是记录在日志中The categories are:channel - 所有与AMQP通道有关的事件connection - 对于所有与网络连接有关的事件federation - 对于所有与federation有关的事件mirroring - 对于与镜像队列相关的所有事件Default: [{connection, info}] frame_max 框架最大允许大小(以字节为单位)与消费者进行数据交换。设置为0意味着“无限”，但会在一些QPid客户端触发一个bug。设置更大的值可能会提高吞吐量;设置较小的值可能会提高延迟。Default: 131072 channel_max 与消费者进行谈判的最大允许数量。设置为0意味着“无限”。使用更多的通道会增加代理的内存占用。Default: 0 channel_operation_timeout 通道操作超时为毫秒(内部使用，由于消息传递协议的差异和限制而不直接暴露于客户机)。 Default: 15000 heartbeat 该值表示服务器在连接中发送的心跳延迟，在几秒钟内。优化框架。如果设置为0，则会禁用心跳。客户端可能不会遵循服务器的建议，请参阅AMQP参考以了解更多细节。在有大量连接的情况下，禁用心跳可能改善性能，但可能会导致连接在关闭非活动连接的网络设备的出现。Default: 60 (580 prior to release 3.5.5) default_vhost 当RabbitMQ创建一个新的数据库时，创建一个虚拟主机。交换amq.rabbitmq.logwill存在于这个虚拟主机中。Default: &lt;&lt;”/“&gt;&gt; default_user 当RabbitMQ从头创建一个新数据库时，要创建用户名。 Default: &lt;&lt;”guest”&gt;&gt; default_pass 默认用户的密码。 Default: &lt;&lt;”guest”&gt;&gt; default_user_tags 默认用户的标记。 Default: [administrator] default_permissions 在创建时分配给默认用户的权限。 Default: [&lt;&lt;”.“&gt;&gt;, &lt;&lt;”.“&gt;&gt;, &lt;&lt;”.*”&gt;&gt;] loopback_users 只允许通过环回接口连接到代理的用户列表(即localhost)。 如果您希望允许缺省的来宾用户远程连接，则需要将其更改为 [].Default: [&lt;&lt;”guest”&gt;&gt;] cluster_nodes 当一个节点开始第一次启动时，将它设置为使集群自动发生。元组的第一个元素是节点试图集群到的节点。第二个元素是磁盘或ram，并确定节点类型。 Default: {[], disc} server_properties 键值对的列表，在连接上向客户端宣布。 Default: [] collect_statistics 统计数据收集模式。主要与管理插件有关。选项有: none (不要发布统计数据)coarse (发出每个队列/每个通道/每个连接统计信息)fine (发出的每条数据)通常情况下不需要设置该参数 Default: none collect_statistics_interval 统计数据收集间隔以毫秒为间隔。 主要相关插件 management plugin.Default: 5000 management_db_cache_multiplier 管理插件将缓存诸如队列清单之类的代价较高的查询的时间。缓存将把最后一个查询的运行时间乘以这个值，并在此时间内缓存结果。 Default: 5 auth_mechanisms SASL authentication mechanisms to offer to clients.Default: [‘PLAIN’, ‘AMQPLAIN’] auth_backends List of authentication and authorisation backends to use.Other databases than rabbit_auth_backend_internalare available through plugins.Default: [rabbit_auth_backend_internal] reverse_dns_lookups 设置为true，让RabbitMQ对客户端连接执行反向DNS查找，并通过rabbitmqctl和管理插件呈现该信息。 Default: false delegate_count 用于集群内部通信的委托进程的数量。当为多核CPU时可以考虑设置该值 Default: 16 trace_vhosts Used internally by the tracer. 通常情况下不需要设置该参数Default: [] tcp_listen_options 默认的套接字选项。通常情况下不需要设置该参数 Default:[{backlog, 128}, {nodelay, true}, {linger, {true,0}}, {exit_on_close, false}] hipe_compile 设置为true，使用HiPE预编译RabbitMQ的部分，这是Erlang的即时编译器。这将增加服务器的吞吐量，以增加启动时间的成本。 您可能会看到，在启动时延迟几分钟，您的性能会提高20-50%。这些数据是高度工作负载和硬件依赖的。HiPE支持可能不会编译到您的Erlang安装中。如果不是这样，启用这个选项只会导致一个警告消息被显示，而启动将照常进行。例如，Debian/Ubuntu用户需要安装erlangbase-base-hipe包。HiPE在某些平台上是不可用的，尤其是Windows。HiPE在17.5之前就已经知道了erlangp/otp版本的问题。HiPE推荐使用最新的erlangp/otp版本Default: false cluster_partition_handling 如何处理网络分区。可用模式: ignorepause_minority{pause_if_all_down, [nodes], ignore \ autoheal} (例: [‘rabbit@node1’, ‘rabbit@node2’])autoheal详情请看documentation on partitions Default: ignore cluster_keepalive_interval 节点应该多频繁地将keepalive消息发送到其他节点(以毫秒为单位)。请注意，这与netticktime不一样; 错过的keepalive消息不会导致节点被认为挂机。 Default: 10000 queue_index_embed_msgs_below 在消息的字节数中，消息将被直接嵌入到队列索引中。详情请看 persister tuning Default: 4096 msg_store_index_module 用于队列索引的实现模块。 详情请看 persister tuning Default: rabbit_msg_store_ets_index backing_queue_module 队列内容的实现模块。通常情况下不需要设置该参数 Default: rabbit_variable_queue msg_store_file_size_limit Tunable value for the persister. 通常情况下不需要设置该参数Default: 16777216 mnesia_table_loading_retry_limit 在等待集群中的Mnesia tables可用时，需要重试的次数。 Default: 10 mnesia_table_loading_retry_timeout 在集群中等待每个重试的时间，以便可用 Default: 30000 queue_index_max_ journal_entries Tunable value for the persister. 通常情况下不需要设置该参数Default: 65536 queue_master_locator Queue master定位策略可用策略:&lt;&lt;”min-masters”&gt;&gt;&lt;&lt;”client-local”&gt;&gt;&lt;&lt;”random”&gt;&gt;详情请看 documentation on queue master location Default: &lt;&lt;”client-local”&gt;&gt; lazy_queue_explicit_gc_run_operation_threshold 调优： 只有在内存压力下有延迟队列时。 这是触发垃圾收集器和其他内存减少活动的阈值。一个低的值可以降低性能，一个高的值可以提高性能，但是会导致更高的内存消耗。通常情况下不需要设置该参数Default: 1000 queue_explicit_gc_run_operation_threshold 调优： 在内存压力较大时。这是触发垃圾收集器和其他内存减少活动的阈值。一个低的值可以降低性能，一个高的值可以提高性能，但是会导致更高的内存消耗。通常情况下不需要设置该参数Default: 1000 配置条目加密1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 可以在RabbitMQ配置文件中加密敏感配置条目（例如密码，包含URL的凭据）。代理在开始时解密加密的条目.请注意，加密配置条目不会使系统有意义地更安全。然而，它们允许RabbitMQ的部署符合各国的规定，要求在配置文件中不应以纯文本形式显示敏感数据。# 加密值必须在Erlang加密元组内：&#123;encrypted，...&#125;。以下是默认用户加密密码的配置[ &#123;rabbit, [ &#123;default_user, &lt;&lt;"guest"&gt;&gt;&#125;, &#123;default_pass,&#123;encrypted, &lt;&lt;"cPAymwqmMnbPXXRVqVzpxJdrS8mHEKuo2V+3vt1u/fymexD9oztQ2G/oJ4PAaSb2c5N/hRJ2aqP/X0VAfx8xOQ=="&gt;&gt;&#125; &#125;, &#123;config_entry_decoder, [ &#123;passphrase, &lt;&lt;"mypassphrase"&gt;&gt;&#125; ]&#125;]&#125;].# 注意configentrydecoder密钥与RabbitMQ用于解密加密值的密码。密码短语不需要在配置文件中进行硬编码，它可以在一个单独的文件中。[ &#123;rabbit, [ ... &#123;config_entry_decoder, [ &#123;passphrase, &#123;file, "/path/to/passphrase/file"&#125;&#125; ]&#125;]&#125;].# 当使用&#123;passphrase，prompt&#125;启动时，RabbitMQ也可以要求操作者输入密码# 使用rabbitmqctl和encode命令加密值rabbitmqctl encode '&lt;&lt;"guest"&gt;&gt;' mypassphrase&#123;encrypted,&lt;&lt;"... long encrypted value..."&gt;&gt;&#125;rabbitmqctl encode '"amqp://fred:secret@host1.domain/my_vhost"' mypassphrase&#123;encrypted,&lt;&lt;"... long encrypted value..."&gt;&gt;&#125;# 如果要解密值，请添加--decode选项rabbitmqctl encode --decode '&#123;encrypted, &lt;&lt;"..."&gt;&gt;&#125;' mypassphrase&lt;&lt;"guest"&gt;&gt;rabbitmqctl encode --decode '&#123;encrypted, &lt;&lt;"..."&gt;&gt;&#125;' mypassphrase"amqp://fred:secret@host1.domain/my_vhost"# 可以对不同类型的值进行编码。上面的例子编码了二进制文件（&lt;&lt;“guest”&gt;&gt;）和字符串（“amqp：// fred：secret@host1.domain/my_vhost”）。# 加密机制使用PBKDF2从密码短语中产生派生密钥。默认散列函数为SHA512，默认迭代次数为1000.默认密码为AES 256 CBC# 您可以在配置文件中更改这些默认值：[ &#123;rabbit, [ ... &#123;config_entry_decoder, [ &#123;passphrase, "mypassphrase"&#125;, &#123;cipher, blowfish_cfb64&#125;, &#123;hash, sha256&#125;, &#123;iterations, 10000&#125; ]&#125;]&#125;]. # 在命令行：rabbitmqctl encode --cipher blowfish_cfb64 --hash sha256 --iterations 10000 \ '&lt;&lt;"guest"&gt;&gt;' mypassphrase]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>RabbitMQ基本命令与配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ概念]]></title>
    <url>%2F2018%2F10%2F19%2FRabbitMQ%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[转：干货：这也许是最全面透彻的一篇RabbitMQ指南！原文地址：https://www.cnblogs.com/zhangxiaoliu/p/7524846.html 本文大纲： RabbitMQ 历史 RabbitMQ 应用场景 RabbitMQ 系统架构 RabbitMQ 基本概念 RabbitMQ 细节阐明 历史-从开始到现在 RabbitMQ是一个Erlang开发的AMQP（Advanced Message Queuing Protocol ）的开源实现。AMQP 的出现其实也是应了广大人民群众的需求，虽然在同步消息通讯的世界里有很多公开标准（如 Cobar）的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 WebSphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Red Hat、iMatix 等联合制定了 AMQP 的公开标准。 RabbitMQ由RabbitMQ Technologies Ltd开发并且提供商业支持的。该公司在2010年4月被SpringSource（VMware的一个部门）收购。在2013年5月被并入Pivotal。其实VMware，Pivotal和EMC本质上是一家的。不同的是，VMware是独立上市子公司，而Pivotal是整合了EMC的某些资源，现在并没有上市。 RabbitMQ官网：http://www.rabbitmq.com 应用场景言归正传。RabbitMQ，或者说AMQP解决了什么问题，或者说它的应用场景是什么？ 对于一个大型的软件系统来说，它会有很多的组件或者说模块，又或者说子系统。那这些模块又如何通信？这和传统的IPC有很大的区别。传统的IPC很多都是在单一系统上的，模块耦合性很大，不适合扩展（Scalability）。如果使用Socket，那么不同的模块的确可以部署到不同的机器上，但是还是有很多问题需要解决。比如： 信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据是以什么方式丢失？ 如何降低发送者和接收者的耦合度？ 如何让Priority高的接收者先接到数据？ 如何做到Load Balance？有效均衡接收者的负载？ 如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。 如何做到可扩展，甚至将这个通信模块发到cluster上？ 如何保证接收者接收到了完整，正确的数据？ AMQP协议解决了以上的问题，而RabbitMQ实现了AMQP。 系统架构 RabbitMQ Server&emsp;&emsp;也叫Broker Server，它不是运送食物的卡车，而是一种传输服务。原话是RabbitMQ isn’t a food truck, it’s a delivery service. 它的角色就是维护一条从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。虽然这个保证也不是100%的保证，但是对于普通的应用来说这已经足够了。当然对于商业系统来说，可以再做一层数据一致性的guard，就可以彻底保证系统的一致性了。 producer&emsp;&emsp;数据的发送方。Create messages and publish (send) them to a Broker Server (RabbitMQ)。一个Message有两个部分：payload（有效载荷）和label（标签）。payload顾名思义就是传输的数据。label是exchange的名字或者说是一个tag，它描述了payload，而且RabbitMQ也是通过这个label来决定把这个Message发给哪个Consumer。AMQP仅仅描述了label，而RabbitMQ决定了如何使用这个label的规则。 consumer&emsp;&emsp;数据的接收方。Consumers attach to a Broker Server (RabbitMQ) and subscribe to a queue。把queue比作是一个有名字的邮箱。当有Message到达某个邮箱后，RabbitMQ把它发送给它的某个订阅者即Consumer。当然可能会把同一个Message发送给很多的Consumer。在这个Message中，只有payload，label已经被删掉了。对于Consumer来说，它是不知道谁发送的这个信息的,就是协议本身不支持。如果Producer发送的payload包含了Producer的信息就另当别论了。 对于一个数据从Producer到Consumer的正确传递，还有三个概念需要明确：exchanges, queues and bindings。 Exchanges are where producers publish their messages. Queues are where the messages end up and are received by consumers. Bindings are how the messages get routed from the exchange to particular queues. 还有几个概念是上述图中没有标明的，那就是Connection（连接）和Channel（通道，频道）。 Connection&emsp;&emsp;就是一个TCP的连接。Producer和Consumer都是通过TCP连接到RabbitMQ Server的。 Connection Factory&emsp;&emsp;连接管理器。应用程序与Rabbit之间建立连接的管理器，程序代码中使用； Channel&emsp;&emsp;信道。消息推送使用的通道。虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。因为对于系统来说，建立和关闭TCP连接是有代价的，频繁的建立关闭TCP连接对于系统的性能有很大的影响，而且TCP的连接数也有限制，这也限制了系统处理高并发的能力。但是，在TCP连接中建立Channel是没有上述代价的。对于Producer或者Consumer来说，可以并发的使用多个Channel进行Publish或者Receive。有实验表明，1s的数据可以Publish10K的数据包。当然对于不同的硬件环境，不同的数据包大小这个数据肯定不一样，但是我只想说明，对于普通的Consumer或者Producer来说，这已经足够了。如果不够用，你考虑的应该是如何细化SPLIT你的设计。 相关定义 Broker： 简单来说就是消息队列服务器实体 Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列 Queue： 消息队列载体，每个消息都会被投入到一个或多个队列 Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来 Routing Key： 路由关键字，exchange根据这个关键字进行消息投递 VHost： 虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 Producer： 消息生产者，就是投递消息的程序 Consumer： 消息消费者，就是接受消息的程序 Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务 由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。 基本概念&emsp;&emsp;Connection Factory（连接管理器）、Connection、Channel（信道）都是RabbitMQ对外提供的API中最基本的对象。Connection是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。Connection Factory则是Connection的制造工厂。Channel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。 Queue&emsp;&emsp;Queue（队列）是RabbitMQ的内部对象，用于存储消息，用下图表示。 &emsp;&emsp;RabbitMQ中的消息都只能存储在Queue中，生产者（下图中的P）生产消息并最终投递到Queue中，消费者（下图中的C）可以从Queue中获取消息并消费。 &emsp;&emsp;多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 Message acknowledgment&emsp;&emsp;在实际应用中，可能会发生消费者收到Queue中的消息，但没有处理完成就宕机（或出现其他意外）的情况，这种情况下就可能会导致消息丢失。为了避免这种情况发生，我们可以要求消费者在消费完消息后发送一个回执给RabbitMQ，RabbitMQ收到消息回执（Message acknowledgment）后才将该消息从Queue中移除。 &emsp;&emsp;如果RabbitMQ没有收到回执并检测到消费者的RabbitMQ连接断开，则RabbitMQ会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在timeout，一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者，除非它的RabbitMQ连接断开。 &emsp;&emsp;这里会产生另外一个问题，如果我们的开发人员在处理完业务逻辑后，忘记发送回执给RabbitMQ，这将会导致严重的bug——Queue中堆积的消息会越来越多。消费者重启后会重复消费这些消息并重复执行业务逻辑。 &emsp;&emsp;另外publish message 是没有ACK的。 Message durability&emsp;&emsp;如果我们希望即使在RabbitMQ服务重启的情况下，也不会丢失消息，我们可以将Queue与Message都设置为可持久化的（durable），这样可以保证绝大部分情况下我们的RabbitMQ消息不会丢失。但依然解决不了小概率丢失事件的发生（比如RabbitMQ服务器已经接收到生产者的消息，但还没来得及持久化该消息时RabbitMQ服务器就断电了），如果我们需要对这种小概率事件也要管理起来，那么我们要用到事务。 Prefetch count&emsp;&emsp;前面我们讲到如果有多个消费者同时订阅同一个Queue中的消息，Queue中的消息会被平摊给多个消费者。这时如果每个消息的处理时间不同，就有可能会导致某些消费者一直在忙，而另外一些消费者很快就处理完手头工作并一直空闲的情况。我们可以通过设置Prefetch count来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后Queue会再给该消费者发送一条消息。 Exchange&emsp;&emsp;生产者将消息投递到Queue中，实际上这在RabbitMQ中这种事情永远都不会发生。实际的情况是，生产者将消息发送到Exchange（交换器，下图中的X），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。 Routing Key&emsp;&emsp;生产者在将消息发送给Exchange的时候，一般会指定一个Routing Key，来指定这个消息的路由规则，而这个Routing Key需要与Exchange Type及Binding key联合使用才能最终生效。 &emsp;&emsp;在Exchange Type与Binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定Routing Key来决定消息流向哪里。 &emsp;&emsp;RabbitMQ为Routing Key设定的长度限制为255 bytes。 Binding&emsp;&emsp;RabbitMQ中通过Binding将Exchange与Queue关联起来，这样RabbitMQ就知道如何正确地将消息路由到指定的Queue了。 Binding key&emsp;&emsp;在绑定（Binding）Exchange与Queue的同时，一般会指定一个Binding key。消费者将消息发送给Exchange时，一般会指定一个Routing Key。当Binding key与Routing Key相匹配时，消息将会被路由到对应的Queue中。 &emsp;&emsp;在绑定多个Queue到同一个Exchange的时候，这些Binding允许使用相同的Binding key。 &emsp;&emsp;Binding key并不是在所有情况下都生效，它依赖于Exchange Type，比如fanout类型的Exchange就会无视Binding key，而是将消息路由到所有绑定到该Exchange的Queue。 Exchange Types&emsp;&emsp;RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义，这里不予以描述），下面分别进行介绍。 fanout&emsp;&emsp;fanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 &emsp;&emsp;上图中，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被两个消费者（C1与C2）消费。 direct&emsp;&emsp;direct类型的Exchange路由规则也很简单，它会把消息路由到那些Binding key与Routing key完全匹配的Queue中。 &emsp;&emsp;以上图的配置为例，我们以routingKey=”error”发送消息到Exchange，则消息会路由到Queue1（amqp.gen-S9b…，这是由RabbitMQ自动生成的Queue名称）和Queue2（amqp.gen-Agl…）；如果我们以Routing Key=”info”或routingKey=”warning”来发送消息，则消息只会路由到Queue2。如果我们以其他Routing Key发送消息，则消息不会路由到这两个Queue中。 topic&emsp;&emsp;前面讲到direct类型的Exchange路由规则是完全匹配Binding Key与Routing Key，但这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到Binding Key与Routing Key相匹配的Queue中，但这里的匹配规则有些不同，它约定：Routing Key为一个句点号“.”分隔的字符串（我们将被句点号”. “分隔开的每一段独立的字符串称为一个单词），如”stock.usd.nyse”、”nyse.vmw”、”quick.orange.rabbit”。Binding Key与Routing Key一样也是句点号“. ”分隔的字符串。 &emsp;&emsp;Binding Key中可以存在两种特殊字符”*“与”#”，用于做模糊匹配，其中”*“用于匹配一个单词，”#”用于匹配多个单词（可以是零个）。 &emsp;&emsp;以上图中的配置为例，routingKey=”quick.orange.rabbit”的消息会同时路由到Q1与Q2，routingKey=”lazy.orange.fox”的消息会路由到Q1，routingKey=”lazy.brown.fox”的消息会路由到Q2，routingKey=”lazy.pink.rabbit”的消息会路由到Q2（只会投递给Q2一次，虽然这个routingKey与Q2的两个bindingKey都匹配）；routingKey=”quick.brown.fox”、routingKey=”orange”、routingKey=”quick.orange.male.rabbit”的消息将会被丢弃，因为它们没有匹配任何bindingKey。 headers&emsp;&emsp;headers类型的Exchange不依赖于Routing Key与Binding Key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 &emsp;&emsp;在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对。如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。 RPC&emsp;&emsp;MQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。 &emsp;&emsp;RabbitMQ中实现RPC的机制是：客户端发送请求（消息）时，在消息的属性（Message Properties，在AMQP协议中定义了14种properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败）。服务器端收到消息处理完后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性。客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理。 使用ACK确认Message的正确传递&emsp;&emsp;默认情况下，如果Message 已经被某个Consumer正确的接收到了，那么该Message就会被从Queue中移除。当然也可以让同一个Message发送到很多的Consumer。 &emsp;&emsp;如果一个Queue没被任何的Consumer Subscribe（订阅），当有数据到达时，这个数据会被cache，不会被丢弃。当有Consumer时，这个数据会被立即发送到这个Consumer。这个数据被Consumer正确收到时，这个数据就被从Queue中删除。 &emsp;&emsp;那么什么是正确收到呢？通过ACK。每个Message都要被acknowledged（确认，ACK）。我们可以显式的在程序中去ACK，也可以自动的ACK。如果有数据没有被ACK，那么RabbitMQ Server会把这个信息发送到下一个Consumer。 &emsp;&emsp;如果这个APP有bug，忘记了ACK，那么RabbitMQ Server不会再发送数据给它，因为Server认为这个Consumer处理能力有限。而且ACK的机制可以起到限流的作用（Benefitto throttling）：在Consumer处理完成数据后发送ACK，甚至在额外的延时后发送ACK，将有效的balance Consumer的load。 &emsp;&emsp;当然对于实际的例子，比如我们可能会对某些数据进行merge，比如merge 4s内的数据，然后sleep 4s后再获取数据。特别是在监听系统的state，我们不希望所有的state实时的传递上去，而是希望有一定的延时。这样可以减少某些IO，而且终端用户也不会感觉到。 Reject a message&emsp;&emsp;有两种方式，第一种的Reject可以让RabbitMQ Server将该Message 发送到下一个Consumer。第二种是从Queue中立即删除该Message。 Creating a queue&emsp;&emsp;Consumer和Procuder都可以通过 queue.declare 创建queue。对于某个Channel来说，Consumer不能declare一个queue，却订阅其他的queue。当然也可以创建私有的queue。这样只有APP本身才可以使用这个queue。queue也可以自动删除，被标为auto-delete的queue在最后一个Consumer unsubscribe后就会被自动删除。那么如果是创建一个已经存在的queue呢？那么不会有任何的影响。需要注意的是没有任何的影响，也就是说第二次创建如果参数和第一次不一样，那么该操作虽然成功，但是queue的属性并不会被修改。 &emsp;&emsp;那么谁应该负责创建这个queue呢？是Consumer，还是Producer？ &emsp;&emsp;如果queue不存在，当然Consumer不会得到任何的Message。那么Producer Publish的Message会被丢弃。所以，还是为了数据不丢失，Consumer和Producer都try to create the queue！反正不管怎么样，这个接口都不会出问题。 &emsp;&emsp;queue对load balance的处理是完美的。对于多个Consumer来说，RabbitMQ 使用循环的方式（round-robin）均衡地发送给不同的Consumer。 Exchanges&emsp;&emsp;从架构图可以看出，Procuder Publish的Message进入了Exchange。接着通过”routing keys”， RabbitMQ会找到应该把这个Message放到哪个queue里。queue也是通过这个routing keys来做的绑定。 &emsp;&emsp;有三种类型的Exchanges：direct, fanout,topic。 每个实现了不同的路由算法（routing algorithm）。 Direct exchange&emsp;&emsp;如果 routing key 匹配，那么Message就会被传递到相应的queue中。其实在queue创建时，它会自动的以queue的名字作为routing key来绑定那个exchange。 Fanout exchange&emsp;&emsp;会向响应的queue广播。 Topic exchange&emsp;&emsp;对key进行模式匹配，比如ab可以传递到所有ab的queue。 Virtual hosts&emsp;&emsp;每个virtual host本质上都是一个RabbitMQ Server，拥有它自己的queue，exchagne，和bings rule等等。这保证了你可以在多个不同的Application中使用RabbitMQ。 附录acknowledgment[əkˈnɔlidʒmənt]：确认 cache[kæʃ]： 缓存 balance[ˈbæləns]：平衡 merge[mə:dʒ]：合并 unsubscribe[ˌʌnsəbˈskraɪb]：退订 declare[diˈklɛə]：声明 Publish[ˈpʌbliʃ]：发布 exchange[iksˈtʃeindʒ]：交换 fanout[fænaʊt]：分列（帐户） derect[diˈrekt]：直接]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>RabbitMQ概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ部署]]></title>
    <url>%2F2018%2F10%2F18%2FRabbitMQ%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[介绍 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 AMQP，即Advanced message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 概念 RabbitMQ Server也称为Broker Server，是一种传输服务。它的角色就是维护一条从Producer（生产者）到Consumer（消费者）的路线，保证数据能够按照指定的方式进行传输。虽然这个保证也不是100%的保证，但是对于普通的应用来说这已经足够了。当然对于商业系统来说，可以再做一层数据一致性的guard，就可以彻底保证系统的一致性了。 producer：数据的发送方。Create messages and publish (send) them to a Broker Server (RabbitMQ)。一个Message有两个部分：payload（有效载荷）和label（标签）。payload顾名思义就是传输的数据。label是exchange的名字或者说是一个tag，它描述了payload，而且RabbitMQ也是通过这个label来决定把这个Message发给哪个Consumer。AMQP仅仅描述了label，而RabbitMQ决定了如何使用这个label的规则。 consumer：数据的接收方。Consumers attach to a Broker Server (RabbitMQ) and subscribe to a queue。把queue比作是一个有名字的邮箱。当有Message到达某个邮箱后，RabbitMQ把它发送给它的某个订阅者即Consumer。当然可能会把同一个Message发送给很多的Consumer。在这个Message中，只有payload，label已经被删掉了。对于Consumer来说，它是不知道谁发送的这个信息的,就是协议本身不支持。如果Producer发送的payload包含了Producer的信息就另当别论了。 Connection：就是一个TCP的连接。Producer和Consumer都是通过TCP连接到RabbitMQ Server的。 Connection Factory：连接管理器。应用程序与Rabbit之间建立连接的管理器，程序代码中使用； Channel：信道。消息推送使用的通道。虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。因为对于系统来说，建立和关闭TCP连接是有代价的，频繁的建立关闭TCP连接对于系统的性能有很大的影响，而且TCP的连接数也有限制，这也限制了系统处理高并发的能力。但是，在TCP连接中建立Channel是没有上述代价的。对于Producer或者Consumer来说，可以并发的使用多个Channel进行Publish或者Receive。 exchanges：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列，用于存储生产者的消息。 Binding：绑定是如何将消息从Exchange路由到特定队列的。也就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递 由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。 VHost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 publish消息确认机制 如果采用标准的 AMQP 协议，则唯一能够保证消息不会丢失的方式是利用事务机制 — 令 channel 处于 transactional 模式、向其 publish 消息、执行 commit 动作。在这种方式下，事务机制会带来大量的多余开销，并会导致吞吐量下降 250% 。为了补救事务带来的问题，引入了 confirmation 机制（即 Publisher Confirm）。 confirm 机制是在channel上使用 confirm.select方法，处于 transactional 模式的 channel 不能再被设置成 confirm 模式，反之亦然。 在 channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被 nack 一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm 又被 nack 。 RabbitMQ 将在下面的情况中对消息进行 confirm ： RabbitMQ发现当前消息无法被路由到指定的 queues 中； 非持久属性的消息到达了其所应该到达的所有 queue 中（和镜像 queue 中）； 持久消息到达了其所应该到达的所有 queue 中（和镜像 queue 中），并被持久化到了磁盘（被 fsync）； 持久消息从其所在的所有 queue 中被 consume 了（如果必要则会被 acknowledge）。 consumer消息确认机制 为了保证数据不被丢失，RabbitMQ支持消息确认机制，即acknowledgments。 如果没启动消息确认机制，RabbitMQ在consumer收到消息后就会把消息删除。 启用消息确认后，consumer在处理数据后应通过回调函数显示发送ack， RabbitMQ收到ack后才会删掉数据。如果consumer一段时间内不回馈，RabbitMQ会将该消息重新分配给另外一个绑定在该队列上的consumer。另一种情况是consumer断开连接，但是获取到的消息没有回馈，则RabbitMQ同样重新分配。 注意：如果consumer 没调用basic.qos 方法设置prefetch_count=1，那即使该consumer有未ack的messages，RabbitMQ仍会继续发messages给它。 消息持久化 消息确认机制确保了consumer退出时消息不会丢失，但如果是RabbitMQ本身因故障退出，消息还是会丢失。为了保证在RabbitMQ出现意外情况时数据仍没有丢失，需要将queue和message都要持久化。 queue持久化：channel.queue_declare(queue=’hello’, durable=True) message持久化：channel.basic_publish(exchange=”, routing_key=”task_queue”, body=message, properties=pika.BasicProperties( delivery_mode = 2,) #消息持久化 ) 即使有消息持久化，数据也有可能丢失，因为rabbitmq是先将数据缓存起来，到一定条件才保存到硬盘上，这期间rabbitmq出现意外数据有可能丢失。 网上有测试表明：持久化会对RabbitMQ的性能造成比较大的影响，可能会下降10倍不止。 RABBITMQ集群基本概念 一个RABBITMQ集群中可以共享user，virtualhosts，queues（开启Highly Available Queues），exchanges等。但message只会在创建的节点上传输。当message进入A节点的queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。 RABBITMQ的集群节点包括内存节点、磁盘节点。内存节点的元数据仅放在内存中，性能比磁盘节点会有所提升。不过，如果在投递message时，打开了message的持久化，那么内存节点的性能只能体现在资源管理上，比如增加或删除队列（queue），虚拟主机（vrtual hosts），交换机（exchange）等，发送和接受message速度同磁盘节点一样。一个集群至少要有一个磁盘节点。 镜像队列概念 镜像队列可以同步queue和message，当主queue挂掉，从queue中会有一个变为主queue来接替工作。 镜像队列是基于普通的集群模式的,所以你还是得先配置普通集群,然后才能设置镜像队列。 镜像队列设置后，会分一个主节点和多个从节点，如果主节点宕机，从节点会有一个选为主节点，原先的主节点起来后会变为从节点。 queue和message虽然会存在所有镜像队列中，但客户端读取时不论物理机连接的主节点还是从节点，都是从主节点读取数据，然后主节点再将queue和message的状态同步给从节点，因此多个客户端连接不同的镜像队列不会产生同一message被多次接受的情况。 安装 下载rpm包http://www.rabbitmq.com/download.html 分别点击两个箭头指向的页面下载相应包 箭头指向为CentOS7中可以安装的erlang的rpm包和rabbitmq的rpm包 12345678910111213141516yum install -y erlang-19.3.6.11-2.el7.centos.x86_64.rpmyum install -y rabbitmq-server-3.6.16-2.el7.noarch.rpm# 将两个rpm包上传到服务器并安装vim /etc/rabbitmq/rabbitmq.config [&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].# 安装后没有此文件，自已创建此文件并加入上面内容，不要忘记最后的点rabbitmq-plugins enable rabbitmq_management# 开启网页管理页面的插件。如果停用可以使用disable参数cd /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.16/plugins/wget https://dl.bintray.com/rabbitmq/community-plugins/rabbitmq_delayed_message_exchange-0.0.1.ez# 消息延迟发送给消费者的插件rabbitmq-plugins enable rabbitmq_delayed_message_exchangeservice rabbitmq-server start# 如果无法启动，可以使用journalctl -xe &gt; /root/abc.txt命令将报错信息重定向到一个文件，并查看。测试中无法启动是因为上面的配置文件写错了，改成上面的样子后启动就没问题了。ss -tlnp# rabbitmq的网页默认监听在15672端口上，服务器监听在5672端口 访问rabbitmq远程管理页面。默认用户名和密码都是guest 添加用户账号级别 超级管理员administrator，可以登录控制台，查看所有信息，可以对用户和策略进行操作 监控者monitoring，可以登录控制台，可以查看节点的相关信息，比如进程数，内存磁盘使用情况 策略制定者policymaker，可以登录控制台，制定策略，但是无法查看节点信息 普通管理员management，仅能登录控制台 其他，无法登录控制台，一般指的是提供者和消费者 添加账号命令添加1234rabbitmqctl add_user username password#添加用户和密码rabbitmqctl set_user_tags username Account_level# 给用户一个账号级别，如administrator,monitoring等 网页添加 添加用户 添加后的用户还没有指定可以访问的路径 添加虚拟主机 点击/test进入页面，之后指定用户。这相当于建立了一个用户可以访问的库 集群部署创建并加入集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102==============================================================================================准备三台主机主机名：rabbitmq1 地址：192.168.1.60主机名：rabbitmq2 地址：192.168.1.61主机名：rabbitmq3 地址：192.168.1.62注意事项1. 三台主机互相可以解析主机名，erlang是通过主机名来连接服务，必须保证各个主机名之间可以ping通。2. 三台主机的cookie文件要一致3. 如果queue是非持久化queue，则如果创建queue的那个节点失败，发送方和接收方可以创建同样的queue继续运作。但如果是持久化queue，则只能等创建queue的那个节点恢复后才能继续服务。4. 在集群元数据有变动的时候需要有disk node在线，但是在节点加入或退出的时候所有的disk node必须全部在线。如果没有正确退出disk node，集群会认为这个节点当掉了，在这个节点恢复之前不要加入其它节点。.集群创建流程1. 关闭两个节点的rabbitmq服务2. 第一个节启动rabbitmq服务，将cookie文件与hosts文件复制到另两个节点3. 另两个节点将cookie文件的属主属组改为rabbitmq。启动rabbitmq服务，关闭5672端口，加入集群，再启动5672端口==============================================================================================------------------------ rabbitmq2&amp;3------------------------[root@rabbitmq1 ~]# ps aux|grep rabbit|awk '&#123;print $2&#125;'|xargs kill -9# 杀掉三台主机上的rabbitmq进程----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# systemctl start rabbitmq-server# rabbitmq1上的服务不能关闭[root@rabbitmq1 ~]# scp /var/lib/rabbitmq/.erlang.cookie 192.168.1.61:/var/lib/rabbitmq/ [root@rabbitmq1 ~]# scp /var/lib/rabbitmq/.erlang.cookie 192.168.1.62:/var/lib/rabbitmq/# 将cookie文件传到另两台主机，使三台主机的cookie文件一致[root@rabbitmq1 ~]# vim /etc/hosts192.168.1.60 rabbitmq1192.168.1.61 rabbitmq2192.168.1.62 rabbitmq3[root@rabbitmq1 ~]# scp /etc/hosts 192.168.1.61:/etc/[root@rabbitmq1 ~]# scp /etc/hosts 192.168.1.62:/etc/------------------------ rabbitmq2&amp;3------------------------[root@rabbitmq3 ~]# chown rabbitmq.rabbitmq /var/lib/rabbitmq/.erlang.cookie# cookie文件的属主属组应该是rabbitmq，启动rabbitmq程序的也是rabbitmq用户[root@rabbitmq2 ~]# systemctl start rabbitmq-server.service# 启动两个节点的rabbitmq服务----------------- rabbitmq1-----------------# 下面进行加入集群工作[root@rabbitmq1 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@rabbitmq1 ...[&#123;nodes,[&#123;disc,[rabbit@rabbitmq1]&#125;]&#125;, &#123;running_nodes,[rabbit@rabbitmq1]&#125;, &#123;cluster_name,&lt;&lt;"rabbit@rabbitmq1"&gt;&gt;&#125;, &#123;partitions,[]&#125;]...done.# 在rabbitmq1上查看集群中主机的情况，这时只有一台主机----------------- rabbitmq2-----------------[root@rabbitmq2 ~]# rabbitmqctl stop_appStopping node rabbit@rabbitmq2 ......done.# 关闭应用，也就是关闭了5672端口[root@rabbitmq2 ~]# rabbitmqctl join_cluster rabbit@rabbitmq1Clustering node rabbit@rabbitmq2 with rabbit@rabbitmq1 ......done.# 加入集群，集群名称rabbit@rabbitmq1是在rabbitmq1上查看集群信息显示的[root@rabbitmq2 ~]# rabbitmqctl start_appStarting node rabbit@rabbitmq2 ......done.# 启动应用[root@rabbitmq2 ~]# rabbitmq-plugins enable rabbitmq_management# 两个从节点也一定要启动rabbitmq_management，不然在网页中可以看到两个从节点，但提示"Node statistics not available"----------------- rabbitmq3-----------------[root@rabbitmq3 ~]# rabbitmqctl stop_appStopping node rabbit@rabbitmq3 ......done.[root@rabbitmq3 ~]# rabbitmqctl join_cluster rabbit@rabbitmq1Clustering node rabbit@rabbitmq3 with rabbit@rabbitmq1 ......done.[root@rabbitmq3 ~]# rabbitmqctl start_appStarting node rabbit@rabbitmq3 ......done.[root@rabbitmq3 ~]# rabbitmq-plugins enable rabbitmq_management----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@rabbitmq1 ...[&#123;nodes,[&#123;disc,[rabbit@rabbitmq1,rabbit@rabbitmq2,rabbit@rabbitmq3]&#125;]&#125;, &#123;running_nodes,[rabbit@rabbitmq3,rabbit@rabbitmq2,rabbit@rabbitmq1]&#125;, &#123;cluster_name,&lt;&lt;"rabbit@rabbitmq1"&gt;&gt;&#125;, &#123;partitions,[]&#125;]...done.# 这时可以看到三台主机在集群中，[&#123;nodes,[&#123;disc,[rabbit@rabbitmq1,rabbit@rabbitmq2,rabbit@rabbitmq3]&#125;]&#125;,中的disc表示三个节点都是磁盘节点，后面是节点的名称。 改变存储模式12345678910111213141516171819202122232425-------------------- rabbitmq1&amp;2--------------------[root@rabbitmq1 ~]# rabbitmqctl stop_appStopping node rabbit@rabbitmq1 ......done.[root@rabbitmq1 ~]# rabbitmqctl change_cluster_node_type ramTurning rabbit@rabbitmq1 into a ram node ......done.# 改两个节点为内存节点，ram表示内存节点，disc表示磁盘节点[root@rabbitmq1 ~]# rabbitmqctl start_appStarting node rabbit@rabbitmq1 ......done.----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@rabbitmq1 ...[&#123;nodes,[&#123;disc,[rabbit@rabbitmq3]&#125;,&#123;ram,[rabbit@rabbitmq2,rabbit@rabbitmq1]&#125;]&#125;, &#123;running_nodes,[rabbit@rabbitmq2,rabbit@rabbitmq3,rabbit@rabbitmq1]&#125;, &#123;cluster_name,&lt;&lt;"rabbit@rabbitmq1"&gt;&gt;&#125;, &#123;partitions,[]&#125;]...done.# 这时可以看到节点3为磁盘节点，另外两个为内存节点 退出集群12345678910111213141516171819202122232425262728----------------- rabbitmq2-----------------[root@rabbitmq2 ~]# rabbitmqctl stop_appStopping node rabbit@rabbitmq2 ......done.[root@rabbitmq2 ~]# rabbitmqctl resetResetting node rabbit@rabbitmq2 ......done.[root@rabbitmq2 ~]# rabbitmqctl start_appStarting node rabbit@rabbitmq2 ......done.----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# rabbitmqctl forget_cluster_node rabbit@rabbitmq2Removing node rabbit@rabbitmq2 from cluster ...Error: &#123;not_a_cluster_node,"The node selected is not in the cluster."&#125;# 移除节点时会有一个错误提示："选定的节点不在群集中。"[root@rabbitmq1 ~]# rabbitmqctl cluster_status Cluster status of node rabbit@rabbitmq1 ...[&#123;nodes,[&#123;disc,[rabbit@rabbitmq3]&#125;,&#123;ram,[rabbit@rabbitmq1]&#125;]&#125;, &#123;running_nodes,[rabbit@rabbitmq3,rabbit@rabbitmq1]&#125;, &#123;cluster_name,&lt;&lt;"rabbit@rabbitmq1"&gt;&gt;&#125;, &#123;partitions,[]&#125;]...done.# 再查看已经没有rabbitmq2节点了 集群重启123456789101112131415# 集群重启时，最后一个挂掉的节点应该第一个重启，如果因特殊原因（比如同时断电），而不知道哪个节点最后一个挂掉。可用以下方法重启：* 先在一个节点上执行rabbitmqctl force_bootservice rabbitmq-server start* 在其他节点上执行service rabbitmq-server start* 查看cluster状态是否正常（要在所有节点上查询）。rabbitmqctl cluster_status # 如果有节点没加入集群，可以先退出集群，然后再重新加入集群。# 上述方法不适合内存节点重启，内存节点重启的时候是会去磁盘节点同步数据，如果磁盘节点没起来，内存节点一直失败。 配置镜像队列12345678910111213141516171819202122232425----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# rabbitmqctl list_queuesListing queues ......done.# 查看队列[root@rabbitmq1 ~]# rabbitmqctl eval 'rabbit_amqqueue:declare(&#123;resource,&lt;&lt;"/"&gt;&gt;,queue,&lt;&lt;"hello"&gt;&gt;&#125;,true,false,[],none).'&#123;new,&#123;amqqueue,&#123;resource,&lt;&lt;"/"&gt;&gt;,queue,&lt;&lt;"hello"&gt;&gt;&#125;, true,false,none,[],&lt;5370.11741.0&gt;,[],[],undefined,[],[]&#125;&#125;...done.# 创建一个叫hello的队列[root@rabbitmq1 ~]# rabbitmqctl list_queuesListing queues ...hello 0test 0...done.# 现在可以看到两个队列，test队列是在web页面上创建的，相对简单，只要在queues页面中添加一个队列，输入队列名即可完成简单的创建。[root@rabbitmq1 ~]# rabbitmqctl set_policy ha-all "test" '&#123;"ha-mode":"all"&#125;' Setting policy "ha-all" for pattern "test" to "&#123;\"ha-mode\":\"all\"&#125;" with priority "0" ......done.# 把名为“test”的队列设置为同步给所有节点# ha-all 是同步模式，指同步给所有节点，还有另外两种模式ha-exactly表示在指定个数的节点上进行镜像，节点的个数由ha-params指定，ha-nodes表示在指定的节点上进行镜像，节点名称通过ha-params指定；# test 是同步的队列名，可以用正则表达式匹配；# &#123;"ha-mode":"all"&#125; 表示同步给所有，同步模式的不同，此参数也不同。 执行上面命令后，可以在web管理界面查看queue 页面，里面test队列的node节点后会出现+2标签，表示有2个从节点，而主节点则是当前显示的node。而hello因为没有设置镜像队列，所以没有+2标签。 创建帐户123456789101112131415161718192021222324252627282930313233343536373839----------------- rabbitmq2-----------------[root@rabbitmq2 ~]# rabbitmqctl stop_appStopping node rabbit@rabbitmq2 ......done.[root@rabbitmq2 ~]# rabbitmqctl join_cluster rabbit@rabbitmq1Clustering node rabbit@rabbitmq2 with rabbit@rabbitmq1 ......done.[root@rabbitmq2 ~]# rabbitmqctl start_appStarting node rabbit@rabbitmq2 ......done.# 先将rabbitmq2加入集群----------------- rabbitmq1-----------------[root@rabbitmq1 ~]# rabbitmqctl add_user test centosCreating user "test" ......done.# 创建一个叫test的用户，密码是centos[root@rabbitmq1 ~]# rabbitmqctl set_user_tags test administratorSetting tags for user "test" to [administrator] ......done.# 给test用户添加一个管理员的角色[root@rabbitmq1 ~]# rabbitmqctl set_permissions -p / test ".*" ".*" ".*"Setting permissions for user "test" in vhost "/" ......done.# 在根虚拟机里设置test用户配置权限、写权限、读权限。.*是正则表达式。rabbitmq的权限是根据不同的虚拟主机（virtual hosts）配置的，同用户在不同的虚拟主机（virtual hosts）里可能不一样。--------------------- rabbitmq2&amp;3---------------------[root@rabbitmq2 ~]# rabbitmqctl list_usersListing users ...guest [administrator]test [administrator]...done.# 因为是集群，只要在一台主机设置即可，其它会自动同步。 问题Node statistics not available 12345678910111213141516# 显示Node statistics not available是因为节点的web插件未启用--------------------- rabbitmq2&amp;3---------------------[root@rabbitmq2 ~]# rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementPlugin configuration has changed. Restart RabbitMQ for changes to take effect.[root@rabbitmq2 ~]# systemctl restart rabbitmq-server.service# 需要重新启动才能生效# 如果不能启动插件，可以先rabbitmqctl stop_app，之后再添加]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>RabbitMQ部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk内置函数]]></title>
    <url>%2F2018%2F10%2F17%2Fawk%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[awk内置函数算数函数rand函数1234567[root@bogon ~]# awk 'BEGIN&#123;print rand()&#125;'0.237788[root@bogon ~]# awk 'BEGIN&#123;print rand()&#125;'0.237788[root@bogon ~]# awk 'BEGIN&#123;print rand()&#125;'0.237788# 单纯的使用rand函数，生成的值是不变的 srand函数1234567[root@bogon ~]# awk 'BEGIN&#123;srand();print rand()&#125;'0.121122[root@bogon ~]# awk 'BEGIN&#123;srand();print rand()&#125;'0.665691[root@bogon ~]# awk 'BEGIN&#123;srand();print rand()&#125;'0.383723# 配合srand函数使用rand函数就可以生成小于1的随机数了 int函数1234567[root@bogon ~]# awk 'BEGIN&#123;srand();print rand()&#125;'0.999933[root@bogon ~]# awk 'BEGIN&#123;srand();print 100*rand()&#125;'72.6895[root@bogon ~]# awk 'BEGIN&#123;srand();print int(100*rand())&#125;'82# 使用int函数最后截取出一个整数，第二步后要取出多少位的值就乘以多少 字符串函数gsub函数123456789101112131415161718192021222324252627[root@bogon ~]# cat test4Allen PhillipsGreen LeeWilliam Aiden James LeeAngel JackTyler KevinLucas ThomasKevin[root@bogon ~]# awk '&#123;gsub("l","L",$1);print $0&#125;' test4ALLen PhillipsGreen LeeWiLLiam Aiden James LeeAngeL JackTyLer KevinLucas ThomasKevin# 使用gsub函数，将小写字母"l"替换成大写字母"L"，但是替换的范围只限于"$1"，所以，当我们再次输出文本时，发现只有文本中的第一列中的小写字母"l"被替换成了大写字母"L"，其他列中的小写字母"l"并未被替换。如果想要替换文本中所有的小写字母"l"，则可以将上图中的"$1"换成"$0"，或者省略gsub函数中的第三个参数，省略gsub中的第三个参数时，默认为"$0"[root@bogon ~]# awk '&#123;gsub("[a-z]","6",$1);print $0&#125;' test4A6666 PhillipsG6666 LeeW666666 Aiden James LeeA6666 JackT6666 KevinL6666 ThomasK6666# 通过正则表达式进行匹配，这里将第一列中的小写字母都替换成了6 sub函数123456789[root@bogon ~]# awk '&#123;sub("l","L",$1);print $0&#125;' test4ALlen PhillipsGreen LeeWiLliam Aiden James LeeAngeL JackTyLer KevinLucas ThomasKevin# sub函数只会替换指定范围内第一次匹配到的符合条件的字符。 length函数1234567891011121314151617181920212223242526[root@bogon ~]# awk '&#123;for(i=1;i&lt;=NF;i++)&#123;print $i,length($i)&#125;&#125;' test4Allen 5Phillips 8Green 5Lee 3William 7Aiden 5James 5Lee 3Angel 5Jack 4Tyler 5Kevin 5Lucas 5Thomas 6Kevin 5# 通过length函数，获取到指定字符串的长度。[root@bogon ~]# awk '&#123;print $0,length()&#125;' test4Allen Phillips 14Green Lee 9William Aiden James Lee 23Angel Jack 10Tyler Kevin 11Lucas Thomas 12Kevin 5# length函数可以省略传入的参数，即不指定任何字符串，当省略参数时，默认使用"$0"作为参数 index函数123456789[root@bogon ~]# awk '&#123;print index($0,"Lee")&#125;' test407210000# 使用index函数，在每一行中找字符串"Lee"，如果Lee存在于当前行，则返回字符串Lee位于当前行的位置，如果Lee不存在于当前行，则返回0，表示当前行并不存在Lee，如上，第二行中包含Lee，而且Lee位于第二行的第7个字符的位置，所以返回数字7 split函数12345678910111213[root@bogon ~]# awk -v ts="大鹏:少松:老董" 'BEGIN&#123;split(ts,test,":");for(i in test)&#123;print test[i]&#125;&#125;'大鹏少松老董# 通过split函数，将字符串ts切割，以":"作为分割符，将分割后的字符串保存到了名为test的数组中，当我们输出数组中的元素时，每个元素的值为分割后的字符，其实，split函数也有对应的返回值，其返回值就是分割以后的数组长度[root@bogon ~]# awk -v ts="大鹏:少松:老董" 'BEGIN&#123;print split(ts,test,":")&#125;'3# 被split函数分割后的数组的元素下标从1开始，不像其他语言中的数组下标是从0开始的，而且数组中元素输出的顺序可能与字符串中字符的顺序不同[root@bogon ~]# awk -v ts="大鹏:少松:老董" 'BEGIN&#123;ruo=split(ts,test,":");for(i=1;i&lt;=ruo;i++)&#123;print i,test[i]&#125;&#125;'1 大鹏2 少松3 老董# 使用for(i=1;i&lt;=ruo;i++)这样的循环语句，才能按顺序输出内容 其他函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* asort# asort 函数可以根据元素的值进行排序[root@bogon ~]# awk 'BEGIN&#123;t["a"]=66;t["b"]=88;t["c"]=3;for(i in t)&#123;print i,t[i]&#125;&#125;'a 66b 88c 3[root@bogon ~]# awk 'BEGIN&#123;t["a"]=66;t["b"]=88;t["c"]=3;asort(t);for(i in t)&#123;print i,t[i]&#125;&#125;'1 32 663 88# 数组中元素的值均为数字，但是下标为自定义的字符串，通过asort函数对数组排序后，再次输出数组中的元素时，已经按照元素的值的大小进行了排序，但是，数组的下标也被重置为了纯数字。[root@bogon ~]# awk 'BEGIN&#123;t["a"]=66;t["b"]=88;t["c"]=3;asort(t,newt);for(i in t)&#123;print i,t[i]&#125;&#125;'a 66b 88c 3[root@bogon ~]# awk 'BEGIN&#123;t["a"]=66;t["b"]=88;t["c"]=3;asort(t,newt);for(i in newt)&#123;print i,newt[i]&#125;&#125;'1 32 663 88# 对原数组元素值排序的同时，创建一个新的数组，将排序后的元素放置在新数组中。上面两条命令一条打印源数组的值，一条打印新数组的值。[root@bogon ~]# awk 'BEGIN&#123;t["a"]=66;t["b"]=88;t["c"]=3;len=asort(t,newt);for(i=1;i&lt;=len;i++)&#123;print i,newt[i]&#125;&#125;'1 32 663 88# asort函数也有返回值，它的返回值就是数组的长度。这里将asort的返回值保存在了len中* asorti# asorti 函数可以根据元素的下标进行排序[root@bogon ~]# awk 'BEGIN&#123;t["z"]=66;t["q"]=88;t["a"]=3;for(i in t)&#123;print i,t[i]&#125;&#125;'z 66a 3q 88[root@bogon ~]# awk 'BEGIN&#123;t["z"]=66;t["q"]=88;t["a"]=3;len=asorti(t,newt);for(i=1;i&lt;=len;i++)&#123;print i,newt[i]&#125;&#125;'1 a2 q3 z# asorti 函数根据数组t的下标排序后，创建了一个新的数组newt，newt中元素的值即为t数组下标的值，上例中，我们使用len变量保存了asorti函数的返回值，并且输出了最后排序后的新数组。[root@bogon ~]# awk 'BEGIN&#123;t["z"]=66;t["q"]=88;t["a"]=3;len=asorti(t,newt);for(i=1;i&lt;=len;i++)&#123;print i,newt[i]&#125;&#125;'1 a2 q3 z[root@bogon ~]# awk 'BEGIN&#123;t["z"]=66;t["q"]=88;t["a"]=3;len=asorti(t,newt);for(i=1;i&lt;=len;i++)&#123;print i,t[newt[i]]&#125;&#125;'1 32 883 66# 根据排序后的下标再次输出对应的元素值，从而达到根据数组下标排序后，输出原数组元素的目的。新数组负责排序老数组的下标，并将排序后的下标作为新数组的元素，而我们输出新数组元素的同时，又将新数组的元素值作为老数组下标，从而输出了老数组中的元素值]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>awk内置函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk数组]]></title>
    <url>%2F2018%2F10%2F17%2Fawk%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[awk数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129[root@bogon ~]# awk 'BEGIN&#123;test[0]="大鹏";test[1]="少松";test[2]="老董";print test[1]&#125;'少松# 为数组中的元素赋值，下标从0开始。最后打印数组中的第二个元素。awk的数组默认从1开始。[root@bogon ~]# awk 'BEGIN&#123;test[0]="大鹏";test[1]="少松";test[2]="老董";test[3]="正伟";test[4]="法林";test[5]="";print test[5]&#125;'# 上面test[5]设置为了空字符串，在awk中也是被允许的，所以可以打印出一个空行[root@bogon ~]# awk 'BEGIN&#123;test[0]="大鹏";test[1]="少松";test[2]="老董";test[3]="正伟";test[4]="法林";test[5]="";print test[6]&#125;'# 在引用一个不存在的数组元素也是可以的，会打印出一个空字符串。* 语法 if(下标 in 数组名) # 判断数组中是否存在对应的元素 delete # 删除整个数组 * 使用数字为下标[root@bogon ~]# awk 'BEGIN&#123;test[0]="大鹏";test[1]="少松";test[2]="老董";test[3]="正伟";test[4]="法林";test[5]="";if(6 in test)&#123;print "数组的第7个元素存在即可看到"&#125;&#125;'# 如果下标是6的元素存在，就会打印后面的一段话[root@bogon ~]# awk 'BEGIN&#123;test[0]="大鹏";test[1]="少松";test[2]="老董";test[3]="正伟";test[4]="法林";test[5]="";if(!(6 in test))&#123;print "数组的第7个元素不存在即可看到"&#125;&#125;'数组的第7个元素不存在即可看到# 也可以取反* 以字符串为下标[root@bogon ~]# awk 'BEGIN&#123;test["a"]="大鹏";test["b"]="少松";test["cc"]="老董";test["fe"]="正伟";test["ews"]="法林";test["adg"]="";&#123;print test["ews"]&#125;&#125;'法林# 还可以使用字符串作为下标，但字符串两侧一个要有双引号* 删除[root@bogon ~]# awk 'BEGIN&#123;test["a"]="大鹏";test["b"]="少松";test["cc"]="老董";test["fe"]="正伟";test["ews"]="法林";test["adg"]="";print test["ews"];delete test;&#123;print test["ews"]&#125;&#125;'法林# 在delete前的print可以打印出内容，经过delete删除数组后，就没法打印出同样数据元素的内容了* 打印所有元素[root@bogon ~]# awk 'BEGIN&#123;test[1]="大鹏";test[2]="少松";test[3]="老董";test[4]="正伟";test[5]="法林";test[6]="";for (i=1;i&lt;=6;i++)&#123;print i,test[i]&#125;&#125;'1 大鹏2 少松3 老董4 正伟5 法林6 # 这种for循环只能输出以数字为下标的数组[root@bogon ~]# awk 'BEGIN&#123;test["a"]="大鹏";test["b"]="少松";test["cc"]="老董";test["fe"]="正伟";test["ews"]="法林";test["adg"]="";for(i in test)&#123;print i,test[i]&#125;&#125;'cc 老董a 大鹏b 少松fe 正伟ews 法林adg # for循环中的变量"i"表示的是元素的下标，而并非表示元素的值，所以，如果想要输出元素的值，则需要使用"print 数组名[变量]"[root@bogon ~]# awk 'BEGIN&#123;test[1]="大鹏";test[2]="少松";test[3]="老董";test[4]="正伟";test[5]="法林";test[6]="";for (i in test)&#123;print i,test[i]&#125;&#125;'4 正伟5 法林6 1 大鹏2 少松3 老董# 使用这种for循环，是不能按数字顺序打印元素的，因为数字被转换成了字符串。awk中的数组本质上就是关联数组* 统计次数[root@bogon ~]# awk 'BEGIN&#123;a=1;print a;a=a+1;print a&#125;'12# 将变量a的值设置为1，进行加法计算，每次自加后，再次打印变量a的值，都会加1。a=a+1可以写为a++[root@bogon ~]# awk 'BEGIN&#123;a="test";print a;a=a+1;print a;a++;print a&#125;'test12# 字符串两侧一定要有双引号。字符串也可以进行运算，如果参与运算，字符串将被当做数字0进行运算[root@bogon ~]# awk 'BEGIN&#123;a="";print a;a=a+1;print a;a++;print a&#125;'12# 空字符串也可以当做0进行运算[root@bogon ~]# awk 'BEGIN&#123;print test["i"];test["i"]++;print test["i"]&#125;'1# 不存在的字符串也可以参与运算，因为不存在的字符串会被赋值为空字符串[root@bogon ~]# cat test5192.168.1.123 192.168.1.124 192.168.1.123 192.168.1.123192.168.1.124192.168.2.222172.16.100.3172.16.100.3172.16.100.3172.16.100.3172.16.100.3172.16.100.3192.168.1.15172.16.100.7[root@bogon ~]# awk '&#123;count[$1]++&#125;END&#123;for(i in count)&#123;print i,count[i]&#125;&#125;' test5172.16.100.3 6192.168.2.222 1172.16.100.7 1192.168.1.123 3192.168.1.124 2192.168.1.15 1# 使用空模式与END模式，空模式中，我们随便创建了一个数组，并且将IP地址作为引用元素的下标，进行引用，所以，当执行到第一行时，我们引用的是count["192.168.1.123"]，这个元素并不存在，所以，当第一行被空模式中的动作处理完毕后，count["192.168.1.123"]的值已经被赋值为1了。这时，空模式中的动作继续处理下一行，而下一行的IP地址为192.168.1.124，所以，count["192.168.1.124"]第一次参与运算的过程与上述过程一样。其他IP地址第一次参与运算的过程与上述过程也一样。直到再次遇到相同的IP地址时，使用同样一个IP地址作为下标的元素将会再次被自加，每次遇到相同的IP地址，对应元素的值都会加1。直到处理完所有行，开始执行END模式中的动作。而END模式中，我们打印出了count数组中的所有元素的下标，以及元素对应的值。此刻，count数组中的下标即为IP地址，元素的值即为对应IP地址出现的次数。# 我们对一个不存在的元素进行自加运算后，这个元素的值就变成了自加运算的次数[root@bogon ~]# cat test4Allen PhillipsGreen LeeWilliam Aiden James LeeAngel JackTyler KevinLucas ThomasKevin[root@bogon ~]# awk '&#123;for(i=1;i&lt;=NF;i++)&#123;count[$i]++&#125;&#125;END&#123;for(s in count)&#123;print s,count[s]&#125;&#125;' test4Tyler 1Angel 1James 1Lucas 1William 1Thomas 1Green 1Jack 1Phillips 1Kevin 2Lee 2Allen 1Aiden 1# 此命令与上面计算IP地址出现次数的命令同理，只是文件中比上面的文件多了几列，所以先将每列的内容赋值给count，NF就表示一共有几列，这会先将第一列的内容赋值给count，之后第二列第三列，但不会超过每行的总列数。理解了前半部分命令，END后面的动作就和上面的命令意思一样了。这里count[$i]赋值后就会变为count[Tyler]、count[Angel]等，然后给这个元素赋值，因为这是一个不存在的数组，并且空模式处理后会自加，所以赋值从1开始，也就是count[Tyler]=1、count[Angel]=1等，这个数字实际也就是最后要计算的次数了]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>awk数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk动作]]></title>
    <url>%2F2018%2F10%2F17%2Fawk%E5%8A%A8%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[awk动作 输出语句 组合语句 条件判断控制语句 循环控制语句 12345678910111213141516171819202122[root@bogon ~]# awk '&#123;print $0&#125;' test2heyheeyheeeyheeeey# &#123;&#125;与print $0是两个动作。"print"属于"输出语句"类型的动作，"输出语句"类型的动作的作用就是输出、打印信息。"&#123; &#125;"属于"组合语句"类型的动作，组合语句"类型的动作的作用就是将多个代码组合成代码块。[root@bogon ~]# cat testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei[root@bogon ~]# awk '&#123;print $1&#125;&#123;print $2&#125;' testabc345123klj# 使用了两个大括号"&#123; &#125;"，它们属于"组合语句"类型的动作，它们分别将两个print括住，表示这两个print动作分别作为两个独立的个体。先打印$1再打印$2[root@bogon ~]# awk '&#123;print $1;print $2&#125;' testabc345123klj# 将上面的动作组合在一起。当我们把多个动作（多段代码）组合成一个代码块的时候，每段动作（每段代码）之间需要用分号";"隔开 条件判断控制语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687* 语法 if(条件) &#123; 语句1; 语句2; ... &#125; [root@bogon ~]# awk '&#123;if(NR == 1)&#123;print $0&#125;&#125;' testabc 345 ssd asdf lkj;l# 一定要将动作写在&#123;&#125;中，控制语句也要有&#123;&#125;，所以这里有两个&#123;&#125;，if语句中的大括号中，也可以执行多个动作。将行号是1的行打印出来。[root@bogon ~]# awk '&#123;if(NR == 1)&#123;print $1;print $2&#125;&#125;' testabc345# 如果行号是1，就打印第一列再打印第二列[root@bogon ~]# awk '&#123;if(NR == 1)print $1&#125;' testabc# 如果if后的动作只有一个，那么也可以不写&#123;&#125;* 语法 "if...else..."的语法如下： if(条件) &#123; 语句1; 语句2; ... &#125; else &#123; 语句1; 语句2; ... &#125; "if...else if...else"的语法如下： if(条件1) &#123; 语句1; 语句2; ... &#125; else if(条件2) &#123; 语句1; 语句2; ... &#125; else &#123; 语句1; 语句2; ... &#125;[root@bogon ~]# awk -F":" '&#123;if($3 &lt; 1000)&#123;print $1,"系统用户"&#125;else&#123;print $1,"普通用户"&#125;&#125;' /etc/passwdroot 系统用户bin 系统用户daemon 系统用户adm 系统用户lp 系统用户sync 系统用户shutdown 系统用户halt 系统用户mail 系统用户operator 系统用户games 系统用户ftp 系统用户nobody 系统用户systemd-network 系统用户dbus 系统用户polkitd 系统用户postfix 系统用户sshd 系统用户openvpn 系统用户ruopu 普通用户# 对/etc/passwd文件中的用户做判断，用户ID小于1000的为系统用户，否则就是普通用户[root@bogon ~]# cat test7姓名 年龄aaa 18bbb 66ccc 36[root@bogon ~]# awk 'NR !=1&#123;if($2&lt;=30)&#123;print $1,"年轻人"&#125;else if($2&gt;=30 &amp;&amp; $2&lt;=50)&#123;print $1,"中年人"&#125;else&#123;print $1,"老年人"&#125;&#125;' test7aaa 年轻人bbb 老年人ccc 中年人# 首先忽略第一行，然后判断文件中第二列的年龄，最后打印出结果 三元运算12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455* 语法条件?结果1:结果2# 如果条件成立，则返回结果1，如果条件不成立，则返回结果2。表达式1 ? 表达式2 : 表达式3# 如果表达式1为真，则执行表达式2，如果表达式1为假，则执行表达式3[root@bogon ~]# awk -F: '&#123;if($3 &lt; 1000)&#123;usertype="系统用户"&#125;else&#123;usertype="普通用户"&#125;;print $1,usertype&#125;' /etc/passwdroot 系统用户bin 系统用户daemon 系统用户adm 系统用户lp 系统用户sync 系统用户shutdown 系统用户halt 系统用户mail 系统用户operator 系统用户games 系统用户ftp 系统用户nobody 系统用户systemd-network 系统用户dbus 系统用户polkitd 系统用户postfix 系统用户sshd 系统用户openvpn 系统用户ruopu 普通用户# 使用"if...else"结构，对usertype变量进行了赋值，如果用户的UID小于1000，则对usertype变量赋值为"系统用户"，否则赋值usertype变量为"普通用户"，最后打印出用户名所在的列与usertype变量的值。[root@bogon ~]# awk -F: '&#123;usertype=$3&lt;1000?"系统用户":"普通用户";print $1,usertype&#125;' /etc/passwdroot 系统用户bin 系统用户daemon 系统用户adm 系统用户lp 系统用户sync 系统用户shutdown 系统用户halt 系统用户mail 系统用户operator 系统用户games 系统用户ftp 系统用户nobody 系统用户systemd-network 系统用户dbus 系统用户polkitd 系统用户postfix 系统用户sshd 系统用户openvpn 系统用户ruopu 普通用户# "$3&lt;1000"就是语法中的"条件"，"系统用户"就是语法中"?"后面的"结果1"，"普通用户"就是语法中":"后面的"结果2" ，同时，在上例中我们使用usertype变量接收了三元运算后的返回值，所以，当条件成立时，usertype变量被赋值为"系统用户"，当条件不成立时，usertype变量被赋值为"普通用户"。[root@bogon ~]# awk -F: '&#123;$3&lt;1000?a++:b++&#125;END&#123;print a,b&#125;' /etc/passwd19 1# "$3&lt;1000"即为表达式1，"a++"即为表达式2，"b++"即为表达式3。当每遇到一个UID小于1000的用户，我就对变量a加1，否则我就对变量b加1，从而算出了系统用户与普通用户的数量，最后再END模式中输出了变量a与变量b的值。 循环控制语句12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394* 语法 # for循环语法格式1 for(初始化; 布尔表达式; 更新) &#123; //代码语句 &#125; # for循环语法格式2 for(变量 in 数组) &#123; //代码语句 &#125; # while循环语法 while( 布尔表达式 ) &#123; //代码语句 &#125; # do...while循环语法 do &#123; //代码语句 &#125;while(条件)[root@bogon ~]# awk 'BEGIN&#123;for(i=1;i&lt;=6;i++)&#123;print i&#125;&#125;'123456[root@bogon ~]# awk -v i=1 'BEGIN&#123;while(i&lt;=5)&#123;print i;i++&#125;&#125;'12345[root@bogon ~]# awk 'BEGIN&#123;i=1;while(i&lt;=5)&#123;print i;i++&#125;&#125;'12345[root@bogon ~]# awk 'BEGIN&#123;i=1;do&#123;print "test";i++&#125;while(i&lt;1)&#125;'test[root@bogon ~]# awk 'BEGIN&#123;i=1;do&#123;print "test";i++&#125;while(i&lt;11)&#125;'testtesttesttesttesttesttesttesttesttest# 不论如何，先执行一次do后面的动作* 跳出循环语法 continue的作用：跳出"当前"循环 break的作用：跳出"整个"循环[root@bogon ~]# awk 'BEGIN&#123;for(i=0;i&lt;6;i++)&#123;if(i==3)&#123;continue&#125;;print i&#125;&#125;'01245# 先设置i在0到6之前循环，再判断，如果i等于3就跳过此次循环。if动作是for循环的一部分。也就是for()&#123;if()&#123;&#125;&#125;[root@bogon ~]# awk 'BEGIN&#123;for(i=0;i&lt;6;i++)&#123;if(i==3)&#123;break&#125;;print i&#125;&#125;'012# break可以跳出整个循环# continue与break同样可以用于while循环与do...while循环，此处就不再赘述了。* 退出 exit next [root@bogon ~]# awk 'BEGIN&#123;print 1;exit;print 2;print 3&#125;'1# 使用exit会跳出整个脚本，所以没有打印2和3[root@bogon ~]# awk 'BEGIN&#123;print "start";exit&#125;&#123;print $0&#125;END&#123;print "over"&#125;' teststartover# exit并不会跳出awk命令，遇到exit后，之后的命令都不执行，它会直接执行END模式的动作。如果没有END模式，将直接退出整个awk命令。[root@bogon ~]# cat test8123[root@bogon ~]# awk '&#123;if(NR==2)&#123;next&#125;;print $0&#125;' test813# next命令可以促使awk不对当前行执行对应的动作，而是直接处理下一行。next与continue有些类似，只是，continue是针对"循环"而言的，continue的作用是结束"本次循环"，而next是针对"逐行处理"而言的，next的作用是结束"对当前行的处理"，从而直接处理"下一行"]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>awk动作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk模式]]></title>
    <url>%2F2018%2F10%2F17%2Fawk%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[awk模式 BEGIN/END模式 关系表达式模式 空模式 正则模式 行范围模式 模式也可以理解为条件。不指定任何”条件”，awk会一行一行的处理文本中的每一行。指定了”条件”，只有满足”条件”的行才会被处理，不满足”条件”的行就不会被处理。 关系表达式模式 关系运算符 含义 用法示例 &lt; 小于 x &lt; y &lt;= 小于等于 x &lt;= y == 等于 x == y != 不等于 x != y &gt;= 大于等于 x &gt;= y &gt; 大于 x &gt; y ~ 与对应的正则匹配则为真 x ~ /正则/ !~ 与对应的正则不匹配则为真 x !~ /正则/ 123456789101112131415[root@bogon ~]# cat testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei[root@bogon ~]# awk 'NF==5 &#123;print $0&#125;' testabc 345 ssd asdf lkj;l# 打印正好有五列的行。这里的条件就是这一行一共有五列[root@bogon ~]# awk 'NF&gt;2&#123;print $0&#125;' testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei[root@bogon ~]# awk 'NF&lt;=4 &#123;print $0&#125;' test# 文件中没有小于等于四列的行[root@bogon ~]# awk '$1==123 &#123;print $0&#125;' test123 klj adf daff adeills adsfei# 一定要用两个等号 空模式1234[root@bogon ~]# awk '&#123;print $0&#125;' testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei# 没有使用模式实际是使用的空模式，"空模式"会匹配文本中的每一行，所以，每一行都满足"条件" 打印奇偶行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113[root@bogon ~]# cat test9123456789101112[root@bogon ~]# awk 'i=!i' test91357911[root@bogon ~]# awk '!(i=!i)' test924681012# 当awk开始处理第一行时，变量 i 被初始化，变量 i 在被初始化时，值为"空"，而awk中，数字0或者"空字符串"表示假，所以可以认为模式为假，但是 i 直接取反了，对假取反后的值为真，将取反后的值又赋值给了变量i，此刻，变量i的值为真，所以当awk处理第一行文本时，变量i的值被赋值为真，模式成立则需要执行对应的动作，而上例中又省略了动作，所以默认动作为"&#123;print $0&#125;"，所以，第一行被整行打印了。当第一行文本处理完毕后，awk开始处理第二行文本，此时，i 为真，但是取反后，i 为假，所以第二行没有被输出，依次类推，最终只打印了奇数行。打印偶数行同理，只是从第一次就让i为空字符串为假* 知识点# 在awk中，如果省略了模式对应的动作，当前行满足模式时，默认动作为打印整行，即&#123;print $0&#125;。# 在awk中，0或者空字符串表示"假"，非0值或者非空字符串表示"真"* 解析[root@bogon ~]# awk '/1/&#123;print $0&#125;' test91101112# 如果当前行中包含字符"1"，则执行对应的动作，而对应的动作就是打印整行。root@ccjd:~# awk '/regi/&amp;&amp;/mi/&amp;&amp;/192/&#123;print $0&#125;' daemon.json | head "registry-mirrors":["http://192.168.0.198:80"],# 也可以通过&amp;&amp;符号指定多个条件，需要同时满足才可以。[root@bogon ~]# awk '$1&gt;10&#123;print $0&#125;' test91112# 如果test9文本中文本行的第一列的值如果大于10，则打印整行。[root@bogon ~]# awk '/1/' test91101112[root@bogon ~]# awk '$1&gt;10' test91112# 当使用了模式时，如果省略了模式对应的动作，默认动作为"&#123;print $0&#125;"，"空模式"与"BEGIN/END模式"除外。[root@bogon ~]# cat test2heyheeyheeeyheeeey[root@bogon ~]# awk '&#123;print $0&#125;' test2heyheeyheeeyheeeey[root@bogon ~]# awk '1&#123;print $0&#125;' test2heyheeyheeeyheeeey[root@bogon ~]# awk '2&#123;print $0&#125;' test2heyheeyheeeyheeeey[root@bogon ~]# awk '2' test2heyheeyheeeyheeeey[root@bogon ~]# awk '0&#123;print $0&#125;' test2[root@bogon ~]# awk '0' test2# 第一条awk命令使用了"空模式"，也就是说，每一行都满足模式，每一行经过"空模式"匹配以后结果都是"真"，所以每一行都会执行对应的动作。第二条awk命令原来"模式的位置"被替换为了数字"1"，我们可以把数字"1"理解成一种模式匹配后的结果，而1是非零值，在awk中非零值表示真，所以，"1"表示"真"， 换句话说就是模式的匹配结果为真，模式成立则会执行对应的动作，也就是打印整行。第三条awk命令与第二条awk命令同理，动作前的数字可以换为任何非0数字或非空字符串。第四条awk命令数字"2"为非零值，表示模式为真，当使用模式时，可以省略动作，当使用模式并省略动作时，默认动作为打印整行，所以，第四条awk命令表示打印所有行，因为每一行的模式都为真。第五条awk命令与第六条awk命令因为数字"0"与空字符串表示假，当模式为假时，不会执行对应的动作，而当存在模式并省略动作时，默认动作为打印整行，但是由于模式为假，所以对应的动作并未执行。# 理解了此处，再看上面打印奇偶行就容易理解了[root@bogon ~]# awk '!0' test2heyheeyheeeyheeeey[root@bogon ~]# awk '!5' test2# 还能对真与假进行取反，非真即为假，非假即为真[root@bogon ~]# awk 'i=1' test2heyheeyheeeyheeeey[root@bogon ~]# awk 'i=a' test2[root@bogon ~]# awk 'i="a"' test2heyheeyheeeyheeeey[root@bogon ~]# awk 'i=0' test2[root@bogon ~]# awk 'i=""' test2# 使用了awk的变量，将变量 i赋值为1，当 i=1 以后，i为非零值，表示为真，我们可以认为这是一种模式匹配后的结果，当模式为真时，同时省略了对应动作时，默认动作为打印整行，所以上例会输出test2中的所有行。[root@bogon ~]# awk '&#123;i=!i;print i&#125;' test21010# 打印出处理每一行时，i 对应的值。 正则模式12345678910111213141516171819202122232425262728293031323334353637383940414243# 把"正则表达式"当做"条件"，能与正则匹配的行，就算满足条件，满足条件的行才会执行对应的动作，不能被正则匹配到的行，则不会执行对应的动作。语法awk '/正则表达式/&#123;动作&#125;' 文件[root@bogon ~]# grep "^ruo" /etc/passwdruopu:x:1000:1000::/home/ruopu:/bin/bash[root@bogon ~]# awk '/^ruo/&#123;print $0&#125;' /etc/passwdruopu:x:1000:1000::/home/ruopu:/bin/bash[root@bogon ~]# awk -F":" 'BEGIN&#123;printf "%-10s%-10s\n","用户名","用户ID"&#125; /^ruo/&#123;printf "%-10s\t%-10s\n",$1,$3&#125;' /etc/passwd用户名 用户ID ruopu 1000# 从/etc/passwd文件中找出符合条件的行（用户名以ruo开头的用户）；找出符合条件的文本行以后，以":"作为分隔符，将文本行分段；取出我们需要的字段，格式化输出；结合BEGIN模式，输出一个格式化以后的文本，提高可读性[root@bogon ~]# grep "/bin/bash" /etc/passwdroot:x:0:0:root:/root:/bin/bashruopu:x:1000:1000::/home/ruopu:/bin/bash[root@bogon ~]# awk '/\/bin\/bash/&#123;print $0&#125;' /etc/passwdroot:x:0:0:root:/root:/bin/bashruopu:x:1000:1000::/home/ruopu:/bin/bash# 使用斜线时要用转义符# 当在awk命令中使用正则模式时，使用到的正则用法属于"扩展正则表达式"；[root@bogon ~]# awk -VGNU Awk 4.0.2# CentOS7使用awk版本[root@bogon ~]# cat test2heyheeyheeeyheeeey[root@bogon ~]# awk '/he&#123;2,3&#125;y/&#123;print $0&#125;' test2heeyheeey# CentOS7中可以直接使用&#123;x,y&#125;的形式匹配[root@bogon ~]# awk --posix '/he&#123;2,3&#125;y/&#123;print $0&#125;' test2heeyheeey[root@bogon ~]# awk --re-interval '/he&#123;2,3&#125;y/&#123;print $0&#125;' test2heeyheeey# 如果无法直接使用&#123;x,y&#125;的形式，就要使用--posix或者--re-interval选项 行范围模式1234567891011121314151617181920212223242526272829303132333435363738394041* 语法awk '/正则1/,/正则2/&#123;动作&#125;' 文件# 从被正则1匹配到的行开始，到被正则2匹配到的行结束，之间的所有行都会执行对应的动作。在行范围模式中，不管是正则1，还是正则2，都以第一次匹配到的行为准[root@bogon ~]# cat -n test4 1 Allen Phillips 2 Green Lee 3 William Aiden James Lee 4 Angel Jack 5 Tyler Kevin 6 Lucas Thomas 7 Kevin[root@bogon ~]# awk '/Lee/,/Kevin/&#123;print $0&#125;' test4Green LeeWilliam Aiden James LeeAngel JackTyler Kevin# 找出从Lee第一次出现的行，到Kevin第一次出现的行之间的所有行[root@bogon ~]# awk 'NR&gt;=3 &amp;&amp; NR&lt;=6 &#123;print $0&#125;' test4William Aiden James LeeAngel JackTyler KevinLucas Thomas# 这样也可以打印出需要范围的行* 关系运算符~与!~的使用[root@bogon ~]# cat test3主机名 网卡1的IP 网卡2的IP主机A 192.168.1.123 192.168.1.124主机B 192.168.2.222 172.16.100.3主机C 10.1.0.1 172.16.100.3主机D 10.1.2.1 192.168.1.15主机E 10.1.5.1 172.16.100.5主机F 192.168.1.234 172.16.100.6主机G 10.1.7.1 172.16.100.7[root@bogon ~]# awk '$2~/192\.168\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;/&#123;print $1,$2&#125;' test3主机A 192.168.1.123主机B 192.168.2.222主机F 192.168.1.234# 找出网卡1的IP地址在192.168.0.0/16网段内的主机。先执行第二列匹配相应地址，最后再打印出来。如果正则模式不能使用，要加入--posix或者--re-interval选项]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>awk模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk基础]]></title>
    <url>%2F2018%2F10%2F16%2Fawk%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[语法123456789101112131415161718192021222324# 我们在linux上所使用的awk其实是gawk，也就是GNU awk，简称为gawk。awk其实是一门编程语言，它支持条件判断、数组、循环等功能。grep：更适合单纯的查找或匹配文本、sed：更适合编辑匹配到的文本、awk：更适合格式化文本，对文本进行较复杂格式处理[root@bogon ~]# ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Oct 8 14:20 /usr/bin/awk -&gt; gawk* 语法awk [options] 'program' file1 , file2 , ...# 对于上述语法中的program来说，又可以细分成pattern（模式）和action（动作），也就是说，awk的基本语法如下awk [options] 'Pattern&#123;Action&#125;' file-F：用于指定输入分隔符。-v：用于设置变量的值。* 常用内置变量： FS：输入字段分隔符， 默认为空白字符 OFS：输出字段分隔符， 默认为空白字符 RS：输入记录分隔符(输入换行符)， 指定输入时的换行符 ORS：输出记录分隔符（输出换行符），输出时用指定符号代替换行符 NF：number of Field，当前行的字段的个数(即当前行被分割成了几列)，字段数量 NR：行号，当前处理的文本行的行号。 FNR：各文件分别计数的行号 FILENAME：当前文件名 ARGC：命令行参数的个数 ARGV：数组，保存的是命令行所给定的各参数#$0 表示显示整行 ，$NF表示当前行分割后的最后一列（$0和$NF均为内置变量）。$NF 和 NF 要表达的意思是不一样的，对于awk来说，$NF表示最后一个字段，NF表示当前行被分隔符切开以后，一共有几个字段。假如一行文本被空格分成了7段，那么NF的值就是7，$NF的值就是$7, 而$7表示当前行的第7个字段，也就是最后一列，那么每行的倒数第二列可以写为$(NF-1)。 测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960* 打印全部[root@bogon ~]# echo ddd &gt; testd[root@bogon ~]# awk '&#123;print&#125;' testd ddd# 将testd文件中的内容打印了出来[root@bogon ~]# awk '&#123;print $0&#125;' testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei# 上面两种写法都可以打印整行* 打印某列[root@bogon ~]# df -h | awk '&#123;print $2&#125;'Size30G234M245M245M245M1014M976M49M# 输出df的信息的第2列，$2表示将当前行按照分隔符分割后的第2列，不指定分隔符时，默认使用空格作为分隔符# awk是逐行处理的，处理完当前行，再处理下一行。awk默认以"换行符"为标记，识别每一行，每次遇到"回车换行"，就认为是当前行的结束，新的一行的开始，awk会按照用户指定的分割符去分割当前行* 打印多个列[root@bogon ~]# cat testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei[root@bogon ~]# awk '&#123;print $2,$5,$6&#125;' test345 lkj;l klj adeills adsfei# 第一行并没有第六列，所以并没有输出任何文本，而第二行有第六列，所以输出了。* 添加自己的字段[root@bogon ~]# awk '&#123;print $1,$2,"string"&#125;' testabc 345 string123 klj string[root@bogon ~]# awk '&#123;print $1,$2,423&#125;' testabc 345 423123 klj 423[root@bogon ~]# awk '&#123;print "diyilie:" $1,"diyilie:" $2&#125;' testdiyilie:abc diyilie:345diyilie:123 diyilie:klj[root@bogon ~]# awk '&#123;print "diyilie:"$1,"534","diyilie:"$2&#125;' testdiyilie:abc 534 diyilie:345diyilie:123 534 diyilie:klj[root@bogon ~]# cat test | awk '&#123;print $1&#125;'abc123[root@bogon ~]# cat test | awk '&#123;print "$1"&#125;'$1$1# 变量不能加引号[root@bogon ~]# cat test | awk '&#123;print "firstF:"$1&#125;'firstF:abcfirstF:123[root@bogon ~]# cat test | awk '&#123;print "firstF:$1"&#125;'firstF:$1firstF:$1# $1这种内置变量的外侧不能加入双引号，否则$1会被当做文本输出 特殊模式BEGIN12345678910111213# BEGIN 模式指定了处理文本之前需要执行的操作[root@bogon ~]# awk 'BEGIN&#123;print "aaa","bbb"&#125;' testaaa bbb# 在开始处理test文件中的文本之前，先执行打印动作，输出的内容为"aaa","bbb".[root@bogon ~]# awk 'BEGIN&#123;print "aaa","bbb"&#125;'aaa bbb# 因为不打算处理文本文件，所以也可以不指定文本文件，只进行一个处理前的打印动作。[root@bogon ~]# awk 'BEGIN&#123;print "aaa","bbb"&#125;&#123;print $1,$2&#125;' testaaa bbbabc 345123 klj# 可以先进行处理前打印，再处理文本文件，但两次打印要分开写 END12345678# END 模式指定了处理完所有行之后所需要执行的操作[root@bogon ~]# awk 'BEGIN&#123;print "aaa","bbb"&#125;&#123;print $1,$2&#125;END&#123;print "ccc","ddd"&#125;' testaaa bbbabc 345123 kljccc ddd# 结合BEGIN模式和END模式一起使用 分隔符 awk的分隔符还分为两种，”输入分隔符” 和 “输出分隔符” 输入分隔符，英文原文为field separator，此处简称为FS。awk默认以空白字符为分隔符对每一行进行分割。 输出分割符，英文原文为output field separator，此处简称为OFS。awk默认的输出分割符也是空格。 输入分隔符12345678910111213[root@bogon ~]# cat test1aaa#dfa#123#jkl;aiew#adkf#alkdjf#asdjfj[root@test ~]# awk -F# '&#123;print $1,$2&#125;' test1aaa dfaaiew adkf# 指定默认分隔符为#号，对文本进行分隔[root@test ~]# awk -v FS=# '&#123;print $1,$2&#125;' test1 aaa dfaaiew adkf# 还能够通过设置内部变量的方式，指定awk的输入分隔符，awk内置变量FS可以用于指定输入分隔符，但是在使用变量时，需要使用-v选项，用于指定对应的变量 输出分隔符1234567891011121314151617181920212223242526272829# 当我们要对处理完的文本进行输出的时候，以什么文本或符号作为分隔符。[root@bogon ~]# awk '&#123;print $1,$2&#125;' testabc 345123 klj[root@bogon ~]# awk -v OFS="+++" '&#123;print $1,$2&#125;' testabc+++345123+++klj[root@bogon ~]# awk -v OFS='+++' '&#123;print $1,$2&#125;' testabc+++345123+++klj# 加号两侧可以是单引号或双引号[root@bogon ~]# awk -v FS='#' -v OFS='---' '&#123;print $1,$2&#125;' test1aaa---dfaaiew---adkf# 同时指定输入分隔符和输出分割符[root@bogon ~]# awk '&#123;print $1,$2&#125;' testabc 345123 klj# 分开显示要使用逗号分隔两个变量[root@bogon ~]# awk '&#123;print $1 $2&#125;' testabc345123klj[root@bogon ~]# awk '&#123;print $1$2&#125;' testabc345123klj# 输出不使用分隔符，打印在一起 变量 “变量”又分为”内置变量” 和 “自定义变量” , “输入分隔符FS”和”输出分隔符OFS”都属于内置变量。内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。 内置变量NR12345678910111213# 在awk中，只有在引用$0、$1等内置变量的值的时候才会用到"$"，引用其他变量时，不管是内置变量，还是自定义变量，都不使用"$"，而是直接使用变量名。[root@bogon ~]# cat testabc 345 ssd asdf lkj;l123 klj adf daff adeills adsfei[root@bogon ~]# awk '&#123;print NR,NF&#125;' test1 52 6# 打印每一行的行号以及每一行对应的列的数量。内置变量NR表示每一行的行号，内置变量NF表示每一行中一共有几列[root@bogon ~]# awk '&#123;print NR,$0&#125;' test1 abc 345 ssd asdf lkj;l2 123 klj adf daff adeills adsfei# 先打印出行号，再打印出整行的内容 内置变量FNR12345678910111213[root@bogon ~]# awk '&#123;print NR,$0&#125;' test test11 abc 345 ssd asdf lkj;l2 123 klj adf daff adeills adsfei3 aaa#dfa#123#jkl;4 aiew#adkf#alkdjf#asdjfj# awk处理多个文件的时候，如果使用NR显示行号，那么，多个文件的所有行会按照顺序进行排序。[root@bogon ~]# awk '&#123;print FNR,$0&#125;' test test11 abc 345 ssd asdf lkj;l2 123 klj adf daff adeills adsfei1 aaa#dfa#123#jkl;2 aiew#adkf#alkdjf#asdjfj# FNR变量可以在处理多个文件时分开显示行号。 内置变量RS12345678910111213141516[root@bogon ~]# awk '&#123;print NR,$0&#125;' test1 abc 345 ssd asdf lkj;l2 123 klj adf daff adeills adsfei[root@bogon ~]# awk -v RS=" " '&#123;print NR,$0&#125;' test1 abc2 3453 ssd4 asdf5 lkj;l1236 klj7 adf8 daff9 adeills10 adsfei# 指定空格为换行符并打印，第5行是因为test文本中的第一行行尾和第二行开头之间没有空格，只有回车，所以打印成这个样子。 内置变量ORS12345678[root@bogon ~]# awk -v ORS='+++' '&#123;print NR,$0&#125;' test1 abc 345 ssd asdf lkj;l+++2 123 klj adf daff adeills adsfei+++[root@bogon ~]## 指定输出换行符，awk认为有+++号就是换行了，所以才打印成这个样子[root@bogon ~]# awk -v RS=" " -v ORS='+++' '&#123;print NR,$0&#125;' test1 abc+++2 345+++3 ssd+++4 asdf+++5 lkj;l123+++6 klj+++7 adf+++8 daff+++9 adeills+++10 adsfei# 一起使用输入输出换行符。 内置变量FILENAME123456[root@bogon ~]# awk '&#123;print FILENAME,FNR,$0&#125;' test test1test 1 abc 345 ssd asdf lkj;ltest 2 123 klj adf daff adeills adsfeitest1 1 aaa#dfa#123#jkl;test1 2 aiew#adkf#alkdjf#asdjfj# FILENAME是为了显示文件名的。上面每行都打印了文件名，行号，文件内容 内置变量ARGC与ARGV1234567891011[root@bogon ~]# awk 'BEGIN&#123;print "aaa",ARGV[1]&#125;' test test1aaa test[root@bogon ~]# awk 'BEGIN&#123;print "aaa",ARGV[1],ARGV[2]&#125;' test test1aaa test test1# ARGV内置变量表示的是一个数组。数组的索引都是从0开始的，所以，ARGV[1]表示引用ARGV数组中的第二个元素的值。命令后的文件名组成了这个数组，使用ARGV调用数组中的元素值，ARGV[1]对应的值为test，ARGV[2]对应的值为test1，ARGV[0]对应的值为awk[root@bogon ~]# awk 'BEGIN&#123;print "aaa",ARGV[0]&#125;' testaaa awk[root@bogon ~]# awk 'BEGIN&#123;print "aaa",ARGV[0],ARGV[1],ARGV[2],ARGC&#125;' test test1aaa awk test test1 3# 在上面的例子中，应该有三个参数，awk、test、test1，这三个参数作为数组的元素存放于ARGV中，而ARGC则表示参数的数量，也可以理解为ARGV数组的长度。 自定义变量123456789101112131415161718192021# 自定义变量方法# 方法一：-v varname=value 变量名区分字符大小写。# 方法二：在program中直接定义。* 方法一[root@bogon ~]# awk -v myVar="testVar" 'BEGIN&#123;print myVar&#125;'testVar* 方法二[root@bogon ~]# awk 'BEGIN&#123;myvar="ttt";print myvar&#125;'ttt# ttt两侧一定要使用双引号，不能使用单引号。分号两侧有没有空格都可以。* 一次定义多个变量[root@bogon ~]# awk 'BEGIN&#123;myvar1="111";myvar2="222";print myvar1,myvar2&#125;'111 222[root@bogon ~]# abc=123[root@bogon ~]# awk -v myvar=$abc 'BEGIN&#123;print myvar&#125;'123# 需要在awk中引用shell中的变量的时候，可以通过方法一间接的引用。 printf命令 printf命令的作用是按照我们指定的格式输出文本。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109# 语法# printf "指定的格式" "文本1" "文本2" "文本3" ......[root@bogon ~]# echo abcabc[root@bogon ~]# printf abcabc[root@bogon ~]## echo命令会对输出的文本进行换行，而printf命令则不会对输出的文本进行换行[root@bogon ~]# echo -e "abc \ndef \njkl \ndfj"abc def jkl dfj[root@bogon ~]# printf "abc \ndef \njkl \ndfj \n"abc def jkl dfj[root@bogon ~]# printf "%s\n" abc def jkl dfjabcdefjkldfj# 前两种方法要使用转义符\n进行换行。第三条命令中的每一个"文本"都会被当做参数项传入printf命令，而每个被传入的参数都会按照指定的"格式"被"格式化"。"%s\n"就是格式，而后面的每一段字符串，都被当做参数传入到了printf命令中，并按照我们指定的格式进行了格式化。# %s是"格式替换符"。使用"%s"代替传入的每一个参数，上面命令中的参数就是abc def jkl dfj，如果我们指定的格式为"%s\n"，当abc被当做参数传入printf命令时，printf就会把"%s\n"中的%s替换成abc，于是，abc就变成了我们指定的格式"abc\n"，最终printf输出的就是格式化后的"abc\n"，以此类推，每一段文本都被当做一个参数传入printf命令，然后按照指定的格式输出了。[root@bogon ~]# printf "%s\n" 1 11 213 1112311121311123[root@bogon ~]# printf "%f\n" 1 11 213 111231.00000011.000000213.00000011123.000000# "%f"也代替了每一个传入的参数，它会将每一个传入的参数转换成"浮点类型"* 格式替换符# %s 字符串# %f 浮点格式（也就是我们概念中的float或者double）# %b 相对应的参数中包含转义字符时，可以使用此替换符进行替换，对应的转义字符会被转义。# %c ASCII字符。显示相对应参数的第一个字符# %d, %i 十进制整数# %o 不带正负号的八进制值# %u 不带正负号的十进制值# %x 不带正负号的十六进制值，使用a至f表示10至15# %X 不带正负号的十六进制值，使用A至F表示10至15# %% 表示"%"本身* printf常用的转义符# \a 警告字符，通常为ASCII的BEL字符# \b 后退# \c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略# \f 换页（formfeed）# \n 换行# \r 回车（Carriage return）# \t 水平制表符# \v 垂直制表符# \\ 一个字面上的反斜杠字符，即"\"本身。# \ddd 表示1到3位数八进制值的字符，仅在格式字符串中有效# \0ddd 表示1到3位的八进制值字符[root@bogon ~]# printf "( %s ) " 1 23 234 23423;echo ""( 1 ) ( 23 ) ( 234 ) ( 23423 )# 为每个传入的参数添加一对"括号"，并且括号内侧需要有空格。最后的echo命令是为了换行[root@bogon ~]# printf "%s\t" 1 23 234 23423;echo1 23 234 23423# 使用"制表符"隔开每个参数，echo后不加引号也可以[root@bogon ~]# printf "%s %s\n" a b df ad e ra bdf ade r# 指定的"格式"中所包含的"格式替换符"的数量，就代表每次格式化的参数的数量，每个"格式替换符"与参数都是一一对应的[root@bogon ~]# printf "%s %s %s\n" a b c d e f a b cd e f[root@bogon ~]# printf "%s %s %s\n" 姓名 性别 年龄 董鹏 男 29 少松 女 39姓名 性别 年龄董鹏 男 29少松 女 39# 下面的年龄与其上面的标题没有对齐[root@bogon ~]# printf "%7s %5s %4s\n" 姓名 性别 年龄 董鹏 男 29 少松 女 39 姓名 性别 年龄 董鹏 男 29 少松 女 39# 在原来的"格式替换符"中间加入了特定的数字，可以使输出的文字向右对齐。如果想向左对齐，就将数字改为负数，如：%-9s# 如果使用%+9s，表示给后面对应的参数前加一个+号。[root@bogon ~]# printf "aaa fff\n";printf "%-9s %-12f \n" abc 123.123123 bbb 2312.12345aaa fffabc 123.123123 bbb 2312.123450[root@bogon ~]# printf "aaa fff\n";printf "%-9s %-12.2f \n" abc 123.123123 bbb 2312.12345aaa fffabc 123.12 bbb 2312.12 # 第一条命令的数字修饰符为12，表示对应的替换符"%f"的输出宽度为12个字符，第二条命令的数字修饰符为12.2 ，表示对应的替换符"%f"的输出宽度为12个字符，并且小数点的精度为2。[root@bogon ~]# printf "aaa fff\n";printf "%-9s %-12d \n" abc 123 bbb 2312aaa fffabc 123 bbb 2312 [root@bogon ~]# printf "aaa fff\n";printf "%-9s %-12.4d \n" abc 123 bbb 2312aaa fffabc 0123 bbb 2312# 当格式替换符为"%d"时，如果数字修饰符带有小数点，则数字修饰符小数点后的数字表示整数的长度，长度不够时，高位用0补全 printf动作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@bogon ~]# awk '&#123;print $1&#125;' testabc123[root@bogon ~]# awk '&#123;printf $1&#125;' testabc123[root@bogon ~]## printf动作不会自动换行[root@bogon ~]# awk '&#123;printf "%s\n",$1&#125;' testabc123# 使用格式替换符，不要忘记$1前面的逗号[root@bogon ~]# awk 'BEGIN&#123;printf "%s\n",1,2,3,4,5&#125;'1[root@bogon ~]# awk 'BEGIN&#123;printf "%s\n%s\n%s\n%s\n%s\n",1,2,3,4,5&#125;'12345# 在awk中，格式替换符的数量必须与传入的参数的数量相同。也就是格式替换符必须与需要格式化的参数一一对应。不可以像使用printf命令一样，一个格式替换符可以反复使用。# 使用printf动作注意事项# 1. 使用printf动作输出的文本不会换行，如果需要换行，可以在对应的"格式替换符"后加入"\n"进行转义。# 2. 使用printf动作时，"指定的格式" 与 "被格式化的文本" 之间，需要用"逗号"隔开。# 3. 使用printf动作时，"格式"中的"格式替换符"必须与 "被格式化的文本" 一一对应。[root@bogon ~]# awk '&#123;printf "第一列： %s 第二列： %s\n",$1,$2&#125;' test第一列： abc 第二列： 345第一列： 123 第二列： klj[root@bogon ~]# awk -v FS="#" '&#123;printf "第一列： %s 第二列： %s\n",$1,$2&#125;' test1第一列： aaa 第二列： dfa第一列： aiew 第二列： adkf[root@bogon ~]# awk -v FS=":" 'BEGIN&#123;printf "%-10s\t %s\n","用户名称","用户ID"&#125;&#123;printf "%-10s\t %s\n",$1,$3&#125;' /etc/passwd用户名称 用户IDroot 0bin 1daemon 2adm 3lp 4sync 5shutdown 6halt 7mail 8operator 11games 12ftp 14nobody 99systemd-network 192dbus 81polkitd 999postfix 89sshd 74openvpn 998]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>awk基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables动作]]></title>
    <url>%2F2018%2F10%2F16%2Fiptables%E5%8A%A8%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[“动作”与”匹配条件”一样，也有”基础”与”扩展”之分。同样，使用扩展动作也需要借助扩展模块，但是，扩展动作可以直接使用，不用像使用”扩展匹配条件”那样指定特定的模块。 REJECT12345678910111213141516171819202122232425262728# 常用选项为--reject-with# 可用值如下:# icmp-net-unreachable# icmp-host-unreachable# icmp-port-unreachable,# icmp-proto-unreachable# icmp-net-prohibited# icmp-host-pro-hibited# icmp-admin-prohibited# 当不设置任何值时，默认值为icmp-port-unreachable。[root@test ~]# iptables -I INPUT -p tcp -m tcp --dport 22 -j ACCEPT[root@localhost ~]# iptables -I INPUT -j REJECT# 拒绝所有主机访问本机[root@localhost ~]# ping 10.5.5.90PING 10.5.5.90 (10.5.5.90) 56(84) bytes of data.From 10.5.5.90 icmp_seq=1 Destination Port UnreachableFrom 10.5.5.90 icmp_seq=2 Destination Port Unreachable# 这时用其他主机ping本机提示是“Destination Port Unreachable”[root@localhost ~]# iptables -I INPUT -p tcp --dport 22 -j ACCEPT[root@localhost ~]# iptables -A INPUT -j REJECT --reject-with icmp-host-unreachable# 修改提示信息为“icmp-host-unreachable”[root@localhost ~]# ping 10.5.5.90PING 10.5.5.90 (10.5.5.90) 56(84) bytes of data.From 10.5.5.90 icmp_seq=1 Destination Host UnreachableFrom 10.5.5.90 icmp_seq=2 Destination Host Unreachable# 用其他主机ping本机时提示已改为“Destination Host Unreachable” LOG1234567891011121314151617181920212223242526272829303132# 使用LOG动作，可以将符合条件的报文的相关信息记录到日志中，但当前报文具体是被"接受"，还是被"拒绝"，都由后面的规则控制# --log-level选项可以指定记录日志的日志级别，可用级别有emerg，alert，crit，error，warning，notice，info，debug。# --log-prefix选项可以给记录到的相关信息添加"标签"之类的信息，以便区分各种记录到的报文信息，方便在分析时进行过滤。--log-prefix对应的值不能超过29个字符。* 基本设置[root@localhost ~]# iptables -I INPUT -p tcp --dport 22 -j LOG# 上述规则表示所有发往22号端口的tcp报文都符合条件，所以都会被记录到日志中，查看/var/log/messages即可看到对应报文的相关信息。但是上述规则只是用于示例，因为上例中使用的匹配条件过于宽泛。所以在使用LOG动作时，匹配条件应该尽量写的精确一些，匹配到的报文数量也会大幅度的减少，这样冗余的日志信息就会变少，同时日后分析日志时，日志中的信息可用程度更高。[root@localhost ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 48 packets, 4200 bytes)num pkts bytes target prot opt in out source destination 1 46 3296 LOG tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 LOG flags 0 level 4[root@localhost ~]# tail -f /var/log/messages Oct 16 17:27:36 localhost kernel: IN=eno16777736 OUT= MAC=00:0c:29:45:17:9b:50:7b:9d:65:f9:ff:08:00 SRC=10.5.5.23 DST=10.5.5.90 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=2314 DF PROTO=TCP SPT=51108 DPT=22 WINDOW=16243 RES=0x00 ACK URGP=0 Oct 16 17:27:37 localhost kernel: IN=eno16777736 OUT= MAC=00:0c:29:45:17:9b:50:7b:9d:65:f9:ff:08:00 SRC=10.5.5.23 DST=10.5.5.90 LEN=92 TOS=0x00 PREC=0x00 TTL=64 ID=2323 DF PROTO=TCP SPT=51108 DPT=22 WINDOW=16243 RES=0x00 ACK PSH URGP=0# LOG动作默认会将报文的相关信息记录在/var/log/message文件中[root@localhost ~]# vim /etc/rsyslog.conf kern.warning /var/log/iptables.log# 加入上面一行，让iptables将日志记录在其他位置 [root@localhost ~]# systemctl restart rsyslog# 重启日志服务* --log-prefix[root@localhost ~]# iptables -I INPUT -p tcp --dport 22 -m state --state NEW -j LOG --log-prefix "want-in-from-port-22"# 将主动连接22号端口的报文的相关信息都记录到日志中，并且把这类记录命名为"want-in-from-port-22"[root@localhost ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 44 packets, 3150 bytes)num pkts bytes target prot opt in out source destination 1 0 0 LOG tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 state NEW LOG flags 0 level 4 prefix "want-in-from-port-22"[root@localhost ~]# tail -f /var/log/iptables.log Oct 16 17:41:08 localhost kernel: want-in-from-port-22IN=eno16777736 OUT= MAC=00:0c:29:45:17:9b:00:0c:29:96:6b:bf:08:00 SRC=10.5.5.91 DST=10.5.5.90 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=7879 DF PROTO=TCP SPT=42102 DPT=22 WINDOW=14600 RES=0x00 SYN URGP=0# 使用其他主机连接本机时会有相关记录。这条日志中包含"标签"：want-in-from-port-22，如果有很多日志记录，我们就能通过这个"标签"进行筛选了，这样方便我们查看日志，同时，从上述记录中还能够得知报文的源IP与目标IP，源端口与目标端口等信息，从上述日志我们能够看出，10.5.5.91这个IP想要在17:41:08连接到10.5.5.91（当前主机的IP）的22号端口，报文由eno16777736网卡进入，eno16777736网卡的MAC地址为00:0c:29:45:17:9b，客户端网卡的mac地址为00:0c:29:96:6b:bf。 测试源地址与目标地址转换123456# 准备四台主机，一台主机为公网主机，一台为防火墙，两台为内网主机。使用公网主机通过防火墙访问内网linux服务器。# A 公网主机IP：10.5.5.90# B 防火墙IP：10.5.5.91、192.168.116.129# C 内网linux服务器IP：192.168.116.130# D 内网windows主机IP：192.168.116.131# 将主机C和D的网关都指向B的内网地址，主机A和B的公网地址是桥接到宿主机的网卡上，打开B防火墙的路由功能ip_forward，在A和C主机上启动httpd服务。 SNAT123456789101112131415161718192021222324[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.116.0/24 -j SNAT --to-source 10.5.5.91# 添加规则，让内网主机经过防火墙出去时的地址都改为防火墙的外网地址。"-t nat"表示操作nat表。filter表的功能是过滤，nat表的功能就是地址转换，所以我们需要在nat表中定义nat规则。"-A POSTROUTING"表示将SNAT规则添加到POSTROUTING链的末尾，在centos7中，SNAT规则只能存在于POSTROUTING链与INPUT链中，在centos6中，SNAT规则只能存在于POSTROUTING链中。"-j SNAT"表示使用SNAT动作，对匹配到的报文进行处理，对匹配到的报文进行源地址转换。"--to-source 10.5.5.91"表示将匹配到的报文的源IP修改为10.5.5.91# 在centos7中，SNAT规则也可以定义在INPUT链中，我们可以这样理解，发往本机的报文经过INPUT链以后报文就到达了本机，如果再不修改报文的源地址，就没有机会修改了。# 这时还要注意客户端是否有多块网卡，默认路由是什么，如果有多块网卡，默认路由又不是从我们想要的出去的网卡，可以暂时关闭不需要的网卡。如果不关闭，客户端也是不能访问互联网的。[root@localhost ~]# iptables -t nat --line -nvxLChain PREROUTING (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 0 0 SNAT all -- * * 192.168.116.0/24 0.0.0.0/0 to:10.5.5.91# 配置上面的规则后就可以ping通外网主机了* A[root@localhost ~]# tcpdump -i eno16777736 -nn icmp18:41:22.375035 IP 10.5.5.91 &gt; 10.5.5.90: ICMP echo request, id 14189, seq 17, length 6418:41:22.375090 IP 10.5.5.90 &gt; 10.5.5.91: ICMP echo reply, id 14189, seq 17, length 64# 这时在主机A上抓包，用C主机ping主机A，可以看到是10.5.5.91发来的数据。在主机C上也可以看到是主机A返回的信息。在C主机上抓包也可以看到是外网主机返回的信息# 在A主机上不要添加到内网的路由，这样，在防火墙没有添加SNAT规则时，内网是不能ping通外网的，当添加了SNAT规则后，内网主机就可以ping通外网了 DNAT12345678910111213141516171819202122[root@localhost ~]# iptables -t nat -I PREROUTING -d 10.5.5.91 -p tcp --dport 3389 -j DNAT --to-destination 192.168.116.131:3389# 加入一条规则，在PREROUTING链上，目标地址是防火墙的外网地址，端口是3389。目标地址转换为内网地址192.168.116.131:3389。实际就是地址与端口映射，将外网的地址与端口映射为内网的地址与端口[root@localhost ~]# iptables -t nat --line -nvxLChain PREROUTING (policy ACCEPT 18 packets, 2657 bytes)num pkts bytes target prot opt in out source destination 1 1 52 DNAT tcp -- * * 0.0.0.0/0 10.5.5.91 tcp dpt:3389 to:192.168.116.131:3389Chain INPUT (policy ACCEPT 18 packets, 2657 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain POSTROUTING (policy ACCEPT 1 packets, 52 bytes)num pkts bytes target prot opt in out source destination 1 6 904 SNAT all -- * * 192.168.116.0/24 0.0.0.0/0 to:10.5.5.91# 配置内网windows主机可以远程访问，之后用本机远程连接10.5.5.91，也就是防火墙地址，这时是可以连接到内网主机192.168.116.131上的。# 理论上只配置DNAT规则即可，但是如果在测试时无法正常DNAT，可以尝试配置对应的SNAT，此处按照配置SNAT的流程进行。SNAT规则与上面是一样的，就是将内网的主机出去的地址都改为防火墙的地址。[root@localhost ~]# iptables -t nat -I PREROUTING -d 10.5.5.91 -p tcp --dport 8080 -j DNAT --to-destination 192.168.116.130:80# 加一条端口映射，将外网的8080端口映射到内网的80端口上# 这次，我们不用再次定义SNAT规则了，因为之前已经定义过SNAT规则，上次定义的SNAT规则只要定义一次就行，而DNAT规则则需要根据实际的情况去定义。 MASQUERADE1234# 当我们拨号网上时，每次分配的IP地址往往不同，不会长期分给我们一个固定的IP地址，如果这时，我们想要让内网主机共享公网IP上网，就会很麻烦，因为每次IP地址发生变化以后，我们都要重新配置SNAT规则，这样显得不是很人性化，我们通过MASQUERADE即可解决这个问题，MASQUERADE会动态的将源地址转换为可用的IP地址，其余与SNAT实现的功能完全一致，都是修改源地址，只不过SNAT需要指明将报文的源地址改为哪个IP，而MASQUERADE则不用指定明确的IP，会动态的将报文的源地址修改为指定网卡上可用的IP地址[root@localhost ~]# iptables -t nat -I POSTROUTING -s 192.168.116.0/24 -o eno16777736 -j MASQUERADE# 通过外网网卡出去的报文在经过POSTROUTING链时，会自动将报文的源地址修改为外网网卡上可用的IP地址，这时，即使外网网卡中的公网IP地址发生了改变，也能够正常的、动态的将内部主机的报文的源IP映射为对应的公网IP。可以把MASQUERADE理解为动态的、自动化的SNAT，如果没有动态SNAT的需求，没有必要使用MASQUERADE，因为SNAT更加高效。 REDIRECT12345# 使用REDIRECT动作可以在本机上进行端口映射[root@localhost ~]# iptables -t nat -A PREROUTING -p tcp --dport 19000 -j REDIRECT --to-ports 22# 将本机的22端口映射到本机的19000端口上。REDIRECT规则只能定义在PREROUTING链或者OUTPUT链中。[root@template network-scripts]# ssh 192.168.1.14 -p 19000# 在另一台主机连接测试]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables动作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables网络防火墙]]></title>
    <url>%2F2018%2F10%2F15%2Fiptables%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[概念 网络防火墙往往处于网络的入口或者边缘 网络防火墙的职责就是”过滤并转发”。要想”过滤”，只能在INPUT、OUTPUT、FORWARD三条链中实现，要想”转发”，报文则只会经过FORWARD链（发往本机的报文才会经过INPUT链），所以，iptables的角色变为”网络防火墙”时，规则只能定义在FORWARD链中。 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 准备三台linux主机，一台为外网主机，一台为内网主机，一台允当防火墙# A外网主机IP：10.5.5.90# B内网主机IP：192.168.116.130# C网络防火墙IP：192.168.116.129、10.5.5.91# 将虚拟机C的第二块网卡和B的网卡设置为仅主机* B[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 IPADDR=192.168.116.130 NETMASK=255.255.255.0 GATEWAY=192.168.116.129# 将B主机的网关指向C（防火墙）主机的内网地址192.168.116.129* A[root@localhost ~]#route add -net 192.168.116.0/24 gw 10.5.5.91# 给外网主机加一条路由，让外网主机知道如何到内网主机# 现在外网与内网主机还不能互相ping通，因为防火墙没有路由数据包# 因为在CentOS中，IP地址属于主机，所以内外网的主机都可以ping通防火墙的外网地址* C[root@localhost ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward# 开启防火墙路由功能# 这时内外网可以互相ping通了。[root@localhost ~]# iptables -A FORWARD -j REJECT# 拒绝所有数据转发。这时内外网又不能互相ping通了。* A[root@localhost ~]# vim /var/www/html/index.html 10.5.5.90# 添加默认主页[root@localhost ~]# systemctl start httpd* B[root@localhost ~]# vim /var/www/html/index.html 192.168.116.130# 添加默认主页[root@localhost ~]# systemctl start httpd# 启动两台主机的httpd服务# 这时两台主机是不能互相访问的* C[root@localhost ~]# iptables -I FORWARD -s 192.168.116.0/24 -p tcp --dport 80 -j ACCEPT# 让源地址是192.168.116.0网段的主机可以访问外部的80端口。只加入这一条还不行，这只是数据流出的规则，还要加数据流入的规则[root@localhost ~]# iptables -I FORWARD -d 192.168.116.0/24 -p tcp --sport 80 -j ACCEPT# 加入此条后，192.168.116.0网段的主机就可以访问外部的80端口了。[root@localhost ~]# iptables -D FORWARD 1# 删除FORWARD中的第一条规则[root@localhost ~]# iptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT# 加入这一条就可以将绝大多数响应报文放行了。配置完上述规则后，我们只要考虑请求报文的方向就行了，而回应报文，上述一条规则就能搞定，这样配置，即使以后有更多服务的响应报文需要放行，我们也不用再去针对响应报文设置规则了[root@localhost ~]# iptables -I FORWARD -s 192.168.116.0/24 -p tcp --dport 22 -j ACCEPT# 加入这一条就可以实现内网主机使用ssh连接外部主机了[root@test ~]# iptables -I FORWARD -p icmp -j ACCEPT# 放行内外网间的ping请求]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables网络防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables自定义规则链]]></title>
    <url>%2F2018%2F10%2F15%2Fiptables%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%84%E5%88%99%E9%93%BE%2F</url>
    <content type="text"><![CDATA[创建自定义规则链123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 当默认链中的规则非常多时，不方便我们管理。所以要自定义规则链# 自定义链并不能直接使用，而是需要被默认链引用才能够使用* 创建自定义链[root@bogon ~]# iptables -t filter -N IN_WEB# "-t filter"表示操作的表为filter表，与之前的示例相同，省略-t选项时，缺省操作的就是filter表。"-N IN_WEB"表示创建一个自定义链，自定义链的名称为"IN_WEB"[root@bogon ~]# iptables --line -nvxLChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:802 386 26796 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:223 4087 278278 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 44 packets, 4228 bytes)num pkts bytes target prot opt in out source destination Chain IN_WEB (0 references)num pkts bytes target prot opt in out source destination # 查看filter表中的链，这条自定义链的引用计数为0 (0 references)，也就是说，这条自定义链还没有被任何默认链所引用，所以，即使IN_WEB中配置了规则，也不会生效* 创建自定义链规则[root@bogon ~]# iptables -I IN_WEB -s 10.5.5.249 -j REJECT[root@bogon ~]# iptables --line -nvxL IN_WEBChain IN_WEB (0 references)num pkts bytes target prot opt in out source destination 1 0 0 REJECT all -- * * 10.5.5.249 0.0.0.0/0 reject-with icmp-port-unreachable# 自定义链中已经有了一条规则，但是目前，这条规则无法匹配到任何报文，因为我们并没有在任何默认链中引用它。* 引用自定义链[root@bogon ~]# iptables -I INPUT -p tcp --dport 80 -j IN_WEB# 在INPUT链中添加了一条规则，访问本机80端口的tcp报文将会被这条规则匹配到，而上述规则中的"-j IN_WEB"表示：访问80端口的tcp报文将由自定义链"IN_WEB"中的规则进行处理。此处，我们将"动作"替换为了"自定义链"，当"-j"对应的值为一个自定义链时，就表示被当前规则匹配到的报文将交由对应的自定义链处理。当IN_WEB自定义链被INPUT链引用以后，可以发现，IN_WEB链的引用计数已经变为1，表示这条自定义链已经被引用了1次，自定义链还可以引用其他的自定义链[root@bogon ~]# iptables --line -nvxLChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 0 0 IN_WEB tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:222 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:803 663 46156 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:224 5196 351595 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 76 packets, 7396 bytes)num pkts bytes target prot opt in out source destination Chain IN_WEB (1 references)num pkts bytes target prot opt in out source destination 1 0 0 REJECT all -- * * 10.5.5.249 0.0.0.0/0 reject-with icmp-port-unreachable 重命名自定义链12345678910111213141516171819[root@bogon ~]# iptables -E IN_WEB WEB# 使用"-E"选项可以修改自定义链名[root@bogon ~]# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 80 5672 WEB tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 888 62080 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 6265 425K REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 24 packets, 2328 bytes) pkts bytes target prot opt in out source destination Chain WEB (2 references) pkts bytes target prot opt in out source destination 1 60 REJECT all -- * * 10.5.5.249 0.0.0.0/0 reject-with icmp-port-unreachable 删除自定义链1234567891011121314# 使用"-X"选项可以删除自定义链，但是删除自定义链时，需要满足两个条件：# 1、自定义链没有被任何默认链引用，即自定义链的引用计数为0。# 2、自定义链中没有任何规则，即自定义链为空。[root@bogon ~]# iptables -X WEBiptables: Too many links.# 提示：Too many links，是因为WEB链已经被默认链所引用[root@bogon ~]# iptables -D INPUT 1[root@bogon ~]# iptables -X WEBiptables: Directory not empty.# 删除引用自定义链的规则后，再次尝试删除自定义链，提示：Directory not empty，是因为WEB链中存在规则[root@bogon ~]# iptables -t filter -F WEB[root@bogon ~]# iptables -t filter -X WEB# 清除规则后再删除自定义链就没问题了。使用"-X"选项可以删除一个引用计数为0的、空的自定义链]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables自定义规则链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables匹配条件]]></title>
    <url>%2F2018%2F10%2F12%2Fiptables%E5%8C%B9%E9%85%8D%E6%9D%A1%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[基本匹配条件指定地址12345678910111213141516171819202122232425262728293031323334353637* 一次指定多个源地址[root@bogon ~]# iptables -I INPUT -s 10.5.5.249,10.5.5.224 -j DROP# 用逗号分隔多个地址[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 55 packets, 4698 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 10.5.5.224 0.0.0.0/0 2 12 1008 DROP all -- * * 10.5.5.249 0.0.0.0/0 # 指定后会一次添加两条规则* 指定网段[root@bogon ~]# iptables -I FORWARD -s 10.5.5.0/16 -j DROP# 拒绝10.5.5.0网段的所有地址访问[root@bogon ~]# iptables --line -nvxL FORWARDChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 10.5.0.0/16 0.0.0.0/0* 对条件取反[root@bogon ~]# iptables -A INPUT ! -s 10.5.5.25 -j ACCEPT# 使用"! -s 10.5.5.25"表示对 -s 10.5.5.25这个匹配条件取反， -s 10.5.5.25表示报文源IP地址为10.5.5.25即可满足匹配条件，使用 "!" 取反后则表示，报文源地址IP只要不为10.5.5.25即满足条件，那么，上例中规则表达的意思就是，只要发往本机的报文的源地址不是10.5.5.25，就接受报文。但10.5.5.25还是可以ping通这台主机，因为filter表的INPUT链中只有一条规则，这条规则要表达的意思就是：只要报文的源IP不是10.5.5.25，那么就接受此报文，但并不能代表，报文的源IP是10.5.5.25时，会被拒绝。因为并没有任何一条规则指明源IP是10.5.5.25时，该执行怎样的动作，所以，当来自10.5.5.25的报文经过INPUT链时，并不能按上例中的规则处理报文，这时报文被两条规则匹配，一是拒绝10.5.5.25的报文，一是默认允许所有报文通过的规则。于是，此报文就继续匹配后面的规则，因为只有一条规则，于是，此报文就会去匹配当前链的默认动作(默认策略)，因为默认策略是ACCEPT，所以10.5.5.25还可以ping通这台主机。[root@bogon ~]# iptables --line -vnxL INPUTChain INPUT (policy ACCEPT 287 packets, 24108 bytes)num pkts bytes target prot opt in out source destination 1 159 12226 ACCEPT all -- * * !10.5.5.25 0.0.0.0/0 * 指定目标地址[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -d 10.5.5.22 -j DROP# 这条规则就可以实现上面的禁止10.5.5.249访问本机10.5.5.22# 使用-d选项指定目标地址。如果我们不指定任何目标地址，则目标地址默认为0.0.0.0/0，同理，如果我们不指定源地址，源地址默认为0.0.0.0/0。-d选项也可以使用"叹号"进行取反，也能够同时指定多个IP地址，使用"逗号"隔开即可。# 但是请注意，不管是-s选项还是-d选项，取反操作与同时指定多个IP的操作不能同时使用。# 当一条规则中有多个匹配条件时，那么多个匹配条件之间，默认存在"与"的关系。如上面规则表示源地址与目标地址必须同时能被这两个条件匹配，才算作被当前规则匹配[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 12 1008 DROP all -- * * 10.5.5.249 10.5.5.22 2 1978 144348 ACCEPT all -- * * !10.5.5.25 0.0.0.0/0 协议类型12345678910[root@bogon ~]# iptables -I INPUT -p tcp -s 10.5.5.249 -j DROP# 拒绝10.5.5.249的tcp请求，所以ssh无法连接，但可以ping通。# 当不使用-p指定协议类型时，默认表示所有类型的协议都会被匹配到，与使用-p all的效果相同。[root@bogon ~]# iptables -I INPUT ! -p udp -s 10.5.5.249 -j DROP[root@bogon ~]# iptables --line -xvnL INPUTChain INPUT (policy ACCEPT 192 packets, 11044 bytes)num pkts bytes target prot opt in out source destination 1 18 1512 DROP !udp -- * * 10.5.5.249 0.0.0.0/0 2 0 0 DROP tcp -- * * 10.5.5.249 0.0.0.0/0 # -p用于匹配报文的协议类型,可以匹配的协议类型tcp、udp、udplite、icmp、esp、ah、sctp等（centos7中还支持icmpv6、mh） 网卡接口123456789101112131415161718* 流入[root@bogon ~]# iptables -I INPUT -p icmp -i eth0 -j DROP[root@bogon ~]# iptables -I INPUT -p icmp ! -i eth0 -j DROP# -i用于匹配报文是从哪个网卡接口流入本机的，由于匹配条件只是用于匹配报文流入的网卡，所以在OUTPUT链与POSTROUTING链中不能使用此选项。[root@bogon ~]# iptables --line -xvnL INPUTChain INPUT (policy ACCEPT 52 packets, 4422 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP icmp -- !eth0 * 0.0.0.0/0 0.0.0.0/0 2 25 2100 DROP icmp -- eth0 * 0.0.0.0/0 0.0.0.0/0* 流出[root@bogon ~]# iptables -I OUTPUT -p icmp -o eth0 -j DROP[root@bogon ~]# iptables -I OUTPUT -p icmp ! -o eth0 -j DROP[root@bogon ~]# iptables --line -xvnL OUTPUTChain OUTPUT (policy ACCEPT 65 packets, 6908 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP icmp -- * !eth0 0.0.0.0/0 0.0.0.0/0 2 23 1932 DROP icmp -- * eth0 0.0.0.0/0 0.0.0.0/0 扩展匹配条件tcp扩展模块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152* 目标端口[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp -m tcp --dport 22 -j REJECT# 使用-m选项来指定扩展模块，如果想要使用--dport这个扩展匹配条件，则必须依靠某个扩折模块完成，上例中，这个扩展模块就是tcp扩展模块。 -m tcp表示使用tcp扩展模块，--dport表示tcp扩展模块中的一个扩展匹配条件，可用于匹配报文的目标端口。-p tcp与 -m tcp并不冲突，-p用于匹配报文的协议，-m 用于指定扩展模块的名称，正好这个扩展模块也叫tcp。# 基本匹配条件我们可以直接使用，而如果想要使用扩展匹配条件，则需要依赖一些扩展模块# 扩展匹配条件是可以取反的，同样是使用"!"进行取反，比如 "! --dport 22"，表示目标端口不是22的报文将会被匹配到。[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp --dport 22 -j REJECT# 也可以省略-m选项。当使用-p选项指定了报文的协议时，如果在没有使用-m指定对应的扩展模块名称的情况下，使用了扩展匹配条件， iptables默认会调用与-p选项对应的协议名称相同的模块。* 源端口[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp --sport 22 -j ACCEPT[root@bogon ~]# iptables --line -xvnL INPUTChain INPUT (policy ACCEPT 59 packets, 4224 bytes)num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT tcp -- * * 10.5.5.249 0.0.0.0/0 tcp spt:222 1 60 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 tcp dpt:22 reject-with icmp-port-unreachable* 指定端口范围[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp --dport 22:25 -j REJECT[root@bogon ~]# iptables --line -xvnL INPUTChain INPUT (policy ACCEPT 9 packets, 662 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 tcp dpts:22:25 reject-with icmp-port-unreachable# --dport 22:25表示目标端口为22到25之间的所有端口[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp --dport :22 -j REJECT[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp --sport 80: -j REJECT [root@bogon ~]# iptables --line -xvnL INPUTChain INPUT (policy ACCEPT 46 packets, 3358 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 tcp spts:80:65535 reject-with icmp-port-unreachable2 0 0 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 tcp dpts:0:22 reject-with icmp-port-unreachable# --sport和--dport都可以指定多个端口，第一条表示从0到22端口，第二条表示80端口到65535端口* --tcp-flags# "--tcp-flags"指的就是tcp头中的标志位，我们可以通过此扩展匹配条件，去匹配tcp报文的头部的标识位，然后根据标识位的实际情况实现访问控制的功能。[root@bogon ~]# iptables -I INPUT -p tcp -m tcp --dport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN -j REJECT# "-m tcp --dport 22"的表示使用tcp扩展模块，指定目标端口为22号端口(ssh默认端口)，"--tcp-flags"用于匹配报文tcp头部的标志位，"SYN,ACK,FIN,RST,URG,PSH SYN"就是用于配置我们要匹配的标志位的，我们可以把这串字符拆成两部分去理解，第一部分为"SYN,ACK,FIN,RST,URG,PSH"，第二部分为"SYN"。第一部分表示：我们需要匹配报文tcp头中的哪些标志位，这里指定了六个标志位。第二部分表示：第一部分的标志位列表中，哪些标志位必须为1，这里指定的是SYN标志位必须为1，其他标志位必须为0。也就是tcp三次握手时第一次握手时的情况。[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 44 packets, 3226 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 flags:0x3F/0x02 reject-with icmp-port-unreachable[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN -j REJECT[root@bogon ~]# iptables -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN,ACK -j REJECT# 第一条命令匹配到的报文是第一次握手的报文，第二条命令匹配到的报文是第二次握手的报文。[root@bogon ~]# iptables -I INPUT -p tcp -m tcp --dport 22 --tcp-flags ALL SYN -j REJECT[root@bogon ~]# iptables -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags ALL SYN,ACK -j REJECT# 上面两条命令可以简写成这样，也就是将六个标志位用ALL代替* --syn[root@bogon ~]# iptables -I INPUT -p tcp -m tcp --dport 22 --syn -j REJECT# 使用"--syn"选项匹配第一次握手，这相当于使用"--tcp-flags SYN,RST,ACK,FIN SYN"，也就是说，可以使用"--syn"选项去匹配tcp新建连接的请求报文。 udp扩展1234567891011[root@bogon ~]# iptables -I INPUT -p udp -m udp --dport 137 -j ACCEPT[root@bogon ~]# iptables -I INPUT -p udp -m udp --dport 138 -j ACCEPT# 放行samba服务的137与138这两个UDP端口[root@bogon ~]# iptables -I INPUT -p udp --dport 137 -j ACCEPT[root@bogon ~]# iptables -I INPUT -p udp --dport 138 -j ACCEPT# 可以省略-m选项[root@bogon ~]# iptables -I INPUT -p udp --dport 137:157 -j ACCEPT# 开放137到157之间的所有udp端口# udp中的--sport与--dport也只能指定连续的端口范围，并不能一次性指定多个离散的端口# 使用multiport扩展模块，即可指定多个离散的UDP端口 icmp扩展12# ICMP协议的全称为Internet Control Message Protocol，翻译为互联网控制报文协议，它主要用于探测网络上的主机是否可用，目标是否可达，网络是否通畅，路由是否可用等。# 我们平常使用ping命令ping某主机时，如果主机可达，对应主机会对我们的ping请求做出回应（此处不考虑禁ping等情况），也就是说，我们发出ping请求，对方回应ping请求，虽然ping请求报文与ping回应报文都属于ICMP类型的报文，但是如果在概念上细分的话，它们所属的类型还是不同的，我们发出的ping请求属于类型8的icmp报文，而对方主机的ping回应报文则属于类型0的icmp报文，根据应用场景的不同，icmp报文被细分为如下各种类型。 1234567891011121314151617# 从上图可以看出，所有表示"目标不可达"的icmp报文的type码为3，而"目标不可达"又可以细分为多种情况，是网络不可达呢？还是主机不可达呢？再或者是端口不可达呢？所以，为了更加细化的区分它们，icmp对每种type又细分了对应的code，用不同的code对应具体的场景，所以，我们可以使用type/code去匹配具体类型的ICMP报文，比如可以使用"3/1"表示主机不可达的icmp报文。# 上图中的第一行就表示ping回应报文，它的type为0，code也为0，从上图可以看出，ping回应报文属于查询类（query）的ICMP报文，从大类上分，ICMP报文还能分为查询类与错误类两大类，目标不可达类的icmp报文则属于错误类报文。# 而我们发出的ping请求报文对应的type为8，code为0。[root@bogon ~]# iptables -I INPUT -p icmp -j REJECT# 上例中，我们并没有使用任何扩展匹配条件，我们只是使用"-p icmp"匹配了所有icmp协议类型的报文。如果进行了上述设置，别的主机向我们发送的ping请求报文无法进入防火墙，我们向别人发送的ping请求对应的回应报文也无法进入防火墙。所以，我们既无法ping通别人，别人也无法ping通我们。[root@bogon ~]# iptables -F[root@bogon ~]# iptables -I INPUT -p icmp -m icmp --icmp-type 8/0 -j REJECT# 本机可以ping通外部主机，但外部主机不能ping通本机# "-m icmp"表示使用icmp扩展，因为上例中使用了"-p icmp"，所以"-m icmp"可以省略，使用"--icmp-type"选项表示根据具体的type与code去匹配对应的icmp报文，而上图中的"--icmp-type 8/0"表示icmp报文的type为8，code为0才会被匹配到，也就是只有ping请求类型的报文才能被匹配到，所以，别人对我们发起的ping请求将会被拒绝通过防火墙，而我们之所以能够ping通别人，是因为别人回应我们的报文的icmp type为0，code也为0，所以无法被上述规则匹配到，所以我们可以看到别人回应我们的信息。[root@bogon ~]# iptables -I INPUT -p icmp -m icmp --icmp-type 8 -j REJECT# 因为type为8的类型下只有一个code为0的类型，所以我们可以省略对应的code[root@test ~]# iptables -I OUTPUT -p icmp --icmp-type 8 -j REJECT# 如果这样设置，那么我们的主机就无法ping通外部主机了，因为我们ping外部主机发出的是类型8的报文，设置在OUTPUT链上，就无法出去了。我们ping外部主机出去的是类型8进来的是类型0的报文，外部主机ping我们的主机，进来的是类型8出去的是类型0的报文。[root@bogon ~]# iptables -I INPUT -p icmp -m icmp --icmp-type "echo-request" -j REJECT# 我们可以用icmp报文的描述名称去匹配对应类型的报文。使用 --icmp-type "echo-request"与 --icmp-type 8/0的效果完全相同# 名称中的"空格"需要替换为"-"，如echo request要命令中要写为echo-request multiport扩展模块1234567891011121314151617* 指定不连续端口[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp -m multiport --dports 22,36,80 -j REJECT[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 121 packets, 7270 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 multiport dports 22,36,80 reject-with icmp-port-unreachable# 禁止来自249的主机上的tcp报文访问本机的22号端口、36号端口以及80号端口# 可以使用multiport模块的--sports扩展条件同时指定多个离散的源端口。使用multiport模块的--dports扩展条件同时指定多个离散的目标端口* 指定连续端口[root@bogon ~]# iptables -I INPUT -s 10.5.5.249 -p tcp -m multiport --dports 22,80:88 -j REJECT[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 47 packets, 3474 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 10.5.5.249 0.0.0.0/0 multiport dports 22,80:88 reject-with icmp-port-unreachable# 使用multiport模块的--sports与--dpors时，也可以指定连续的端口范围，并且能够在指定连续的端口范围的同时，指定离散的端口号# 拒绝来自10.5.5.249的tcp报文访问当前主机的22号端口以及80到88之间的所有端口号 iprange扩展模块1234567891011# 使用iprange扩展模块可以指定"一段连续的IP地址范围"，用于匹配报文的源地址或者目标地址。# iprange扩展模块中有两个扩展匹配条件可以使用# --src-range# --dst-range[root@bogon ~]# iptables -I INPUT -m iprange --src-range 10.5.5.240-10.5.5.249 -j REJECT[root@bogon ~]# iptables --line -nxvL INPUTChain INPUT (policy ACCEPT 208 packets, 11763 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 source IP range 10.5.5.240-10.5.5.249 reject-with icmp-port-unreachable# 如果报文的源IP地址在10.5.5.240到10.5.5.249之间，则丢弃报文，IP段的始末IP使用"横杠"连接，--src-range与--dst-range和其他匹配条件一样，能够使用"!"取反 string扩展模块123456789101112131415161718192021222324252627282930# 使用string扩展模块，可以指定要匹配的字符串，如果报文中包含对应的字符串，则符合匹配条件。# string模块的常用选项# --algo：用于指定匹配算法，可选的算法有bm与kmp，此选项为必须选项，我们不用纠结于选择哪个算法，但是我们必须指定一个。# --string：用于指定需要匹配的字符串。# 下面在10.5.5.249上部署[root@test html]# yum install -y httpd[root@test html]# vim /var/www/html/index.html OOXX[root@test html]# vim /var/www/html/index1.html Hello World[root@test ~]# systemctl start httpd# 下面到10.5.5.22主机访问[root@bogon ~]# curl 10.5.5.249OOXX[root@bogon ~]# curl 10.5.5.249/index1.htmlHello World# 在249主机上安装httpd，提供两个网页，内容分别为OOXX和Hello World。此时在另一台主机可以正常访问[root@bogon ~]# iptables -I INPUT -m string --algo bm --string "OOXX" -j REJECT# 如果报文中包含"OOXX"字符，我们就拒绝报文进入本机。'-m string'表示使用string模块，'--algo bm'表示使用bm算法去匹配指定的字符串，' --string "OOXX" '则表示我们想要匹配的字符串为"OOXX"# 这是设置返回的信息中如果有OOXX就拒绝进入本机[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 51 packets, 3603 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 STRING match "OOXX" ALGO name bm TO 65535 reject-with icmp-port-unreachable[root@bogon ~]# curl 10.5.5.249^C[root@bogon ~]# curl 10.5.5.249/index1.htmlHello World# 在22主机上设置规则后，因为249主机的默认页中包含“OOXX”，所以访问时会停留在空白处，没有信息返回。如果访问index1.html页面是没有问题的。 time扩展模块12345678910111213141516171819202122232425262728293031# 可以通过time扩展模块，根据时间段匹配报文，如果报文到达的时间在指定的时间范围以内，则符合匹配条件。# --monthdays与--weekdays可以使用"!"取反，其他选项不能取反。* 指定时间[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --timestart 09:00:00 --timestop 18:00:00 -j REJECT[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 443 -m time --timestart 09:00:00 --timestop 18:00:00 -j REJECT# 每天早上9点到下午6点不能看网页。"-m time"表示使用time扩展模块，--timestart选项用于指定起始时间，--timestop选项用于指定结束时间。# 测试时，此条设置完未生效，依然可以访问网页[root@bogon ~]# iptables --line -nvxL OUTPUTChain OUTPUT (policy ACCEPT 37 packets, 3516 bytes)num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:443 TIME from 09:00:00 to 18:00:00 UTC reject-with icmp-port-unreachable2 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 TIME from 09:00:00 to 18:00:00 UTC reject-with icmp-port-unreachable* 按周指定日期[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --weekdays 6,7 -j REJECT# 只有周六日不能看网页。使用--weekdays选项可以指定每个星期的具体哪一天，可以同时指定多个，用逗号隔开，除了能够数字表示"星期几",还能用缩写表示，例如：Mon, Tue, Wed, Thu, Fri, Sat, Sun[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays 6,7 -j REJECT# 将上面两种方法结合使用。指定只有周六日的早上9点到下午6点不能浏览网页。* 指月指定日期[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --monthdays 22,23 -j REJECT# 使用--monthdays选项可以具体指定的每个月的22号，23号不能访问网页。[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --weekdays 5 --monthdays 22,23,24,25,26,27,28 -j REJECT# 当一条规则中同时存在多个条件时，多个条件之间默认存在"与"的关系。所以，上面的规则表示匹配的时间必须为星期五，并且这个"星期五"同时还需要是每个月的22号到28号之间的一天，也就表示每个月的第4个星期五* 指定具体时间[root@bogon ~]# iptables -I OUTPUT -p tcp --dport 80 -m time --datestart 2018-10-15 --datestop 2018-10-19 -j REJECT# 可以使用--datestart 选项与-datestop选项，指定具体的日期范围。测试中，此条可以生效。 connlimit扩展模块1234567891011121314151617# 使用connlimit扩展模块，可以限制每个IP地址同时链接到server端的链接数量，注意：我们不用指定IP，其默认就是针对"每个客户端IP"，即对单IP的并发连接数限制。* --connlimit-above[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT# 超过两个连接就拒绝。使用"-m connlimit"指定使用connlimit扩展，使用"--connlimit-above 2"表示限制每个IP的链接数量上限为2，再配合-p tcp --dport 22，即表示限制每个客户端IP的ssh并发链接数量不能超过(above)2。# centos6中，我们可以对--connlimit-above选项进行取反[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 -m connlimit ! --connlimit-above 2 -j ACCEPT# 每个客户端IP的ssh链接数量只要不超过两个，则允许链接。但上例的规则并不能表示：每个客户端IP的ssh链接数量超过两个则拒绝链接。因为匹配不到时要匹配默认规则，如果默认规则是ACCEPT，那么依然可以连接# 即使我们配置了上例中的规则，也不能达到"限制"的目的，所以我们通常并不会对此选项取反，因为既然使用了此选项，我们的目的通常就是"限制"连接数量。# centos7中iptables为我们提供了一个新的选项，--connlimit-upto，这个选项的含义与"! --commlimit-above"的含义相同，即链接数量未达到指定的连接数量之意，所以综上所述，--connlimit-upto选项也不常用。* --connlimit-mask[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 2 --connlimit-mask 24 -j REJECT# "--connlimit-mask 24"表示某个C类网段。上面规则表示，一个最多包含254个IP的C类网络中，同时最多只能有2个ssh客户端连接到当前服务器[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 10 --connlimit-mask 27 -j REJECT# "--connlimit-mask 27"表示某个C类网段，通过计算后可以得知，这个网段中最多只能有30台机器（30个IP），这30个IP地址最多只能有10个ssh连接同时连接到服务器端# 在不使用--connlimit-mask的情况下，连接数量的限制是针对"每个IP"而言的，当使用了--connlimit-mask选项以后，则可以针对"某类IP段内的一定数量的IP"进行连接数量的限制 limit扩展模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# limit模块是对"报文到达速率"进行限制的.如果想要限制单位时间内流入的包的数量，就能用limit模块* --limit[root@bogon ~]# iptables -I INPUT -p icmp -m limit --limit 10/minute -j ACCEPT# "-p icmp"表示我们针对ping请求添加了一条规则（ping使用icmp协议），"-m limit"表示使用limit模块， "--limit 10/minute -j ACCEPT"表示每分钟最多放行10个包，就相当于每6秒钟最多放行一个包[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 5950 packets, 5128996 bytes)num pkts bytes target prot opt in out source destination 1 111 9416 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 limit: avg 10/min burst 5# 上面的规则并不会起作用。因为每6秒放行一个包，那么iptables就会计时，每6秒一个轮次，到第6秒时，达到的报文就会匹配到对应的规则，执行对应的动作ACCEPT。那么在第6秒之前到达的包，则无法被上述规则匹配到。那么这些包就要向下匹配策略中的其他规则，如果都不能匹配，就会匹配默认策略，因为默认策略是ACCEPT，所以ping此主机的时候还是会正常运行。[root@bogon ~]# iptables -A INPUT -p icmp -j REJECT# 拒绝所有的ping包[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 6 packets, 428 bytes)num pkts bytes target prot opt in out source destination 1 150 12692 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 limit: avg 10/min burst 52 56 4704 REJECT icmp -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachable# 第一条规则表示每分钟最多放行10个icmp包，也就是6秒放行一个，第6秒的icmp包会被上例中的第一条规则匹配到，第6秒之前的包则不会被第一条规则匹配到，于是被后面的拒绝规则匹配到了# 这时再ping此主机时就可以发现每6秒才能ping通一次了。但还有一个问题，就是最开始的5个ping包是不受限制的，可以正常ping通。现象如下，下面解释原因[root@test ~]# ping 10.5.5.22PING 10.5.5.22 (10.5.5.22) 56(84) bytes of data.64 bytes from 10.5.5.22: icmp_seq=1 ttl=64 time=0.248 ms64 bytes from 10.5.5.22: icmp_seq=2 ttl=64 time=0.355 ms64 bytes from 10.5.5.22: icmp_seq=3 ttl=64 time=0.332 ms64 bytes from 10.5.5.22: icmp_seq=4 ttl=64 time=0.261 ms64 bytes from 10.5.5.22: icmp_seq=5 ttl=64 time=0.528 msFrom 10.5.5.22 icmp_seq=6 Destination Port Unreachable64 bytes from 10.5.5.22: icmp_seq=7 ttl=64 time=0.418 msFrom 10.5.5.22 icmp_seq=8 Destination Port UnreachableFrom 10.5.5.22 icmp_seq=9 Destination Port UnreachableFrom 10.5.5.22 icmp_seq=10 Destination Port UnreachableFrom 10.5.5.22 icmp_seq=11 Destination Port UnreachableFrom 10.5.5.22 icmp_seq=12 Destination Port Unreachable64 bytes from 10.5.5.22: icmp_seq=13 ttl=64 time=0.435 msFrom 10.5.5.22 icmp_seq=14 Destination Port UnreachableFrom 10.5.5.22 icmp_seq=15 Destination Port Unreachable* --limit-burst# "--limit-burst"可以指定"空闲时可放行的包的数量。在不使用"--limit-burst"选项明确指定放行包的数量时，默认值为5，所以才会有上面的现象。# 如果想要彻底了解limit模块的工作原理，我们需要先了解一下"令牌桶"算法，因为limit模块使用了令牌桶算法。我们可以这样想象，有一个木桶，木桶里面放了5块令牌，而且这个木桶最多也只能放下5块令牌，所有报文如果想要出关入关，都必须要持有木桶中的令牌才行，这个木桶有一个神奇的功能，就是每隔6秒钟会生成一块新的令牌，如果此时，木桶中的令牌不足5块，那么新生成的令牌就存放在木桶中，如果木桶中已经存在5块令牌，新生成的令牌就无处安放了，只能溢出木桶（令牌被丢弃），如果此时有5个报文想要入关，那么这5个报文就去木桶里找令牌，正好一人一个，于是他们5个手持令牌，快乐的入关了，此时木桶空了，再有报文想要入关，已经没有对应的令牌可以使用了，但是，过了6秒钟，新的令牌生成了，此刻，正好来了一个报文想要入关，于是，这个报文拿起这个令牌，就入关了，在这个报文之后，如果很长一段时间内没有新的报文想要入关，木桶中的令牌又会慢慢的积攒了起来，直到达到5个令牌，并且一直保持着5个令牌，直到有人需要使用这些令牌，这就是令牌桶算法的大致逻辑。# "--limit"选项就是用于指定"多长时间生成一个新令牌的"，"--limit-burst"选项就是用于指定"木桶中最多存放几个令牌的"[root@bogon ~]# iptables -I INPUT -p icmp -m limit --limit-burst 1 --limit 10/minute -j ACCEPT# 使用"--limit"选项时，可以选择的时间单位有多种，如：/second、/minute、/hour、/day。比如，3/second表示每秒生成3个"令牌"，30/minute表示每分钟生成30个"令牌"。[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 174 packets, 11316 bytes)num pkts bytes target prot opt in out source destination 1 13 1092 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 limit: avg 10/min burst 12 194 16296 REJECT icmp -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachable state扩展模块123456789101112# 对于state模块而言的"连接"并不能与tcp的"连接"画等号，在TCP/IP协议簇中，UDP和ICMP是没有所谓的连接的，但是对于state模块来说，tcp报文、udp报文、icmp报文都是有连接状态的。对于state模块而言，只要两台机器在"你来我往"的通信，就算建立起了连接# state模块中的报文状态# NEW：连接中的第一个包，状态就是NEW，我们可以理解为新连接的第一个包的状态为NEW。# ESTABLISHED：我们可以把NEW状态包后面的包的状态理解为ESTABLISHED，表示连接已建立。# RELATED：从字面上理解RELATED译为关系、相关的，但是这样仍然不容易理解，我们举个例子。比如FTP服务，FTP服务端会建立两个进程，一个命令进程，一个数据进程。命令进程负责服务端与客户端之间的命令传输（我们可以把这个传输过程理解成state中所谓的一个"连接"，暂称为"命令连接"）。数据进程负责服务端与客户端之间的数据传输 ( 我们把这个过程暂称为"数据连接" )。但是具体传输哪些数据，是由命令去控制的，所以，"数据连接"中的报文与"命令连接"是有"关系"的。那么，"数据连接"中的报文可能就是RELATED状态，因为这些报文与"命令连接"中的报文有关系。## (注：如果想要对ftp进行连接追踪，需要单独加载对应的内核模块nf_conntrack_ftp，如果想要自动加载，可以配置/etc/sysconfig/iptables-config文件)# INVALID：如果一个包没有办法被识别，或者这个包没有任何状态，那么这个包的状态就是INVALID，我们可以主动屏蔽状态为INVALID的报文。# UNTRACKED：报文的状态为UNTRACKED时，表示报文未被追踪，当报文的状态为UNTRACKED时通常表示无法找到相关的连接。[root@bogon ~]# iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT[root@bogon ~]# iptables -A INPUT -j REJECT# 将状态为RELATED和ESTABLISHED的报文都放行，这样，就表示只有回应我们的报文能够通过防火墙，如果是别人主动发送过来的新的报文，则无法通过防火墙。如想通过ssh连接本机，是不行的，但本机可以ssh连接其他主机。 黑白名单机制123456789101112131415161718# 当链的默认策略为ACCEPT时，链中的规则对应的动作应该为DROP或者REJECT，表示只有匹配到规则的报文才会被拒绝，没有被规则匹配到的报文都会被默认接受，这就是"黑名单"机制。# 当链的默认策略为DROP时，链中的规则对应的动作应该为ACCEPT，表示只有匹配到规则的报文才会被放行，没有被规则匹配到的报文都会被默认拒绝，这就是"白名单"机制。* 白名单[root@bogon ~]# iptables -I INPUT -p tcp --dport 22 -j ACCEPT[root@bogon ~]# iptables -I INPUT -p tcp --dport 80 -j ACCEPT[root@bogon ~]# iptables -P INPUT DROP[root@bogon ~]# iptables --line -nxvL INPUTChain INPUT (policy DROP 336 packets, 17902 bytes)num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:802 130 9172 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22# 放行22与80端口，并将默认策略改为DROP，这样其他端口都是无法访问的。因为只改了INPUT链为DROP，OUTPUT链的默认策略还是ACCEPT，所以可以访问80与22端口。如果OUTPUT的默认策略也是DROP，那就要再写两条出的规则。# 如果此时有误操作，删除了防火墙规则，那么所有连接就都无法进来了。也就是无法通过远程连接主机了。# 如果想要使用"白名单"的机制，最好将链的默认策略保持为"ACCEPT"，然后将"拒绝所有请求"这条规则放在链的尾部，将"放行规则"放在前面，这样做，既能实现"白名单"机制，又能保证在规则被清空时，管理员还有机会连接到主机[root@bogon ~]# iptables -P INPUT ACCEPT[root@bogon ~]# iptables -A INPUT -j REJECT# 当所有放行规则设置完成后，在INPUT链的尾部，设置一条拒绝所有请求的规则。这样就能必免上面的问题了]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables匹配条件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables基本操作]]></title>
    <url>%2F2018%2F10%2F12%2Fiptables%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[查看12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@bogon ~]# iptables -t filter -LChain INPUT (policy ACCEPT)target prot opt source destination ACCEPT all -- anywhere anywhere ctstate RELATED,ESTABLISHEDChain FORWARD (policy ACCEPT)target prot opt source destination ACCEPT all -- anywhere anywhere ctstate RELATED,ESTABLISHEDChain OUTPUT (policy ACCEPT)target prot opt source destination OUTPUT_direct all -- anywhere anywhere# 列出filter表的所有规则# 报文发往本机时，会经过PREROUTING链与INPUT链。所以，如果我们想要禁止某些报文发往本机，我们只能在PREROUTING链和INPUT链中定义规则，但是PREROUTING链并不存在于filter表中，因为PREROUTING链没有过滤功能，所以，只能在INPUT链上定义root@bogon ~]# iptables -L INPUTChain INPUT (policy ACCEPT)target prot opt source destination ACCEPT all -- anywhere anywhere ctstate RELATED,ESTABLISHED#只查看指定表中的指定链规则。可以省略-t filter，当没有使用-t选项指定表时，默认为操作filter表[root@bogon ~]# iptables -vL INPUTChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 1894 144K ACCEPT all -- any any anywhere anywhere ctstate RELATED,ESTABLISHED# 使用-v选项可以显示更多信息。字段含义如下：# pkts:对应规则匹配到的报文的个数。# bytes:对应匹配到的报文包的大小总和。# target:规则对应的target（目标），往往表示规则对应的"动作"，即规则匹配成功后需要采取的措施。# prot:表示规则对应的协议，是否只针对某些协议应用此规则。# opt:表示规则对应的选项。# in:表示数据包由哪个接口(网卡)流入，我们可以设置通过哪块网卡流入的报文需要匹配当前规则。# out:表示数据包由哪个接口(网卡)流出，我们可以设置通过哪块网卡流出的报文需要匹配当前规则。# source:表示规则对应的源头地址，可以是一个IP，也可以是一个网段。# destination:表示规则对应的目标地址。可以是一个IP，也可以是一个网段。# source与destination为anywhere是因为做了名称解析[root@bogon ~]# iptables -nvL INPUTChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 1918 146K ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED# 在规则非常多的情况下如果进行名称解析，效率会比较低。可以使用-n选项，表示不对IP地址进行名称反解，直接显示IP地址[root@bogon ~]# iptables --line-number -nvL INPUTChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 1971 150K ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED# 使用--line-numbers即可显示规则的编号。--line-numbers选项并没有对应的短选项，不过我们缩写成--line# Chain INPUT (policy ACCEPT 0 packets, 0 bytes)的含义如下：# policy表示当前链的默认策略，policy ACCEPT表示INPUT的链的默认动作为ACCEPT，默认接受通过INPUT关卡的所有请求# packets表示当前链（上例为INPUT链）默认策略匹配到的包的数量，0 packets表示默认策略匹配到0个包。# bytes表示当前链默认策略匹配到的所有包的大小总和。[root@bogon ~]# iptables --line -xnvL INPUTChain INPUT (policy ACCEPT 5557 packets, 332K bytes)num pkts bytes target prot opt in out source destination 1 2012 153468 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED# 其实，我们可以把packets与bytes称作"计数器"，上例中的计数器记录了默认策略匹配到的报文数量与总大小，"计数器"只会在使用-v选项时，才会显示出来。当被匹配到的包达到一定数量时，计数器会自动将匹配到的包的大小转换为可读性较高的单位。如果你想要查看精确的计数值，而不是经过可读性优化过的计数值，那么你可以使用-x选项，表示显示精确的计数值 添加规则12345678910111213141516171819202122232425* 拒绝某地址访问[root@bogon ~]# iptables -t filter -I INPUT -s 10.5.5.249 -j DROP# 拒绝10.5.5.249访问本机，这时249主机不能ping通本机# -I表示将规则插入到每一条，-s指定源地址，-j指定动作。在iptables中，动作被称之为"target"[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 519 packets, 33559 bytes)num pkts bytes target prot opt in out source destination 1 193 16212 DROP all -- * * 10.5.5.249 0.0.0.0/0# 有193个包被对应的规则匹配到，总计大小16212bytes。[root@bogon ~]# iptables -A INPUT -s 10.5.5.249 -j ACCEPT# -A为append之意，表示追加一条规则到末尾[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 86 packets, 6164 bytes)num pkts bytes target prot opt in out source destination 1 598 50232 DROP all -- * * 10.5.5.249 0.0.0.0/0 2 0 0 ACCEPT all -- * * 10.5.5.249 0.0.0.0/0 # 追加规则后发现追加的规则并未匹配到，因为数据是按规则序列从上向下匹配的，第一条规则已经拒绝了所有请求，所以后面的规则也不会匹配到了。[root@bogon ~]# iptables -I INPUT 3 -s 10.5.5.249 -j DROP# 指定将规则插入到INPUT链的第三条[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 51 packets, 3610 bytes)num pkts bytes target prot opt in out source destination 1 941 79044 DROP all -- * * 10.5.5.249 0.0.0.0/0 2 0 0 ACCEPT all -- * * 10.5.5.249 0.0.0.0/0 3 0 0 DROP all -- * * 10.5.5.249 0.0.0.0/0 删除123456789101112131415[root@bogon ~]# iptables -D INPUT 3# 删除INPUT链中的第三条规则[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 6 packets, 466 bytes)num pkts bytes target prot opt in out source destination 1 1040 87360 DROP all -- * * 10.5.5.249 0.0.0.0/0 2 0 0 ACCEPT all -- * * 10.5.5.249 0.0.0.0/0[root@bogon ~]# iptables -D INPUT -s 10.5.5.249 -j ACCEPT# 根据匹配条件删除规则，这里要删除的是源地址是10.5.5.249，动作是ACCEPT的规则[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 6 packets, 428 bytes)num pkts bytes target prot opt in out source destination 1 1128 94752 DROP all -- * * 10.5.5.249 0.0.0.0/0[root@bogon ~]# iptables -t filter -F# 删除filter表中的所有规则 修改123456789101112131415[root@bogon ~]# iptables -R INPUT 1 -s 10.5.5.249 -j REJECT# -R选项表示修改指定的链，使用-R INPUT 1表示修改INPUT链的第1条规则，使用-j REJECT表示将INPUT链中的第一条规则的动作修改为REJECT，注意：上例中， -s选项以及对应的源地址不可省略。在使用-R选项修改某个规则时，必须指定规则对应的原本的匹配条件。如果上例中的命令没有使用-s指定对应规则中原本的源地址，那么在修改完成后，你修改的规则中的源地址会自动变为0.0.0.0/0# 如果你想要修改某条规则，还不如先将这条规则删除，然后在同样位置再插入一条新规则[root@bogon ~]# iptables --line -nvxL INPUTChain INPUT (policy ACCEPT 9 packets, 662 bytes)num pkts bytes target prot opt in out source destination 1 2 168 REJECT all -- * * 10.5.5.249 0.0.0.0/0 reject-with icmp-port-unreachable* 修改默认策略[root@bogon ~]# iptables -P FORWARD DROP# 使用-P选项修改默认策略，修改filter表中的FORWARD链的默认策略为DROP[root@bogon ~]# iptables --line -nvxL FORWARDChain FORWARD (policy DROP 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination# 可以看到policy后面是DROP了 保存12345678910111213141516171819* CentOS6[root@bogon ~]# service iptables save# 使修改的规则永久生效[root@bogon ~]# cat /etc/sysconfig/iptables# 规则保存在/etc/sysconfig/iptables中* CentOS7[root@test ~]# yum install -y iptables-services[root@bogon ~]# systemctl start iptables[root@bogon ~]# systemctl enable iptables[root@bogon ~]# service iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ]# 要安装iptables-services后才能使用service命令保存规则* 其他保存方法[root@bogon ~]# iptables-save &gt; /etc/sysconfig/iptables* 重新加载规则[root@bogon ~]# iptables-restore &lt; /etc/sysconfig/iptables]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdyc环境简单部署]]></title>
    <url>%2F2018%2F10%2F12%2Fjdyc%E7%8E%AF%E5%A2%83%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[web、netty、wechat、processor12345678910111213141516171819202122232425* 安装环境yum install -y java-1.8.0-openjdk-develvim /etc/profile.d/java.sh export JAVA_HOME=/usrtar xf apache-tomcat-8.5.33.tar.gz -C /usr/localcd /usr/localln -sv apache-tomcat-8.5.33 tomcat* 部署** webvim /usr/local/tomcat/conf/server.xml &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="" docBase="echarge" reloadable="true" /&gt;#修改tomcat的启动端口，加入Context** wechat &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="" docBase="rest-app" debug="0" reloadable="true"/&gt; #netty与processor不必调整tomcat设置，将相关包放入tomcat中的webapps中* 启动/usr/local/tomcat/bin/startup.shtail -f /usr/local/tomcat/logs/catalina.out#查看启动日志 mysql1234567891011121314151617181920212223242526272829303132333435yum install -y mariadbvim /etc/my.cnf [client] default-character-set = utf8mb4 [mysql] default-character-set = utf8mb4 #字符集要加上，不然使用中会有字符不能正常显示 socket=/var/lib/mysql/mysql.sock [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock symbolic-links=0 character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci wait_timeout=10 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES innodb_file_per_table=ON skip_name_resolve=ON server_id=1 log-bin=master-log relay_log=relay-log auto_increment_offset=1 auto_increment_increment=2 #这是为了做主主复制的配置 [mysqld_safe] log-error=/var/log/mysqld.logmysql_secure_installation#设置用户名和密码mysqlGRANT ALL ON *.* TO 'echarge'@'%' IDENTIFIED BY 'centos';FLUSH PRIVILEGES; zk&amp;kafka123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# zookeeper环境依赖JVM虚拟机yum install -y java-1.8.0-openjdk-develvim /etc/profile.d/java.sh export JAVA_HOME=/usr # 需要准备三台主机，在三台主机上做相同的操作* zookeepertar -xf zookeeper-3.4.9.tar.gz -C /usr/localcd /usr/localln -sv zookeeper-3.4.9 zookeepermkdir -pv /data/zookeepercd /usr/local/zookeeper/confcp zoo_sample.cfg zoo.cfgvim zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/zookeeper clientPort=2181 server.1=10.5.5.19:2888:3888 server.2=10.5.5.7:2888:3888 server.3=10.5.5.2:2888:3888scp zoo.cfg node2:/usr/local/zookeeperscp zoo.cfg node3:/usr/local/zookeepercd /data/zookeeperecho 1 &gt; myid//给zookeeper一个ID号，这个ID号与配置文件中的server.ID要一致。另两个节点要改为2和3。cd /usr/local/zookeeperbin/zkServer.sh start//启动bin/zkServer.sh status//查看状态，如果是主节点，就显示leader，否则显示follower./bin/zkCli.sh -server 10.5.5.2:2181//连接到其他服务器上的zookeeper* kafkatar xf kafka_2.10-0.10.0.1.tgz -C /usr/localcd /usr/localln -sv kafka_2.10-0.10.0.1 kafkacd kafkavim config/server.properties broker.id=0 //三个节点的broker.id要不一样，不然另两个节点不能启动kafka port=9092 host.name=10.5.5.2 #本机的地址 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 log.dirs=/tmp/kafka-logs num.partitions=3 num.recovery.threads.per.data.dir=3 log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 zookeeper.connect=10.5.5.19:2181,10.5.5.7:2181,10.5.5.2:2181 zookeeper.connection.timeout.ms=6000bin/kafka-server-start.sh config/server.properties//启动* 创建主题bin/kafka-topics.sh --create --zookeeper 10.5.5.232:2181 --replication-factor 3 --partitions 22 --topic inboundMsgbin/kafka-topics.sh --create --zookeeper 10.5.5.232:2181 --replication-factor 3 --partitions 22 --topic outboundMsg#创建3个副本，22个分区* 测试bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --broker-info --group inbound --topic inboundMsg --zookeeper 192.168.2.182:2181#结果中的Lag是待消费的数量watch '/usr/local/kafka/bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 192.168.2.182:9092 --group inbound --describe'#如果是多个分区，用此命令bin/kafka-topics.sh --describe --zookeeper 10.5.5.2:2181#查看Topic；--zookeeper 为zk集群地址，使用任意一个节点都行bin/kafka-topics.sh --list --zookeeper 10.5.5.7:2181#查看Topic 列表bin/kafka-console-producer.sh --broker-list 10.5.5.2:9092,10.5.5.7:9092,10.5.5.19:9092 --topic my-test#在一个节点上创建生产者，在任意节点执行均可，之后输入一些内容 abadfasdfasbin/kafka-console-consumer.sh --bootstrap-server 10.5.5.2:9092,10.5.5.7:9092,10.5.5.19:9092 --from-beginning --topic my-test#在另两个节点，创建消费者。--broker-server broker 节点列表，类似于上面的 --broker-list；即三台服务器节点列表，实际上写成其中一个、两个或者三个均可，中间逗号隔开；--from-beginning 表明从头获取，而不是从接入时间获取之后的消息 redis123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#准备三台主机* 安装yum install -y redis* 配置vim /etc/sudoers #Defaults requiretty#注释上面一行vim /etc/sudoers.d/redis redis ALL=(ALL) NOPASSWD:/sbin/ip,NOPASSWD:/sbin/arping#这是为了让redis用户使用sudo命令时不用密码也可执行ip和arping命令。因为redis-sentinel进程是以redis身份运行的，所以执行脚本时也是redis用户，但redis用户是不能设置本机地址的，所以要给它权限。vim /opt/notify_mymaster.sh #!/bin/bash # MASTER_IP=$&#123;6&#125; LOCAL_IP='192.168.2.65' VIP='192.168.2.183' NETMASK='24' INTERFACE='ens160' if [ $&#123;MASTER_IP&#125; = $&#123;LOCAL_IP&#125; ];then sudo /usr/sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; sudo /usr/sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0 else sudo /usr/sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; exit 0 fi exit 1chmod +x /opt/notify_mymaster.sh# /sbin是/usr/sbin的软链接# 因为如果没有脚本或脚本没有执行权限，redis-sentinel服务就不能启动，所以提前设置。* redis1vim /etc/redis.conf bind 0.0.0.0 #监听所有地址systemctl start redisredis-cli CONFIG SET requirepass redisqwer1234 AUTH redisqwer1234 CONFIG GET requirepass CONFIG SET masterauth redisqwer1234 CONFIG REWRITE#设置并查看认证密码* redis2&amp;3vim /etc/redis.conf bind 0.0.0.0systemctl start redisredis-cli SLAVEOF 192.168.2.65 6379 #指明主节点地址与端口 CONFIG SET masterauth redisqwer1234 #设置主节点的认证信息 CONFIG SET requirepass redisqwer1234 CONFIG REWRITE#这里的三个节点都应该设置masterauth和requirepass的值，requirepass的值是自己作为主节点时，别人请求要用的认证密码。masterauth是与主节点通信时要用到的认证密码。也就是说，masterauth指向的密码就是requirepass设置的密码。因为三个节点都可以做主节点，所以都要设置。如果只设置一个，那么在主节点查看从节点信息时，有可能只显示一个。#可在从节点查看/var/log/redis/redis.conf日志，日志中会显示不能加入集群的信息* redis1INFO replication#查看状态信息，有slave0的信息，也就是从节点的信息。如： slave0:ip=192.168.2.62,port=6379,state=online,offset=212225,lag=1 slave1:ip=192.168.2.65,port=6379,state=online,offset=212225,lag=1* redis2&amp;3redis-cli CONFIG SET requirepass redisqwer1234 AUTH redisqwer1234 CONFIG REWRITE#设置两个节点的认证信息与主节点一样，这是为了在从节点提升为主节点时的准备* redis1vim /etc/redis-sentinel.conf port 26379 bind 0.0.0.0 #这一项一定要加上，不然不能通过认证 sentinel monitor mymaster 10.5.5.235 6379 2 #sentinel监听主节点的地址和端口，2表示至少有几个sentinel进行选举才能通过 sentinel auth-pass mymaster ccjd.redis.com #认证mymaster的主节点的密码，建议用随机字符串。如果不写此项就无法用sentinel slaves mymaster命令查看到从节点的信息 sentinel down-after-milliseconds mymaster 5000 #多久连接不到主节点就认为它宕机了，这是主观宕机。这里定义是30秒，可改为5000 sentinel parallel-syncs mymaster 1 #一次只给几个从节点同步。并行同步的数量 sentinel failover-timeout mymaster 60000 #故障转移多久完成不了，就进行新的转移。这个时间不要太短。这里是3分钟 sentinel client-reconfig-script mymaster /opt/notify_mymaster.sh #故障转移时执行notify_mymaster.sh脚本。加入这一行，sentinel的client-reconfig-script在每次执行时会传递出7个参数，第6个就是主redis的地址scp /etc/redis-sentinel.conf redis2:/etcscp /etc/redis-sentinel.conf redis3:/etcsystemctl start redis-sentinelss -tln#监听26379端口tail -f /var/log/redis/sentinel.log* redis2&amp;3systemctl start redis-sentinel* redis1redis-cli -h 10.5.5.21 -p 26379 SENTINEL master mymaster #查看主节点状态 SENTINEL slaves mymaster #查看从节点状态 SENTINEL failover mymaster #切换主节点 SENTINEL master mymaster SENTINEL failover mymaster #当再次切换时就很慢，停掉主节点的服务后还要等一会。可能与设置中的failover-timeout的时间是3分钟有关。 SENTINEL get-master-addr-by-name mymaster #获得现在名称为mymaster主redis的IP和端口]]></content>
      <categories>
        <category>jdbc</category>
      </categories>
      <tags>
        <tag>jdbc部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM逻辑卷]]></title>
    <url>%2F2018%2F10%2F08%2FLVM%E9%80%BB%E8%BE%91%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[概念 MD：在內核中它的所有調配工作由md這個模塊來完成，進而能實現將多個物理設備組合成一個邏輯設備或叫元設備（meta device）。主要用來實現軟RAID： /dev/md# DM：Device Mapper 設備映射；這種機制也能夠提供將多個物理設備映射成一個邏輯設備，功能比MD強大；由多個子模塊組成，完成多種不同的組織方式。 ​ 可提供軟RAID，LVM2功能 快照功能：保留數據在你做快照那一刻的狀態，快照一般小於原數據，它只是訪問同一個數據的另一條路徑，與文件軟鏈接相似，默認訪問只有一個路徑，快照是另一條路徑，又不僅限於路徑，它也可以作爲用戶去訪問對應磁盤上它所映射文件的通路。將快照那一刻的狀態保留下來作爲文件的訪問通道，被快照的文件被修改時，先保存一份快照，訪問時看數據是否改變，如果改變就訪問快照裏的數據，沒改變就訪問原數據，所以快照文件很小。快照裏只有一些改變的數據。主要是用來做數據備份的 ​ 多路徑功能：讓我們實現數據存儲設備的尋路，能通過多种不同的線來完成 左圖為最初的 LV 磁盘快照區的狀況，LVM 會預留一個區域 (左圖的左側三個 PE 區塊) 作為資料存放處。 此時快照區內並沒有任何資料，而快照區與系統區共享所有的 PE 資料， 因此你會看到快照區的內容與檔案系統是一模一樣的。 等到系統運作一陣子後，假設 A 區域的資料被变動了 (上面右圖所示)，則变動前系統會將該區域的資料移動到快照區， 所以在右圖的快照區被佔用了一塊 PE 成為 A，而其他 B 到 I 的區塊則還是與檔案系統共用 LVM 的全名是 Logical Volume Manager，中文可以翻译作逻辑卷轴管理员。LVM 的作用是将几个实体磁盘 通过软件组合成为一块看起来是独立的大磁盘(VG) ，然后将这块大磁盘再经过分割，成为可使用的分割槽 (LV)， 最终就能够挂载使用了。这样的系统可以进行文件通讯员的扩充或缩小与一个称为 PE 的项目有关。 LVM的作用：邏輯設備動態增減 PV：Physical Volume，实体卷轴。磁盘需要调整系统识别码为8e，然后经过pvcreate命令转为LVM最底层的实体卷轴（PV） VG：Volume Group，卷轴组。LVM的大磁盘就是将许多PV整合成一个VG。每个VG最多仅能包含65534个PE，如果使用LVM的默认参数，则一个VG最大可达256GB容量。 PE：Physical Extend，实体延伸区块。LVM默认使用4MB的PE区块，而LVM的VG最多可以含有65534个PE，因此默认的VG容量是256GB。这个PE是整个LVM最小的储存区块，我们的文件资料都是由写入PE来处理的。调整PE的大小会影响到VG的最大容量。 LV：Logical Volume，逻辑卷轴。VG最终会被切成LV，这个LV就是最后可以被格式化使用的分区。LV的名称通常为/dev/vgname/lvname。LVM的文件系统容量变更是通过交换PE来进行文件转换的，将原来LV内的PE转移到其他装置中就可以降低LV容量，或将其他装置的PE加到此LV中就可以加大容量。 操作流程 线性模式 (linear)：假如我将 /dev/hda1, /dev/hdb1 这两个 partition 加入到 VG 当中，并且整个 VG 只有一个 LV 时，那么所谓的线性模式就是：当 /dev/hda1 的容量用完之后，/dev/hdb1 的硬碟才会被使用到， 这也是我们所建议的模式。 交错模式 (triped)：那什么是交错模式？很简单啊，就是我将一笔资料拆成两部分，分别写入 /dev/hda1 与 /dev/hdb1 的意思，感觉上有点像 RAID 0 啦！如此一来，一份资料用两颗硬碟来写入，理论上，读写的效能会比较好。 基本上，LVM 最主要的用处是在实现一个可以弹性调整容量的文件系统上， 而不是在建立一个效能为主的磁盘上，所以，我们应该利用的是 LVM 可以弹性管理整个 partition 大小的用途上，而不是着眼在效能上的。因此， LVM 预设的读写模式是线性模式。 如果你使用 triped 模式，要注意，当任何一个 partition 损坏时，所有的资料都会‘损毁’的。 在增減邏輯卷大小的時候要用到物理邊界，邏輯邊界的概念，物理邊界指磁盤的大小，邏輯邊界指文件系統的大小。創建分區的過程就是創建物理邊界的過程，在物理邊界內部創建文件系統，文件存儲在文件系統上，文件系統邊界叫邏輯邊界，存多少數據取決於物理邊界大小與邏輯邊界大小，邏輯邊界是緊靠在物理邊界大小上創建的。所以擴展時要先擴展物理邊界，然後再擴展邏輯邊界，如果縮減就相反，先縮減文件系統邊界，再縮減物理邊界。 對卷創建快照指給邏輯卷創建快照，但快照卷必須與邏輯卷在同一個卷組中 命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566* pvpvcreate：#将实体 partition 建立成为 PV pvremove：#将 PV 属性移除，让该 partition 不具有 PV 属性。刪除PV中的原數據pvscan：#搜寻目前系统里面任何具有 PV 的磁碟pvdisplay：#显示出目前系统上面的 PV 状态pvmove：#移動PV中的數據到其他PV上，就可以拆掉這個磁盤了。* vgvgcreate：#创建VG vgcreate [-s N[mgt]] VG名称 PV名称选项与参数： #-s ：后面接 PE 的大小 (size) ，单位可以是 m, g, t (大小写均可)。默認為4MBvgremove：#删除一个VGvgscan：#搜寻系统上面是否有VG存在vgextend：#在VG内擴展额外的PVvgreduce：#在VG内移除PVvgs：#搜寻VG，简单输出vgdisplay：#显示目前系统上面的VG状态vgchange:#设定 VG 是否启动 (active)； * lvlvcreate：#创建LV lvcreate [-L N[mgt]] [-n LV名称] VG名称 lvcreate [-l N] [-n LV名称] VG名称选项与参数： #-L ：后面接容量，容量的单位可以是 M,G,T 等，要注意的是，最小单位为 PE，因此这个数量必须要是 PE 的倍数，若不相符，系统会自行计算最相近的容量。 #-l ：后面可以接 PE 的‘个数’，而不是容量。若要这么做，得要自行计算 PE 数。 #-n ：后面接的就是 LV 的名称lvremove：#删除LVlvextend：#在LV里面增加容量lvreduce：#在LV里面减少容量lvresize：#对LV进行容量大小的调整lvslvdisplay：#显示系统上面的LV状态 * 擴展邏輯卷 lvextend -L [+]n /PATH/TO/LV #擴展物理邊界，有加號表示要再擴展多大，不用加號表示擴展到多大 resize2fs resize2fs /PATH/TO/LV n #擴展邏輯邊界，這裏只能指定擴展到多大，最大不能超過物理邊界。因爲是ext文件系統，其他文件系統不一定要這樣用，或用其他命令。 -p：不用指定擴展多少，能有多大擴多大 resize2fs -p /PATH/TO/LV * 縮減邏輯卷 resize2fs resize2fs [-f] [device] [size]选项与参数： #-f ：强制进行 resize 的动作！ #[device]：装置的档案名称； #[size] ：可以加也可以不加。如果加上 size 的话，那么就必须要给予一个单位，譬如 M, G 等等。如果没有 size 的话，那么预设使用‘整个 partition’的容量来处理！ #縮減邏輯邊界 #不能在線縮減，要先卸載，確保縮減後的空間大小依然能存儲原有的所有數據；在縮減前應該先強行檢查文件，以確保文件系統處於一至性狀態 lvreduce -L [-]# /PATH/TO/LV #縮減物理邊界* 快照卷1. 生命周期為整個數據時長，在這段時長內，數據的增長量不能超出快照卷大小；大小自己估計， 保險的辦法是和原卷一樣大，或與原卷中數據一樣大2. 快照卷應該是只讀的3. 跟原卷在同一卷組內 lvcreate -s: #指定為快照卷 -P r|w: #設定是只讀還是讀寫權限，建議爲只讀 lvcreate -L n -n SLV_NAME -s -p r /PATH/TO/LV #-L指定大小，-n指定快照卷名稱，最後指定對哪個邏輯卷創建 测试创建LVM卷123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153* 准备分区fdisk /dev/sdb#分出四个分区，并将分区system ID改为8e。partprobe /dev/sdbfdisk -l#四个分区的system都应该是Linux LVM，改为8及机是为了使LVM的侦测指令可以侦测到partition。不改也可以进行LVM创建。* PV[root@bogon ~]# pvcreate /dev/sdb&#123;1,2,3,5&#125; Physical volume "/dev/sdb1" successfully created. Physical volume "/dev/sdb2" successfully created. Physical volume "/dev/sdb3" successfully created. Physical volume "/dev/sdb5" successfully created.[root@bogon ~]# pvscan PV /dev/sda2 VG centos lvm2 [&lt;31.00 GiB / 4.00 MiB free] PV /dev/sdb1 lvm2 [1.00 GiB] PV /dev/sdb3 lvm2 [1.00 GiB] PV /dev/sdb2 lvm2 [1.00 GiB] PV /dev/sdb5 lvm2 [&lt;9.00 GiB] Total: 5 [42.99 GiB] / in use: 1 [&lt;31.00 GiB] / in no VG: 4 [&lt;12.00 GiB]#这里分别显示每个PV的信息与系统所有PV的信息。最后一行显示的是：整体PV的量/已经被使用的VG的PV量/剩余的PV量[root@bogon ~]# pvdisplay --- Physical volume --- PV Name /dev/sda2 #实际的 partition 装置名称 VG Name centos #分配到哪个VG的名称 PV Size &lt;31.00 GiB / not usable 3.00 MiB #容量说明 Allocatable yes #是否已被分配出去，已分配就是yes，否则是NO。 PE Size 4.00 MiB #在此PV内的PE的大小 Total PE 7935 #共有几个PE Free PE 1 #未被LV用掉的PE Allocated PE 7934 #还可分配出去的PE的数量 PV UUID 4jHxbK-P3Py-rV7o-3o1l-fOQc-LhY0-lvFtJv "/dev/sdb1" is a new physical volume of "1.00 GiB" --- NEW Physical volume --- PV Name /dev/sdb1 VG Name #因为没有分配到VG，所以这里是空白 PV Size 1.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID totx56-SkbA-AXtb-gpUS-MGW2-1rdZ-XTrUQn ......#由于PE是在建立VG时才给予的参数，因此在这里看到的PV里头的PE都是0，而且也没有多余的PE可供分配* VG[root@bogon ~]# vgcreate -s 16M ruopuvg /dev/sdb&#123;1,2,3&#125; Volume group "ruopuvg" successfully created# -s：卷组上的物理卷的PE大小；ruopuvg是vg的名称[root@bogon ~]# vgscan Reading volume groups from cache. Found volume group "ruopuvg" using metadata type lvm2 Found volume group "centos" using metadata type lvm2[root@bogon ~]# pvscan PV /dev/sdb1 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb2 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb3 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sda2 VG centos lvm2 [&lt;31.00 GiB / 4.00 MiB free] PV /dev/sdb5 lvm2 [&lt;9.00 GiB] Total: 5 [&lt;42.95 GiB] / in use: 4 [&lt;33.95 GiB] / in no VG: 1 [&lt;9.00 GiB]#显示有三个PV被用了，sdb5没被用。[root@bogon ~]# vgdisplay --- Volume group --- VG Name ruopuvg System ID Format lvm2 Metadata Areas 3 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 3 Act PV 3 VG Size 2.95 GiB #整体的VG容量大小 PE Size 16.00 MiB #PE的大小 Total PE 189 #PE的整体数量 Alloc PE / Size 0 / 0 Free PE / Size 189 / 2.95 GiB VG UUID DAWGEA-EGjX-tsd0-DHoL-2MOq-R4SV-VaTHcT#最后三行指PE能够使用的情况，由于还未创建LV，所以所有的PE均可自由使用。[root@bogon ~]# vgextend ruopuvg /dev/sdb5 Volume group "ruopuvg" successfully extended#将sdb5加入到刚创建的VG中 * LV[root@bogon ~]# lvcreate -l 100 -n ruopulv ruopuvg Logical volume "ruopulv" created.#分配100个PE给这个LV，也可以用lvcreate -L 2G -n ruopulv ruopuvg来创建LV[root@bogon ~]# ll /dev/ruopuvg/ruopulv lrwxrwxrwx. 1 root root 7 Oct 9 11:39 /dev/ruopuvg/ruopulv -&gt; ../dm-2[root@bogon ~]# lvdisplay --- Logical volume --- LV Path /dev/ruopuvg/ruopulv LV Name ruopulv #LV的名称 VG Name ruopuvg LV UUID 7Nxeng-bsdp-i3OA-ckl2-0YiQ-TOKi-Ng03JH LV Write Access read/write LV Creation host, time bogon, 2018-10-09 11:39:05 +0800 LV Status available # open 0 LV Size 1.56 GiB #LV的容量 Current LE 100 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2* 格式化与使用[root@bogon ~]# mkfs.ext4 /dev/ruopuvg/ruopulv mke2fs 1.42.9 (28-Dec-2013)Discarding device blocks: done Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks102544 inodes, 409600 blocks20480 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=41943040013 block groups32768 blocks per group, 32768 fragments per group7888 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): doneWriting superblocks and filesystem accounting information: done #格式化LV[root@bogon ~]# mount /dev/ruopuvg/ruopulv /mnt#挂载 扩容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@bogon ~]# fdisk /dev/sdc#新加一块硬盘，创建两个新分区，system ID改为8e[root@bogon ~]# partprobe /dev/sdcpvcreate /dev/sdc1[root@bogon ~]# pvcreate /dev/sdc1 Physical volume "/dev/sdc1" successfully created.[root@bogon ~]# pvscan PV /dev/sdb1 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb2 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb3 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb5 VG ruopuvg lvm2 [8.98 GiB / 7.42 GiB free] PV /dev/sda2 VG centos lvm2 [&lt;31.00 GiB / 4.00 MiB free] PV /dev/sdc1 lvm2 [1.00 GiB] Total: 6 [43.93 GiB] / in use: 5 [42.93 GiB] / in no VG: 1 [1.00 GiB]* 加大VG[root@bogon ~]# vgextend ruopuvg /dev/sdc1 Volume group "ruopuvg" successfully extended[root@bogon ~]# vgdisplay --- Volume group --- VG Name ruopuvg System ID Format lvm2 Metadata Areas 5 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 5 Act PV 5 VG Size 12.92 GiB PE Size 16.00 MiB Total PE 827 Alloc PE / Size 100 / 1.56 GiB Free PE / Size 727 / &lt;11.36 GiB VG UUID DAWGEA-EGjX-tsd0-DHoL-2MOq-R4SV-VaTHcT#整体的VG变大了，PE的数量也增加了* 加大LV[root@bogon ~]# lvresize -l +100 /dev/ruopuvg/ruopulv Size of logical volume ruopuvg/ruopulv changed from 1.56 GiB (100 extents) to 3.12 GiB (200 extents). Logical volume ruopuvg/ruopulv successfully resized.#给LV再增加100个PE，也可以使用-L选项[root@bogon ~]# lvdisplay --- Logical volume --- LV Path /dev/ruopuvg/ruopulv LV Name ruopulv VG Name ruopuvg LV UUID 7Nxeng-bsdp-i3OA-ckl2-0YiQ-TOKi-Ng03JH LV Write Access read/write LV Creation host, time bogon, 2018-10-09 11:39:05 +0800 LV Status available # open 1 LV Size 3.12 GiB Current LE 200 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2[root@bogon ~]# df -h /mntFilesystem Size Used Avail Use% Mounted on/dev/mapper/ruopuvg-ruopulv 1.6G 38M 1.4G 3% /mnt#虽然增加了LV的容量，但实际中，LV挂载的分区并未变大[root@bogon ~]# dumpe2fs /dev/ruopuvg/ruopulv dumpe2fs 1.42.9 (28-Dec-2013)......Block count: 409600#这个文件系统的block总数......Blocks per group: 32768#多少个block设定成为一个block group[root@bogon ~]# resize2fs /dev/ruopuvg/ruopulv resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/ruopuvg/ruopulv is mounted on /mnt; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 1The filesystem on /dev/ruopuvg/ruopulv is now 819200 blocks long.#这里使用整个lvresize命令扩容进来的空间，也可以用size来指定扩容多少空间[root@bogon ~]# df -h /mntFilesystem Size Used Avail Use% Mounted on/dev/mapper/ruopuvg-ruopulv 3.1G 38M 2.9G 2% /mnt#使用resize2fs命令后，LV才会真正扩容[root@bogon ~]# ll /mnttotal 20drwxr-xr-x. 80 root root 4096 Oct 9 11:45 etcdrwx------. 2 root root 16384 Oct 9 11:44 lost+found#之前复制进去的/etc目录还存在。这样就实现了热扩容root@ruopu:~# lvextend -r -l +100%free /dev/ubuntu-vg/ubuntu-lv# 使用-r选项可以使扩容的空间当时生效，无需再使用resize2fs命令，使用-l表示指定逻辑卷的LE数，-L表示指定逻辑卷的大小，单位为“kKmMgGtT”字节。+100%free表示将所有空余空间都加进来，只能使用-l选项指定。root@ruopu:~# lvextend -r -L 19G /dev/ubuntu-vg/ubuntu-lv 缩减123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155[root@bogon ~]# resize2fs /dev/ruopuvg/ruopulv 1500Mresize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/ruopuvg/ruopulv is mounted on /mnt; on-line resizing requiredresize2fs: On-line shrinking not supported#resize2fs命令不能使用小数点，如1.5G，所以这里改为1500M，也就是将LV空间缩减为1500M。另外，使用此命令进行缩减时不能在LV已挂载的情况下做。[root@bogon ~]# umount /mnt[root@bogon ~]# resize2fs /dev/ruopuvg/ruopulv 1500Mresize2fs 1.42.9 (28-Dec-2013)Please run 'e2fsck -f /dev/ruopuvg/ruopulv' first.#系统要求我们先进行磁盘检查[root@bogon ~]# e2fsck -f /dev/ruopuvg/ruopulv e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/ruopuvg/ruopulv: 2467/197200 files (0.2% non-contiguous), 30101/819200 blocks[root@bogon ~]# resize2fs /dev/ruopuvg/ruopulv 1500Mresize2fs 1.42.9 (28-Dec-2013)Resizing the filesystem on /dev/ruopuvg/ruopulv to 384000 (4k) blocks.The filesystem on /dev/ruopuvg/ruopulv is now 384000 blocks long.[root@bogon ~]# mount /dev/ruopuvg/ruopulv /mnt[root@bogon ~]# df -h /mntFilesystem Size Used Avail Use% Mounted on/dev/mapper/ruopuvg-ruopulv 1.5G 38M 1.3G 3% /mnt#这样就缩减成功了[root@bogon ~]# lvdisplay --- Logical volume --- LV Path /dev/ruopuvg/ruopulv LV Name ruopulv VG Name ruopuvg LV UUID 7Nxeng-bsdp-i3OA-ckl2-0YiQ-TOKi-Ng03JH LV Write Access read/write LV Creation host, time bogon, 2018-10-09 11:39:05 +0800 LV Status available # open 1 LV Size 3.12 GiB Current LE 200 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2#但此时LV并没有缩减[root@bogon ~]# lvresize -L -1.6G /dev/ruopuvg/ruopulv Rounding size to boundary between physical extents: 1.59 GiB. WARNING: Reducing active and open logical volume to 1.53 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce ruopuvg/ruopulv? [y/n]: y Size of logical volume ruopuvg/ruopulv changed from 3.12 GiB (200 extents) to 1.53 GiB (98 extents). Logical volume ruopuvg/ruopulv successfully resized.#这里将LV缩减1.6G[root@bogon ~]# lvdisplay --- Logical volume --- LV Path /dev/ruopuvg/ruopulv LV Name ruopulv VG Name ruopuvg LV UUID 7Nxeng-bsdp-i3OA-ckl2-0YiQ-TOKi-Ng03JH LV Write Access read/write LV Creation host, time bogon, 2018-10-09 11:39:05 +0800 LV Status available # open 1 LV Size 1.53 GiB Current LE 98 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2#这样LV也缩减完成了。[root@bogon ~]# pvdisplay --- Physical volume --- PV Name /dev/sdb1 VG Name ruopuvg PV Size 1.00 GiB / not usable 16.00 MiB Allocatable yes PE Size 16.00 MiB Total PE 63 Free PE 63 Allocated PE 0 PV UUID totx56-SkbA-AXtb-gpUS-MGW2-1rdZ-XTrUQn --- Physical volume --- PV Name /dev/sdb2 VG Name ruopuvg PV Size 1.00 GiB / not usable 16.00 MiB Allocatable yes PE Size 16.00 MiB Total PE 63 Free PE 63 Allocated PE 0 PV UUID zL5fa0-hfxX-zfnH-VAGf-Eu09-2uoz-ZNFj12 --- Physical volume --- PV Name /dev/sdb3 VG Name ruopuvg PV Size 1.00 GiB / not usable 16.00 MiB Allocatable yes PE Size 16.00 MiB Total PE 63 Free PE 63 Allocated PE 0 PV UUID ljRtmq-e75k-xz00-SJkC-W569-1Ge7-9quZB7 --- Physical volume --- PV Name /dev/sdb5 VG Name ruopuvg PV Size &lt;9.00 GiB / not usable 14.00 MiB Allocatable yes PE Size 16.00 MiB Total PE 575 Free PE 477 Allocated PE 98 PV UUID CJgQ6x-4oRB-WD3i-bKaf-jRdB-Sz93-Xeoqpm --- Physical volume --- PV Name /dev/sdc1 VG Name ruopuvg PV Size 1.00 GiB / not usable 16.00 MiB Allocatable yes PE Size 16.00 MiB Total PE 63 Free PE 63 Allocated PE 0 PV UUID lIAqor-XGnw-PTYo-L6yY-ld6y-AeNz-41imsu #可以看到，sdb1,sdb2,sdb3,sdc1的PE都是空闲的了 [root@bogon ~]# pvmove /dev/sdb5 /dev/sdb1 Insufficient free space: 98 extents needed, but only 63 available Unable to allocate mirror extents for ruopuvg/pvmove0. Failed to convert pvmove LV to mirrored #如果要转移PE，可以使用此命令，但这里因为一共有98个PE要转移，而sdb1上只有63个PE而无法完成转移 [root@bogon ~]# pvscan PV /dev/sdb1 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb2 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb3 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb5 VG ruopuvg lvm2 [8.98 GiB / 7.45 GiB free] PV /dev/sdc1 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sda2 VG centos lvm2 [&lt;31.00 GiB / 4.00 MiB free] Total: 6 [&lt;43.92 GiB] / in use: 6 [&lt;43.92 GiB] / in no VG: 0 [0 ][root@bogon ~]# vgreduce ruopuvg /dev/sdb1 Removed "/dev/sdb1" from volume group "ruopuvg"#将分区从VG中移除[root@bogon ~]# pvscan PV /dev/sdb2 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb3 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sdb5 VG ruopuvg lvm2 [8.98 GiB / 7.45 GiB free] PV /dev/sdc1 VG ruopuvg lvm2 [1008.00 MiB / 1008.00 MiB free] PV /dev/sda2 VG centos lvm2 [&lt;31.00 GiB / 4.00 MiB free] PV /dev/sdb1 lvm2 [1.00 GiB] Total: 6 [43.93 GiB] / in use: 5 [42.93 GiB] / in no VG: 1 [1.00 GiB]#可以看到sdb1已经没有了[root@bogon ~]# pvremove /dev/sdb1 Labels on physical volume "/dev/sdb1" successfully wiped.#最后将sdb1从PV中移除。这样系统以及实际的LV与VG都变小了，sdb1可以进行其他工作了 快照123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156快照卷就是为LV卷创建的快照，创建时快照卷就会有与原LV卷相同的内容，当原LV卷改变时，会将改变前的数据保存到快照卷，而新内容是与快照卷共享的。如果出现问题，可以将快照卷的内容恢复到上一次改变时的内容。但不要让快照卷的使用超过100%，如果超过100%，快照卷就自动销毁了。如果将原本的LV卷当备份资料，将快照卷当实际使用的磁盘，添加删除数据都在快照卷中进行，测试完后可将数据删除，而原LV卷不会有影响，如果快照卷有问题，可以删除并重新创建，也可制作多个一样的快照卷。* 创建[root@bogon ~]# vgdisplay --- Volume group --- VG Name ruopuvg System ID Format lvm2 Metadata Areas 4 Metadata Sequence No 7 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 4 Act PV 4 VG Size &lt;11.94 GiB PE Size 16.00 MiB Total PE 764 Alloc PE / Size 98 / 1.53 GiB Free PE / Size 666 / &lt;10.41 GiB VG UUID DAWGEA-EGjX-tsd0-DHoL-2MOq-R4SV-VaTHcT[root@bogon ~]# pvcreate /dev/sdb1 Physical volume "/dev/sdb1" successfully created.[root@bogon ~]# vgextend ruopuvg /dev/sdb1 Volume group "ruopuvg" successfully extended[root@bogon ~]# vgdisplay --- Volume group --- VG Name ruopuvg System ID Format lvm2 Metadata Areas 5 Metadata Sequence No 8 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 5 Act PV 5 VG Size 12.92 GiB PE Size 16.00 MiB Total PE 827 Alloc PE / Size 98 / 1.53 GiB Free PE / Size 729 / 11.39 GiB VG UUID DAWGEA-EGjX-tsd0-DHoL-2MOq-R4SV-VaTHcT [root@bogon ~]# lvcreate -L 1.53G -s -n ruopuss1 /dev/ruopuvg/ruopulv Using default stripesize 64.00 KiB. Logical volume "ruopuss" created.#-s表示是snapshot快照功能之意；-n后面接快照区的设备名称， /dev/.... 则是要被快照的 LV 完整名称。-l 后面则是接使用多少个 PE 来作为这个快照区使用。这里创建快照卷时尽量将快照卷与原LV创建成一样大的空间，以便对原LV中的数据进行快照[root@bogon ~]# vgdisplay --- Logical volume --- LV Path /dev/ruopuvg/ruopuss1 LV Name ruopuss1 VG Name ruopuvg LV UUID 2OBmjd-WnN7-V1c5-p90S-E8MM-6xN8-uOcmlF LV Write Access read/write LV Creation host, time bogon, 2018-10-10 15:29:25 +0800 LV snapshot status active destination for ruopulv LV Status available # open 0 LV Size 1.53 GiB #被快照的原LV磁盘容量 Current LE 98 COW-table size 1.53 GiB #快照区的实际容量 COW-table LE 98 #快照区占用的PE数量 Allocated to snapshot 0.00% Snapshot chunk size 4.00 KiB Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:7[root@bogon ~]# mount /dev/ruopuvg/ruopuss /mnt#挂载快照卷[root@bogon ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 30G 2.0G 29G 7% /devtmpfs 234M 0 234M 0% /devtmpfs 245M 0 245M 0% /dev/shmtmpfs 245M 29M 216M 12% /runtmpfs 245M 0 245M 0% /sys/fs/cgroup/dev/sda1 1014M 125M 890M 13% /boottmpfs 49M 0 49M 0% /run/user/0/dev/mapper/ruopuvg-ruopuss 1.5G 38M 1.3G 3% /mnt/dev/mapper/ruopuvg-ruopulv 1.5G 38M 1.3G 3% /media#这里显示快照卷与原LV是一样大的，里面的数据也是一样大的，因为共享了一样的数据且数据尚没有变更[root@bogon ~]# umount /mnt* 利用快照区复原系统[root@bogon ~]# df /mediaFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/ruopuvg-ruopulv 1479424 38088 1357064 3% /mnt#原LV卷的磁盘信息[root@bogon ~]# ll /mediatotal 20drwxr-xr-x. 80 root root 4096 Oct 9 11:45 etcdrwx------. 2 root root 16384 Oct 9 11:44 lost+found[root@bogon ~]# rm -rf /media/etc[root@bogon ~]# cp -ar /boot/ /sbin/ /media[root@bogon ~]# ll /mediatotal 40dr-xr-xr-x. 5 root root 4096 Oct 8 14:29 bootdrwx------. 2 root root 16384 Oct 9 11:44 lost+founddr-xr-xr-x. 2 root root 16384 Oct 8 16:28 sbin[root@bogon ~]# lvdisplay /dev/ruopuvg/ruopuss --- Logical volume --- LV Path /dev/ruopuvg/ruopuss LV Name ruopuss1 VG Name ruopuvg LV UUID 2OBmjd-WnN7-V1c5-p90S-E8MM-6xN8-uOcmlF LV Write Access read/write LV Creation host, time bogon, 2018-10-10 15:29:25 +0800 LV snapshot status active destination for ruopulv LV Status available # open 1 LV Size 1.53 GiB Current LE 98 COW-table size 1.53 GiB COW-table LE 98 Allocated to snapshot 43.44% #快照卷使用情况 Snapshot chunk size 4.00 KiB Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:7[root@bogon ~]# mount /dev/ruopuvg/ruopuss /mnt[root@bogon ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/centos-root 31433732 1133104 30300628 4% /devtmpfs 238980 0 238980 0% /devtmpfs 250036 0 250036 0% /dev/shmtmpfs 250036 4500 245536 2% /runtmpfs 250036 0 250036 0% /sys/fs/cgroup/dev/sda1 1038336 127400 910936 13% /boottmpfs 50008 0 50008 0% /run/user/0/dev/mapper/ruopuvg-ruopulv 999320 137356 793152 15% /media/dev/mapper/ruopuvg-ruopuss 999320 35444 895064 4% /mnt[root@bogon ~]# mkdir -p /backups[root@bogon ~]# cd /mnt[root@bogon mnt]# tar -zcf /backups/lvm.tar.gz *[root@bogon ~]# umount /mnt[root@bogon ~]# lvremove /dev/ruopuvg/ruopuss Do you really want to remove active logical volume ruopuvg/ruopuss? [y/n]: y Logical volume "ruopuss" successfully removed[root@bogon ~]# umount /mnt[root@bogon ~]# mkfs.ext4 /dev/ruopuvg/ruopulv[root@bogon ~]# mount /dev/ruopuvg/ruopulv /media[root@bogon ~]# tar xf /backups/lvm.tar.gz -C /media 实例11234567891011121314151617181920212223242526272829# 完成一次磁盘从缩减到扩充的过程umount /home/ruopu/shareumount /home# 卸载分区fuser -km /home# 如果分区被占用，可用此命令清理分区的使用者umount /home# 再次卸载分区resize2fs /dev/shouyu-vg/home 330000M# 将LVM分区缩减到330000M，会提示使用e2fsck -f /dev/shouyu-vg/home命令先检查e2fsck -f /dev/shouyu-vg/home# 检查resize2fs /dev/shouyu-vg/home 330000M# 再缩减mount /dev/shouyu-vg/home /home# 缩减后挂载df -h# 可以看到分区缩减了lvsvgs# 但lv和vg并未减少lvresize -L -71G /dev/shouyu-vg/home# 将分区真正减少，减少的磁盘容量就是缩减前与缩减后的差df -h# 真正减少了lvextend -r -L +20G /dev/shouyu-vg/varlvextend -r -l +100%free /dev/shouyu-vg/home# 直接给分区扩容# 扩容也可能失败，需要将分区再次卸载之后再使用上面命令扩容，扩容后再挂载 实例21234pvcreate /dev/sd&#123;b,c,d,e&#125;1vgcreate -s 16M raid50 /dev/sd&#123;b,c,d,e&#125;1lvcreate -l 100%free -n storage raid50# 将所有空间分配给逻辑卷]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>磁盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdyc测试环境搭建]]></title>
    <url>%2F2018%2F09%2F30%2Fjdyc%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[ansibleIP：10.5.5.242 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768yum install -y ansiblevim /etc/ansible/hosts [ansible] 10.5.5.242 [web] 10.5.5.223 [netty] 10.5.5.221 10.5.5.222 [wechat] 10.5.5.224 10.5.5.227 [processor] 10.5.5.228 10.5.5.229 [mysql] 10.5.5.238 10.5.5.239 [kafka] 10.5.5.232 10.5.5.233 10.5.5.234 [redis] 10.5.5.235 10.5.5.236 10.5.5.237ssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub 10.5.5.237#将密钥复制到ansible中加入的所有主机，实现无密钥登录ansible web,wechat,processor -m shell -a "yum install -y java-1.8.0-openjdk-devel"ansible web,wechat,processor -m shell -a "rpm -q java-1.8.0-openjdk-devel"ansible redis -m shell -a "yum install -y epel-release"ansible redis -m shell -a "yum install -y redis"ansible web,wechat,processor -m shell -a "yum install -y epel-release"ansible web,wechat,processor -m shell -a "yum install -y nginx"* webmkdir -pv /root/nginx/&#123;web,wechat&#125;vim /root/nginx/web/web.conf proxy_cache_path /etc/nginx/cache levels=1:2:2 keys_zone=web_cache:10m max_size=2g; server&#123; server_name web.jdyichong.com; index index.html index.htm; charset utf-8; proxy_cache web_cache; proxy_cache_key $request_uri; proxy_cache_methods GET HEAD; proxy_cache_min_uses 1; proxy_cache_valid 200 302 10m; proxy_cache_valid 400 1m; proxy_cache_use_stale http_502; location / &#123; proxy_pass http://10.5.5.223:8081; &#125; &#125;ansible web -m copy -a "src=/root/nginx/web/web.conf dest=/etc/nginx/conf.d"ansible web -m command -a "systemctl start nginx"ansible web -m command -a "systemctl enable nginx"#设置web服务器上的nginx启动并加入开机启动。测试时这里有报错，不能启动nginx，原因是使用了OpenVZ的模板，此模板中安装了httpd服务，并且开机启动，需要关闭。 webIP：10.5.5.223 12]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables概念]]></title>
    <url>%2F2018%2F09%2F27%2Fiptables%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[防火墙概念 主机防火墙：针对于单个主机进行防护。 网络防火墙：往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。网络防火墙和主机防火墙并不冲突，可以理解为，网络防火墙主外（集体）， 主机防火墙主内（个人）。 iptables是工作在linux内核中的网络防火墙，netfilter才是防火墙真正的安全框架（framework），iptables和netfilter是一组工具，真正起到防火墙作用的是netfilter，netfilter是内核中的一個過濾框架，iptables是一個生成防火牆規則，並能將其符加在netfilter上，真正實現數據報文過濾、NAT、mangle等規則生成的工具。 防火牆工作在主機或網絡的邊緣，對進出的數據報文進行檢查監控，按事先定義的規則進行相應處理。防火牆可以是硬件或軟件，規則包括匹配標準和處理辦法。 防火牆規則必須放在內核上，因爲我們是不能和內核打交道的，有人在內核的TCP/IP協議棧上開放了幾個位置，開放給用戶空間的應用程序 netfile就是內核中可以放規則的位置；iptables是工作在用戶空間可以寫規則並可通過系統調用放置在內核相應位置的應用程序；報文流向有三種：進來的，出去的和轉發的，在/proc/sys/net/ipv4/ip_forward中就是定義是否轉發的；根據IP地址完成路由表中的路由決策，無論從哪進來的只要到了TCPIP協議棧後，下一個就是路由決策 Netfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能： 网络地址转换(Network Address Translate) 数据包内容修改 以及数据包过滤的防火墙功能 iptables概念 当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到”防火”的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为”关卡”,而被称为”链”。当客户端发来的报文访问的目标地址是其他服务器时，本机的内核要支持IP_FORWARD，我们就可以将报文转发给其他服务器，所以，这个时候，我们就会提到iptables中的其他”链”，他们就是 “路由前”、”转发”、”路由后”，他们的英文名是：PREROUTING、FORWARD、POSTROUTING。如果报文需要转发，那么报文则不会经过input链发往用户空间，而是直接在内核空间中经过forward链和postrouting链转发出去的。 报文的流向： 到本机某进程的报文：PREROUTING –&gt; INPUT 由本机转发的报文：PREROUTING –&gt; FORWARD –&gt; POSTROUTING 由本机的某进程发出报文（通常为响应报文）：OUTPUT –&gt; POSTROUTING 将具有相同功能的规则放在一起就是“表” hook function：鈎子函數，有五個位置。分別是input（進）, output（出）, forward（轉發）, prerouting（路由做出前）, postrouting（路由之後再發出） 鈎子函數的規則鏈：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING； PREROUTING的规则可以存在于：raw表，mangle表，nat表。 INPUT的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。 FORWARD的规则可以存在于：mangle表，filter表。 OUTPUT的规则可以存在于：raw表，mangle表，nat表，filter表。 POSTROUTING的规则可以存在于：mangle表，nat表。 filter表：INPUT，OUTPUT，FORWARD；负责过滤功能；内核模块：iptables_filter nat表：PREROUTING，POSTROUTING，OUTPUT（centos7中还有INPUT，centos6中没有）；network address translation，网络地址转换功能；内核模块：iptable_nat mangle表：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING；拆解报文，做出修改，并重新封装報文首部的功能；内核模块：iptable_mangle 過濾與mangle是不能放在一起的； raw表：PREROUTING，OUTPUT；关闭nat表上启用的连接追踪机制；iptable_raw iptables为我们定义了4张”表”,当他们处于同一条”链”时，执行的优先级如下。 优先级次序（由高而低）： raw –&gt; mangle –&gt; nat –&gt; filter 某些链天生就不能使用某些表中的规则，所以，4张表中的规则处于同一条链的目前只有output链 数据转发流程 INPUT、OUTPUT是從內核空間到用戶空間實現過濾的，是主機防火牆設置，通過本機轉發的通過FORWARD鏈，是網絡防火牆的設置。路由的轉發功能可以是一臺主機上的兩個網段的地址。一臺交換機上可以配置多個網段的地址，但它們之間不能通信，但如果不同網段的主機的網關指向了一臺網關服務器上一塊網卡的兩個不同網段的地址，且服務器上開通了路由的功能，那麼就可以通信了；因爲IP地址不是屬於網卡的，而是屬於主機的，所以一塊網卡可以连接兩個網絡 啓用了ip_forward鏈，默認所有報文都要轉發 應該隔離可以被公網訪問的主機與不能被公網訪問的主機，如在網關服務器上放三塊網卡，其中一塊是面對互聯網的，另一塊是面對內網的，最後一塊面對服務器，開放互聯網訪問時只能從面對互聯網的網卡到面對服務器的網卡；所有在面對內網網卡上的報文要想進來必須得是一個響應，其他不允許，網關服務器被叫做三宿主的主機 netfilter：是一個框架，在TCP/IP協議橈上有5個鈎子函數分別對應5個規則鏈，工作在內核中。不能手動向netfilter中添加數據，要用iptables編寫規則送達netfilter的某個鏈上，但它必須先屬於某張表。默認表是filter，還有nat、mangle表 目標地址轉換在進入時改，源地址轉換在出去的時候改。 可以使用自定義鏈，但只在被默認鏈調用時才能發揮作用，而且如果沒有自定義鏈中的任何規則匹配，還應該有返回機制。用戶可以刪除自定義的空鏈，默認鏈不能刪除。 每個規則都有兩個內置的計數器，一個記錄被匹配的報文個數，一個記錄被匹配的報文大小之和 DNAT：目標地址轉換，轉換IP報文中的目標IP地址。目標地址轉換DNAT，指在返回結果時將地址轉換爲請求的地址。如一臺服務器上沒有服務，但将其設置成轉換到后端兩臺服務器的地址，一臺80一臺21,用户訪問時訪問的是這臺沒有服務的主機，但返回結果是有服務的兩臺主機的內容，在返回結果時就要將地址轉換成沒有服務的主機的IP。也就是当用户访问一个地址时，这个地址本没有服务，但可将此请求转到相应的地址服务上，并在服务返回结果时自动将源地址转为用户请求的地址，这就是目标地址转换。源地址转换与目标地址转换效果相反。我们只操作一半，另一半转换由服务器自动完成 SNAT：源地址轉換，轉換IP報文中的源IP地址（可在POSTROUTING或OUTPUT上做，對網關來講只在POSTROUTING上作）。雖然稱爲源地址轉換，但目標IP地址也會轉換，只不過回程的目標地址會轉換 在互聯網上發送報文的時候，無論經過任何路由設備源IP與目標IP是不會改變的 對linux主機而言，IP地址是屬於主機的，不屬於網卡,配在什麼網卡上並不重要，關鍵是是否屬於這臺主機，無論是否打開轉發功能。這裏所說指一臺主機ping自己的網關地址，在網關這臺主機上的IP網關地址即使不在一個網段上也沒有開轉發功能，同樣可以被ping通。只有在ping第三臺網關指向這臺網關主機另一個網段IP的主機時，才需要轉發。 對linux主機而言，IP地址是屬於主機的，不屬於網卡,配在什麼網卡上並不重要，關鍵是是否屬於這臺主機，無論是否打開轉發功能。這裏所說指一臺主機ping自己的網關地址，在網關這臺主機上的IP網關地址即使不在一個網段上也沒有開轉發功能，同樣可以被ping通。只有在ping第三臺網關指向了這臺網關主機另一個網段IP的主機時，才需要轉發。 涉及到轉發與本機無關時一定是在FORWARD鏈上做 iptables在二三四層上進行過濾 处理动作 ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。 MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。 DNAT：目标地址转换。 REDIRECT：在本机做端口映射。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。 四表五链 filter表——过滤数据包 Nat表——用于网络地址转换（IP、端口） Mangle表——修改数据包的服务类型、TTL、并且可以配置路由实现QOS Raw表——决定数据包是否被状态跟踪机制处理 INPUT链——进来的数据包应用此规则链中的策略 OUTPUT链——外出的数据包应用此规则链中的策略 FORWARD链——转发数据包时应用此规则链中的策略 PREROUTING链——对数据包作路由选择前应用此链中的规则（所有的数据包进来的时侯都先由这个链处理） POSTROUTING链——对数据包作路由选择后应用此链中的规则（所有的数据包出来的时侯都先由这个链处理） 状态 NEW：新連接請求。主机连接目标主机，在目标主机上看到的第一个想要连接的包 ESTABLISHED：已建立的連接。主机已与目标主机进行通信，判断标准只要目标主机回应了第一个包，就进入该状态。 INVALID：非法連接請求。无效的封包，例如数据破损的封包状态 RELATED：相關聯的。主机已与目标主机进行通信，目标主机发起新的链接方式，例如ftp]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>iptables概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables使用方法]]></title>
    <url>%2F2018%2F09%2F27%2Fiptables%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[防火墙概念 &emsp;&emsp;iptables是工作在linux内核中的网络防火墙，iptables和netfilter是一组工具，真正起到防火墙作用的是netfilter，netfilter是内核中的一個過濾框架，iptables是一個生成防火牆規則，並能將其符加在netfilter上，真正實現數據報文過濾、NAT、mangle等規則生成的工具。 &emsp;&emsp;防火牆工作在主機或網絡的邊緣，對進出的數據報文進行檢查監控，按事先定義的規則進行相應處理。防火牆可以是硬件或軟件，規則實施防火，規則包括匹配標準和處理辦法。 &emsp;Framework: &emsp;默認規則： &emsp;如果防火牆默認是全部開放的，那就用堵的辦法 &emsp;如果防火牆默認是全部關閉的，那就用通的辦法 &emsp;&emsp;防火牆規則必須放在內核上，因爲我們是不能和內核打交道的，有人在內核的TCP/IP協議棧上開放了幾個位置，開放給用戶空間的應用程序 &emsp;&emsp;netfile就是內核中可以放規則的位置；iptables是工作在用戶空間可以寫規則並可通過系統調用放置在內核相應位置的應用程序；報文流向有三種：進來的，出去的和轉發的，在/proc/sys/net/ipv4/ip_forward中就是定義是否轉發的；根據IP地址完成路由表中的路由決策，無論從哪進來的只要到了TCPIP協議棧後的下一個就是路由決策 iptables概念 hook function：鈎子函數，有五個位置。分別是input（進）, output（出）, forward（轉發）, prerouting（路由做出前）, postrouting（路由之後再發出） 鈎子函數的規則鏈：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING； filter（過濾）：表：INPUT，OUTPUT，FORWARD； nat（地址轉換）：表：PREROUTING，POSTROUTING，OUTPUT； mangle（拆開、修改、封裝報文首部）：表：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING； 過濾與mangle是不能放在一起的； raw()：表：PREROUTING，OUTPUT IINPUT、OUTPUT是從內核空間到用戶空間實現過濾的，是主機防火牆設置，通過本機轉發的通過FORWARD鏈，是網絡防火牆的設置。路由的轉發功能可以是一臺主機上的兩個網段的地址.一臺交換機上可以配置多個網段的地址，但它們之間不能通信，但如果不同網段的主機的網關指向了一臺網關服務器上一塊網卡的兩個不同網段的地址，且服務器上開通了路由的功能，那麼就可以通信了；因爲IP地址不是屬於網卡的，而是屬於主機的，所以一塊網卡可以邊接兩個網絡 啓用了ip_forward鏈，默認所有報文都要轉發 應該隔離可以被公網訪問的主機與不能被公網訪問的主機，如在網關服務器上放三塊網卡，其中一塊是面對互聯網的，另一塊是面對內網的，最後一塊面對服務器，開放互聯網訪問時只能從面對互聯網的網卡到面對服務器的網卡；所有在面對內網網卡上的報文要想進來必須得是一個響應，其他不允許，網關服務器被叫做三宿主的主機 netfilter:是一個框架，在TCP/IP協議橈上有5個鈎子函數分別對應5個規則鏈，工作在內核中。不能手動向netfilter中添加數據，要用iptables編寫規則送達netfilter的某個鏈上，但它必須先屬於某張表。默認表是filter，還有nat、mangle表 目標地址轉換在進入時改，源地址轉換在出去的時候改。 可以使用自定義鏈，但只在被默認鏈調用時才能發揮作用，而且如果沒有自定義鏈中的任何規則匹配，還應該有返回機制。用戶可以刪除自定義的空鏈，默認鏈不能刪除。 每個規則都有兩個內置的計數器，一個記錄被匹配的報文個數，一個記錄被匹配的報文大小之和 NAT：Network Address Translation DNAT：目標地址轉換，轉換IP報文中的目標IP地址。目標地址轉換DNAT，指在返回結果時將地址轉換爲請求的地址。如一臺服務器上沒有服務，但将其設置成轉換到后端兩臺服務器的地址，一臺80一臺21,用户訪問時訪問的是這臺沒有服務的主機，但返回結果是有服務的兩臺主機的內容，在返回結果時就要將地址轉換成沒有服務的主機的IP。也就是当用户访问一个地址时，这个地址本没有服务，但可将此请求转到相应的地址服务上，并在服务返回结果时自动将源地址转为用户请求的地址，这就是目标地址转换。源地址转换与目标地址转换效果相反。我们只操作一半，另一半转换由服务器自动完成 SNAT：源地址轉換，轉換IP報文中的源IP地址（可在POSTROUTING或OUTPUT上做，對網關來講只在POSTROUTING上作）。雖然稱爲源地址轉換，但目標IP地址也會轉換，只不過回程的目標地址會轉換 在互聯網上發送報文的時候，無論經過任何路由設備源IP與目標IP是不會改變的 對linux主機而言，IP地址是屬於主機的，不屬於網卡,配在什麼網卡上並不重要，關鍵是是否屬於這臺主機，無論是否打開轉發功能。這裏所說指一臺主機ping自己的網關地址，在網關這臺主機上的IP網關地址即使不在一個網段上也沒有開轉發功能，同樣可以被ping通。只有在ping第三臺網關指向這臺網關主機另一個網段IP的主機時，才需要轉發。 對linux主機而言，IP地址是屬於主機的，不屬於網卡,配在什麼網卡上並不重要，關鍵是是否屬於這臺主機，無論是否打開轉發功能。這裏所說指一臺主機ping自己的網關地址，在網關這臺主機上的IP網關地址即使不在一個網段上也沒有開轉發功能，同樣可以被ping通。只有在ping第三臺網關指向了這臺網關主機另一個網段IP的主機時，才需要轉發。 涉及到轉發與本機無關時一定是在FORWARD鏈上做 iptables在二三四層上進行過濾 四表五链 filter表——过滤数据包 Nat表——用于网络地址转换（IP、端口） Mangle表——修改数据包的服务类型、TTL、并且可以配置路由实现QOS Raw表——决定数据包是否被状态跟踪机制处理 INPUT链——进来的数据包应用此规则链中的策略 OUTPUT链——外出的数据包应用此规则链中的策略 FORWARD链——转发数据包时应用此规则链中的策略 PREROUTING链——对数据包作路由选择前应用此链中的规则（所有的数据包进来的时侯都先由这个链处理） POSTROUTING链——对数据包作路由选择后应用此链中的规则（所有的数据包出来的时侯都先由这个链处理） 状态NEW：新連接請求。主机连接目标主机，在目标主机上看到的第一个想要连接的包ESTABLISHED：已建立的連接。主机已与目标主机进行通信，判断标准只要目标主机回应了第一个包，就进入该状态。INVALID：非法連接請求。无效的封包，例如数据破损的封包状态RELATED：相關聯的。主机已与目标主机进行通信，目标主机发起新的链接方式，例如ftp 规则及语法语法1iptables [-t TABLE] COMMAND CHAIN [num] 匹配條件 -j 處理動作 規則：匹配標準1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192通用匹配：自身能夠檢查 -s, --src #指定源地址 -d, --dst #指定目標地址 -p &#123;tcp|udp|icmp&#125; #指定協議 -i eth* #指定數據報文流入的接口，可用於自定義鏈，和以下鏈PREROUTING，INPUT，FORWARD -o INTERFACE #指定數據報文流出的接口，可用於標準定義的鏈和以下鏈OUTPUT,POSTROUTING,FORWARD擴展匹配：依賴模塊才能檢查，在/lib/iptables下的.so擴展模塊 隱含擴展：不用特別指明由哪個模塊進行的擴展，因爲此時使用-p &#123;tcp|udp|icmp&#125; -p tcp --sport PORT [-PORT] #源端口；可使用連續端口 --dport PORT [-PORT] #目標端口 --tcp-flags mask comp #只檢查mask指定的標志位，是逗號分隔的標志位列表；comp：此列表中出現的標記位必須爲1；comp中沒出現，而mask中出現的，必須爲0；如： --tcp-flags SYN，FIN，ACK，RST SYN，ACK 等同 --syn選項 #檢查tcp報文的 SYN，FIN，ACK，RST標志位，這些標志位中只能是SYN，ACK爲1，其他爲0 --syn：三次握手的第一次 -p icmp --icmp-type #icmp協議報文的類型，主要有0和8兩種,我們ping別人的時候出去的是8進來的是0,別人ping我們的時候進來的是8出去的是0 0：echo-reply #響應報文 8：echo-request #請求報文 -p udp --sport --dport 顯式擴展：必須指明由哪個模塊進行的擴展，在iptables中使用-m選項可完成此功能 -m EXTESTION_NAME -specific-opt(-m 擴展名 擴展選項) * state：#狀態擴展 --state 結合ip_conntrack追蹤會話的狀態，有四種，跟據IP、連接追蹤 NEW：#新連接請求 ESTABLISHED：#已建立的連接 INVALID：#非法連接請求 RELATED：#相關聯的 例： -m state --state NEW -j ACCEPT #只檢查NEW狀態，狀態爲NEW的可以通過 -m state --state NEW,ESTABLISHED -j ACCEPT #狀態爲NEW和ESTABLISHED的全部放行，與地址，協誶無關 * multiport：#多端口匹配擴展，可實現離散的多端口匹配 --source-ports：#源端口 --destination-ports：#目標端口 --ports：#不論是上面兩種哪一種端口；另外多個端口可用逗號隔開，但最多只能有15個 例： -m multiport --destination-ports 21,22,80 -j ACCEPT * iprange：#指定IP範圍 --src-range --dst-range 例： iptables -A INPUT -p tcp -m iprange --src-range 172.16.100.3-172.16.100.100 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT #源IP是100.3到100的，可以訪問目標端口22,狀態要是NEW或ESTABLISHED * connlimit：#連接數限定，也就是線程數，如只能使用5個連接請求 ! --connlimit-above n：#connlimit的上限，但這裏是達到n個 例：本機的web服務器最多允許同時發起兩個請求進來 iptables -A INPUT -d 172.16.100.7 -p tcp --dport 80 -m connlimit ! --connlimit-above 2 -j ACCEPT #這是沒達到2個就允許，所以一般要在--connlimit-above前加！號。如果不加！号，可改ACCEPT的狀態爲DROP或REJECT了 * limit --limit RATE：給的是一個速率，如每秒多少人 --limit-burst：給的是一個上限，第一批可放行多少個 例： iptables -I INPUT -d 172.16.100.7 -p tcp --dport 22 -m limit --limit 3/minute --limit-burst 3 -j ACCEPT #每分鍾放行3個，最多一次擁入3個 iptables -R INPUT 3 -d 172.6.100.7 -p icmp --icmp-type 8 -m limit --limit 5/minute --limit-burst 6 -j ACCEPT #修改第三條規則爲限定每分種5個ping請求，但前6個是很快的 測試，連續打開多個ssh連接服務器 * string --algo &#123;bm|kmp&#125;：#指定算法 --string "STRING"：#指定字符串，支持正則 例： vim /var/www/html/test.html h7n9 hello world iptables -I INPUT -d 172.16.100.7 -m string --algo kmp --string "h7n9" -j REJECT #上面這條是匹配不到的，因爲當用戶的請求中沒有h7n9，請求頁面時，我們響應的報文是從OUTPUT響應出去的，所以應將規則寫在OUTPUT上 iptables -R OUTPUT 1 -s 172.16.100.7 -m string --algo kmp --string "h7n9" -j REJECT #不能訪問有h7n9的頁面 ,-R選項是修改之意。 #iptables -L -n -v顯示信息中的pkts是匹配到的規則 常用命令123456789101112131415161718192021管理規則 -A：#附加一條規則，在鏈的尾部追加 -I CHAIN [num]：#插入一條規則，可以指定添加在什麼位置，插入爲對應CHAIN上的第num條，如果省略num則插入爲第一條 -D CHAIN [num]：#刪除指定鏈中的第num條規則； -R CHAIN [num]：#替換指定的規則管理鏈 -F [CHAIN]：#flush：清空指定規則鏈，如果省略CHAIN，則可以實現刪除對應表中的所有鏈 -p CHAIN：#設定指定鏈的默認策略 -N：#自定義一個新的空鏈 -X：#刪除一個自定議的空鏈 -Z：#置零指定鏈中所有規則的計數器 -E：#重命名自定義的鏈查看類 -L：#顯示指定表中的規則 -n：#以數字格式顯示主機地址和端口號，與-L一起使用 -v：#顯示鏈及規則的詳細信息 -vv：#顯示更詳細的信息 -x：#顯示計數器的精確值 --line-numbers：#顯示規則號碼 動作（target）1234567891011121314151617181920-j TARGET:跳轉 ACCEPT：#放行 DROP：#丟棄 REJECT：#拒絕 DNAT：#目標地址轉換 SNAT：#源地址轉換 REDIRECT：#端口重定向 MASQUERADE：#地址僞裝 LOG：#記錄日志 MARK：#給報文加上標記注：只要有允許或拒絕，是做過濾的，一定在filter表上-j SNAT：#源地址轉換 --to-source：#轉換成哪個源地址 -j MASQUERADE #外網地址是動態獲取時用此選項，它不需要—to-source選項，可以自動查到上外網的地址。-j DNAT --to-destination IP[:port] 保存123456iptables規則保存位置，/etc/sysconfig/iptablesiptables-save &gt; /etc/sysconfig/iptables.tus #保存方法iptables-restore &lt; /etc/sysconfig/iptables.tus #此爲載入方法 例查看规则1234567例： iptables -L -n #默認顯示filter表 iptables -t filter -L -n iptables -t nat -L -n iptables -t mangle -L -n #顯示內容中的Chain INPUT一項中沒有寫哪個表，默認就是filter表中的規則，policy表示默認策略，ACCEPT表示其爲默認值時只拒絕已知的壞蛋，如果是DROP就是只接受已知的好人。pkts表示被某一條規則所匹配到的數據包的個數，bytes表示字節數 测试112345678910111213141516171819202122232425262728iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.7 -p tcp --dport 22 -j ACCEPTiptables -t filter -A OUTPUT -s 172.16.100.7 -d 172.16.0.0/16 -p tcp --sport 22 -j ACCEPTyum install -y httpd vsftpd mysql-server service httpd start #啓動服務browser測試是否可以打開ip地址#修改默認設置爲都不能訪問本機，之前寫的兩條可以訪問本機22端口ssh服務的規則是爲了不讓遠程連接斷開，如果先寫下面的默認規則會使遠程連接斷開，造成麻煩iptables -P INPUT DROPiptables -P OUTPUT DROPiptables -P FORWARD DROPiptables -L -n#允計所有外部主機訪問本機的80端口，如果web服務比ssh服務訪問量大要放在其上面，所以這裏用-I選項，默認插入在第一行。當地址爲0.0.0.0的時候可以不寫，所以這裏沒有寫-s選項iptables -I INPUT -d 172.16.100.7 -p tcp --dport 80 -j ACCEPT #進規則iptables -L -n #查看規則iptables -L OUTPUT -s 172.16.100.7 -p tcp --sport 80 -j ACCEPT #出規則echo hello &gt; /var/www/html/index.html #添加默認網頁並測試#因ping請求使用的是icmp協議，所以這時是不能ping通的。因爲ping命令要先從OUTPUT鏈出去再從INPUT鏈進來，所以用本機ping 127.0.0.1也是不通的iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -i lo -j ACCEPT #-i選項是指定從哪個接口流入的請求iptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -o lo -j ACCEPT #-o選項指定從哪個接口流出iptables -A OUTPUT -s 172.16.100.7 -p icmp --icmp-type 8 -j ACCEPTiptables -A INPUT -d 172.16.100.7 -p icmp --icmp-type 0 -j ACCEPT#ping別人的時候，出去的是8,進來的是0，別人ping我們的時候，進來的是8,出去的是0；這樣就可以實現我們ping外面的主機了，但別人是ping不了我們的 测试21234567891011121314iptables -t filter -A INPUT -s 172.16.0.0/16 -j DROP #來自172.16.0.0/16網段的報文無論訪問本機哪個地址都被丟棄。-A表示添加一條規則iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.7 -j DROP #來自172.16.0.0/16網段訪問100.7的經過INPUT鏈的都被丟棄iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.7 -p tcp --dport 22 -j ACCEPTiptables -t filter -A OUTPUT -s 172.16.100.7 -d 172.16.0.0/16 -p tcp --sport 22 -j ACCEPT###這兩條命令第一條是進第二條是出，在寫規則時一定要把進出都寫上，意思是放行172.16.0.0/16網段的地址訪問172.16.100.7的22號端口ssh服務iptables -L -n -v#lsmod命令可以查看啓動的模塊，這裏查看iptables模塊是否啓動，四個表：iptable_mangle、iptable_nat、iptable_raw、iptable_filtermodprobe -r 模塊名 #注銷或裝載一個模塊#iptables不是服務，但有服務腳本；服務腳本的主要作用在於管理保存規則，它保存在內核的內存空間上。可以使用lsmod查看iptables的相關模塊是否加載，啓動與停止服務就是裝載及移除iptables/netfilter相關的內核模塊。模塊一般有：iptables_nat, iptables_filter, iptables_mangle, iptables_raw, ip_nat, ip_conntrack； ip_conntrack是當我們啓用nat功能時，每一個地址轉換的相應的返回的報文是要自動管理的，要追蹤每一個地址轉換的報文的，這就是ip_conntrack的功能。 测试31234567891011121314151617181920我們是一個DNS服務器，用戶請求不是我們負責的域，我們就到互聯網找出結果；默認策略INPUT,OUTPUT,FORWARD都是DORP的話，該怎麼寫規則#我們是DNS服務器，應該監聽在UDP的53號端口上，當一個客戶端到我們這來請求解析的時候，我們要允許這個請求進來，源地址是客戶端，目標地址是我們的主機，目標端口是53，這應該放行；出去時原端口是53，目標地址是客戶機；但別人請求的是一個不是我們的主機負責的域時，服務器要去找根，它找根時就不是服務器端了，而是客戶端，這就要放行目標端口；當我們作爲客戶端時與這個服務器就沒關系了。這要寫四條規則，而且這只是UDP，它還要監聽在TCP上，所以一共要写八條规则。作爲web服務器，只開放80端口的響應與放行就可以避免決大多數的攻擊了，80端口應該是只有別人請求進來，它才響應出去。只有這樣反彈式木馬在沒有人請求時才不能響應出去。這種功能在iptables中叫連接追蹤的功能，叫ip_conntrack，這是一個內核模塊，它能時時記錄着主機上客戶端，服務器端彼此正在建立的連接關系，並能追蹤到哪一個連接與其他連接之間處於什麼狀態並有什麼關系，所以上面的情況就可以判定只允許本地主機出去的連接必須爲某一種狀態，必須處於已經建立的連接，也就是必須是對別人的響應我們才允許出去，如果不是響應是決不放行的，這就靠ip_conntrack實現，ip_conntrack可根據IP報文來追蹤TCP和UDP與ICMP的連接。它可以根據請求方與響應方處理什麼過程。在/proc/sys/net/ipv4/ip_conntrack內核文件，它是位於內存當中的，因爲它在proc系統上，這個文件保存有當前系統上每一個客戶端和當前主機與每一個其他主機所建立的連接關系 cat /proc/sys/net/ipv4/ip_conntrack#顯示內容中每條記錄兩個來回的兩個通道的信息，並保存了當前會話所處的狀態。ip_conntrack的這種功能是靠ip_conntrack模塊實現的#用iptstate命令也可查看到這些信息iptstate -t #顯示當前所有連接的個數#/proc/sys/net/ipv4/ip_conntrack_max是設置ip_conntrack的同時追蹤的最大值，默認是32768個，超出的連接會被超時丟棄，使用戶無法連接，如果訪問量過大最好不要啓動此模塊，如果不大最好調大此項的值，這個模塊是追蹤已連接的地址的。在iptables停止的狀態下，如果執行iptables -t nat -L命令就要激活ip_conntrack和nfnetlink模塊。#iptables重啓會清空規則，重新加載/etc/sysconfig/iptables目錄中的文件，使用命令service iptables save可以保存規則。保存規則：service iptables save #保存規則#默認保存在/etc/sysconfig/iptablesiptables-save &gt; /etc/sysconfig/iptables.*** #手動指定保存位置iptables-restore &lt; /etc/sysconfig/iptables.*** #因爲手動指定保存位置所以無法加載，要用此條命令指定加載位置 開通服務器的sshd, httpd訪問端口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566一臺服務器，地址172.16.100.7iptables -F #清空規則iptables -A INPUT -d 172.16.100.7 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT #放行所有狀態是NEW,ESTABLISHED的訪問22號端口的連接，因爲是進來所以有NEW狀態lsmod | grep ipiptables -A OUTPUT -s 172.16.100.7 -p tcp --sport 22 -m state –state ESTABLISHED -j ACCEPT #這是出去所有只有ESTABLISHED已連接狀態iptables -P INPUT DROPiptables -P OUTPUT DROP #改變默認策略爲不允許連接iptables -L -n #查看現在的規則iptables -A INPUT -d 172.16.100.7 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -s 172.16.100.7 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT#再改80端口爲相同的規則iptstate #查看連接狀態sysctl -w net.ipv4.ip_conntrack_max=65536 #改最大值，臨時生效，要永久生效要寫在/etc/sysctl.conf中cat /proc/sys/net/ipv4/ip_conntrack_max #查看 #在/proc/sys/net/ipv4/netfilter目錄中保存了ip_conntrack的很多設置的值，其中的ip_conntrack_tcp_timeout_established中有tcp連接的保持時間，是120小時，這裏的默認單位的秒，建議將此值改小。ip_conntrack是可以追蹤三種協議tcp，udp，icmp，只是對udp，icmp只追蹤超時。iptables -A INPUT -d 172.16.100.7 -p icmp --icmp-type 8 -m state --state NEW,ESTABLISHED -j ACCEPT #進規則iptables -A OUTPUT -s 172.16.100.7 -p icmp --icmp-type 0 -m state --state ESTABLISHED -j ACCEPT #出規則#寫規則時按邏輯寫，像上面兩條是允許外面的主機ping我們的主機，所以要先寫進來的規則再寫出去iptables -L -n --line-numbers #查看規則，--line-numbers是顯示行號iptables -I OUTPUT -s 172.16.100.7 -m state --state ESTABLISHED -j ACCEPT#用這一條規則可以檢查所有出去的響應，也就是不用再寫其他出去的規則了，這樣雖然默認的規則是DROP，但這條規則可以規定所有出去的規則iptables -D OUTPUT 2 #刪除OUTPUT的第二條iptables -A INPUT -i lo -j ACCEPT iptables -A OUTPUT -o lo -j ACCEPT #放行本機的回環地址，因爲ftp服務要通過本機回環地址在mysql數據庫中查詢用戶名密碼，所以要放行才能使用ftp服務或iptables對ftp服務的規則才能生效;ftp服務中PORT表示主動模式，PASV表示被動模式，要使用被動模式因端口是隨機的，所以要使用iptables狀態中的RELATED（相關聯的，與之前的命令有關系）狀態在規則中。如：iptables -A INPUT -d 172.16.100.7 -p tcp -m state --state RELATED -j ACCEPTiptables -R OUTPUT 1 -s 172.16.100.7 -m state --state ESTABLISHED,RELATED -j ACCEPT #修改OUTPUT中的第一條iptables -R INPUT 6 -d 172.16.100.7 -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT #修改INPUT中的第六條，因爲第一次加這條規則時沒有指明ESTABLISHED狀態，使ftp服務連接後不能查看數據。最後，要先裝載ip_conntrack_ftp和ip_nat_ftp模塊才可進行下面的步驟，裝載方法如下：vim /etc/sysconfig/iptables-config #編輯此文件 IPTABLES_MODULES="ip_nat_ftp ip_conntrack_ftp" iptables -I INPUT -d 172.16.100.7 -p tcp -m state --state RELATED,ESTABLISHED -j ACCEPT#用這一條規則先來判斷連接的狀態，符合的就放行，這樣可以讓之後的規則不必再寫這兩種狀態service iptables savevim /etc/sysconfig/iptables #直接編輯此文件來修改規則，刪除INPUT其他規則中的RELATED和ESTABLISHEDservice iptables reloadiptables -L -niptables -I INPUT 2 -d 172.16.100.7 -p tcp -m multiport --destination-ports 21,22,80 -m state --state NEW -j ACCEPT #加入到INPUT中的第二條，只要是21,22,80端口爲NEW狀態的就放行；另外，之前所有命令中都可以用！號取反，如： -s ！ 172.16.100.7 #表示除了100.7都可以 -j TARGET LOG：記錄日志信息，log與DROP、ACCEPT使用時要放在前面 --log-prefix "STRING" #指定LOG日志的前綴 #記日志最好加上速率限定，不然記錄太多，產生大量磁盤IO,使性能下降例：iptables -I INPUT 4 -d 172.16.100.7 -p icmp --icmp-type 8 -j LOG --logprefix "--firewall log for icmp--"#記錄ping本機的日志，在日志中加上一個字符串"--firewall log for icmp--" 自定義規則鏈並在主鏈中被調用123456789101112131415161718192021iptables -N clean_in #新建一條叫clean_in的規則鏈，其中references表示引用，也就是被主鏈調用iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP #添加一條規則iptables -L -n –line-numbersiptables -A clean_in -d 172.168.255.255 -p icmp -j DROPiptables -A clean_in -p tcp ! --syn -m state --state NEW -j DROPiptables -A clean_in -p tcp --tcp-flags ALL ALL -j DROPiptables -A clean_in -p tcp --tcp-flags ALL NONE -j DROPiptables -A clean_in -d 172.16.100.7 -j RETURN #返回到主鏈上去iptables -A INPUT -d 172.16.100.7 -j clean_iniptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPTiptables -A INPUT -i eth0 -m multiport -p tcp --dports 53,113,135,137,139,445 -j DROPiptables -A INPUT -i eth0 -m multiport -p udp --dports 53,113.135.137.139.445 -j DROPiptables -A INPUT -i eth0 -p udp --dport 1026 -j DROPiptables -A INPUT -i eth0 -m multiport -p tcp --dports 1433,4899 -j DROPiptables -A INPUT -p icmp -m limit --limit 10/second -j ACCEPTiptables -I INPUT -j clean_in #無論什麼地址，先交給clean_in處理一遍，clean_in如果沒有問題再返回主鏈第二條進行處理；如果要刪除自定義鏈要先刪除其中的鏈規則，再刪除自定義的鏈 利用iptables的recent模块来抵御DOS攻击123456789101112ssh远程连接iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 3 -j DROPiptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSHiptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP#利用connlimit模块将单IP的并发设置为3，会误杀使用NAT上网的用户，可以根据实际情况增大该值#利用recent和state模块限制单IP在300s内只能与本机建立3个新连接，被限制五分钟后即可恢复访问下面对最后两名做一个说明：#第二句是记录访问tcp22端口的新连接，记录名为SSH。--set记录数据包的来源IP，如果IP已经存在将更新已经存在的条目#第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接。--update是指每次建立连接都更新列表；--seconds必须与--rcheck或者--update同时使用；--hitcount必须与--rcheck或者--update同时使用#iptables的记录：/proc/net/ipt_recent/SSH#也可以使用下面的这句记录日志：iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --name SSH --second 300 --hitcount 3 -j LOG --log-prefix "SSH Attack" 测试41試驗在虛擬機中建三臺主機，一臺linux主機，一塊網卡橋接；一臺linux路由，一塊網卡橋接，地址172，一塊網卡用HOST ONLY,地址192；一臺win主機，網卡用HOST ONLY；這時linux主機可與linux路由通信，因爲都是橋接網卡；win主機也可與linux路由通信，因爲是HOST ONLY；而且兩臺主機可以ping通路由上的任一個地址，因爲路由上的兩個地址在一臺主機上，即使不在一個網段也可以通信。但linux主機不能與win主機通信，因爲沒有路由，這時改路由的/proc/sys/net/ipv4/ip_forward項爲1，那麼這臺主機就具有了路由功能。再將兩臺主機的網關指向路由的兩個IP地址，這時就能通信了，這時是用不到NAT功能的。因爲要與公網通信，私網地址不能在公網上路由，所以才用NAT；需要轉換時路由的NAT功能會自動完成，在做源地址轉換時也會做目標地址轉換，只是目標地址轉換是自動進行的 源地址转换123456iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT --to-source 172.16.100.7 #要在nat表中創建，鏈是POSTROUTING。此条命令指對服務器來講，任何源地址是192.168.10.0/24網段的地址都轉換爲172.16.100.7。--to-source選項可指定一個地址範圍，如****-****，兩個地址間用橫線隔開來表示tcpdump -i eth0 -nn -X icmp#到10.7抓包iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT –to-source 123.2.3.2#在服務器上寫一條規則，讓所有同學可以訪問互聯網的任一網絡，公網IP地址是123.2.3.2 测试512iptables -A FORWARD -s 192.168.10.0/24 -p icmp -j REJECT #禁止192.168.10.0/24網段主機ping外網，此規則只是禁止了主機之間的ping，而沒有進入中間的防火牆服務器，所以不經過INPUT或OUTPUT進入服務器，而只是經過服務器轉發FORWARD 测试61234567891011iptables -P FORWARD DROPiptables -A FORWARD -m state --state ESTABLISHED -j ACCEPT#如果是已建立的連接都放行iptables -A FORWARD -s 192.168.10.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT#出去的規則，如果訪問的是web服務都放行，這是只能從內網出去的，外網是進不來的IPTABLES -A FORWARD -s 192.168.10.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCEPT #放行ping，可以ping其他主機。這是只能從內網出去的，外網是進不來的iptables -A FORWARD -s 192.168.10.0/24 -p tcp --dport 21 -m state --state NEW -j ACCEPT#放行ftp服務iptables -R FORWARD 1 -m state --state ESTABLISHED,RELATED -j ACCEPT #用上面兩條規則可開放ftp服務，但不要忘記在/etc/sysconfig/iptables-config中加載ip_nat_ftp和ip_nat模塊 目标地址转换123456iptables -t nat -A PREROUTING -d 172.16.100.7 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.22 #目標地址轉換要在PREROUTING上做。訪問172主機80端口都以192的80端口返回結果，且只在請求80服務時才轉發iptables -t nat -R PREROUTING 1 -d 172.16.100.7 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.22:8080 #改上一條規則，訪問172主機80端口的訪問結果都以192的8080端口返回，這就是PNAT：Port NAT 端口映射或端口轉換iptables -A FORWARD -m string --algo kmp --string "h7n9" -j DROP #涉及到轉發與本機無關時一定是在FORWARD鏈上。這時沒有寫協議，所以是禁止訪問任何內容中有h7n9的 iptables脚本12345678910111213141516#!/bin/bash#ipt=/usr/sbin/iptableseinterface=eth1iinterface=eth0eip=172.16.100.7iip=192.168.10.6$ipt -t nat -F$ipt -t filter -F$ipt -t mangle -F$ipt -N clean_up$ipt -A clean_up -d 255.255.255.255 -p icmp -j DROP$ipt -A clean_up -j RETURN 测试7123456iptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPTiptables -A INPUT -p icmp --icmp-type echo-request -j LOG --log-prefix "Denied ICMP:" --log-level 7iptables -A INPUT -p icmp --icmp-type echo-request -j DROP#每秒只响应一次ping，超过的记录日志并丢弃iptables -A INPUT -i eth0 -p icmp --icmp-type echo-request -m statistic --mode nth --every 2 --packet 0 -j DROP#每两个echo-request就丢弃一个 测试81234567891011121314iptables -A INPUT -p icmp --icmp-type 8 -j DROP#不允许接受icmp数据包到本地iptables -A INPUT -p all -m state --state INVALID -j DROP#不允许发送未知数据包到本地iptables -A INPUT all -m state --state ESTABLISHED,RELATED -j ACCEPT#允许已经允许过的连接和被动请求数据包发送到本地iptables -A INPUT -p tcp --syn --dport 22 -m state --state NEW -j ACCEPT#检查该连接中第一个数据包，并检查该数据包是否包含syn标记，符合两项条件才允许进入。iptables -A INPUT -p tcp --syn -m state --state NEW -m multiport --dport 21,22,23,24,25 -j ACCEPT#使用Multiport模块一次添加多个端口iptables -A INPUT -p tcp --tcp-flags ALL SYN,FIN -j DROP#检查所有 TCP-Flags，但只有syn及fin两个标记同时为1时，数据包才会被筛选出来iptables -A INPUT -p tcp --tcp-flags SYN,FIN SYN,FIN -j DROP#检查所有 TCP-Flags中syn及fin两个标记同时为1时，数据包才会被筛选出来 数据指添加12345cat /root/mac_list.txt | while read MACdo MAC=$( echo $MAC | awk '&#123;print $1&#125;' ) iptables -t filter -A FORWARD -i eth1 -o eth0 -m mac --mac-source $MAC -j ACCEPTdone mangle表用法 MARK模块匹配（单数据包）12iptables -t mangle -A PREROUTING -p tcp --dport 80 -j MARK --set-mark 80iptables -A FORWARD -p all -m mark --mark 80 -j DROP 管理用户或组模块123iptables -A OUTPUT -p tcp -m owner --uid--owner tom --dport 80 -j ACCEPTiptables -A OUTPUT -p udp -m owner --uid--owner tom --dport 53 -j ACCEPTiptables -A OUTPUT -p all -m owner --uid--owner tom -j DROP 使用iprange模块添加ip范围12iptables -A INPUT -m iprange --src-range 192.168.0.2-192.168.0.61 -j DROPiptables -A INPUT -m iprange --dst-range 192.168.0.2-192.168.0.61 -j DROP ttl值匹配模块1234iptables -A INPUT -m ttl --ttl-eq 64 -j REJECT#--ttl-eq 等于#--ttl-lt 小于#--ttl-gt 大于 IPSEC SPI 值控制模块12iptables -A FORWARD -p ah -m ah --ahspi 300 -j ACCEPTiptables -A FORWARD -p esp -m esp --espspi 200 -j ACCEPT pkttype模块1234iptables -A FORWARD -i eth0 -p icmp -m pkttype --pky-type broadcast -j DROP#unicast:数据包发送的对象时特定的，如主机A传输给主机B即为unicast类型#broadcast:数据包传送的对象为广播地址，如192.168.0.255#multicast:通常应用于网络的“音频”或“视频”广播，而Multicast数据包的特点是，其Source IP一定介于224.0.0.0/24之间。 length模块123456iptables -A INPUT -p icmp --icmp -type 8 -m length --length 92 -j ACCEPTiptables -A INPUT -p icmp --icmp -type 8 -j DROP#MTU=(IP包+ICMP包+DATA)#--length 50 匹配MTU值刚好为50字节的数据包#--length :100 匹配MTU值小于100个字节的数据包#--length 50:100 匹配MTU值介于50-100个字节的数据包 limit数据包重复率匹配123iptables -A INPUT -p icmp --icmp-type 8 -m limit --limit 6/m --limit-burst 10 -j ACCEPTiptables -A INPUT -p icmp --icmp-type 8 -j DROP#一分钟进入10个数据包以上，就会限制一分钟进入6个数据包，直到6*10s内没有收到数据包，将会解除 recent模块1234567891011121314iptables -A INPUT -p icmp --icmp-type 8 -m recent --name icmp_db --rcheck --second 60 --hitcount 6 -j DROPiptables -A INPUT -p icmp --icmp-type 8 -m recent --set --name icmp_dbcat /proc/net/xt_recent/icmp_dbmodprobe xt_recent ip_list_tot=1024 ip_pkt_list_tot=50#ip_list_tot设置ip上限条数，默认100#ip_pkt_list_tot设置数据存储空间，默认20#--name 设置跟踪数据库的文件名#[!]--set将符合条件的来源数据添加到数据库中，但如果来源端数据已经存在，则更新数据库中的记录信息#[!]--rcheck只进行数据库中信息的匹配，并不会对已存在的数据做任何变更操作#[!]--update如果来源端的数据已存在，则将其更新；若不存在，则不做任何处理#[!]--remove如果来源端数据已存在，则将其删除，若不存在，则不做任何处理#[!]--seconds seconds当事件发生时，只会匹配数据库中前“几秒”内的记录，--seconds必须与--rcheck或--update参数共用#[!]--hitcount hits匹配重复发生次数，必须与--rcheck或--update参数共用 string模块 匹配字符串12345iptables -A FORWARD -i eth0 -o eth1 -p tcp -d $WEB_SERVER --dport 80 -m string --algo bm --string "system32" -j DROP#--algo 字符串匹配算法的选择，string模块提供了两种不同的算法，分别是bm(Boyer-Moore)及kmp(Knuth-Pratt-Morris),其中bm算法平均速度会比kmp快，不过，你也不必太在意，因为我们匹配的对象不会太大，因此用哪种都差不多#--from、--to设置匹配字符串的范围，我们可以使用--from来设置匹配的起点，并以--to来设置匹配的终点，其单位为字节，如--from 10意为从第10个字符串开始匹配，如果没有设置这个参数，那么匹配的范围将是整个数据包#[!]--string匹配条件，如--string "system32"是指要匹配的字符串为system32#[!]--hex-string匹配条件，但不同于--string参数的地方在于--hex-string是以16进制的方式进行匹配，特别适合用于非ascii字符串的匹配，其匹配条件的表示方法为--hex-string "|2e2f303132333435|"，请注意实际匹配条件为2e2f303132333435，但其左右要使用"|"符号 connlimit模块 匹配连接数123iptables -A FORWARD -i eth0 -o eth1 -p tcp --syn -d $Web_Server --dport 80 -m connlimit --connlimit-above 30 --connlimit-mask 32 -j DROP#[!]--connlimit-above 指定最大连接数量#--connlimit-mask 此参数为子网络掩码，用于匹配范围，例如 8A 16B 24C 25 1/2个c 32代表单一个IP connbytes模块限制每个连接中所能传输的数据量1234iptables -A FORWARD -p tcp -d $Web_Server --dport 80 -m connbytes --connbytes-dir reply --connbytes-mode bytes --connbytes 20971520: -j DROP#[!]--connbytes-dir original来源方向 reply应答方向 both双向#--connbytes-mode packets以数据包的数量来计算 bytes以数据量来计算#--connbytes 10:匹配10个以上的单位量 :50匹配50个一下的单位量 10:50匹配10个-50个之间的单位量 quota模块 匹配每个ip限制流量（不会清除纪录，要刷新纪录）12iptables -A FORWARD -i eth0 -o eth1 -p tcp --sport 80 -m quota --quota 524288000 -j ACCEPTiptables -A FORWARD -i eth0 -o eth1 -p tcp --sport 80 -j DROP time模块 设置规则生效时间12345678iptables -A FORWARD -o eth1 -d $SRV_FARM -m time --weekdays Mon,Tue,Wed,Thu,Fri --timestart 09:00 --timestop 21:00 -j ACCEPTiptables -A FORWARD -o eth1 -d $SRV_FARM -j DROP #--datestart:YYYY[-MM[-DD[Thh[:mm[:ss]]]]]#--datestop#--timestart:hh:mm[:ss]#--timestop#[!]--monthdays:day[,day]...1,2,3,4,5,6,7,8,9,10,31#[!]--weekdays:day[,day]...Mon,Tue,Wed,Thu,Fri,Sat,Sun connmark模块匹配mark值（整条连接）12345678910111213141516171819202122232425262728293031323334iptables -A INPUT -m connmark --mark 1 -j DROP #conntrack模块匹配数据包状态，是state模块的加强版#[!]--ctstate:匹配数据包的状态，状态列表分别为NEW,ESTABLISHED,RELATED,INVALID,DNAT,SNAT#[!]--ctproto:用于匹配OSI七层中第四层的通信层，其功能与用法就如同iptables中的-p参数，如-p tcp,-p udp,-p 47等。#[!]--ctorigsrc匹配连接发起方向的来源端IP#[!]--ctorigdst匹配连接发起方向的目的端IP#[!]--ctreplsrc匹配数据包应答方向的来源端IP#[!]--ctrepldst匹配数据包应答方向的目的端IP#[!]--ctorigsrcport#[!]--ctorigdstport#[!]--ctreplsrcport#[!]--ctrepldstport#[!]--ctexpire连接在Netfilter Conntrack数据库(/porc/net/nf_conntrack)的存活时间，使用方法如下：#匹配特定的存活时间--ctexpire time#匹配特定区间的存活时间--ctexpire time:time#--ctdir设置要匹配那个方向的数据包，使用方法如下：#只匹配连接发起方向的数据包--ctdir ORIGINAL#只匹配数据包应答方向的数据包--ctdir REPLY#若没有设置这个参数，默认会匹配双向的所有数据包#!/bin/bashiptables -Fmodprobe nf_conntrack_ftpiptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp -s 192.168.1.0/24 --dport 21 -m state --state NEW -j ACCEPTiptables -A INPUT -p tcp --dport 21 -j DROP #!/bin/bashiptables -Fmodprobe nf_conntrack_ftpiptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -m conntrack --ctproto tcp --ctorigsrc 192.168.1.0/24 --ctorigdstport 21 --ctstate NEW -j ACCEPTiptables -A INTPU -p tcp --dport 21 -j DROP statistic模块进行比例匹配12345678以随机方式丢弃50%的数据包iptables -A INPUT -p icmp -m statistic --mode random --probability 0.5 -j DROP#按一定规律在每10个icmp包中丢弃1个icmp包iptables -A INPUT -p icmp -m statistic --mode nth --every 10 -j DROP#--mode:random以随机方式丢弃数据包，nth按一定规律丢弃数据包#--probability:此参数需结合random模式使用，例如--probability 0.4 即代表丢弃40%的数据，其中的数值为0-1#--every此参数需结合nth模式使用，例如--every 10代表在每10个数据包中要丢弃1个数据包#--packet此参数需要在nth模式与--every参数结合使用，例如--every 10 --packet5 layer7 – 17]]></content>
      <categories>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip命令的使用]]></title>
    <url>%2F2018%2F09%2F27%2Fip%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[安装123yum install -y iprouterpm -qi iproute#这个软件的版本与内核版本是一样的，因为它要将信息写入内核 语法123ip [ OPTIONS ] OBJECT &#123; COMMAND | help &#125;#OBJECT := &#123; link | addr | route | netns &#125;#OBJECT可简写，各OBJECT的子命令也可简写； 使用方法link语法123456789101112ip link set - change device attributes#网络设备配置，set是修改设备属性 dev NAME (default)：指明要管理的设备，dev关键字可省略； up和down： multicast on或multicast off：启用或禁用多播功能； name NAME：重命名接口 mtu NUMBER：设置MTU的大小，默认为1500； netns PID：ns为namespace，用于将接口移动到指定的网络名称空间；只能在centos7上做 address：改地址ip link show - display device attributes#show是显示设备属性的，state是状态。显示的是二层设备属性的，与IP无关ip link help - 显示简要使用帮助； 例1234567891011121314151617ip link set eth1 down/up#关闭或开启eth1网卡ip link set eth1 multicast off/on#关闭或开启多播功能ip link set eth2 downip link set eth1 name eno6668889999#先down掉网卡再改名，不然会报错ip netns list#查看网络空间名称ip link add mynet#添加一个叫mynet的网络空间ip link set eno16777736 netns mynet#将16777736放入mynet空间ip netns exec mynet ip link show#这时用普通的命令是查看不到16777736网卡的，用此命令才能查看到此网卡，这像是一个虚拟机一样。这是用来创建虚拟网络的ip netns del mynet#删除网络空间 netns语法12345678910ip netns： - manage network namespaces. ip netns list#列出所有的netnsip netns add NAME#创建指定的netnsip netns del NAME#删除指定的netnsip netns exec NAME COMMAND#在指定的netns中运行命令 address语法12345678910111213141516171819202122ip address - protocol address management. ip address add - add new protocol addressip addr add IFADDR dev IFACE [label NAME]：为额外添加的地址指明接口别名； [broadcast ADDRESS]：广播地址；会根据IP和NETMASK自动计算得到； [scope SCOPE_VALUE]：路由的范围，主要是 link ，是与本设备有关的直接连接。 global：全局可用； link：接口可用； host：仅本机可用； [proto]：此路由的路由协定，主要有 redirect, kernel, boot, static, ra 等， 其中 kernel 指的是直接由核心判断自动设定。 ip address delete - delete protocol addressip addr delete IFADDR dev IFACE ip address show - look at protocol addressesip addr list [IFACE]：显示接口的地址； ip address flush - flush protocol addressesip addr flush dev IFACE#清空接口上的所有地址 例123456789101112131415ip addr show#显示所有IP地址ip addr listifconfig eth1 0#删除eth1上的地址ip addr add 192.168.1.22/24 dev eno16777736#添加地址，可以在一块网卡上添加多个地址，只有在一个网段的地址上才会有secondary，不同网段不会有。添加的地址用ifconfig是显示不了的，如果要显示需要加接口别名ip addr add 192.168.1.43/24 dev eno16777736 lable eno16777736:0#这样用ifconfig就能显示了ip link show#这样可以查看到地址ip addr del 192.168.1.43/24 dev eno16777736#删除地址ip addr flush dev eth1#清空eth1上的所有地址 route语法123456789101112131415161718192021ip route - routing table management ip route add - add new route#添加路由ip route change - change route#修改路由ip route delete - delete routeip route del TYPE PRIFIX#删除路由ip route show - list routes#显示路由 ip route flush - flush routing tables#清空路由表ip route get - get a single routeip route get TYPE PRIFIX#获取单条路由ip route replace - change or add new one#替换路由，有老的就改老的，没有就加新的ip route add TYPE PREFIX via GW [dev IFACE] [src SOURCE_IP]ip route add default via GW #添加默认网关 例123456789101112131415161718ip route add 192.168.0.0/24 via 10.0.0.1 dev eth1 src 10.0.20.100#添加一条到192.168.0.0/24网络的路由，（via是指明下一跳地址的）下一跳的地址是10.0.0.1，设备是eth1，源地址是10.0.20.100。（src指定源地址，源地址应该是本地网卡上的地址中的一个）也就是本机地址是10.0.20.100，如果想到达192的网络，就要通过eth1设备，走10.0.0.1这个网关。ip route delete 192.168.1.0/24ip route get 192.168.0.0/24ip route list#显示路由ip route add 192.168.122.0/24 via 192.168.1.10 dev eno16777736 src 192.168.1.109#有两个虚拟机，分别位于两台主机上，一台主机地址是192.168.1.10，一台是192.168.1.4，10主机上的虚拟机是用NAT方式联网的，地址是192.168.122.103/24；4主机上的虚拟机是桥接联网的，地址是192.168.1.109/24。现在要用109地址ssh登录192.168.122.103.添加路由，意为到192.168.122.0网络的下一跳地址是192.168.1.10，通过本机的eno16777736网卡，源地址是192.168.1.109。加完此条路由后，可以ping通192.168.122.1，但ping 192.168.122.103时显示Destination Port Unreachable。原因是在192.168.1.10的ubuntu主机上有iptables规则，用/sbin/iptables -F清除规则后，暂时解决了问题ip route add default via 172.16.0.1 dev eno16777736#添加默认网关ip route delete 192.168.1.0/24#删除到192网络的路由ip route show src 172.16.100.6#只显示源地址是172的路由条目ip route get 192.168.0.0/24#显示到192网络的路由ip route flush 10/8#清除10开头的网络路由，如果删除不了，就要将地址写的再详细些 策略路由设置策略路由1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253问题：在某服务器上安装CentOS7.3系统，配置两个网段的IP地址，一为10.129.14.16/27，一为10.129.14.40/27。客户端使用10.129.14.27/27，网关10.129.14.1。使用客户端ping服务器两地址时，只能ping通10.129.14.16/27，ping10.129.14.40/27时页面停住不动，查看服务器，应该是ping包可以到达服务器，但无法返回。解决：1. 配置服务器网卡vim /etc/sysconfig/network-scripts/ifcfg-enp96s0f0TYPE="Ethernet"BOOTPROTO=noneDEFROUTE="yes"NAME="enp96s0f0"UUID="5f90c86f-c21f-489e-ae8f-cf36e6eac588"DEVICE="enp96s0f0"ONBOOT="yes"DNS1="202.96.209.6"DNS2="202.96.209.133"IPADDR=10.129.14.16PREFIX=27#GATEWAY=10.129.14.1# 注释网卡配置中的GATEWAY一项，多块网卡都要注释2. 配置策略路由表vim /etc/iproute2/rt_tables 252 enp96s0f1-32251 enp96s0f0-0# 加入上面两行，前面的数字是路由表的编号，后面是自定义的表名。路由表的编号是自定义的，但linux最多可管理255个表，不要超过这个数字，另外，rt_table中原有的编号不要动，自定义的表编号也不要与原有的编号冲突。3. 配置策略路由# 将路由规则加入CentOS7中的/etc/rc.d/init.d/network中可以使重启网卡时路由依然生效，方法如下vim /etc/rc.d/init.d/networkip route flush table enp96s0f0-0# 先清空策略路由表ip route add default via 10.129.14.1 dev enp96s0f0 src 10.129.14.16 table enp96s0f0-0# 添加一条策略路由规则，下一跳到10.129.14.1，网卡是enp96s0f0，源地址为10.129.14.16，添加到策略路由表enp96s0f0-0ip rule add from 10.129.14.16 table enp96s0f0-0# 将从10.129.14.16经过的数据包都从enp96s0f0-0策略路由表中走ip route flush table enp96s0f1-32ip route add default via 10.129.14.33 dev enp96s0f1 src 10.129.14.40 table enp96s0f1-32ip rule add from 10.129.14.40 table enp96s0f1-32ip route add default via 10.129.14.1 dev enp96s0f0exit $rc# 这里要注意，一定要添加在最后一行的exit $rc之上。systemctl daemon-reloadsystemctl restart networkip route# 查看路由，加入的默认路由生效了ip rule# 查看生效的策略路由表# 最后，测试的机器上也要加一条到某网段的路由，如sudo ip route add 10.129.14.32/27 via 10.129.14.1。因为默认会从无线走如果不加这条路由规则，就要将无线断开或删除这条默认路由# 这时客户端就可以ping通服务器的两个ip地址了 查看策略12345678ip route show table all# 显示所有路由表ip rule# 显示所有转发策略ip route list table eno2# 显示某个策略路由表的规则ip route list table all# 显示全部策略路由表]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>ip命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云创建pptp_vpn]]></title>
    <url>%2F2018%2F09%2F21%2F%E9%98%BF%E9%87%8C%E4%BA%91%E5%88%9B%E5%BB%BApptp-vpn%2F</url>
    <content type="text"><![CDATA[Server安装1yum install -y ppp pptpd 配置pptpd文件1234567891011121314151617vim /etc/pptpd.conf localip 172.17.89.106 remoteip 172.17.0.120-123#localip 172.17.89.106和remoteip 172.17.0.120-123分别是VPN的网关地址和VPN拨号获取地址段。vim /etc/ppp/options.pptpd ms-dns 223.5.5.5 ms-dns 223.6.6.6#IP 地址 223.5.5.5 和 223.6.6.6是阿里云的公共 DNS 服务器地址，您可以根据需要调整为其它公共 DNS 服务地址。vim /etc/ppp/chap-secrets test * 123456 *#设置 pptpd 的用户名和密码。根据需要添加账号，一行只添加一个用户账号。按照 用户名 pptpd 密码 IP地址 的格式输入，每一项用空格隔开。保存后退出。示例：test pptpd 123456 *，其中 * 表示所有IP。vim /etc/ppp/ip-up ifconfig ppp0 mtu 1472#设置最大传输单元 MTU，在命令符 [ -x /etc/ppp/ip-up.local ] &amp;&amp; /etc/ppp/ip-up.local “$@” 下面添加 ifconfig ppp0 mtu 1472。 修改内核参数123456vim /etc/sysctl.conf net.ipv4.ip_forward = 1sysctl -pecho 1 &gt; /proc/sys/net/ipv4/ip_forward#临时生效 添加防火墙规则1234iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADEiptables -t nat -A POSTROUTING -s 192.168.0.0/255.255.255.0 -j SNAT --to-source 123.127.82.11#添加 NAT 转发规则，其中123.127.82.11为您的实例公网 IP 地址iptables-save 启动12systemctl start pptpdsystemctl enable pptpd Client安装1yum install -y ppp pptp pptp-setup 创建连接12345pptpsetup --create test --server 123.127.82.11 --username test --password 123456 --encrypt --start#创建后会自动连接vim /etc/ppp/options.pptpd require-mppe-128#如果有报错，要加入这一行。 添加路由123456789101112* 实际情况，因为测试发现连接VPN后，可以连接kafka，但硬件设备不能向netty发送数据。但不连接VPN时，硬件设备可以向netty发送数据，但连接不上阿里云的kafka。判断认为，这是由于使用了阿里云提供的添加路由的方法，替换了默认网关。所以有此现象。重新调整了添加路由的命令如下ip route add 172.17.0.0/16 via 172.17.89.106 dev ppp0#添加一条路由，到172.17.0.0/16网络，下一跳地址是172.17.89.106，设备是ppp0。使用via指定下一跳地址。* 阿里云方法，实际中这样是不行的ip route replace default dev ppp0#测试发现，要先连接VPN，再添加路由。如果VPN断开，要重新添加路由。添加后会有三条信息加入，如下第一条和最后两条[root@bogon ~]# ip route ldefault dev ppp0 scope link default via 10.5.5.1 dev ens160 proto static metric 100 10.5.5.0/24 dev ens160 proto kernel scope link src 10.5.5.25 metric 100 113.52.7.78 via 10.5.5.1 dev ens160 src 10.5.5.25 172.17.89.106 dev ppp0 proto kernel scope link src 172.17.0.120 添加命令123cp /usr/share/doc/ppp-2.4.5/scripts/pon /usr/sbincp /usr/share/doc/ppp-2.4.5/scripts/poff /usr/sbinchmod +x /usr/sbin/pon /usr/sbin/poff 使用命令1234pon test#连接vpnpoff test#关闭vpn连接 参考：https://help.aliyun.com/knowledge_detail/41345.html?spm=5176.11065259.1996646101.searchclickresult.7c0b72c0WCltyE&amp;accounttraceid=1de748fe-9665-48c9-972a-021e6cfdf811#CentOSVPNclient]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习三：使用镜像]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E5%AD%A6%E4%B9%A0%E4%B8%89%EF%BC%9A%E4%BD%BF%E7%94%A8%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[获取镜像12345678910111213141516* 命令格式docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]# 具体的选项可以通过docker pull --help命令看到# Docker 镜像仓库地址：地址的格式一般是&lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。# 仓库名：这里的仓库名是两段式名称，即&lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub,如果不给出用户名，则默认为library，也就是官方镜像。* 例：root@test:~# docker pull ubuntu:16.0416.04: Pulling from library/ubuntu18d680d61657: Pull complete 0addb6fece63: Pull complete 78e58219b215: Pull complete eb6959a66df2: Pull complete Digest: sha256:76702ec53c5e7771ba3f2c4f6152c3796c142af2b3cb1a02fce66c697db24f12Status: Downloaded newer image for ubuntu:16.04# 上面的命令中没有给出 Docker 镜像仓库地址，因此将会从 Docker Hub 获取镜像。而镜像名称是ubuntu:16.04，因此将会获取官方镜像library/ubuntu仓库中标签为16.04的镜像。 从下载过程中可以看到我们之前提及的分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件。下载过程中给出了每一层的 ID 的前 12 位。并且下载结束后，给出该镜像完整的sha256的摘要，以确保下载一致性。层 ID 以及sha256的摘要不总是一样的。这是因为官方镜像是一直在维护的，有任何新的 bug，或者版本更新，都会进行修复再以原来的标签发布，这样可以确保任何使用这个标签的用户可以获得更安全、更稳定的镜像。 运行1234567891011121314151617181920root@test:~# docker run -it --rm ubuntu:16.04 bashroot@82e7f3542e12:/# cat /etc/os-release NAME="Ubuntu"VERSION="16.04.5 LTS (Xenial Xerus)"ID=ubuntuID_LIKE=debianPRETTY_NAME="Ubuntu 16.04.5 LTS"VERSION_ID="16.04"HOME_URL="http://www.ubuntu.com/"SUPPORT_URL="http://help.ubuntu.com/"BUG_REPORT_URL="http://bugs.launchpad.net/ubuntu/"VERSION_CODENAME=xenialUBUNTU_CODENAME=xenial# 以上面的ubuntu:16.04为基础，使用上面命令进行交互式操作# docker run是运行容器的命令# -it：这是两个参数，一个是-i：交互式操作；一个是-t：终端。我们这里打算进入bash执行一些命令并查看返回结果，因此我们需要交互式终端。# --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动docker rm。我们这里只是随便执行个命令，看看结果，因此使用--rm可以避免浪费空间。# ubuntu:16.04：这是指用ubuntu:16.04镜像为基础来启动容器# bash：放在镜像名后的是命令，这里我们希望有个交互式shell，因此用的是bash。# 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是Ubuntu 16.04.4 LTS系统。最后我们通过exit退出了这个容器。 列出镜像12345678root@test:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 4a689991aa24 4 weeks ago 116MBubuntu latest 4a689991aa24 4 weeks ago 116MBhello-world latest 4ab4c602aa5e 2 months ago 1.84kB# image ls可以替换为images，也就是docker images，显示的效果与上面的命令相同# 列出已经下载下来的镜像。列表包含了仓库名、标签、镜像 ID、创建时间以及所占用的空间。# 镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个标签。因此，在上面的例子中，我们可以看到ubuntu:latest和ubuntu:16.04拥有相同的 ID，因为它们对应的是同一个镜像。 镜像体积 如果仔细观察，会注意到，这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，ubuntu:16.04镜像大小，在这里是116MB，但是在 Docker Hub 显示的却是50。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而docker image ls显示的是镜像下载到本地后，展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。另外一个需要注意的问题是，docker image ls列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。 1234567root@test:~# docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 2 1 116MB 116MB (99%)Containers 2 0 0B 0BLocal Volumes 0 0 0B 0BBuild Cache 0 0 0B 0B# 使用此命令可以便捷的查看镜像、容器、数据卷所占用的空间。 虚悬镜像123456789101112131415REPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB# 使用docker image ls命令查看时，可能会出现上面的结果。这个镜像既没有仓库名，也没有标签，均为&lt;none&gt;。# 这个镜像原本是有镜像名和标签的，随着官方镜像维护，发布新版本后，重新执行"docker pull 镜像名"命令时，这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了&lt;none&gt;。除了docker pull命令可能导致这种情况，docker build命令也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取走，从而出现仓库名、标签均为&lt;none&gt;的镜像。这类无标签镜像也被称为虚悬镜像(dangling image)root@test:~# docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB# 使用上面命令可以显示出虚悬镜像。一般虚悬镜像已经没有了存在的价值，可以随意删除。root@test:~# docker image prune WARNING! This will remove all dangling images.Are you sure you want to continue? [y/N] yTotal reclaimed space: 0B# 删除所有的虚悬镜像 中间层镜像 为了加速镜像构建、重复利用资源，Docker 会利用中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的docker image ls列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加-a参数。 12root@test:~# docker image ls -a# 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 列出部分镜像123456789101112131415161718root@test:~# docker image ls ubuntuREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 4a689991aa24 4 weeks ago 116MB# 根据仓库名列出镜像root@test:~# docker image ls ubuntu:16.04REPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 4a689991aa24 4 weeks ago 116MB# 指定仓库名和标签，列出特定的某个镜像root@test:~# docker image ls -f since=ubuntu:16.04# 过滤器参数--filter，或者简写为-f。查询在ubuntu:16.04之后建立的镜像。root@test:~# docker image ls -f before=ubuntu:16.04# 将since改为before，可以查询在ubuntu:16.04之前建立的镜像。root@test:~# docker image ls -f label=com.example.version=0.1# 如果镜像构建时，定义了LABEL，还可以通过LABEL来过滤。 以特定格式显示123456789101112131415root@test:~# docker image ls -q4a689991aa244ab4c602aa5e# 默认情况下，docker image ls会输出一个完整的表格，但是我们并非所有时候都会需要这些内容。比如，刚才删除虚悬镜像的时候，我们需要利用docker image ls把所有的虚悬镜像的 ID 列出来，然后才可以交给docker image rm命令作为参数来删除指定的这些镜像，这个时候就用到了-q参数。--filter配合-q产生出指定范围的 ID 列表，然后送给另一个docker命令作为参数，从而针对这组实体成批的进行某种操作的做法在 Docker 命令行使用过程中非常常见root@test:~# docker image ls --format "&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;"4a689991aa24: ubuntu4ab4c602aa5e: hello-world# 我们可能只是对表格的结构不满意，希望自己组织列；或者不希望有标题，这样方便其它程序解析结果等，这就用到了 Go 的模板语法。上面的命令会直接列出镜像结果，并且只包含镜像ID和仓库名root@test:~# docker image ls --format "table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Repository&#125;&#125;\t&#123;&#123;.Tag&#125;&#125;"IMAGE ID REPOSITORY TAG4a689991aa24 ubuntu 16.044ab4c602aa5e hello-world latest# 以表格等距显示，并且有标题行，和默认一样，不过列为自定义 删除本地镜像123456* 命令格式docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...]# 删除镜像docker rm &lt;containerID&gt;# 删除容器 用 ID、镜像名、摘要删除镜像123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* 使用ID删除镜像root@test:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 4a689991aa24 4 weeks ago 116MBhello-world latest 4ab4c602aa5e 2 months ago 1.84kBroot@test:~# docker image rm 4abError response from daemon: conflict: unable to delete 4ab4c602aa5e (must be forced) - image is being used by stopped container 641b04116b0a# 我们可以通过镜像的ID号删除镜像，并且ID号可以只使用前几位。但上面删除时有报错，说明有容器在依赖此镜像，需要先停止这个容器才能删除镜像。root@test:~# docker rm 641b04116b0a641b04116b0a# 删除容器root@test:~# docker image rm 4abError response from daemon: conflict: unable to delete 4ab4c602aa5e (must be forced) - image is being used by stopped container 41a0dff7c649# 再次删除镜像时依然有此报错，但这次容器的ID变了root@test:~# docker rm 41a0dff7c64941a0dff7c649root@test:~# docker image rm 4ab Untagged: hello-world:latestUntagged: hello-world@sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788Deleted: sha256:4ab4c602aa5eed5528a6620ff18a1dc4faef0e1ab3a5eddeddb410714478c67fDeleted: sha256:428c97da766c4c13b19088a471de6b622b038f3ae8efa10ec5a37d6d31a2df0b# 再次删除容器后就可以删除镜像了# 我们可以用镜像的完整 ID，也称为长 ID，来删除镜像。使用脚本的时候可能会用长 ID，但是人工输入就太累了，所以更多的时候是用短 ID来删除镜像。docker image ls默认列出的就已经是短 ID 了，一般取前3个字符以上，只要足够区分于别的镜像就可以了。* 使用镜像名删除镜像root@test:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 4a689991aa24 4 weeks ago 116MBhello-world latest 4ab4c602aa5e 2 months ago 1.84kBroot@test:~# docker image rm hello-worldUntagged: hello-world:latestUntagged: hello-world@sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788Deleted: sha256:4ab4c602aa5eed5528a6620ff18a1dc4faef0e1ab3a5eddeddb410714478c67fDeleted: sha256:428c97da766c4c13b19088a471de6b622b038f3ae8efa10ec5a37d6d31a2df0b# 用镜像名，也就是&lt;仓库名&gt;:&lt;标签&gt;，来删除镜像。* 使用镜像摘要删除镜像root@test:~# docker image ls --digests REPOSITORY TAG DIGEST IMAGE ID CREATED SIZEubuntu 16.04 sha256:76702ec53c5e7771ba3f2c4f6152c3796c142af2b3cb1a02fce66c697db24f12 4a689991aa24 4 weeks ago 116MBhello-world latest sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 4ab4c602aa5e 2 months ago 1.84kB# 查询镜像摘要root@test:~# docker image rm node@sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788Error: No such image: node@sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788# 按镜像摘要删除镜像，但测试失败，提示没有这个镜像* Untagged 和 Deleted# 如果观察上面这几个命令的运行输出信息的话，你会注意到删除行为分为两类，一类是Untagged，另一类是Deleted。我们之前介绍过，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。# 因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的Untagged的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么Delete行为就不会发生。所以并非所有的docker image rm都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 # 当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到没有任何层依赖当前层时，才会真实的删除当前层。这就是为什么，有时候会奇怪，为什么明明没有别的标签指向这个镜像，但是它还是存在的原因，也是为什么有时候会发现所删除的层数和自己docker pull看到的层数不一样的原因。# 除了镜像依赖以外，还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在(即使容器没有运行)，那么同样不可以删除这个镜像。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖，那么删除必然会导致故障。如果这些是容器不需要的，应该先将它们删除，然后再来删除镜像。 用 docker image ls 命令来配合1234docker image rm $(docker image ls -q redis)# 删除所有仓库名为redis的镜像。$()表示输入结果，同``。docker image rm $(docker image ls -q -f before=mongo:3.2)# 删除所有在mongo:3.2之前创建的镜像 CentOS/RHEL 的用户需要注意的事项 在 Ubuntu/Debian 上有UnionFS可以使用，如aufs或者overlay2，而 CentOS 和 RHEL的内核中没有相关驱动。因此对于这类系统，一般使用devicemapper驱动利用 LVM 的一些机制来模拟分层存储。这样的做法除了性能比较差外，稳定性一般也不好，而且配置相对复杂。Docker 安装在 CentOS/RHEL 上后，会默认选择devicemapper，但是为了简化配置，其devicemapper是跑在一个稀疏文件模拟的块设备上，也被称为loop-lvm。这样的选择是因为不需要额外配置就可以运行 Docker，这是自动配置唯一能做到的事情。但是loop-lvm的做法非常不好，其稳定性、性能更差，无论是日志还是docker info中都会看到警告信息。官方文档有明确的文章讲解了如何配置块设备给devicemapper驱动做存储层的做法，这类做法也被称为配置direct-lvm。除了前面说到的问题外，devicemapper+loop-lvm还有一个缺陷，因为它是稀疏文件，所以它会不断增长。用户在使用过程中会注意到/var/lib/docker/devicemapper/devicemapper/data不断增长，而且无法控制。很多人会希望删除镜像或者可以解决这个问题，结果发现效果并不明显。原因就是这个稀疏文件的空间释放后基本不进行垃圾回收的问题。因此往往会出现即使删除了文件内容，空间却无法回收，随着使用这个稀疏文件一直在不断增长。所以对于 CentOS/RHEL 的用户来说，在没有办法使用UnionFS的情况下，一定要配置direct-lvm给devicemapper，无论是为了性能、稳定性还是空间利用率。或许有人注意到了 CentOS 7 中存在被 backports 回来的overlay驱动，不过 CentOS 里的这个驱动达不到生产环境使用的稳定程度，所以不推荐使用。 利用 commit 理解镜像构成 注意：docker commit命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保存现场等。但是，不要使用docker commit定制镜像，定制镜像应该使用Dockerfile来完成。 镜像是容器的基础，每次执行docker run的时候都会指定哪个镜像作为容器运行的基础。在之前的例子中，我们所使用的都是来自于 Docker Hub 的镜像。直接使用这些镜像是可以满足一定的需求，而当这些镜像无法直接满足需求时，我们就需要定制这些镜像。回顾一下之前我们学到的知识，镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。现在让我们以定制一个 Web 服务器为例子，来讲解镜像是如何构建的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566root@ruopu:~# docker pull nginx# 下载nginx镜像root@ruopu:~# docker run --name webserver -d -p 80:80 nginx4fc2b542c0dee4c38cbc1f93c1dd3191f2742f0a58e7724770528e93895b923d# 用nginx镜像启动一个容器，命名为webserver，并且映射了 80 端口，-d表示让容器在后台运行，这样我们就可以用浏览器去访问这个nginx服务器了。root@ruopu:~# curl localhost# 用本机访问或使用浏览器访问IP地址。root@ruopu:~# docker exec -it webserver bash# 使用docker exec命令进入容器，-i：交互式操作，-t：终端。进入容器使用bash执行一些命令root@4fc2b542c0de:/# echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html# 修改默认网页内容root@4fc2b542c0de:/# exit# 退出exitroot@ruopu:~# curl localhostroot@ruopu:~# docker diff webserver C /varC /var/cacheC /var/cache/nginxA /var/cache/nginx/scgi_tempA /var/cache/nginx/uwsgi_tempA /var/cache/nginx/client_tempA /var/cache/nginx/fastcgi_tempA /var/cache/nginx/proxy_tempC /usrC /usr/shareC /usr/share/nginxC /usr/share/nginx/htmlC /usr/share/nginx/html/index.htmlC /runA /run/nginx.pidC /rootA /root/.bash_history# 这里修改了容器的文件，也就是改动了容器的存储层。我们可以通过docker diff命令看到具体的改动。============================================================================================* 当我们运行一个容器的时候(如果不使用卷的话)，我们做的任何文件修改都会被记录于容器存储层里。而 Docker 提供了一个docker commit命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。以后我们运行这个新镜像的时候，就会拥有原有容器最后的文件变化。* 语法docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]]============================================================================================root@ruopu:~# docker commit --author "ruopu &lt;ruopu@ccgoldenet.com&gt;" --message "修改了默认网页" webserver nginx:v2sha256:c3ceec8361f57f2dd49657b42ea808b9062a7a73f6327e5675be3ad8c704055a# --author是指定修改的作者，--message是记录本次修改的内容。这点和git版本控制相似，不过这里这些信息可以省略留空。root@ruopu:~# docker image ls nginxREPOSITORY TAG IMAGE ID CREATED SIZEnginx v2 c3ceec8361f5 About a minute ago 109MBnginx latest e81eb098537d 4 days ago 109MB# 可以在docker image ls中看到这个新定制的镜像root@ruopu:~# docker history nginx:v2 IMAGE CREATED CREATED BY SIZE COMMENTc3ceec8361f5 2 minutes ago nginx -g daemon off; 97B 修改了默认网页e81eb098537d 4 days ago /bin/sh -c #(nop) CMD ["nginx" "-g" "daemon… 0B &lt;missing&gt; 4 days ago /bin/sh -c #(nop) STOPSIGNAL [SIGTERM] 0B &lt;missing&gt; 4 days ago /bin/sh -c #(nop) EXPOSE 80/tcp 0B &lt;missing&gt; 4 days ago /bin/sh -c ln -sf /dev/stdout /var/log/nginx… 22B &lt;missing&gt; 4 days ago /bin/sh -c set -x &amp;&amp; apt-get update &amp;&amp; apt… 53.8MB &lt;missing&gt; 4 days ago /bin/sh -c #(nop) ENV NJS_VERSION=1.15.6.0.… 0B &lt;missing&gt; 4 days ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.15.6-… 0B &lt;missing&gt; 4 days ago /bin/sh -c #(nop) LABEL maintainer=NGINX Do… 0B &lt;missing&gt; 5 days ago /bin/sh -c #(nop) CMD ["bash"] 0B &lt;missing&gt; 5 days ago /bin/sh -c #(nop) ADD file:dab9baf938799c515… 55.3MB # 用docker history具体查看镜像内的历史记录，如果比较nginx:latest的历史记录，我们会发现新增了我们刚刚提交的这一层。root@ruopu:~# docker run --name web2 -d -p 81:80 nginx:v254b6e4618182e413ea4a8873228f743b535667a2421035c46271514ddea7cad3# 使用新定制的镜像运行一个新容器，我们命名为新的服务为web2，并且映射到81端口root@ruopu:~# curl localhost:81# 访问新容器，也可以访问IP:81 慎用docker commit 实际环境一般不会使用上面的方法定制新的镜像。如果仔细观察之前的docker diff webserver的结果，你会发现除了真正想要修改的/usr/share/nginx/html/index.html文件外，由于命令的执行，还有很多文件被改动或添加了。如果进行更多的变动，会导致镜像非常臃肿。 此外，使用docker commit意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令，怎么生成的镜像，别人根本无从得知。虽然docker diff或许可以告诉得到一些线索，但是远远不到可以确保生成一致镜像的地步。 而且，回顾之前提及的镜像所使用的分层存储的概念，除当前层外，之前的每一层都是不会发生改变的，换句话说，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用docker commit制作镜像，以及后期修改的话，每一次修改都会让镜像更加臃肿一次，所删除的上一层的东西并不会丢失，会一直如影随形的跟着这个镜像，即使根本无法访问到。这会让镜像更加臃肿。 使用 Dockerfile 定制镜像 从刚才的docker commit的学习中，我们可以了解到，镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 12345678root@ruopu:~# mkdir mynginxroot@ruopu:~# cd mynginx/root@ruopu:~/mynginx# touch Dockerfile# 在一个空白目录中，建立一个文本文件，并命名为Dockerfileroot@ruopu:~/mynginx# vim Dockerfile FROM nginx RUN echo '&lt;h1&gt;Hello,Docker!!!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html# 这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM和RUN FROM 指定基础镜像 所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个nginx镜像的容器，再进行修改一样，基础镜像是必须指定的。而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 Docker Store中有服务类镜像与基础操作系统镜像可供下载。除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 123&gt; FROM scratch&gt; ...&gt; 如果你以scratch为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接FROM scratch会让镜像体积更加小巧。使用 Go 语言开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go是特别适合容器微服务架构的语言的原因之一。 RUN 执行命令 RUN指令是用来执行命令行命令的。由于命令行的强大能力，RUN指令在定制镜像时是最常用的指令之一。 1234567891011121314151617181920212223242526272829============================================================================================* 格式一shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的RUN指令就是这种格式。 RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html* 格式二exec 格式：RUN ["可执行文件", "参数1", "参数2"]，这更像是函数调用中的格式。# Dockerfile 中每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。也就是说，每一个RUN命令都会创建一层镜像，这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。# Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过127 层。============================================================================================FROM debian:jessieRUN buildDeps='gcc libc6-dev make' \ #设置变量这一步很重要，如果不定义，下面的yum安装时将无法进行，yum会将其后面的命令都当作安装的包 &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz "http://download.redis.io/releases/redis-3.2.5.tar.gz" \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps# 要写成上面的样子，不能每行前面都加一个RUN命令。所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个RUN来一一对应不同的命令，而是仅仅使用一个RUN指令，并使用&amp;&amp;将各个所需命令串联起来。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。# /var/lib/apt/lists/下是apt的缓存文件。apt-get purge 命令可以将包和配置文件一起删除，--auto-remove可以自动删除所有未使用的包。# make命令的-C选项：指定读取makefile的目录。如果有多个“-C”参数，make的解释是后面的路径以前面的作为相对路径，并以最后的目录作为被指定目录。如：“make –C ~hchen/test –C prog”等价于“make –C ~hchen/test/prog”。# 并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加\的命令换行方式，以及行首#进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，,这是一个比较好的习惯。# 此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了apt缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 构建镜像1234567891011121314151617============================================================================================* 语法docker build [选项] &lt;上下文路径/URL/-&gt;============================================================================================root@ruopu:~# cd /root/mynginx/root@ruopu:~/mynginx# docker build -t nginx:v3 .Sending build context to Docker daemon 2.048kBStep 1/2 : FROM nginx ---&gt; e81eb098537dStep 2/2 : RUN echo '&lt;h1&gt;Hello,Docker!!!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html ---&gt; Running in fdbbe8c89936Removing intermediate container fdbbe8c89936 ---&gt; b6eed855d34fSuccessfully built b6eed855d34fSuccessfully tagged nginx:v3# 一定不要少了命令中最后的点，下面会有对这个点的说明#-t nginx:v3表示要构建的镜像的名称。从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在Step 2中，如同我们之前所说的那样，RUN指令启动了一个容器fdbbe8c89936，执行了所要求的命令，随后删除了所用到的这个容器fdbbe8c89936，并最后提交了这一层b6eed855d34f。 镜像构建上下文(Context) 如果注意，会看到docker build命令最后有一个”.”。”.”表示当前目录。而Dockerfile就在当前目录，因此不少初学者以为这个路径是在指定Dockerfile所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定上下文路径。那么什么是上下文呢?首先我们要理解docker build的工作原理。Docker 在运行时分为 Docker 引擎(也就是服务端守护进程)和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如docker命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种docker功能，但实际上，一切都是使用的远程调用形式在服务端(Docker 引擎)完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。当我们进行镜像构建的时候，并非所有定制都会通过RUN指令完成，经常会需要将一些本地文件复制进镜像，比如通过COPY指令、ADD指令等。而docker build命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 如果在Dockerfile中这么写: ./package.jsonlink123456789101112&gt;&gt; 这并不是要复制执行docker build命令所在的目录下的package.json，也不是复制Dockerfile所在目录下的package.json，而是复制上下文(context) 目录下的package.json。&gt; 因此，&lt;font color=red&gt;COPY这类指令中的源文件的路径都是相对路径。&lt;/font&gt;这也是初学者经常会问的为什么COPY ../package.json /app或者COPY /opt/xxxx /app无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。&gt; 现在就可以理解刚才的命令**docker build -t nginx:v3 .** 中的这个 **.** ，实际上是在指定上下文的目录，docker build命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。&gt;&gt; 如果观察docker buile的输出，我们其实已经看到了这个发送上下文的过程，如下：&gt;&gt; ```shell&gt; root@ruopu:~/mynginx# docker build -t nginx:v3 .&gt; Sending build context to Docker daemon 2.048kB&gt; ...&gt; 理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现COPY /opt/xxxx /app不工作后，于是干脆将Dockerfile放到了硬盘根目录去构建，结果发现docker build执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让docker build打包整个硬盘，这显然是使用错误。一般来说，应该会将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用.gitignore一样的语法写一个.dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 那么为什么会有人误以为”.”是指定Dockerfile所在目录呢？这是因为在默认情况下，如果不额外指定Dockerfile的话，会将上下文目录下的名为Dockerfile的文件作为Dockerfile。 这只是默认行为，实际上Dockerfile的文件名并不要求必须为Dockerfile，而且并不要求必须位于上下文目录中，比如可以用-f ../Dockerfile.php 参数指定某个文件作为Dockerfile 其它 docker build 的用法直接用 Git repo 进行构建123456789root@ruopu:~/mynginx# $ docker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14docker build https://github.com/twang2218/gitlab-ce-zh.git\#:8.14Sending build context to Docker daemon 2.048 kBStep 1 : FROM gitlab/gitlab-ce:8.14.0-ce.08.14.0-ce.0: Pulling from gitlab/gitlab-ceaed15891ba52: Already exists773ae8583d14: Already exists...# 这行命令指定了构建所需的 Git repo，并且指定默认的master分支，构建目录为/8.14/，然后 Docker 就会自己去git clone这个项目、切换到指定分支、并进入到指定目录后开始构建。 用给定的 tar 压缩包构建12docker build http://server/context.tar.gz# 如果所给出的 URL 不是个 Git repo，而是个tar压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。 从标准输入中读取 Dockerfile 进行构建1234docker build - &lt; Dockerfile或cat Dockerfile | docker build -# 如果标准输入传入的是文本文件，则将其视为Dockerfile，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件COPY进镜像之类的事情。 从标准输入中读取上下文压缩包进行构建12docker build - &lt; context.tar.gz# 如果发现标准输入的文件格式是gzip、bzip2以及xz的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。 Dockerfile 指令详解COPY 复制文件1234567891011* 格式: COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY ["&lt;源路径1&gt;",... "&lt;目标路径&gt;"]# 和RUN指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。# COPY指令将从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如: COPY package.json /usr/src/app/# &lt;源路径&gt;可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的filepath.Match规则，如: COPY hom* /mydir/ COPY hom?.txt /mydir/# &lt;目标路径&gt;可以是容器内的绝对路径，也可以是相对于工作目录的相对路径(工作目录可以用WORKDIR指令来指定)。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。# 此外，还需要注意一点，使用COPY指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用Git进行管理的时候。 ADD 更高级的复制文件1234567891011# ADD指令和COPY的格式和性质基本一致。但是在COPY基础上增加了一些功能。# 比如&lt;源路径&gt;可以是一个URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。下载后的文件权限自动设置为600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整。另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用RUN指令，然后使用wget或者curl工具下载，处理权限、解压缩，然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。# 如果&lt;源路径&gt;为一个tar压缩文件的话，压缩格式为gzip,bzip2以及xz的情况下，ADD指令将会自动解压缩这个压缩文件到&lt;目标路径&gt;去。# 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像ubuntu中: FROM scratch ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / ...# 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用ADD命令了。# 在 Docker 官方的 Dockerfile 最佳实践文档中要求，尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。最适合使用ADD的场合，就是所提及的需要自动解压缩的场合。# 另外需要注意的是，ADD指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。# 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩的场合使用ADD。 CMD 容器启动命令123456789101112131415161718192021# CMD 指令的格式和RUN相似，也是两种格式: shell 格式：CMD &lt;命令&gt; exec 格式：CMD ["可执行文件", "参数1", "参数2"...] 参数列表格式：CMD ["参数1", "参数2"...]。在指定了ENTRYPOINT指令后，用CMD指定具体的参数。# 之前介绍容器的时候曾经说过，Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。# 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu镜像默认的CMD是/bin/bash，如果我们直接运行docker run -it ubuntu的话，会直接进入bash。我们也可以在运行时指定运行别的命令，如docker run -it ubuntu cat /etc/os-release。这就是用cat /etc/os-release命令替换了默认的/bin/bash命令了，输出了系统版本信息。# 在指令格式上，一般推荐使用exec格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号"，而不要使用单引号。# 如果使用shell格式的话，实际的命令会被包装为sh -c的参数的形式进行执行。-c选项表示命令从-c后的字符串读取。比如: CMD echo $HOME# 在实际执行中，会将其变更为： CMD [ "sh", "-c", "echo $HOME" ]# 这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。# 提到CMD就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。# Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。# 一些初学者将CMD写为: CMD service nginx start# 然后发现容器执行后就立即退出了。甚至在容器内去使用systemctl命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。# 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。# 而使用service nginx start命令，则是希望 upstart 使用后台守护进程形式启动nginx服务。而刚才说了CMD service nginx start会被理解为CMD [ "sh", "-c", "service nginx start"] ，因此主进程实际上是sh。那么当service nginx start命令结束后，sh也就结束了，sh作为主进程退出了，自然就会令容器退出。# 正确的做法是直接执行nginx可执行文件，并且要求以前台形式运行。比如: CMD ["nginx", "-g", "daemon off;"] ENTRYPOINT 入口点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# ENTRYPOINT 的格式和 RUN 指令格式一样，分为exec格式和shell格式。# ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT在运行时也可以替代，不过比CMD要略显繁琐，需要通过docker run的参数--entrypoint来指定。# 当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令，换句话说实际执行时，将变为: &lt;ENTRYPOINT&gt; "&lt;CMD&gt;"# 那么有了CMD后,为什么还要有ENTRYPOINT呢？这种&lt;ENTRYPOINT&gt; "&lt;CMD&gt;"有什么好处么？让我们来看几个场景。* 场景一:让镜像变成像命令一样使用# 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用CMD来实现: FROM ubuntu:16.04 RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/* CMD [ "curl", "-s", "http://ip.cn" ]# 假如我们使用docker build -t myip . 来构建镜像的话,如果我们需要查询当前公网 IP,只需要执行: $ docker run myip 当前 IP:61.148.226.66 来自:北京市 联通# 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的CMD中可以看到实质的命令是curl，那么如果我们希望显示 HTTP头信息，就需要加上-i参数。那么我们可以直接加-i参数给docker run myip么? $ docker run myip -i docker: Error response from daemon: invalid header field value "oci runtime error: con tainer_linux.go:247: starting container process caused \"exec: \\\"-i\\\": executable file not found in $PATH\"\n".# 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是command，运行时会替换CMD的默认值。因此这里的-i替换了原来的CMD，而不是添加在原来的curl -s http://ip.cn后面。而-i根本不是命令，所以自然找不到。# 那么如果我们希望加入-i这个参数，我们就必须重新完整的输入这个命令： $ docker run myip curl -s http://ip.cn -i# 这显然不是很好的解决方案，而使用ENTRYPOINT就可以解决这个问题。现在我们重新用ENTRYPOINT来实现这个镜像: FROM ubuntu:16.04 RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ "curl", "-s", "http://ip.cn" ]# 这次我们再来尝试直接使用docker run myip -i： $ docker run myip 当前 IP:61.148.226.66 来自:北京市 联通 $ docker run myip -i HTTP/1.1 200 OK Server: nginx/1.8.0 Date: Tue, 22 Nov 2016 05:12:40 GMT Content-Type: text/html; charset=UTF-8 Vary: Accept-Encoding X-Powered-By: PHP/5.6.24-1~dotdeb+7.1 X-Cache: MISS from cache-2 X-Cache-Lookup: MISS from cache-2:80 X-Cache: MISS from proxy-2_6 Transfer-Encoding: chunked Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006 Connection: keep-alive 当前 IP:61.148.226.66 来自:北京市 联通# 可以看到，这次成功了。这是因为当存在ENTRYPOINT后，CMD的内容将会作为参数传给ENTRYPOINT，而这里-i就是新的CMD，因此会作为参数传给curl，从而达到了我们预期的效果。* 场景二:应用运行前的准备工作# 启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。# 比如mysql类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的mysql 服务器运行之前解决。# 此外，可能希望避免使用root用户去启动服务，从而提高安全性，而在启动服务前还需要以root身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root身份执行，方便调试等。# 这些准备工作是和容器CMD无关的，无论CMD为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入ENTRYPOINT中去执行，而这个脚本会将接到的参数(也就是&lt;CMD&gt;)作为命令，在脚本最后执行。比如官方镜像redis中就是这么做的： FROM alpine:3.4 ... RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis ... ENTRYPOINT ["docker-entrypoint.sh"] EXPOSE 6379 CMD [ "redis-server" ]# 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了ENTRYPOINT为docker-entrypoint.sh脚本。 #!/bin/sh ... # allow the container to be started with `--user` if [ "$1" = 'redis-server' -a "$(id -u)" = '0' ]; then chown -R redis . exec su-exec redis "$0" "$@" fi exec "$@"# 该脚本的内容就是根据CMD的内容来判断，如果是redis-server的话，则切换到redis用户身份启动服务器，否则依旧使用root身份执行。比如： $ docker run -it redis id uid=0(root) gid=0(root) groups=0(root) ENV 设置环境变量12345678910111213141516171819202122* 格式有两种: ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...# 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \ NAME="Happy Feet"# 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。# 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方node镜像Dockerfile中，就有类似这样的代码: ENV NODE_VERSION 7.2.0 RUN curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.ta r.xz" \ &amp;&amp; curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc" \ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \ &amp;&amp; grep " node-v$NODE_VERSION-linux-x64.tar.xz\$" SHASUMS256.txt | sha256sum -c - \ &amp;&amp; tar -xJf "node-v$NODE_VERSION-linux-x64.tar.xz" -C /usr/local --strip-components= 1 \ &amp;&amp; rm "node-v$NODE_VERSION-linux-x64.tar.xz" SHASUMS256.txt.asc SHASUMS256.txt \ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs# 在这里先定义了环境变量NODE_VERSION，其后的RUN这层里，多次使用$NODE_VERSION来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新7.2.0即可，Dockerfile构建维护变得更轻松了。# 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBU、ILD# 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ARG 构建参数1234* 格式: ARG &lt;参数名&gt;[=&lt;默认值&gt;]# 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用ARG保存密码之类的信息，因为docker history还是可以看到所有值的。# Dockerfile中的ARG指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令docker build中用--build-arg &lt;参数名&gt;=&lt;值&gt;来覆盖。# 在 1.13 之前的版本，要求--build-arg中的参数名，必须在Dockerfile中用ARG定义过了，换句话说，就是--build-arg指定的参数，必须在Dockerfile中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的Dockerfile的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。 VOLUME 定义匿名卷12345678* 格式为: VOLUME ["&lt;路径1&gt;", "&lt;路径2&gt;"...] VOLUME &lt;路径&gt;# 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 VOLUME /data# 这里的/data目录就会在运行时自动挂载为匿名卷，任何向/data中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如: docker run -d -v mydata:/data xxxx# 在这行命令中，就使用了mydata这个命名卷挂载到了/data这个位置，替代了Dockerfile中定义的匿名卷的挂载配置。 EXPOSE 声明端口1234* 格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]# EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是docker run -P时，会自动随机映射EXPOSE的端口。# 此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker引擎参数--icc=false，当指定该参数后，容器间将默认无法互访，除非互相间使用了--links参数的容器才可以互通，并且只有镜像中EXPOSE所声明的端口才可以被访问。这个--icc=false的用法，在引入了docker network后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。# 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开来。-p是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而EXPOSE仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR 指定工作目录12345678* 格式为 WORKDIR &lt;工作目录路径&gt;# 使用WORKDIR指令可用来指定工作目录(或者称为当前目录)，以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR会帮你建立目录。# 之前提到一些初学者常犯的错误是把Dockerfile等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误: RUN cd /app RUN echo "hello" &gt; world.txt# 如果将这个Dockerfile进行构建镜像运行后，会发现找不到/app/world.txt文件，或者其内容不是hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行RUN命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。# 之前说过每一个RUN都会启动一个容器、执行命令、然后提交存储层文件变更。第一层RUN cd /app的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器完全没关系，自然不可能继承前一层构建过程中的内存变化。# 因此如果需要改变以后各层的工作目录的位置，那么应该使用WORKDIR指令。 USER 指定当前用户1234567891011121314151617* 格式: USER &lt;用户名&gt;# USER指令和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后层的执行RUN，CMD以及ENTRYPOINT这类命令的身份。# 当然，和WORKDIR一样，USER只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis USER redis RUN [ "redis-server" ]# 如果以root执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用su或者sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用gosu。 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis # 建立 redis 用户，并使用 gosu 换另一个用户执行命令 RUN wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/1.7/ gosu-amd64" \ &amp;&amp; chmod +x /usr/local/bin/gosu \ &amp;&amp; gosu nobody true # 下载 gosu CMD [ "exec", "gosu", "redis", "redis-server" ]# 设置 CMD，并以另外的用户执行 HEALTHCHECK 健康检查123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* 格式: HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令 HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令# HEALTHCHECK指令是告诉 Docker 应该如何进行判断容器的状态是否正常，这是 Docker 1.12引入的新指令。# 在没有HEALTHCHECK指令前，Docker 引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题，但是如果程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。# 而自 1.12 之后，Docker 提供了HEALTHCHECK指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。# 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。# HEALTHCHECK 支持下列选项：--interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒；--timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；--retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为unhealthy，默认 3次。# 和CMD，ENTRYPOINT一样，HEALTHCHECK只可以出现一次，如果写了多个，只有最后一个生效。# 在HEALTHCHECK [选项] CMD后面的命令，格式和ENTRYPOINT一样，分为shell格式，和exec格式。命令的返回值决定了该次健康检查的成功与否，0：成功；1：失败；2：保留，不要使用这个值。# 假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用curl来帮助判断，其Dockerfile的HEALTHCHECK可以这么写： FROM nginx RUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/* HEALTHCHECK --interval=5s --timeout=3s \ CMD curl -fs http://localhost/ || exit 1# 这里我们设置了每 5 秒检查一次(这里为了试验所以间隔非常短，实际应该相对较长)，如果健康检查命令超过 3 秒没响应就视为失败，并且使用curl -fs http://localhost/ || exit 1 作为健康检查命令。# 使用docker build来构建这个镜像： $ docker build -t myweb:v1 .# 构建好了后，我们启动一个容器: $ docker run -d --name web -p 80:80 myweb:v1# 当运行该镜像后，可以通过docker container ls看到最初的状态为(health: starting): $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 "nginx -g 'daemon off" 3 seconds ago Up 2 seconds (health: starting) 80/tcp, 443/tcp web# 在等待几秒钟后，再次docker container ls，就会看到健康状态变化为了(healthy): $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 "nginx -g 'daemon off" 18 seconds ago Up 16 seconds (healthy) 80/tcp, 443/tcp web# 如果健康检查连续失败超过了重试次数，状态就会变为(unhealthy)。 # 为了帮助排障，健康检查命令的输出(包括stdout以及stderr)都会被存储于健康状态里，可以用docker inspect来查看。$ docker inspect --format '&#123;&#123;json .State.Health&#125;&#125;' web | python -m json.tool&#123; "FailingStreak": 0, "Log": [ &#123; "End": "2016-11-25T14:35:37.940957051Z", "ExitCode": 0, "Output": "&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n body &#123;\n width: 35em;\n margin: 0 auto;\n font-family: Tahoma, Verdana, Arial, sans-serif;\n &#125;\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n", "Start": "2016-11-25T14:35:37.780192565Z" &#125; ], "Status": "healthy"&#125; ONBUILD 为他人做嫁衣裳123456789101112131415161718192021222324252627282930313233343536* 格式: ONBUILD &lt;其它指令&gt;。# ONBUILD是一个特殊的指令，它后面跟的是其它指令，比如RUN，COPY等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。# Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。# 假设我们要制作 Node.js 所写的应用的镜像。我们都知道 Node.js 使用npm进行包管理，所有依赖、配置、启动信息等会放到package.json文件里。在拿到程序代码后，需要先进行npm install才可以获得所有需要的依赖。然后就可以通过npm start来启动应用。因此，一般来说会这样写Dockerfile： FROM node:slim RUN mkdir /app WORKDIR /app COPY ./package.json /app RUN [ "npm", "install" ] COPY . /app/ CMD [ "npm", "start" ]# 把这个Dockerfile放到 Node.js 项目的根目录，构建好镜像后，就可以直接拿来启动容器运行。但是如果我们还有第二个 Node.js 项目也差不多呢？好吧，那就再把这个Dockerfile复制到第二个项目里。那如果有第三个项目呢？再复制么？文件的副本越多，版本控制就越困难，让我们继续看这样的场景维护的问题。# 如果第一个 Node.js 项目在开发过程中，发现这个 Dockerfile 里存在问题，比如敲错字了、或者需要安装额外的包，然后开发人员修复了这个 Dockerfile ，再次构建，问题解决。第一个项目没问题了，但是第二个项目呢？虽然最初Dockerfile是复制、粘贴自第一个项目的，但是并不会因为第一个项目修复了他们的Dockerfile，而第二个项目的Dockerfile就会被自动修复。# 那么我们可不可以做一个基础镜像，然后各个项目使用这个基础镜像呢？这样基础镜像更新，各个项目不用同步Dockerfile的变化，重新构建后就继承了基础镜像的更新？好吧，可以，让我们看看这样的结果。那么上面的这个Dockerfile就会变为： FROM node:slim RUN mkdir /app WORKDIR /app CMD [ "npm", "start" ]# 这里我们把项目相关的构建指令拿出来，放到子项目里去。假设这个基础镜像的名字为my-node的话，各个项目内的自己的Dockerfile就变为： FROM my-node COPY ./package.json /app RUN [ "npm", "install" ] COPY . /app/# 基础镜像变化后，各个项目都用这个Dockerfile重新构建镜像，会继承基础镜像的更新。# 那么，问题解决了么？没有。准确说，只解决了一半。如果这个Dockerfile里面有些东西需要调整呢？比如npm install 都需要加一些参数，那怎么办？这一行RUN是不可能放入基础镜像的，因为涉及到了当前项目的./package.json，难道又要一个个修改么？所以说，这样制作基础镜像，只解决了原来的Dockerfile的前4条指令的变化问题，而后面三条指令的变化则完全没办法处理。# ONBUILD可以解决这个问题。让我们用ONBUILD重新写一下基础镜像的Dockerfile： FROM node:slim RUN mkdir /app WORKDIR /app ONBUILD COPY ./package.json /app ONBUILD RUN [ "npm", "install" ] ONBUILD COPY . /app/ CMD [ "npm", "start" ]# 这次我们回到原始的Dockerfile，但是这次将项目相关的指令加上ONBUILD，这样在构建基础镜像的时候，这三行并不会被执行。然后各个项目的Dockerfile就变成了简单地: FROM my-node# 是的，只有这么一行。当在各个项目目录中，用这个只有一行的Dockerfile构建镜像时，之前基础镜像的那三行ONBUILD就会开始执行，成功的将当前项目的代码复制进镜像、并且针对本项目执行npm install，生成应用镜像。]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker使用]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[基本运行方式搜索12345678docker search centos#搜索centos镜像NAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 4726 [OK] ansible/centos7-ansible Ansible on Centos7 118 [OK]jdeathe/centos-ssh CentOS-6 6.10 x86_64 / CentOS-7 7.5.1804 x86… 99 [OK]consol/centos-xfce-vnc Centos container with "headless" VNC session… 63 [OK]imagine10255/centos6-lnmp-php56 centos6-lnmp-php56 45 [OK] 下载12docker pull guyton/centos6#下载guyton/centos6镜像，官方没有普通的centos6镜像 运行123docker run -it guyton/centos6 bash#这是最简单的运行方式。此命令可以运行多次，每运行一次，就是创建一个新的容器。选项功能如下#-i：交互式操作；-t：终端。我们这里打算进入bash执行一些命令并查看返回结果，因此我们需要交互式终端。bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash 。 查看1234567891011121314151617181920212223242526272829303132333435* 查看正在运行的容器docker@boot2docker:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cd2b28b4f21 guyton/centos6 "bash" 24 seconds ago Up 23 seconds zen_lamarr418cbf256f89 guyton/centos6 "bash" 5 minutes ago Up 5 minutes sad_haibt#因为运行了两次docker run -it guyton/centos6 bash，所以这里有两个容器=======================================================================================#标题含义：#CONTAINER ID:容器的唯一表示ID。#IMAGE:创建容器时使用的镜像。#COMMAND:容器最后运行的命令。#CREATED:创建容器的时间。#STATUS:容器状态。#PORTS:对外开放的端口。#NAMES:容器名。可以和容器ID一样唯一标识容器，同一台宿主机上不允许有同名容器存在，否则会冲突。=======================================================================================* 查看所有容器docker@boot2docker:~$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cd2b28b4f21 guyton/centos6 "bash" 2 minutes ago Exited (0) 8 seconds ago zen_lamarrf2da3e7678a4 guyton/centos6 "bash" 4 minutes ago Exited (0) 2 minutes ago festive_davinci418cbf256f89 guyton/centos6 "bash" 7 minutes ago Up 7 minutes sad_haibt#可从STATUS列看出只有一个运行，另外两个已停止* 查看最新创建的容器，只列出最后创建的docker@boot2docker:~$ docker ps -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cd2b28b4f21 guyton/centos6 "bash" 5 minutes ago Exited (0) 3 minutes ago zen_lamarr* 列出最后创建的x个容器docker@boot2docker:~$ docker ps -n=2CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cd2b28b4f21 guyton/centos6 "bash" 6 minutes ago Exited (0) 4 minutes ago zen_lamarrf2da3e7678a4 guyton/centos6 "bash" 8 minutes ago Exited (0) 6 minutes ago festive_davinci#:-n=x选项，会列出最后创建的x个容器 启动12345678910111213141516171819* 语法：docker start docker_namedocker start docker_ID* 例：docker@boot2docker:~$ docker start f2da3e7678a4f2da3e7678a4docker@boot2docker:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf2da3e7678a4 guyton/centos6 "bash" 10 minutes ago Up 2 seconds festive_davinci418cbf256f89 guyton/centos6 "bash" 14 minutes ago Up 13 minutes sad_haibtdocker@boot2docker:~$ docker start zen_lamarrzen_lamarrdocker@boot2docker:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cd2b28b4f21 guyton/centos6 "bash" 9 minutes ago Up 4 seconds zen_lamarrf2da3e7678a4 guyton/centos6 "bash" 11 minutes ago Up About a minute festive_davinci418cbf256f89 guyton/centos6 "bash" 15 minutes ago Up 15 minutes sad_haibt#第一个是通过ID启动的，第二个通过name启动 终止123* 语法：docker stop [NAME]/[CONTAINER ID]:将容器退出。docker kill [NAME]/[CONTAINER ID]:强制停止一个容器。 删除1234567* 语法docker rm [NAME]/[CONTAINER ID]:不能够删除一个正在运行的容器，会报错。需要先停止容器。* 例：docker rm 'docker ps -a -q'#-a标志列出所有容器，-q标志只列出容器的ID，然后传递给rm命令，依次删除容器。#一次性删除：docker本身没有提供一次性删除操作，但是可以使用如上命令实现 进入12345docker@boot2docker:~$ docker attach 1cd2b28b4f21#使用attach通过ID进入dockerdocker@boot2docker:~$ docker exec -it f2da3e7678a4 /bin/bash#使用exec参数进入 退出1231. exit（命令）：退出后，这个容器也就消失了，容器销毁ps查不到2. Ctrl+D（快捷方式）：退出后，这个容器也就消失了,容器销毁ps查不到 3. 先按Ctrl+P;再按Ctrl+Q（快捷方式）：退出容器，ps能查到，还在后台运行 端口暴露1234567891011121314151617181920212223242526272829303132333435363738394041424344454647docker run -d -P training/webapp#docker自动在host上打开49000到49900的端口，映射到容器（由镜像指定，或者--expose参数指定）的暴露端口docker run -d -p 5000:80 training/webapp#host上5000号端口，映射到容器暴露的80端口docker run -d -p 127.0.0.1:5000:80 training/webapp#host上127.0.0.1:5000号端口，映射到容器暴露的80端口docker run -d -p 127.0.0.1::5000 training/webapp#host上127.0.0.1:随机端口，映射到容器暴露的80端口docker run -d -p 127.0.0.1:5000:5000/udp training/webapp#绑定udp端口docker run -it --privileged --name test --hostname test -p 8080:80 centos#测试发现，在创建时要使用-it选项，不然之后使用docker start 命令是不能启动容器的，原因待查。--name指定容器名，--hostname指定容器内的主机名=======================================================================================docker run选项：Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -a, --attach=[] 登录容器（以docker run -d启动的容器） -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile="" 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 --cpuset="" 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU -d, --detach=false 指定容器运行于前台还是后台，-d表示在后台运行 --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的dns服务器 --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 --entrypoint="" 覆盖image的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 -h, --hostname="" 指定容器的主机名 -i, --interactive=false 打开STDIN，用于控制台交互 --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定--exec-driver=lxc时使用 -m, --memory="" 指定容器的内存上限 --name="" 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net="bridge" 容器网络设置，待详述 -P, --publish-all=false 指定容器暴露的端口，待详述 -p, --publish=[] 指定容器暴露的端口，待详述 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart="" 指定容器停止后的重启策略，待详述 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 -t, --tty=false 分配tty设备，该可以支持终端登录 -u, --user="" 指定容器的用户 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 -w, --workdir="" 指定容器的工作目录 测试1234docker run --name nginx1 -p 8081:80 -itd nginx#创建容器，暴露端口。之后可以通过192.168.99.100:8081访问nginx测试页docker exec -it nginx1 /bin/bash#进入nginx1容器中]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习二：安装]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E5%AD%A6%E4%B9%A0%E4%BA%8C%EF%BC%9A%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[ubuntu18.04_Server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apt install apt-transport-https ca-certificates curl software-properties-common# 由于apt源使用 HTTPS 以确保软件下载过程中不被篡改。因此,我们首先需要添加使用HTTPS 传输的软件包以及 CA 证书。curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 为了确认所下载软件包的合法性,需要添加软件源的GPG密钥。也可以添加官方密钥，如下# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -add-apt-repository "deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 向source.list中添加 Docker 软件源apt updateapt install docker-ce# 安装docker# 在ubuntu19.10版本中，没有找到docker-ce，更新源时还会报错。可以安装docker.io，另外查到方法可尝试# curl https://get.docker.com | bash # sudo apt install docker.iogroupadd dockerusermod -aG docker test# 将当前用户加入docker组# 默认情况下，docker命令会使用 Unix socket 与 Docker 引擎通讯。而只有root用户和组的用户才可以访问 # Docker 引擎的 Unix socket。出于安全考虑,一般 Linux 系统上不会直接使用root用户。因此,更好地做法是# 将需要使用docker的用户加入docker用户组。newgrp docker # 不需要使用sudo，但一定要更新用户组，如果不执行此步，还是会报错:"docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create: dial unix /var/run/docker.sock: connect: permission denied. "# 原因就是上面说的，docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://7ozw7lxv.mirror.aliyuncs.com"] &#125;# 设置docker加速器，地址是从阿里云的容器镜像服务器得到的systemctl daemon-reloadsystemctl start dockerdocker run hello-world# 测试docker安装是否成功。如果安装成功，会输入下列内容 Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the "hello-world" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ ubuntu19.1012345678910111213141516171819202122232425sudo apt install apt-transport-https ca-certificates curl software-properties-common# 使用apt安装一些允许通过HTTPS才能使用的包curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 将官方Docker存储库的GPG密钥添加到系统sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable"# 将Docker存储库添加到APT源sudo apt updateapt-cache policy docker-ce# 显示软件包的安装状态和版本信息。# apt-cache 命令可显示 APT 内部数据库里的多种信息。这些信息是从 sources.list 文件内聚集不同来源的缓# 存。于运行 apt update 运作时产生的。sudo apt install docker-ce# 安装dockersudo systemctl status docker# 检查是否成功安装并在运行中groupadd dockerusermod -aG docker testnewgrp dockervim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://7ozw7lxv.mirror.aliyuncs.com"] &#125;systemctl daemon-reloadsystemctl start dockerdocker run hello-world Kali3.01234567891011121314apt-key adv \--keyserver hkp://ha.pool.sks-keyservers.net:80 \--recv-keys 58118E89F3A912897C070ADBF76221572C52609D# 添加keyvim /etc/apt/sources.list deb https://apt.dockerproject.org/repo debian-wheezy main# 添加源apt updateapt install docker-enginesystemctl start dockersystemctl status dockersystemctl enable docker# 参考：# https://www.jianshu.com/p/6b1cb6927e9e# Docker官网地址：https://docs.docker.com/# Debian安装Docker官方教程：https://docs.docker.com/engine/installation/linux/debian/ Windows7 下载DockerToolbox，地址：https://github.com/docker/toolbox/releases 安装中，如果VirualBox和Git已经安装，可以不选 安装完成后，桌面上会多出3各图标，如下。其中VirtualBox提供了linux虚拟机的运行环境，Docker Quickstart Terminal用于快速介入linux虚拟机，提供命令行交互，Kitematic是docker GUI很少用到。 使用命令创建default虚拟机 12打开cmddocker-machine create default 启动时会进行Docker环境的初始化，会在VirtualBox中自动创建名字为default的linux虚拟机，在此过程中会用到boot2docker.iso镜像文件。默认情况下，启动程序会从GitHub上下载此文件的最新版，但由于文件相对较大且速度不给力，多数情况下会下载失败，造成Docker环境无法启动。解决办法：其实DockerToolbox安装文件自带了boot2docker.iso镜像文件，位于安装目录下（如C:\Program Files\Docker Toolbox） ，将此文件拷至C:\Users\Administrator.docker\machine\cache目录下，然后在网络断开的情况下重新启动，便可初始化成功。 查看default虚拟机的IP地址，使用Xshell连接 123456打开cmddocker-machine ls#查看default地址#登录default信息#用户名：docker#密码：tcuser 更改虚拟磁盘存储位置 虚拟机的默认存储位置是C:\Users\Administrator.docker\machine\machines ，后期docke镜像文件会不断增加，为了给系统盘减负，最好将磁盘移动到其他位置。 首先通过PowerShell或cmd终端中执行【docker-machine stop default】命令停止default虚拟机。 通过VirtualBox”管理”–&gt;”虚拟介质管理”界面对虚拟磁盘进行复制。之后添加新磁盘，删除旧磁盘即可 配置镜像加速器 登录阿里云https://cr.console.aliyun.com，点击右侧的镜像加速器，复制地址。最后用命令修改镜像地址即可 123456登录虚拟机defaultsudo sed -i "s|EXTRA_ARGS='|EXTRA_ARGS='--registry-mirror=加速地址 |g" /var/lib/boot2docker/profile#修改后，可调整default的硬件配置，如CPU，memory，disk等，disk可以不用复制，创建一个新的，大一点的空间。另外，不可取消光驱的启动，因为启动时要用到boot2docker.iso文件打开cmddocker-machine restart default#重启docker服务 参考：https://www.cnblogs.com/canger/p/9028723.html]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云日志文件备份]]></title>
    <url>%2F2018%2F09%2F18%2F%E9%98%BF%E9%87%8C%E4%BA%91%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[密钥访问 123* 准备备份日志的服务器ssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.2.250 脚本 12345678910111213141516171819202122vim /root/sh #!/bin/bash # nettylog=/apps/echarging/log/nettylog processorlog=/apps/echarging/log/processor_1_log nettyback=/home/nettylog processorback=/home/processorlog1 nettybackR=/home/logbackup/nettylog processorbackR=/home/logbackup/processorlog1 cd $nettylog find ./ -name netty.log-`date -d yesterday +%F`."*".log -exec cp &#123;&#125; $nettyback \; tar -zcf $nettyback/netty-log.`date -d yesterday +%F`.tar.gz $nettyback/*.log scp $nettyback/netty-log.`date -d yesterday +%F`.tar.gz 192.168.2.250:$nettybackR rm -rf $nettyback/* cd $processorlog find ./ -name processor_1.log-`date -d yesterday +%F`."*".log -exec cp &#123;&#125; $processorback \; tar -zcf $processorback/processor_1.log-`date -d yesterday +%F`.tar.gz $processorback/*.log scp $processorback/processor_1.log-`date -d yesterday +%F`.tar.gz 192.168.2.250:$processorbackR rm -rf $processorback/*#本打算使用find ./ -name processor_1.log-`date -d yesterday +%F`."*".log -exec tar -zcf processor_log-`date -d yesterday +%F`.tar.gz &#123;&#125; \;命令来直接打包，但测试发现打出的包中只有find查到的最后一个文件。所以将命令改为了两条，先将找到的文件移到一个临时目录，再打包发送。 定时任务 123crontab -e * 4 * * * /bin/bash /root/sh/scplog.shcrontab -l]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云RDS数据库备份下载]]></title>
    <url>%2F2018%2F09%2F18%2F%E9%98%BF%E9%87%8C%E4%BA%91RDS%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[下载RDS数据备份或日志备份 登录RDS管理控制台 选择目标实例所在地域。 单击目标实例的ID，进入基本信息页面 在左侧导航栏中，选择备份恢复，进入备份恢复页面 选择数据备份标签页 选择查询的时间范围，然后单击查询。 在数据备份列表中，找到要下载的数据备份，并单击其对应的下载 在实例备份文件下载窗口，单击复制外网地址，获取数据备份文件外网下载地址。这里可以直接下载到本地，也可以通过内网或外网地址下载 登录云服务器ECS 下载数据备份文件 1234wget -c '&lt;数据备份文件内网或外网下载地址&gt;' -O &lt;自定义文件名&gt;.tar.gz#-c：启用断点续传模式。#-O：将下载的结果保存为指定的文件（建议使用URL中包含的文件名）。#说明：若提示显示100%进度，则表示文件下载完成。]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份与还原]]></title>
    <url>%2F2018%2F09%2F17%2Fmysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F%2F</url>
    <content type="text"><![CDATA[概念 備份：副本 如果在RAID1或RAID10上，是保證硬件損壞而不會業務中止，所以與mysql的備份無關，因其無法避免邏輯上的破壞 備份類型： 比如文件有50G，我們用CP復制的是時間點不一致的數據文件，所以不可以。服務器停了再復制是可以的，但服務器是不能停的。 熱備份（在線備份）：讀寫不受影響 溫備份：能讀不能寫，僅可以執行讀操作 冷備份：離線備份，讀寫操作均不能進行 物理備份和邏輯備份 物理備份：復制數據文件 邏輯備份：將數據導出至文本文件中 物理與邏輯備份可以热備、溫備或冷備份 完全備份、增量備份和差異備份 完全備份：備份全部數據（可以是某個庫的某個單獨數據的全部備份） 增量備份：僅備份上次完全或增量備份以後變化的數據 差異備份：僅備份上次完全備份以來變化的數據 差異備份與增量備份的區別是，增量備份在備份時每次都是和前一次比較，備份那些不同的數據，而恢復時是先恢復完全備份再按時間點恢復每次的增量備份；差異備份是先完全備份，之後每天都和完全備份比較，備份那些增長的數據，在恢復時先恢復完全備份，再恢復最後一天的差異備份即可。差異備份的數據量要比增量備份的數據量大很多 備份策略是完全加差異或完全加增量。可使用物理或邏輯方式進行完全、增量或差異備份，可以自由組合 還原，最好經常測試還原數據功能。要有還原方案 備份什麼？ ​ 數據、配置文件、日志（二進制日志、事務日志） 熱備份 MyISAM幾乎不可能熱備。可使用邏輯卷的快照備份，但最好是溫備份，以共享方式鎖定MyISAM中的所有表 InnoDB：可以熱備不影響進程，但會影響服務器性能。有專門熱備工具：xtrabackup, mysqldump 可把Mysql做成從服務器，需要備份時把從服務器停下來備份，之後再啟動與主服務器同步 物理備份：速度快，不用再借助mysql服務器做任何事 邏輯備份：需要mysql服務器進程參與，速度慢，可能會丟失浮點數精度。可以方便使用文本處理工具直接對其處理、可移植性強 備份策略： 完全+增量 完全+差異 選擇多長時間備份一次取決於兩點 數據變化的頻度和變化量； 能夠忍受的還原時長；完全備份是物理還是邏輯方式取決於我們自己的需要，增量備份使用哪種方式也一樣 mysql備份工具 mysqldump：邏輯備份工具、MyISAM（溫）、InnoDB（熱備份） mysqlhotcopy：物理備份工具，是溫備工具實際是冷備份 文件系統工具 cp：只能冷備份 lvm：借助邏輯卷的快照功能，可實現幾乎熱備 ​ mysql&gt; FLUSH TABLES ​ mysql&gt; LOCK TABLES ​ 創建快照：釋放鎖，而後復制數據 第三組工具 ibbackup：商業工具 xtrabackup：開源工具 mysqldump：邏輯備份 mysqldump（完全備份）+ 二進制日志 完全 + 增量 邏輯備份缺點 可能使浮點數據丟失精度 備份出的數據更佔用存儲空間，壓縮後可大大節省空間 不適合對大數據庫做完全備份 ​ 對InnoDB做熱備，不建議用溫備份 就算執行了FLUSH TABLES WITH READ LOCK;，如果此時有其他執行程序的話，這個加鎖過程可能要等很長時間，就算鎖上了背後可能還有寫操作，mysql後台每隔一段時間會將事務日志中的數據同步到事務文件中，後台可能還在寫，這時要等待事務日志同步到數據文件中，用命令SHOW ENGINE INNODB STATUS;可查看InnoDB的存儲狀態，所以建議熱備。 MVCC多版本並發控制，如果事務隔離級別是REPEATABLE-READ時，這也是默認級別，–single-transaction會啟動一個大事務，直到我們完成備份，這樣意味著在整個讀取過程中我們讀取的數據都是一致的，就算有人改了，我們看到的也是原來的數據，這就是能做熱備的原因 幾乎熱備：LVM snapshot快照：LVM在熱備上是這樣提供技術手段的，我們可對邏輯卷創建快照，快照完成以後，在執行快照那一刻，以後所有變化的數據，通過快照路徑來訪問的話都不會改變的，所以快照的訪問路徑，就是讓數據停留在了過去快照創建的那一刻，任何此後改變了的數據，在改變之前，先把他們復制到快照上然後再改變原始數據所以我們通過快照去訪問的時候，訪問到的都是原始數據，這就是邏輯卷備份，我們在執行快照的那一刻，將整個數據庫鎖定，執行讀鎖，只要能施加上鎖，立即對數據所在的卷創建一個快照，接著並立即釋放那個鎖，而後我們通過快照卷將數據復制出來就能完成備份了。於是我們就有個前提： 數據文件要在邏輯卷上 此邏輯卷所在卷組必須有足夠空間使用快照卷，備份數據要放在快照卷上，快照卷主要是用來備份，備份後就沒用了，可以估計一下數據，如果數據備份要三小時，三小時的數據變化量是100M，我們創建一個500M的快照卷就可以了，如果超出快照卷大小，數據會崩潰的，所以我們要給出足夠的預估 數據文件和事務日志要在同一個邏輯卷上（如果使用快照卷做備份的話事務日志與數據文件一定要在一個卷上，因為我們創建的快照，如果事務日志與數據文件不在同一個卷上，那我們就在給兩個卷各做一個快照，但兩個卷的時間點未必一致，事務日志的主要目的是為了向事務存儲引擎提供ACID功能的，如果時間點不一致的話，是不能拿來執行數據恢復的。事務日志結合數據文件一起完成數據管理，用戶的寫操作是先寫到事務日志中，再由事務日志一點點與數據文件同步。所以我們在創建快照時，我們執行的命令會鎖定所有表，其他用戶不能向這裡寫，但這不意味著數據文件與日志已經統一了，事務日志中的某些語句在後台仍在向數據文件中寫，如果我們把他們放在不同的卷上分別進行快照，快照的時間點有可能不一致，那事務日志就無法向數據文件同步數據。所以一定要放在同一個卷上。如果事務日志正在與數據文件同步，這時我們做一快照，這個快照的備份文件是可以用的，但mysql會做一個內部的修復，在mysql服務器看來這就是一個服務器發生崩潰需要還原的版本。同理，如果我們想執行那些未完成的操作繼續執行的話，還要依賴二進制日志。就算我們使用邏輯卷做了一次完全的物理備份，將來做即時點還原仍然依賴於二進制日志）這裏指的是InnoDB，不包括MyISAM mysqldumpmysqldump备份恢复12345678910111213141516171819202122232425262728293031323334备份vim /etc/my.cnf.d/server.cnf [mysqld] log_bin = mysql_bin#开启二进制日志vim /root/.my.cnf [client] user = 'root' password = 'centos' host = 'localhost'#实现免用户名密码登录mysql -uroot -p &lt; /root/jiaowu.sql#将jiaowu.sql文件导入到数据库中mysqlSHOW DATABASES;#有jiaowu库了SHOW BINARY LOGS;#查看二进制日志位置FLUSH TABLES WITH READ LOCK;#再打开一个终端执行此命令，刷新表並且以只讀的方式鎖定所有表，這時再備分mysqldump -uroot -p jiaowu &gt; /tmp/jiaowu.sql#导出jiaowu库FLUSH LOGS;UNLOCK TABLES;#備份完成後立即釋放鎖SHOW BINARY LOGS;#查看二进制日志位置，只取滾動後新建的日志恢复DROP DATABASE jiaowu;# 刪除jiaowu庫CREATE DATABASE studb;mysql studb &lt; /tmp/jiaowu.sql# 将数据库导入 mysqldump命令选项12345678910111213141516171819202122232425mysqldump -uroot -p jiaowu &gt; /root/jiaowu-`date +%F-%H-%M-%S`.sql #備份mysqldump -uroot -p --master-data=2 jiaowu &gt; /root/jiaowu-`date +%F-%H-%M-%S`.sql#用了第二條命令會在備份的文件中有CHANGE MASTER TO NASTER_LOG_FILE=`mysql-bin.000008, MASTER_LOG_POS=107`指明現在的日志名稱及位置mysqldump -uroot -p --lock-all-tables --flush-logs --all-databases &gt; /root/all.sql #因為不是所有庫都是InnoDB引擎的，所以要用--lock-all-tables選項，之後備份所有庫，還可以加上--master-data=2選項mysqldump -uroot -p --lock-all-tables --flush-logs --all-databases --master-data=2 &gt; /root/all.sqlless /root/all.sql #查看=======================================================================================mysqldump --master-data=n n=&#123;0、1、2&#125; 0表示不記錄二進制日志文件记录位置 1表示以CHNAGER MASTER TO的方式記錄位置，可用於恢復後直接啟動從服務器 2表示以CHNAGER MASTER TO的方式記錄位置，但默認被注釋了 --lock-all-tables：備份前鎖定所有表 --flush-logs：備份前鎖完表執行日志滾動 flush滾動 #如果指定庫中的表類型均為InnoDB，可使用--single-transaction啟動熱備，這時就不用鎖定表了--lock-all-tables，這個過程可能很長 * 備份多個庫 --all-databases：備份所有庫 --databases DB_NAME,DB_NAME,…：備份指定庫 #這兩個命令由於備份不只一個數據庫，所以會自動創建create databases命令，還原前就不用手動再指定庫了 --events：備份事件 --routines：備份存儲過程存儲函數 --triggers：備份觸發器 備份及即時點還原123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596備份及即時點還原備份策略：每周完全+每日增量 完全備份：mysqldump 增量備份：備份二進制日志文件（先flush logs） 步骤：1. 做全量备份2. 删除现有二进制日志之前的所有日志3. 删除某表中的一些行，以便下面测试4. 滚动日志5. 复制滚动前二进制日志到其他路径或将滚动前二进制日志转为sql文件保存到其他目录，实现增量备份6. 在删除了行的表中插入新行7. 将滚动后的日志（也是现在的日志）复制到其他路径8. 删除数据目录中的所有文件9. 停止、启动服务器，实现数据初始10. 修改root密码11. 导入全量备份的sql文件12. 导入增量备份的sql文件13. 将最新的日志文件转为sql文件并导入，实现即时点还原。14. 这里全量备份不存在对应的二进制日志，因为被删除了。删除后仅剩一个二进制日志，这个日志就是增量备份的日志。之后做其他操作后又滚动过一次日志，也就是最新的日志。这个过程涉及两个日志和一个全量备份的sql文件。* 完全备份mysqldump -uroot -p --master-data=2 --flush-logs --all-databases --lock-all-tables &gt; /root/alldatabases.sqlmysql#建議在刪除備份前的二進制日志前先將其備份一份，可能以後有用。less /root/ alldatabases.sqlSHOW BINARY LOGS;PURGE BINARY LOGS TO 'mysql_bin.000011'; #purge[pə:dʒ]：清除。刪除二進制文件，這是為了避免空間被佔滿，这是删除最后的mysql_bin.000011之前的所有二进制日志use studb;SELECT * FROM tutors;DELETE FROM tutors WHERE Age&gt;80; #刪除一些数据* 下面做增量備份mysqlFLUSH LOGS; #滾動quit #退出mysqlcd /mydata/data #到數據目錄中cp mysql-bin.000011 /root/ #因之前已經滾動了日志，所以倒數第二個就是我們要增量備份的日志，將其拷貝到root目錄即可。或mysqlbinlog mysql-bin.000011 &gt; /root/mon-incremental.sql #這種方式的增量備份更好一些mysqluse studb;INSERT INTO tutors (Tname) Values (‘stu123’);退出* 模擬刪除了數據庫，而不能刪二進制日志cp mysql-bin.000012 /root #將二進制日志拷出去rm -rf ./* #刪除數據目錄中的所有文件service mysqld stop #現在無法停止mysqlkillall mysqld #殺死mysql進程cd /usr/local/mysql/ #到此目錄初始化mysqlscripts/mysql_install_db --user=mysql --datadir=/mydata/data #初始化，这是编译安装的。如果是yum安装的可以直接启动，就会初始化service mysqld start #啟動mysqlmysqlUPDATE mysql.user SET PASSWORD=PASSWORD('centos') WHERE User='root';#设置root的密码。或执行mysql_secure_installationmysql -uroot -p &lt; alldatabases.sql #還原完全備份mysqlmysql -uroot -puse studb;SELECT * FROM tutors;退出 #這一過程是為了驗證增量備份恢復後的變化mysql -uroot -p &lt; mon-incremental.sql #恢復增量備份mysql -uroot -p #進入use studb;SELECT * FROM tutors; #查看證明有變化退出mysqlbinlog mysql-bin.000012 &gt; temp.sql #把日志文件導出為.sql文件mysql -uroot -p &lt; temp.sql #即時點還原。或mysqlbinlog mysql-bin.000012 | mysql -uroot -p #這樣一條命令即可實現即時點還原mysql -uroot -puse studb;SELECT * FROM tutors;#上面這樣的試驗只適合在數據量小的時候，如果大的話，mysqldump備份會很慢。視頻中要求寫一個mysql完全備份腳本，增量備份寫成另一個腳本，盡量使用變量定義保存位置，使用日期保存備份的文件名稱。還可用腳本還原 xtrabackup完全备份与恢复123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115* 安装wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.9/binary/redhat/7/x86_64/Percona-XtraBackup-2.4.9-ra467167cdd4-el7-x86_64-bundle.tar＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝* rpm包安装 * CentOS6yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpmyum list|grep perconayum install percona-xtrabackup * CentOS7yum install http://www.percona.com/downloads/percona-release/redhat/0.1-6/percona-release-0.1-6.noarch.rpmyum list|grep perconayum install percona-xtrabackup-24#阿里云建议MySQL5.6及之前的版本需要安装 Percona XtraBackup 2.3。MySQL5.7版本需要安装 Percona XtraBackup 2.4。#Percona XtraBackup 2.3地址：https://www.percona.com/doc/percona-xtrabackup/2.3/installation/yum_repo.html#Percona XtraBackup 2.4地址：https://www.percona.com/doc/percona-xtrabackup/2.4/installation/yum_repo.html========================================================innobackupex --helpinnobackupex --user=DBUSER --password=DBUSERPASS /path/to/BACKUP-DIR/(保存位置)#完全備份。innobackupex是一個腳本，在裡面封裝了一些命令行工具，--user=DBUSER --password=DBUSERPASS是連接服務器要用的帳號密碼。服務器可指定，如--host=localhost，這裡被省略了，因為一般都是在本機上進行備份。/path/to/BACKUP-DIR/指要保存的位置。備份的用戶要有權限，如果要使用一個最小權限的用戶進行備份，則可基於如下命令創建此類用戶。可以創建一個專門備份的用戶，或用管理員也可以========================================================* 授权mysqlMariaDB [(none)]&gt; CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY 'centos';#创建用户MariaDB [(none)]&gt; REVOKE ALL PRIVILEGES,GRANT OPTION FROM 'bkpuser'@'localhost';#取消用户所有权限与授权权限MariaDB [(none)]&gt; GRANT RELOAD,LOCK TABLES,REPLICATION CLIENT ON *.* TO 'bkpuser'@'localhost';#只需要RELOAD, LOCK TABLES, REPLICATION CLIENT這三個權限就可備份了MariaDB [(none)]&gt; FLUSH PRIVILEGES;MariaDB [(none)]&gt; SHOW GRANTS;#查看当前用户的授权。grant[grɑ:nt]：授权。MariaDB [(none)]&gt; SHOW GRANTS FOR bkpuser@localhost;#查看指定用户的授权* 备份innobackupex --user=root /backup #備份數據庫，backup目录是自动创建的。因为在/root/.my.cnf文件中写明了用户名和密码，所以这里的密碼是空，所以省略了，服務器是本機。另外，備份時需要mysql服務器是啟動狀態。備份好後在/backup下有一個以當前時間命名的目錄。使用上面的bkpuser用户备份时会提示有授权问题，也就是缺少某些权限，待解决cd /backup/2016-12-09_22-17-27 # 目錄中的內容如下:# jiaowu、mysql、test、mydb等是數據庫，ibdata1是表空間文件，backup-my.cnf是服務器的配置文件， 備份好以後可以看到備份好的文件中有一個xtrabackup_binlog_info文件，這是二進制日志信息的文件，可用cat打開，裏面是備份這一刻的二進制文件名與相應的號碼。xtrabackup_binary中有在備份時使用了哪個命令進行的備份的信息，視頻中顯示的是xtrabackup 55，测试时没有这个文件。xtrabackup_logfile文件是data數據文件，不能用cat打開；xtrabackup_checkpoints文件裡有備份類型及從哪個邏輯版本號開始的備份，其中to_lsn指的是InnoDB的每一個數據塊InnoDB存儲引擎的數據要存儲在磁盤上，它是存儲數據塊的，每一個數據塊都有一個日志序列號，InnoDB會在內部維持着當前每一數據塊的日志序列號，如果這個塊上的數據發生了改變，這個號碼會加1,下一次可以根據這個號碼做增量備份。如果某一個塊的號碼發生了改變，可以將某一個塊備份一下。這就是可以對InnoDB存儲引擎做增量備份的原因；這裏的信息顯示從0號開始，到1637454結束，下一次就從1637454開始# 這些備份的數據備份完以後是不能直接恢復的，因為備份的數據中有些事務可能只提交了一半，為了避免mysql啟動的修復過程，我們要對備份出來的文件做一些准備工作，然後才能恢復。准備工作包括：# 1.將已經提交的事務同步到數據文件，從日志文件同步到數據文件# 2.將尚未提交的事務做回滾# 用--apply-log選項可完成上面的兩項# innobackupex --apply-log /backup/***** # 最後的路徑是我們備份的數據的路徑。這樣就會完成上面提到的兩項工作，不做這項工作的話恢復後mysql是啟動不了的* 测试恢复mysqlMariaDB [(none)]&gt; use jiaowuMariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu0005');MariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu0006');#插入两条数据MariaDB [jiaowu]&gt; FLUSH LOGS;#做這步是因為備份當前使用的二進制日志會報錯，所以才滾動一次cp /var/lib/mysql/mysql_bin.000003 /root#复制滚动前的日志到其他路径，以备数据恢复时使用systemctl stop mariadbrm -rf /var/lib/mysql/*innobackupex --copy-back /backup/2018-09-19_11-06-30#恢复数据。/恢復時用--copy-back選項，這樣就可以了。這時的數據文件存儲位置（/var/lib/mysql/）一定要是空的，不然會報錯cd /var/lib/mysql/chown -R mysql.mysql /var/lib/mysql/#修改数据目录中文件的属主属组为mysqlsystemctl start mariadb#启动报错，无法启动。提示：#180919 11:51:48 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql#180919 11:51:48 [Note] /usr/libexec/mysqld (mysqld 5.5.60-MariaDB) starting as process 8893 ..#180919 11:51:49 InnoDB: The InnoDB memory heap is disabled#180919 11:51:49 InnoDB: Mutexes and rw_locks use GCC atomic builtins#180919 11:51:49 InnoDB: Compressed tables use zlib 1.2.7#180919 11:51:49 InnoDB: Using Linux native AIO#180919 11:51:49 InnoDB: Initializing buffer pool, size = 2.0G#180919 11:51:50 InnoDB: Completed initialization of buffer pool#180919 11:51:51 InnoDB: highest supported file format is Barracuda.#InnoDB: No valid checkpoint found.#InnoDB: If you are attempting downgrade from MySQL 5.7.9 or later,#InnoDB: please refer to http://dev.mysql.com/doc/refman/5.5/en/upgrading-downgrading.html#InnoDB: If this error appears when you are creating an InnoDB database,#InnoDB: the problem may be that during an earlier attempt you managed#InnoDB: to create the InnoDB data files, but log file creation failed.#InnoDB: If that is the case, please refer to#InnoDB: http://dev.mysql.com/doc/refman/5.5/en/error-creating-innodb.html#180919 11:52:00 [ERROR] Plugin 'InnoDB' init function returned error.#180919 11:52:00 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.#180919 11:52:00 [Note] Plugin 'FEEDBACK' is disabled.#180919 11:52:00 [ERROR] Unknown/unsupported storage engine: InnoDB#180919 11:52:00 [ERROR] Abortingvim /etc/my.cnf [mysqld] innodb_force_recovery=6 log_bin = mysql_bin#加入上面一行后，就可以启动了。启动后可以取消这个选项。也可能是没有开启二进制日志的原因，所以可以加入log_bin = mysql_bin。测试发现，加入开启二进制日志后，就不需要innodb_force_recovery选项了，另外，使用innodb_force_recovery启动后，进入数据库是不能操作的，需要将innodb_force_recovery注释后，再重启才能操作。#innodb_force_recovery可以设置为1-6,大的数字包含前面所有数字的影响。#1. (SRV_FORCE_IGNORE_CORRUPT):忽略检查到的corrupt页。#2. (SRV_FORCE_NO_BACKGROUND):阻止主线程的运行，如主线程需要执行full purge操作，会导致crash。#3. (SRV_FORCE_NO_TRX_UNDO):不执行事务回滚操作。#4. (SRV_FORCE_NO_IBUF_MERGE):不执行插入缓冲的合并操作。#5. (SRV_FORCE_NO_UNDO_LOG_SCAN):不查看重做日志，InnoDB存储引擎会将未提交的事务视为已提交。#6. (SRV_FORCE_NO_LOG_REDO):不执行前滚的操作。#参考：https://www.jb51.net/article/66951.htmmysqlMariaDB [jiaowu]&gt; SHOW DATABASES;MariaDB [jiaowu]&gt; USE jiaowu;MariaDB [jiaowu]&gt; SELECT * FROM tutors;#這時是沒有後來加的00006和000005的，要把剛才備份的二進制日志導入即可mysqlbinlog /root/mysql-bin.000003 &gt; /tmp/abc.sqlmysqlMariaDB [jiaowu]&gt; SET sql_log_bin=0;#临时关闭二进制日志MariaDB [jiaowu]&gt; SOURCE /tmp/abc.sql;#导入滚动后的二进制日志生成的sql文件，因为stu00005和00006是在完全备份后加入的MariaDB [jiaowu]&gt; SET sql_log_bin=1;#开启二进制日志MariaDB [jiaowu]&gt; USE jiaowu;MariaDB [jiaowu]&gt; SELECT * FROM tutors;#现在有刚加入的00006和000005的信息了 增量备份xtrabackup支持對innodb做增量備份，對MyISAM不支持，對MyISAM如果有就做完全備份；MyISAM適合讀多寫少的情況 12345678910111213141516171819202122232425262728293031323334mysqlMariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu0007');MariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu0008');#加入两条数据innobackupex --user=root /backup #恢復過一次後必須再重新做一次完全備份，因爲當前的數據庫沒有完全備份mysqlMariaDB [jiaowu]&gt; use jiaowuMariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu0009');MariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu00010');innobackupex --incremental /backup --incremental-basedir=/backup/2018-09-19_16-04-31/#先要指定增量備份的保存位置/backup，--incremental-basedir是指定完全備份的保存位置，它會針對完全備份以後的數據做備份，備份後保存在/backup目錄下。這是第一次增量備份。如果是再一次增量備份時，--incremental-basedir應該指向上一次的增量備份所在的目錄；如果數據庫再次損壞且沒有數據增長，用完全和增量備份就能恢復，如果有數據增長就要再加上二進制日志才能恢復。mysqluse jiaowuMariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu00011');MariaDB [jiaowu]&gt; INSERT INTO tutors (Tname) VALUES ('stu00012');innobackupex --incremental /backup --incremental-basedir=/backup/2018-09-19_16-05-33/#最後指定的是上一次的增量備份位置,2018-09-19_16-05-33是上一次備份後的目錄。如果之前未做過增量備份，就要指向完全備份innobackupex --apply-log --redo-only /backup/2018-09-19_16-04-34/#/如果有增量備份，這裡一定要指定--redo-only選項；2018-09-19_16-04-34是第一次完全備份；有增量備份的時候我們在實現提交的情況時，只執行redo不要執行endo。这里一定要用--apply-log选项，实现1.將已經提交的事務同步到數據文件，從日志文件同步到數據文件；2.將尚未提交的事務做回滾。不然下面的命令是不能执行的。innobackupex --apply-log --redo-only /backup/2018-09-19_16-04-34/ --incremental-dir=/backup/2018-09-19_16-05-33/#在准備第一次增量備份時要將完全備份寫在前面，還要將增量備份位置寫在最後，用--incremental-dir選項。这是将第一次增量备份合并到完全备份innobackupex --apply-log --redo-only /backup/2018-09-19_16-04-34/ --incremental-dir=/backup/2018-09-19_16-06-15#這是第二次增量備份，還是前面寫完全備份位置，後面是第二次增量備份的位置#之後的還原只需要還原完全備份即可，因為此時所有的提交操作都已合並到完全備份上去了，所以在還原時兩個增量備份就用不上了systemctl stop mariadbrm -rf /var/lib/mysql/*innobackupex --copy-back /backup/2018-09-19_16-04-34/chown -R mysql.mysql /var/lib/mysql/systemctl start mariadbmysqlMariaDB [jiaowu]&gt; use jiaowuMariaDB [jiaowu]&gt; SELECT * FROM tutors;#这里有上面插入的所有数据 導入或導出單張表，前提是每表一個表空間才可以&emsp;&emsp;默認情況下，InnoDB表不能通過直接復制表文件的方式在mysql服務器之間進行移植，即便使用了innodb_file_per_table選項。而使用xtrabackup工具可以實現此種功能，不過，此時需要導出表的mysql服務器啟用了innodb_file_per_table選項（嚴格來說，是要導出的表在其創建之前，mysql服務器就啟用了innodb_file_per_table選項），並且導入表的服務器同時啟用了innodb_file_per_table和innodb_expand_import選項 導出表 導出表是在備份的prepare階段進行的，因此，一旦完全備份完成，就可以在prepare過程中通過–export選項將某表導出了： 12innobackupex --apply-log --export /path/to/backup#此命令會為每個innodb表的表空間創建一個以.exp結尾的文件，這些以.exp結尾的文件則可以用於導入至其它服務器。 導入表 要在mysql服務器上導入來自於其它服務器的某innodb表，需要先在當前服務器上創建一個跟原表表結構一致的表，而後才能實現將表導入 1mysql&gt;CREATE TABLE mytable (…) ENGINE=InnoDB; 然後將此表的表空間刪除 1mysql&gt;ALTER TABLE mydatabase.mytable DISCARD TABLESPACE; 接下來，將來自於導出表的服務器的mytable表的mytable.ibd和mytable.exp文件復制到當前服務器的數據目錄，然後使用如下命令將其導入 1mysql&gt; ALTER TABLE mydatabase.mytable IMPORT TABLESPACE;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx功能测试二]]></title>
    <url>%2F2018%2F09%2F17%2Fnginx%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[https1234567891011121314151617181920212223242526272829303132333435363738* 创建CA服务器cd /etc/pki/CA(umask 077;openssl genrsa -out private/cakey.pem 2048)openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365touch index.txt serialecho 01 &gt; serial* 到web服务器mkdir /etc/nginx/sslcd /etc/nginx/ssl(umask 077;openssl genrsa -out nginx.key 2048)openssl req -new -key http.key -out nginx.csrscp nginx.csr 192.168.1.2:/tmp* 到CA服务器openssl ca -in /tmp/nginx.csr -out /etc/pki/CA/certs/nginx.crt -days 365#newcerts中的也是证书，是pem格式的scp certs/nginx.crt 192.168.1.3:/etc/nginx/ssl* 到web服务器cp conf.d/vhost1.conf conf.d/vhost1_ssl.confvim conf.d/vhost1_ssl.conf server &#123; listen 443 ssl; server_name www.ruopu.com; root /data/nginx/vhost1; access_log /var/log/nginx/vhost1_ssl_access.log main; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; #当前虚拟主机使用PEM格式的证书文件 ssl_certificate_key /etc/nginx/ssl/nginx.key; #当前虚拟主机上与其证书匹配的私钥文件 ssl_protocols sslv3 tlsv1 tlsv1.1 tlsv1.2; #支持ssl协议版本，默认为后三个 ssl_session_cache shared:SSL:10m; #在各worker之间使用一个共享的缓存。SSL是自定义的名字，1m内存空间可以缓存4000个会话，这里定义10M。 &#125; nginx -tnginx -s reloadss -tln访问https://www.ruopu.com，将cacert.pem传到主机，这里定义的CA服务器与客户端的主机名是一样的，访问时通过了。 重写1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162vim /etc/nginx/conf.d/vhost1.conf server&#123; rewrite /(.*)\.png$ /$1.jpg; #rewrite放在server中，另外放在location或if中也可以。上面配置表示，所有以.png结尾的文件都转成.jpg格式的。括号是为了后面的$1引用，/是根，png前面的点需要转义，后面的.jpg的点不需要转义 &#125;nginx -tnginx -s reload访问www.ruopu.com/images/fish.png，这里实际访问的是一个叫fish.jpg的文件，名字一样但格式不同。vim /etc/nginx/conf.d/vhost1.conf server &#123; listen 80; server_name www.ruopu.com; root /data/nginx/vhost1; error_page 404 /notfound.html; # rewrite /(.*)$ https://www.ruopu.com/$1; rewrite /(.*)\.png$ https://www.ruopu.com/$1.jpg; #用户请求任何内容，都转到https的页面上。但两条不要一起写，如果一起写，在访问www.ruopu.com/images/night.png时会先匹配上面的规则，下面的规则就不会生效了。 location = /notfound.html &#123; root /data/nginx/error_pages; &#125; location ^~ /images/ &#123; alias /data/pictures/; &#125; location ~* ^/(admin|login) &#123; auth_basic "admin area or login url"; auth_basic_user_file /etc/nginx/.ngxpasswd; &#125; location /ngxstatus &#123; stub_status; &#125; &#125;vim /etc/nginx/conf.d/vhost1_ssl.conf server &#123; listen 443 ssl; server_name www.ruopu.com; root /data/nginx/vhost1; location ^~ /images/ &#123; alias /data/pictures/; &#125; access_log /var/log/nginx/vhost1_ssl_access.log main; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_protocols sslv3 tlsv1 tlsv1.1 tlsv1.2; ssl_session_cache shared:SSL:10m; &#125;#vhost1_ssl.conf配置文件中也要有与vhost1.conf中相同的配置，这样才能正常访问，这里是定义的别名与vhost1.conf中是一样的，也就是要有相同的访问路径，不然不能正常访问，会有404的错误提示。#上面的重写要写在监听80端口的server中，不能写在监听在443端口的server中，如果写在监听在443端口的server中，那么请求会无限重定向，最后是无法访问的。监听80端口与监听443端口的两个server中定义的内容应该是一样的。不然访问80端口时能访问的路径被重定向到443端口时就访问不到了。如果想让访问80端口的任何以png结尾的文件，都被重定向到443端口的.jpg文件，那么就要在监听443端口的配置文件中加入 rewrite /(.*)\.png$ /$1.jpg;，如果在监听80端口的server中定义是不起作用的。这是在要将所有访问的内容都重定向到443端口，并且还要让访问png文件的请求重定向到443端口的jpg文件，这两个条件都存在的情况下需要的配置。但如果只是将访问80端口的以png结尾的文件重定向到443端口的jpg文件的话，只要在监听80端口的server中写入 rewrite /(.*)\.png$ https://www.ruopu.com/$1.jpg; 就行了。nginx -s reload访问https://www.ruopu.com/images/night.png，rewrite规则可以写多条，rewrite匹配并重写url后会以新的url地址重新匹配配置文件或重新检查location的规则，如果可以匹配到，就会再重写一遍，直到匹配不到。默认的行为是last，就是重写的url会被重新再匹配一遍规则。还有break、redirect、permanentvim /etc/nginx/conf.d/vhost1.conf server&#123; rewrite /(.*)\.png$ /$1.jpg redirect; &#125;#redirect是重定向，客户端要重新发起请求。如果是permanent就是永久重定向，也需要客户端重新发请求。last和break是不需要客户端重新发请求的，只是服务器内部做了转换=======================================================================================#[flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；不能以http://或https://开头；302 permanent：重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301 反代1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495* 准备三台主机，一台反代，两台web服务，反代服务器的地址有两个，一个外网192.168.1.90，一个内网172.16.0.1。web服务器有两个内网地址，一个172.16.0.2，一个172.16.0.3。设置内网地址，就是将虚拟机网卡改为仅主机，然后设置仅主机的IP地址yum install httpd mod_ssl//到web服务器上安装httpd，mod_ssl，并提供主页，最后改为内网网卡并配置地址。改为内网地址172.16.0.2vim /var/www/html/index.html &lt;h1&gt;Real Server 1&lt;/h1&gt;vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 IPADDR=172.16.0.2 NETMASK=255.255.0.0systemctl start httpdsetenforce 0systemctl stop firewalld* 到反代服务器vim /etc/yum.repos.d/nginx.repo [nginx] name=nginx repository baseurl=http://nginx.org/packages/centos/7/$basearch/ gpgcheck=0 enabled=1yum install nginxvim /etc/nginx/conf.d/ruopu.conf server &#123; listen 80; server_name www.ruopu.com location / &#123; proxy_pass http://172.16.0.2:80； //这里要看web服务器是基于什么做的虚拟主机，是IP，port还是FQDN，是哪个就在http后输入哪个 &#125; &#125;nginx -tsystemctl start nginx* 修改客户端hosts文件，让主机可以解析nginx的域名* 访问测试* 到web服务器上tcpdump -i eno16777736 tcp port 80//监听80端口，看一下请求是否为反代服务器发来的* 到第二台web服务器上yum install httpd改为内网地址172.16.0.3systemctl stop firewalldsetenforce 0vim /var/www/html/index.html &lt;h1&gt;Real Server 2&lt;/h1&gt;find /usr/share -iname "*.jpg" -exec cp &#123;&#125; /var/www/html \;//这一次准备将图片文件都反代到这台服务器systemctl start httpd* 到反代服务器，加入vim /etc/nginx/conf.d/ruopu.conf location ~* \.(jpg|jpeg|png)$ &#123; proxy_pass http://172.16.0.3:80; //将访问图片的请求代理到另一台服务器上 &#125;* 到客户端访问，如果是访问域名就返回第一台web服务器的内容，如果访问域名/*.jpg就返回第二台服务器的内容。在配置文件中，如果location中用了正则表达式，在proxy_pass指向的地址中的80端口后是不能加斜线/的，如果没用正则表达式，可以加斜线。像上边的第一个location设置，如果80后有斜线，表示将location中的斜线替换成80后的斜线，如果没有斜线，表示将location中的斜线补在80后* 测试斜线的功能，到反代服务器上vim /etc/nginx/conf.d/ruopu.com server &#123; listen 80; server_name www.ruopu.com; location / &#123; root /data/nginx/html; &#125; location /admin/ &#123; proxy_pass http://172.16.0.2:80; //这个反代的意思是在172.16.0.2的根目录下找admin目录，下面的反代是在访问以jpg等为后缀名的文件时到172.16.0.3:80的根目录下找 &#125; location ~* \.(jpg|jpeg|png)$ &#123; proxy_pass http://172.16.0.3:80; &#125; &#125; //修改配置文件，将admin代理过去mkdir -pv /data/nginx/htmlnginx -s reload* 到客户端访问www.ruopu.com/admin，提示Not Found，因为web服务器上没有admin目录。但是，如果location /admin/中的80后有斜线，那么访问的就是172.16.0.2的根目录，也就是/var/www/html/index.html文件。也就是，没有斜线，就将/admin补在80后，因为172.16.0.2中没有admin目录，所以提示Not Found。如果有斜线，就表示访问http://172.16.0.2/admin就是在访问172.16.0.2的根目录，/admin/就等于/。* 到web服务器上mkdir /var/www/html/adminvim /var/www/html/admin/index.html admin* 到客户端测试，这时显示admin* 到反代服务器上加一个斜线vim /etc/nginx/conf.d/ruopu.com server &#123; listen 80; server_name www.ruopu.com; location / &#123; root /data/nginx/html; &#125; location /admin/ &#123; proxy_pass http://10.5.5.204:80/; &#125; location ~* \.(jpg|jpeg|png)$ &#123; proxy_pass http://10.5.5.205:80; &#125; &#125;nginx -tnginx -s reload* 到客户端访问www.ruopu.com/admin，这时显示的是Real Server 1，也就是web服务器上html中定义的内容，配置的意思就是，当访问admin时，就替换成web服务器根下的内容。当location中定义的是根时，这个斜线就没有意义了，因为访问的都是根]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云数据库连接与设置阿里云RDS字符集]]></title>
    <url>%2F2018%2F09%2F14%2F%E9%98%BF%E9%87%8C%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E4%B8%8E%E8%AE%BE%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91RDS%E5%AD%97%E7%AC%A6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[测试数据库连接注：阿里云在添加白名单时，如果是内网主机，就选专有网络。因为虚拟机与阿里云RDS都使用的是专有网络。如果用外网连接数据库，就将外网的地址添加到白名单的经典网络。另外，还要注意数据库中的用户应该有从外网地址连接的权限。 123456789101112131415161718192021222324252627282930313233[root@test ~]# traceroute -n -T -p 3306 rm-2zeik6f1smno.mysql.rds.aliyuncs.comtraceroute to rm-2zeiks9o06fas81smno.mysql.rds.aliyuncs.com (0.90.0.18), 30 hops max, 60 byte packets 1 * * * 2 123.127.52.225 1.151 ms 1.556 ms 1.948 ms 3 124.65.151.117 9.099 ms 9.282 ms 9.376 ms 4 124.65.226.253 3.983 ms 4.504 ms 4.656 ms 5 * * * 6 * 61.51.169.69 5.301 ms * 7 * * * 8 * * * 9 123.56.34.25 6.576 ms 101.200.109.133 5.156 ms 4.126 ms10 * * 123.56.34.89 4.640 ms11 * * *12 * * *13 * * *14 * * *15 * * *16 * * *17 * * *18 * * *19 * * *20 * * *21 * * *22 * * *23 * * *24 * * *25 * * *26 * * *27 * * *28 * * *29 * * *30 * * *#上述探测数据中，目标端口在第 11 跳之后就没有数据返回。说明相应端口在该节点被阻断。 参考：https://help.aliyun.com/knowledge_detail/40572.html?spm=5176.11065259.1996646101.searchclickresult.4ffa1754h73l7T（能 ping 通但端口不通时端口可用性探测说明） 修改字符集12345678910111213141516171819202122231. 连接数据库mysql -hrm-2zeiks9sm.mysql.rds.aliyuncs.com -uroot -p2. 查看字符集MySQL [(none)]&gt; show variables like '%char%';+--------------------------+---------------------------------------+| Variable_name | Value |+--------------------------+---------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /u01/mysql57_20180725/share/charsets/ |+--------------------------+---------------------------------------+3. 修改字符集MySQL [echarging]&gt; set character_set_client=utf8mb4;MySQL [echarging]&gt; set character_set_connection=utf8mb4;MySQL [echarging]&gt; set character_set_results=utf8mb4;MySQL [echarging]&gt; set character_set_database=utf8mb4; MySQL [echarging]&gt; set character_set_server=utf8mb4;4. 修改character_set_server也可以在阿里云的控制台操作]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云Redis设置公网地址]]></title>
    <url>%2F2018%2F09%2F13%2F%E9%98%BF%E9%87%8C%E4%BA%91Redis%E8%AE%BE%E7%BD%AE%E5%85%AC%E7%BD%91%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[设置 在云服务器 ECS Linux 中安装 rinetd 12345wget http://www.boutell.com/rinetd/http/rinetd.tar.gz&amp;&amp;tar -xvf rinetd.tar.gz&amp;&amp;cd rinetdsed -i 's/65536/65535/g' rinetd.c#修改端口范围mkdir /usr/man&amp;&amp;make&amp;&amp;make install#安装 创建配置文件 rinetd.conf 1234vim /etc/rinetd.conf 0.0.0.0 6379 r-ab.redis.rds.aliyuncs.com 6379 logfile /var/log/rinetd.log#第一条前半部分是本机监听的地址与端口，后半部分是阿里云Redis的地址与端口 启动 1234rinetdecho rinetd &gt;&gt;/etc/rc.local#设置开机启动chmod +x /etc/rc.d/rc.local 在阿里云安全组中开放端口 将ESC主机加入阿里云的白名单 连接测试 123redis-cli -h IPtelnet IP port#两种方法都可以，使用telnet连接上之后，使用quit应该可以退出。 附录 rinetd是为在一个Unix和Linux操作系统中为重定向传输控制协议(TCP)连接的一个工具。rinetd是单一过程的服务器，它处理任何数量的连接到在配置文件etc/rinetd中指定的地址/端口对。尽管rinetd使用非闭锁I/O运行作为一个单一过程，它可能重定向很多连接而不对这台机器增加额外的负担。 使用iptables 很容易将TCP 和UDP 端口从防火墙转发到内部主机上。但是如果您需要将流量从专用地址转发到甚至不在您当前网络上的机器上，又该怎么办呢？可尝试另一个应用层端口转发程序，如rinetd。 这些代码有点古老，但很短小、高效，对于解决这种问题来说是非常完美的。 参考：https://baike.baidu.com/item/rinted/2590570]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx功能测试一]]></title>
    <url>%2F2018%2F09%2F13%2Fnginx%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%80%2F</url>
    <content type="text"><![CDATA[CPU绑定1234567891011121314151617181920212223242526272829303132ps axo user,comm,pid,psr,pcpu | grep nginx#查看进程运行在哪个CPU上，显示的最后一个数字就是指第几颗CPU上。这个命令是查看进程的名称、PID以及CPU的占用率。psr表示绑定内核线程的处理器（如果有）的逻辑处理器号。 对一个进程来说，如果它的线程全都绑定到同一处理器上，那么显示该字段。pcpu表示CPU的占用率。comm表示进程名称。pid表示进程的ID号watch -n.5 'ps axo comm,pid,psr | grep nginx'yum install httpd-toolsab -n 100000 -c 100 http://IP/index.html#这时可以看到上面监测的绑定CPU数字在变化，因为CPU与进程没有绑定vim /etc/nginx/nginx.conf#这时在配置文件中加入绑定设置，定义在全局段 worker_cpu_affinity auto; #自动绑定CPU worker_rlimit_nofile 65536; #如果不加入worker打开文件数量的上限，检查语法时会有报错，提示最多打开1024。定义在全局段 worker_priority -5; #调整优先级watch -n.5 'ps axo comm,pid,psr,ni | grep nginx'#可以看到优先级改为了-5nginx -tnginx -s reloadvim /etc/hosts 192.168.1.15 www.ruopu.comsystemctl stop firewalldsetenforce 0ab -n 100000 -c 100 http://IP/index.html#这时监测页面的CPU数字是不会变化的，因为已经绑定了，显示的内容中第一个是主控进程，只看后四个即可vim /etc/nginx/nginx.conf worker_cpu_affinity 1000 0100 0010 0001; #绑定第0到3颗CPU，因为CPU是四核的。这时监测页面显示绑定在0－3的CPU上vim /etc/nginx/nginx.conf worker_processes 2; worker_cpu_affinity 1000 0100;nginx -s reload#再查看监测页面，这里只绑定在2颗CPU上 设置访问权限123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/nginx/conf.d/vhost1.conf server &#123; listen 80; server_name www.ruopu.com; root /data/nginx/vhost1; location / &#123; deny 192.168.1.22; allow all;#location定义对根及以下的路径的访问拒绝22地址访问，allow也一样，可以用一个地址或一个网段/24或all &#125; &#125;nginx -s reload访问IPvim /etc/nginx/conf.d/vhost1.conf server &#123; listen 80; server_name www.ruopu.com; root /data/nginx/vhost1; location ~* \.(jpg|png) &#123; deny 192.168.1.22; allow all; &#125; &#125;//对目录中的jpg或png文件，拒绝22地址访问。location中定义的地址是在root定义的地址的下面的路径nginx -s reloadfind /usr/share -iname "*.jpg" -exec cp &#123;&#125; /data/nginx/vhost1 \;访问测试,www.ruopu.com/morning.jpg如果location中定义了root，那么以location中的root为准=====================================================================================#在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置；location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;Sets configuration depending on a request URI. =：对URI做精确匹配；例如, http://www.magedu.com/, http://www.magedu.com/index.html，如果等于根，那么就只有根被匹配，如果没有等号，那么从根以下的所有路径都匹配。 location = / &#123; ... &#125; ~：对URI做正则表达式模式匹配，区分字符大小写； ~*：对URI做正则表达式模式匹配，不区分字符大小写； ^~：对URI的左半部分做匹配检查，不区分字符大小写；也就是以什么开头 不带符号：匹配起始于此uri的所有的url； 匹配优先级：=, ^~, ～/～*，不带符号； 定义别名123456789101112131415161718mkdir /data/picturescp fish.jpg /data/picturesvim conf.d/vhost1.conf location ^~ /images/ &#123; #^~是指以其后设定的内容开头的，但这里没有什么用 root /data/pictures； &#125;#这时访问www.ruopu.com/images/fish.jpg提示404，上面定义的应该是在pictures中找images目录，然后再找文件。/data/pictures就相当于根，在根下再打开images目录mkdir /data/pictures/imagesmv /data/pictures/*.jpg /data/pictures/images访问www.ruopu.com/images/flower.jpgvim conf.d/vhost1.conf location ^~ /images/ &#123; alias /data/pictures/； &#125;#将root改为alias。别名中的pictures右边的斜线是相对于images右侧的斜线来说的。所以，上面别名/data/pictures/最右边的斜线一定不能少，不然就不能访问到。nginx -s reload访问www.ruopu.com/images/fish.jpg才有，flower.jpg是访问不到的。因为在pictures中只有fish.jpg文件，没有flower.jpg文件。root是对于左侧的斜线，alias是对于最右侧的斜线来说的。 自定义错误页123456789101112131415161718192021vim /etc/nginx/conf.d/vhost1.conf server &#123; listen 80; server_name www.ruopu.com; root /data/nginx/vhost1; location ~* \.(jpg|png) &#123; error_page 404 =200 /notfound.html;#notfound.html是URL的地址，它的位置是root定义的，因为加了等于200，所以这改变了状态码，在浏览器中按F12时可以看到是200了。测试使用等于200的设置会提示错误的值，原因是在200与其前面的等号中间加了空格，去掉空格就正常了。notfound.html应该是自定义的名字，但定义的名字与location指定的名字，与root定义的目录中的*.html文件的名字，这三个名字要一致，不然访问不了。error_page定义一次即可，这里只是展现了两种方法。 error_page 404 /notfound.html; location = /notfound.html &#123; root /data/nginx/error_pages; &#125; location ^~ /images/ &#123; alias /data/pictures/; &#125; &#125;mkdir /data/nginx/error_pagesvim /data/nginx/error_pages/notfound.html 404nginx -s reload访问www.ruopu.com/test.html，这是一个不存在的页面 认证123456789101112131415161718192021222324252627yum install httpd-toolshtpasswd -c -m /etc/nginx/.ngxpasswd tomhtpasswd -m /etc/nginx/.ngxpasswd jerryvim /etc/nginx/conf.d/vhost1.conf server &#123; listen 80; server_name www.ruopu.com; root /data/nginx/vhost1; error_page 404 /notfound.html; location = /notfound.html &#123; root /data/nginx/error_pages; &#125; location ^~ /images/ &#123; alias /data/pictures/; &#125; location ~* ^/(admin|login) &#123; #~*做正则表达式模式匹配，如果以admin或login开头，就进行认证。当然，这也要求在vhost1中有这个目录才行。 auth_basic "admin area or login url"; #使用ngx_http_auth_basic_module模块实现基于用户的访问控制，使用basic机制进行用户认证；"admin area or login url"是一段自定义提示信息。 auth_basic_user_file /etc/nginx/.ngxpasswd; &#125; &#125;mkdir /data/nginx/vhost1/adminvim /data/nginx/vhost1/admin/index.html admin aeranginx -s reload访问www.ruopu.com/admin，如果访问的是www.ruopu.com/login就会失败，因为在vhost1中没有login目录。 状态页1234567891011vim /etc/nginx/conf.d/vhost1.conf location /ngxstatus &#123; #这里的ngxstatus也是自定义的名称，定义什么名字，访问时就用什么名字 stub_status; #stub_status是一个系统变量 &#125; #ngxstatus是自定义名称，还可以在其中加认证或allow、deny。location后面定义的是URL名，也是路径名nginx -s reload访问www.ruopu.com/ngxstatus。curl --silent http://www.ruopu.com/ngxstatus | awk '^Active/&#123;print $3&#125;'#测试此条命令后的awk用法有问题，在^Active上。 压缩功能12345678910111213141516171819vim /etc/nginx/nginx.conf http &#123; gzip on; gzip_min_length 1k; #不压缩临界值，大于1K的才压缩，一般不用改 gzip_buffers 4 16k; #支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小； gzip_comp_level 6; #压缩级别，1-10，数字越大压缩的越好，时间也越长 gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; #进行压缩的文件类型，缺啥补啥就行了，JavaScript有两种写法，最好都写上吧，总有人抱怨js文件没有压缩，其实多写一种格式就行了 gzip_disable "MSIE [1-6]\."; #IE6对Gzip不怎么友好，不给它Gzip了 &#125; nginx -s reloadcp nginx.conf /data/nginx/vhost1/nginx.htmlchmod +r /data/nginx/vhost1/nginx.htmlcurl -I -H "Accept-Encoding: gzip, deflate" "http://www.ruopu.com/images/morning.jpg"#如果对访问的内容进行了压缩，在结果中会有Content-Encoding: gzip的字样。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装]]></title>
    <url>%2F2018%2F09%2F13%2Fnginx%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[rpm包安装1234567891011121314151617181920212223242526vim /etc/yum.repos.d/nginx.repo [nginx] name=nginx repository baseurl=http://nginx.org/packages/centos/7/$basearch/ gpgcheck=0 enabled=1###自建repo文件或用以下命令；如果是CentOS6上安装nginx，就将上面源地址中的7改为6就可以了。也可以下载安装http://http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm。另外，在CentOS6上如果要安装nginx，还要将openssl升级到1.0.2版本以上。到https://www.openssl.org/source/openssl-1.0.2h.tar.gz下载，之后编译安装###如果提示需要公钥验证，需要执行此命令rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7rpm -ivh https://mirrors.ustc.edu.cn/epel/epel-release-latest-7.noarch.rpm------------------------------------------------------------------------------------rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm//此命令安装后也会自建一个叫nginx.repo的源yum repolistyum info nginxyum install nginx------------------------------------------------------------------------------------yum install epel-release -y###也可以用yum安装epel-release包得到epel仓库。也可以安装epel库来安装nginx，这样安装nginx后会自动配置配色方案注：nginx配置文件默认没有配色，使用下面方法解决mkdir -pv ~/.vim/syntaxcd ~/.vim/syntaxwget http://www.vim.org/scripts/download_script.php?src_id=14376 -O nginx.vimvim ~/.vim/filetype.vim au BufRead,BufNewFile /etc/nginx/* set ft=nginx###其中路径为你的nginx.conf文件路径 源码安装12345678910111213141516171819202122yum install zlib-devel pcre-develyum groupinstall "开发工具"tar nginx-1.12.2.tar.gzcd nginx-1.12.2./configure --with-pcre --with-zlib/usr/local/nginx/sbin/nginx ###启动/usr/local/nginx/sbin/nginx -s reload ###重启/usr/local/nginx/sbin/nginx -s stop ###关闭vim /usr/lib/systemd/system/nginx.service [Unit] Description=Nginx Service [Service] Type=forking PIDFile=/usr/local/nginx/logs/nginx.pid ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf ExecReload=/usr/local/nginx/sbin/nginx -s reload ExecStop=/usr/local/nginx/sbin/nginx -s stop###实现systemd管理nginx###这里一定要注意PIDFile的路径，在/usr/local/nginx/conf/nginx.conf配置文件中，默认pid文件放在/usr/local/nginx/logs中，如果写错路径，nginx是无法启动的，报错为：PID file /run/nginx.pid not readable (yet?) after start.]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置文件说明]]></title>
    <url>%2F2018%2F09%2F13%2Fnginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[nginx配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162vim /etc/nginx/nginx.conf#配置文件中的include出现了多次，在全局中和http、server中都有 user nginx; #进程以哪个用户的身份运行 worker_proceseese auto; #配置工作进程数的，auto指自动探测主机的物理核心数，并启动与核心数一样的进程数。或输入数字。这里只能是等于或小于物理核心数 error_log /var/log/nginx/error.log; #错误日志位置 pid /run/nginx.pid; #进程id worker_cpu_affinity auto; #自动绑定cpu，如果当前主机只运行nginx就非常有效，如果有其他服务，如mysql，就不要做了 include /usr/share/nginx/modules/*.conf; #装载需要的模块的位置。模块位置在/usr/share/nginx/modules中，其中的mod-http-geoip.conf是根据IP地址查询其所在的位置的 events&#123; use epoll; #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能 worker_connections 1024； #配置事件驱动模型的，这里默认是单进程响应1024个请求。worker_proceseese乘以这里的worker_connections就是一共可以并发响应的总数。如果不够可以将1024改大，但不要随便改 &#125; http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; #日志格式，main是名称，之后使用的是nginx的内置变量，官方文档中有对变量的解释 access_log /var/log/nginx/access.log main; #访问日志位置及格式 sendfile on; #提升性能的配置，从内核直接响应用户。sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. tcp_nopush on; tcp_nodelay on; #也是提升性能的 keepalive_tiomout 65; #保持长连接，超时65秒 types_hash_max_size 2048; #types_hash_max_size 影响散列表的冲突率。types_hash_max_size越大，就会消耗更多的内存，但散列key的冲突率会降低，检索速度就更快。types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 include /etc/nginx/mime.types; default_type application/octet-stream; #让nginx知道支持哪些类型。设定mime类型,类型由mime.type文件定义 include /etc/nginx/conf.d/*.conf #启动要加载的配置，如虚拟主机 server &#123; listen 80 default_server; #监听端口，default_server表示默认虚拟主机，如根据主机名访问，如果都不匹配，那么就找第一个虚拟主机。也就是所有匹配不到的虚拟主机，都由默认虚拟主机响应 listen [::]:80 default_server; #这是IPV6的地址 server_name _; #对默认虚拟主机来说，下划线可以匹配所有主机名 root /usr/share/nginx/html; #定义默认网页和路径的 location / &#123; #location指明个人的配置 &#125; error_page 404 /404.html #自定义404错误页是什么 location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; &#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx程序架构]]></title>
    <url>%2F2018%2F09%2F12%2Fnginx%E7%A8%8B%E5%BA%8F%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;nginx是一个模块化的、事件驱动的、异步，单线程的、非阻断的服务。nginx启动后会有master与worker进程，master进程只有一个，负责加载和分析配置文件、管理worker进程、平滑升级。worker进程有一个或多个，负责处理并响应用户请求。 worker模型&emsp;&emsp;nginx并不为每个连接产生一个进程或线程。工作进程从一个共享的“listen”socket接受新的请求，每个worker内运行循环高效执行。每个worker处理数以千计的连接。在启动时，一组初始的监听套接字被创建。当处理HTTP请求和响应时，worker不断接受，读取和写入到socket。 &emsp;&emsp;nginx的worker代码的运行循环是最复杂的部分。它包括全部的内部调用，并在很大程度上依赖于异步处理任务的想法。异步操作通过模块化，事件通知，广泛使用回调函数和微调定时器实现。总体而言，关键的原则是尽可能的非阻塞。 唯一可以让nginx阻塞的情形是，没有足够的磁盘存储供worker操作。 &emsp;&emsp;由于nginx并不会为每个连接产生新的进程或线程，内存使用在绝大多数情况下是非常保守的，效率非常高。 nginx节省CPU周期，因为没有持续的进程或线程的创建销毁模式。nginx要做的是检查网络和存储的状态，初始化新的连接，将它们添加到运行循环，处理直到完成，此时连接被释放，从运行循环中移除。谨慎使用系统调用和准确实现支持接口，如poll和slab内存分配器相结合，nginx通常达到中度至低CPU占用率，即使在极端恶劣的工作负载环境下。 &emsp;&emsp;由于nginx可以产生数个worker进程处理连接，在多核上扩展性很好。一般情况下，每核一个单独的worker可以充分利用多核架构，并防止线程的波动和锁定。隔离的单线程worker进程没有资源匮乏和资源控制机制。该模型还允许在物理存储设备上的可扩展性，有利于更好的磁盘利用率，避免了磁盘I / O阻塞。所以，一些资源在几个worker之间共享可以更有效的被利用 &emsp;&emsp;在磁盘和CPU的负载模式中，nginx的worker数目应该进行相应的调整。这里有一些基本规则，系统管理员应该根据负载量尝试几种配置。以下的是一般建议内容：如果负载模式是CPU密集的情况下，处理大量的TCP / IP，做SSL，压缩，nginx的worker的数量和CPU核的数量应该相匹配；如果负载主要是磁盘I / O范畴的情况下，从储存提供不同的内容，或繁忙的代理。worker的数量可以是一个半到两个核。与之相反的是，一些工程师选择worker的数量是基于独立存储单元的数量，但这种方法的效率取决于磁盘存储的类型和配置。 Nginx进程的作用&emsp;&emsp;nginx在内存中运行多个进程。有一个主进程和多个worker进程。此外，还有一些特殊用途的进程，特别是高速缓存加载器和高速缓存管理器。在nginx的1.x版本中所有的进程都是单线程。所有进程主要使用共享内存的进程间通信机制。主进程以root用户运行。缓存加载器，缓存管理器和worker作为一个非特权用户运行。 &emsp;主进程负责执行以下任务： 读取并验证配置 创建，绑定和关闭套接字 启动，终止和维护配置的工作进程数 不中断服务的情况下重新配置 控制不停止服务的二进制升级（如有必要，启动新的二进制程序和回滚） 重新打开日志文件 编译嵌入式的Perl脚本 &emsp;&emsp;worker进程接受，处置和处理来自客户端的连接，提供反向代理和过滤功能，做nginx能力范围之内的所有事情。关于监测nginx的实例的动态，系统管理员应该留意worker，因为他们是反映了Web服务器的实际日常操作的进程。 &emsp;&emsp;缓存加载器进程负责检查磁盘上的缓存项和使用高速缓存元数据填充Nginx在内存中的数据库。从本质上讲，缓存加载器可以帮助nginx和文件协同工作，一个已经专门分配存储在磁盘上的目录结构。它遍历目录，检查缓存内容，元数据，更新共享内存中的相关条目，当一切都干净并准备投入使用时，它会退出。 &emsp;&emsp;高速缓存管理器主要是负责缓存过期和失效。在正常nginx的操作过程中它驻留在内存中，在失败的情况下，它被主进程重新启动。 Nginx的缓存的简要概述&emsp;&emsp;Nginx的缓存是以分层数据存储的形式在一个文件系统中实现的。缓存键是可配置的，不同请求的目的参数可以用来控制哪些参数可以进入高速缓存中。高速缓存键和缓存元数据存储在共享内存段，从而缓存加载器、缓存管理器和worker都可以访问。没有任何文件缓存在内存中，只有操作系统的虚拟文件系统机制方面的优化。每个高速缓存的响应被放置在文件系统上的不同文件。通过nginx的配置指令控制的层次结构（层次和命名的详细信息）。当一个响应被写入到高速缓存的目录结构，路径和文件的文件名是来自代理URL的MD5哈希。 &emsp;&emsp;放置在高速缓存中的内容的过程如下所示：当nginx从上游服务器读取响应，内容首先被写入到高速缓存的目录结构以外的一个临时文件。当nginx完成处理请求时，临时文件重命名，并被移动到缓存目录中。如果临时文件目录代理是在另一个文件系统上，该文件将被复制，因此建议临时文件和缓存目录保持在同一个文件系统。需要显式地清除，从缓存目录结构删除文件是比较安全的。 HTTP请求处理过程 客户端发送HTTP请求。 nginx的核心段根据所配置的location选择合适匹配请求的处理程序。 如果配置要求这样做，负载平衡器为代理挑选一个上游服务器（或“后端”）。 阶段处理程序执行它的工作，并传递每个输出缓冲器到所述第一滤波器。 第一滤波器的输出传递到所述第二过滤器。 第二滤波器的输出到第三个（等等）。 最终的响应被发送到客户端。 参考：https://my.oschina.net/daleshen128/blog/95130]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改tomcat默认页面]]></title>
    <url>%2F2018%2F09%2F12%2F%E4%BF%AE%E6%94%B9tomcat%E9%BB%98%E8%AE%A4%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[修改tomcat的默认页面为自己的主页，再使用nginx反代到tomcat。实现访问域名即可打开主页。 tomcat 12345678vim /usr/local/tomcat/conf/server.xml &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="" docBase="echarge" reloadable="true" /&gt;//在Host下面加入Context一行，设置path为空，这样就不会访问到默认页了。之后用docBase指定主页的路径，这里写echarge表示是在webapps下的echarge目录。reloadable表示是否自动装载。/usr/local/tomcat/bin/shutdown.sh/usr/local/tomcat/bin/startup.sh//此例中已将主机的IP地址解析为域名了，另外tomcat监听在8081端口。这时可以通过"域名:8081"访问到主页了。 nginx 1234567891011121314151617181920vim /etc/nginx/conf.d/web.conf proxy_cache_path /etc/nginx/cache levels=1:2:2 keys_zone=web_cache:10m max_size=2g; server&#123; server_name web.jdyichong.com; index index.html index.htm; charset utf-8; proxy_cache web_cache; proxy_cache_key $request_uri; proxy_cache_methods GET HEAD; proxy_cache_min_uses 1; proxy_cache_valid 200 302 10m; proxy_cache_valid 400 1m; proxy_cache_use_stale http_502; location / &#123; proxy_pass http://web.jdyichong.com:8081; //这里只要将所有访问都反代到本机的tomcat上即可。 &#125; &#125;//用nginx加入缓存设置，之后反向代理到本机的tomcat上，这样使用域名即可访问到主页了。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO基础知识]]></title>
    <url>%2F2018%2F09%2F12%2FIO%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[概念 同步 等待对方返回消息； 发出调用以后不可进行其他工作。 异步 被调用者通过状态、通知或回调机制通知调用者被调用者。发出调用以后还可以进行其他工作。 阻塞I/O模型 blocking，调用结果返回之前，调用者会被挂起，处于不可中断睡眠状态。在这个状态下，cpu不会给线程分配时间片，即线程暂停运行。属于闲等 对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。 非阻塞I/O模型 nonblocking，调用结果返回之前，调用者不会被挂起；在规定时间内不停询问进程执行结果。在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。属于忙等 区别 阻塞和非阻塞是指当server端的进程访问的数据如果尚未就绪，进程是否需要等待，简单说这相当于函数内部的实现区别，也就是未就绪时是直接返回还是等待就绪 而同步和异步是指client端访问数据的机制，同步一般指主动请求并等待I/O操作完毕的方式，当数据就绪后在读写的时候必须阻塞(区别就绪与读写二个阶段，同步的读写必须阻塞)，异步则指主动请求数据后便可以继续处理其它任务，随后等待I/O，操作完毕的通知，这可以使进程在数据读写时也不阻塞。(等待”通知”) 同步IO和异步IO的区别：数据访问的时候进程是否阻塞 阻塞IO和非阻塞IO的区别：应用程序的调用是否立即返回 同步/异步与阻塞/非阻塞经常看到是成对出现： 同步阻塞，异步非阻塞，同步非阻塞 一次文件IO请求，都会由两阶段组成：第一步：等待数据，即数据从磁盘到内核内存；第二步：复制数据，即数据从内核内存到进程内存； node.js 线程在执行中如果遇到磁盘读写或网络通信（统称为I/O 操作），通常要耗费较长的时间，这时操作系统会剥夺这个线程的CPU 控制权，使其暂停执行，同时将资源让给其他的工作线程，这种线程调度方式称为 阻塞。当I/O 操作完毕时，操作系统将这个线程的阻塞状态解除，恢复其对CPU的控制权，令其继续执行。这种I/O 模式就是通常的同步式I/O（Synchronous I/O）或阻塞式I/O （Blocking I/O）。 相应地，异步式I/O （Asynchronous I/O）或非阻塞式I/O （Non-blocking I/O）则针对所有I/O 操作不采用阻塞的策略。当线程遇到I/O 操作时，不会以阻塞的方式等待I/O 操作的完成或数据的返回，而只是将I/O 请求发送给操作系统，继续执行下一条语句。当操作系统完成I/O 操作时，以事件的形式通知执行I/O 操作的线程，线程会在特定时候处理这个事件。为了处理异步I/O，线程必须有事件循环，不断地检查有没有未处理的事件，依次予以处理。阻塞模式下，一个线程只能处理一项任务，要想提高吞吐量必须通过多线程。而非阻塞模式下，一个线程永远在执行计算操作，这个线程所使用的CPU 核心利用率永远是100%&gt;，I/O 以事件的方式通知。在阻塞模式下，多线程往往能提高系统吞吐量，因为一个线程阻塞时还有其他线程在工作，多线程可以让CPU 资源不被阻塞中的线程浪费。而在非阻塞模式下，线程不会被I/O 阻塞，永远在利用CPU。多线程带来的好处仅仅是在多核CPU 的情况下利用更多的核，而Node.js的单线程也能带来同样的好处。这就是为什么Node.js 使用了单线程、非阻塞的事件编程模式。 I/O复用模型 主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。 信号驱动I/O模型 两次调用，两次返回 首先我们允许套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 异步I/O 数据拷贝的时候进程无需阻塞。 当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作 select() &amp; poll() &amp; epoll() epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现 select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是： 单个进程可监视的fd数量被限制，即能监听端口的大小有限。 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048. 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低： 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll(Linux)与kqueue(BSD)做的。 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大 poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点： 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 epoll epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 epoll的优点： 1. 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）； 2. 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3. 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 select、poll、epoll 区别总结： 支持一个进程所能打开的最大连接数 select单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对其进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 epoll虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 FD剧增后带来的IO效率问题 select因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 poll同上 epoll因为内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 消息传递方式 select内核需要将消息传递到用户空间，都需要内核拷贝动作 poll同上 epoll通过内核和用户空间共享一块内存来实现的。 总结总结 综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python标识符与操作符及基础知识]]></title>
    <url>%2F2018%2F09%2F05%2FPython%E6%A0%87%E8%AF%86%E7%AC%A6%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%AC%A6%E5%8F%8A%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[概念编程基础 计算机语言 人与计算机之间交互的语言 机器语言 一定位数组成二进制的0和1的序列，称为机器指令。机器指令的集合就是机器语言 与自然语言差异太大，难学、难懂、难写、难记、难查错 汇编语言 用一些助记符号替代机器指令，称为汇编语言。ADD A,B指的是将寄存器A的数与寄存器B的数相加得到的数放到寄存器A中 汇编语言写好的程序需要汇编程序转换成机器指令 汇编语言只是稍微好记了些，可以认为就是机器指令对应的助记符。只是符号本身接近自然语言 语言分类 低级语言 面向机器的语言，包括机器语言、汇编语言 不同的机器不能通用，不同的机器需要不同的机器指令或者汇编程序 高级语言 接近自然语言和数学语言的计算机语言 高级语言首先要书写源程序，通过编译程序把源程序转换成机器指令的程序 1954年正式发布的Fortran语言是最早的高级语言，本意是公式翻译 人们只需要关心怎么书写源程序，针对不同机器的编译的事 交给编译器关心处理 低级语言到高级语言 语言越高级，越接近人类的自然语言和数学语言 语言越低级，越能让机器理解 高级语言和低级语言之间需要一个转换的工具：编译器、解释器 C、C++等语言的源代码需要本地编译 Java、Python、C#的源代码需要被解释器编译成中间代码(Bytecode)，在虚拟机上运行 编译语言，把源代码转换成目标机器的CPU指令 解释语言，解释后转换成字节码，运行在虚拟机上，解释器执行中间代码 高级语言的发展 非结构化语言 编号或标签、GOTO、子程序可以有多个入口和出口 有分支、循环 结构化语言 任何基本结构只允许是唯一入口和唯一出口 顺序、分支、循环，废弃GOTO 面向对象语言 更加接近人类认知世界的方式，万事万物抽象成对象，对象间关系抽象成类和继承 封装、继承、多态 函数式语言 古老的编程范式，应用在数学计算、并行处理的场景。引入到了很多现代高级语言中 函数是”一等公民”，高阶函数 程序Program 程序 算法 + 数据结构 = 程序 数据是一切程序的核心 数据结构是数据在计算机中的类型和组织方式 算法是处理数据的方式，算法有优劣之分 写程序难点 理不清数据 搞不清处理方法 无法把数据设计转换成数据结构，无法把处理方法转换成算法 无法用设计范式来进行程序设计 世间程序皆有bug，但不会debug Python解释器 官方CPython C语言开发，最广泛的Python解释器 IPython 一个交互式、功能增强的CPython PyPy Python语言写的Python解释器，JIT技术，动态编译Python代码。JIT指动态编译，实时编译，动态优化。 Jython Python的源代码编译成Java的字节码，跑在JVM上 IronPython 与Jython类似，运行在.Net平台上的解释器，Python代码被编译成.Net的字节码 Python的语言类型python是动态语言、强类型语言 静态编译语言 事先声明变量类型，类型不能再改变 编译时检查 动态编译语言 不用事先声明类型，随时可以赋值为其他类型 编程时不知道是什么类型，很难推断 动态编译语言需要先编译成自解码，再给本地CPU执行代码 强类型语言 不同类型之间操作，必须先强制类型转换为同一类型。print(‘a’+1)是不能执行的 弱类型语言 不同类型间可以操作，自动隐式转换，JavaScript中console.log(1+’a’)可以执行 基础语法 注释：python中单行注释采用 # 开头。 python 中多行注释使用三个单引号(‘’’)或三个双引号(“””)。 数字 整数，不区分long和int。 进制有二进制，八进制，十六进制，如：0xa、0o10、0b10。bool布尔值有两个True、False 浮点数 1.2、3.1415、-0.12、1.46e9等价于1.46*10的9次方 复数 1+2j 字符串 使用 ‘ “ 单双引号引用的字符的序列 ‘’’和”””单双三引号，可以跨行、可以在其中自由的使用单双引号 在字符串前面加上r或者R前缀，表示该字符串不做特殊的处理 字符串或串(String)是由数字、字母、下划线组成的一串字符。 转义序列 \\ \t \r \n \‘ \“ 前缀r，把里面的所有字符当普通字符对待 缩进 未使用C等语言的花括号，而是采用缩进的方式表示层次关系 约定使用4个空格缩进 续行 在行尾使用 \ 如果使用各种括号，认为括号内是一个整体，内部跨行不用 \ 标识符 一个名字，用来指化一个值 只能用字母、下划线和数字 只能以字母或下划线开头 不能是python的关键字，例如def、class就不能作为标识符 Python是大小写敏感的 约定：不允许使用中文；不允许使用歧义单词，例如class_；在python中不要随便使用下划线开头的表示符 常量 一旦赋值就不能改变值的标识符 python中无法定义常量 字面常量 一个单独的量，例如12、”abc”、’242356613.03e-9’ 变量 赋值后，可以改变值的标识符 运算符算术运算符以下假设变量： a=10，b=20： 运算符 描述 实例 + 加 - 两个对象相加 a + b 输出结果 30 - 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -10 * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 200 / 除 - x除以y b / a 输出结果 2 % 取模 - 返回除法的余数 b % a 输出结果 0 ** 幂 - 返回x的y次幂 a**b 为10的20次方， 输出结果 100000000000000000000 // 取整除 - 返回商的整数部分（向下取整） 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 位(bit)运算符按位运算符是把数字看作二进制来进行计算的。Python中的按位运算法则如下： 下表中变量 a 为 60，b 为 13，二进制格式如下： 12345678910111213a = 0011 1100b = 0000 1101-----------------a&amp;b = 0000 1100a|b = 0011 1101a^b = 0011 0001~a = 1100 0011 运算符 描述 实例 &amp; 按位与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100 \ 按位或运算符：只要对应的二个二进位有一个为1时，结果位就为1。 (a \ b) 输出结果 61 ，二进制解释： 0011 1101 ^ 按位异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001 ~ 按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011，在一个有符号二进制数的补码形式。 &lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数字指定了移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000 &gt;&gt; 右移动运算符：把”&gt;&gt;”左边的运算数的各二进位全部右移若干位，&gt;&gt; 右边的数字指定了移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111 原码、反码、补码，负数表示法 原码：正数是其二进制本身；负数是符号位为1,数值部分取X绝对值的二进制。 反码：正数的反码和原码相同；负数是符号位为1,其它位是原码取反。 补码：正数的补码和原码，反码相同；负数是符号位为1，其它位是原码取反，未位加1。（或者说负数的补码是其绝对值反码未位加1） 移码：将符号位取反的补码（不区分正负） 编码 10810（sbyte） -10810（sbyte） 原码 01101100 11101100 反码 01101100 10010011 补码 01101100 10010100 移码 11101100 00010100 注：这里的原码、反码、补码表示计算机在存储数据时形式。 比较运算符以下假设变量a为10，变量b为20： 运算符 描述 实例 == 等于 - 比较对象是否相等 (a == b) 返回 False。 != 不等于 - 比较两个对象是否不相等 (a != b) 返回 true. &lt;&gt; 不等于 - 比较两个对象是否不相等 (a &lt;&gt; b) 返回 true。这个运算符类似 != 。 &gt; 大于 - 返回x是否大于y (a &gt; b) 返回 False。 &lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。 (a &lt; b) 返回 true。 &gt;= 大于等于 - 返回x是否大于等于y。 (a &gt;= b) 返回 False。 &lt;= 小于等于 - 返回x是否小于等于y。 (a &lt;= b) 返回 true。 逻辑运算符Python语言支持逻辑运算符，以下假设变量 a 为 10, b为 20: 运算符 逻辑表达式 描述 实例 and x and y 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔”或” - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 赋值运算符以下假设变量a为10，变量b为20： 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c = a 等效于 c = c a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c = a 等效于 c = c a //= 取整除赋值运算符 c //= a 等效于 c = c // a 成员运算符除了以上的一些运算符之外，Python还支持成员运算符，测试实例中包含了一系列的成员，包括字符串，列表或元组。 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 身份运算符身份运算符用于比较两个对象的存储单元 运算符 描述 实例 is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 False is not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。 注： id() 函数用于获取对象内存地址。 is 与 == 区别： is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等。 1234567891011&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; b is a True&gt;&gt;&gt; b == aTrue&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; b is aFalse&gt;&gt;&gt; b == aTrue 运算符的优先级 算术运算符 &gt; 位运算符 &gt; 身份运算符 &gt; 成员运算符 &gt; 逻辑运算符 记不住，用括号 长表达式，多用括号，易懂、易读 以下表格列出了从最高到最低优先级的所有运算符： 运算符 描述 ** 指数 (最高优先级) ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算符 &amp; 位 ‘AND’ ^\ 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += *= **= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not and or 逻辑运算符 Python保留字符下面的列表显示了在Python中的保留字。这些保留字不能用作常数或变数，或任何其他标识符名称。 所有Python的关键字只包含小写字母。 and exec not assert finally or break for pass class from print continue global raise def if return del import try elif in while else is with except lambda yield 表达式 由数字、符号、括号、变量等的组合 算术表达式 逻辑表达式 赋值表达式 python中，赋值即定义，如果一个变量已经定义，赋值相当于重新定义 练习 计算~12 这是对12取反，首先，12保存到计算机中时要转为二进制，也就是0000 1100，按题目要求对12取反后，得到1111 0011，取反后的数是计算机使用的，如果要给人看还要将此数转换为十进制数，又因为取反后的最高位是1，表示这是一个负数，负数保存到计算机中时使用的是取反的二进制数或说是二进制数的补数，在计算机中保存的是数字的补数，所以转换为十进制时也要取这个二进制数的补数。这里取1111 0011的补数是1000 1101，也就是-13了。 123456789101112131415# -1的补码如下1000 0001 # 原码1111 1110 + 1 = 1111 1111 # 负数的补码是最高位不变，其余位取反，最后再加1，所以是1111 1111，内存中是0xff0000 0101 # 这是5，和上面的1111 1111相与得到下面0000 0100 # 这里用原码的5与补码的1计算，用二进制的5最后的1先与正面的1111 1111相加，得到1 0000 0000，最前面的1溢出了，所以抛弃，得到0000 0000。之后就变成了二进制的0000 0100 + 0000 0000，也就是4了。# 12取反如下0000 1100 # 这是121111 0011 # 这是取反，这是计算机存储的值，也是给计算机看的，如果要给人看，还要将其转为原码。因为计算机中要存补码，所以这个数在计算机看来就是补码，要转为原码才是给人看的，补码的补码就是原码，所以要求这个数的补码。1000 1101 # 这是上面数字的补码，转为原码时最高位不变，之后按位取反再加1。所以12取反是-13# 正数的补码还是正数本身，所以不会变。负数的补码要转换为原码时，要按上面的方法求补码的补码# 1. 计算机中存储的只会是补码# 2. 正数的补码还是正数本身，负数的补码最高位不变，其余位按位取反再加1# 3. 计算机中存储的负数要显示出来时，要按负数的补码求一次才是要显示的内容 附录为何要使用原码, 反码和补码在开始深入学习前，我的学习建议是先”死记硬背”上面的原码，反码和补码的表示方式以及计算方法。现在我们知道了计算机可以有三种编码方式表示一个数。对于正数因为三种编码方式的结果都相同： [+1] = [00000001]原 = [00000001]反 = [00000001]补 所以不需要过多解释. 但是对于负数: [-1] = [10000001]原= [11111110]反= [11111111]补 可见原码，反码和补码是完全不同的。既然原码才是被人脑直接识别并用于计算表示方式，为何还会有反码和补码呢？ 首先，因为人脑可以知道第一位是符号位，在计算的时候我们会根据符号位，选择对真值区域的加减。（补码的绝对值称为真值即去掉符号位的二进制数字）。但是对于计算机，加减乘除已经是最基础的运算，要设计的尽量简单。计算机辨别“符号位”显然会让计算机的基础电路设计变得十分复杂！于是人们想出了将符号位也参与运算的方法。我们知道，根据运算法则减去一个正数等于加上一个负数，即：1-1 = 1 + (-1) = 0 ，所以机器可以只有加法而没有减法，这样计算机运算的设计就更简单了。 于是人们开始探索将符号位参与运算，并且只保留加法的方法。首先来看原码： 计算十进制的表达式：1-1=0 1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原= [10000010]原 = -2 如果用原码表示，让符号位也参与计算，显然对于减法来说，结果是不正确的。这也就是为何计算机内部不使用原码表示一个数。 为了解决原码做减法的问题，出现了反码： 计算十进制的表达式：1-1=0 1 - 1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原= [0000 0001]反+ [1111 1110]反= [1111 1111]反= [1000 0000]原= -0 发现用反码计算减法，结果的真值部分是正确的。而唯一的问题其实就出现在”0”这个特殊的数值上。虽然人们理解上+0和-0是一样的，但是0带符号是没有任何意义的。而且会有[0000 0000]原和[1000 0000]原两个编码表示0。 于是补码的出现，解决了0的符号以及两个编码的问题： 1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补+ [1111 1111]补= [0000 0000]补=[0000 0000]原 这样0用[0000 0000]表示，而以前出现问题的-0则不存在了。而且可以用[1000 0000]表示-128： (-1) + (-127) = [1000 0001]原 + [1111 1111]原 = [1111 1111]补+ [1000 0001]补= [1000 0000]补 -1-127的结果应该是-128，在用补码运算的结果中，[1000 0000]补就是-128。但是注意因为实际上是使用以前的-0的补码来表示-128，所以-128并没有原码和反码表示。（对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原，这是不正确的） 使用补码，不仅仅修复了0的符号以及存在两个编码的问题，而且还能够多表示一个最低数。这就是为什么8位二进制，使用原码或反码表示的范围为[-127, +127]，而使用补码表示的范围为[-128, 127]。 因为机器使用补码，所以对于编程中常用到的32位int类型，可以表示范围是：[-231, 231-1] 因为第一位表示的是符号位。而使用补码表示时又可以多保存一个最小值。 比特和字节Bit，比特，也叫二进制位，是信息的最小单位。一个比特可以理解为一个开关量，0就是关，1就是开。Byte，字节，由8个Bit组成。它通常用作计算机信息计量单位。字节在一些规范中称作Octet。Bit简写为b，Byte简写为B。 字节的进制字节一般以1024(2^10)为进制，目前常用的进制如下。 123456789101112131byte=8bit //bit就是位，也叫比特位，是计算机表示数据最小的单位1B(byte字节) //byte就是字节1KB(Kilobyte千) = 2^10 B = 1024 B1MB(Megabyte兆) = 2^10 KB = 1024 KB = 2^20 B1GB(Gigabyte吉) = 2^10 MB = 1024 MB = 2^30 B1TB(Trillionbyte太) = 2^10 GB = 1024 GB = 2^40 B1PB(Petabyte拍) = 2^10 TB = 1024 TB = 2^50 B1EB(Exabyte艾) = 2^10 PB = 1024 PB = 2^60 B1ZB(Zettabyte泽) = 2^10 EB = 1024 EB = 2^70 B1YB(YottaByte尧) = 2^10 ZB = 1024 ZB = 2^80 B1BB(Brontobyte) = 2^10 YB = 1024 YB = 2^90 B1NB(NonaByte) = 2^10 BB = 1024 BB = 2^100 B1DB(DoggaByte) = 2^10 NB = 1024 NB = 2^110 B 容易混淆的情景情景1 看各种协议时，要看清楚是比特还是字节例：以太帧格式与IPv4包格式。 以太帧格式直接用字节(octet)进行展示，而IP包则采用比特表进行展示。实际读文档的过程中，一定要看仔细是比特还是字节。 情况2 硬盘容量涉及到硬盘、文件等存储类的信息，都以字节为单位。例：买了2T的硬盘，为毛放到计算机上少了那么多？因为硬盘的进制是1000，2TB的硬盘，实际是2000GB，以此类推。计算机统计的进制是采用1024。所以，2TB实际容量是2*1000^4/1024^4，约为1.189T(1862G，这一换算直接少了140G啊)。 情况3 网络带宽网络带宽统计的是比特，所以也叫比特率，单位表示一般用Mbps，Gbps。其进制也不是1024，而是1000。即1Kbps=1000bps 1Mbps=1000Kbps 1Gbps=1000Mbps，以此类推。例：家里面宽带是4兆的，最高的下载速度能达到多少？答：因为网络带宽统计的是比特，而下载统计的是字节，所以换算时有8的除法。即4Mbps/8=0.5MBps=500KBps。所以下载速度最高不超过500K。从最早的下载软件网络蚂蚁(NetAnt)，到后来的FlashGet，迅雷等，都采用的Bps为下载单位，因为下载的是文件，使用存储单位。 有时候，为了不引起歧义，将1024进制用特殊方式单独表示，称为Mebibyte或Megabyte。 12341KiB = 1024 Byte1MiB = 1024 KiB = 1024^2 Byte1GiB = 1024 MiB = 1048576 (1024^2)KiB1TiB = 1024 GiB = 1073741824 (1024^3)KiB 总结 比特和字节，1000进制还是1024进制较为容易混淆。 在计算机科学领域采用1024进制，在信息技术领域，采用1000进制。 1024进制在单位上加字母i进行单独表示。 参考：https://www.jianshu.com/p/abbdae4f3841 参考：https://higoge.github.io/2015/06/23/basic01/]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python安装]]></title>
    <url>%2F2018%2F09%2F05%2FPython%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[linux建议使用3.5以上版本。开发环境使用pyenv，可以管理python解释器、管理python版本、管理python的虚拟环境。可以使多版本共存。pyenv是一个虚拟环境。也有其他的环境可以实现。 pyenv 是 Python 版本管理工具。 pyenv 可以改变全局的 Python 版本，安装多个版本的 Python， 设置目录级别的 Python 版本，还能创建和管理 virtual python environments 。所有的设置都是用户级别的操作，不需要 sudo 命令。 pyenv 主要用来管理 Python 的版本，比如一个项目需要 Python 2.x ，一个项目需要 Python 3.x 。 而 virtualenv 主要用来管理 Python 包的依赖，不同项目需要依赖的包版本不同，则需要使用虚拟环境。 pyenv 通过系统修改环境变量来实现 Python 不同版本的切换。而 virtualenv 通过将 Python 包安装到一个目录来作为 Python 包虚拟环境，通过切换目录来实现不同包环境间的切换。 pyenv 的美好之处在于，它并没有使用将不同的PATH植入不同的shell这种高耦合的工作方式，而是简单地在PATH 的最前面插入了一个垫片路径（shims）：~/.pyenv/shims:/usr/local/bin:/usr/bin:/bin。所有对 Python 可执行文件的查找都会首先被这个 shims 路径截获，从而使后方的系统路径失效。 测试安装使用CentOS6.5-64 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111yum install gitvim /etc/yum.repos.d/python.repo [updates] name=CentOS-Updates baseurl=https://mirrors.aliyun.com/centos/6.9/os/x86_64 gpgcheck=0# 加入yum源yum repolistyum update nss# 更新此包，如果不更新此包，在安装pyenv时可能会报错，提示“curl:(35) SSL connect error”yum install gcc make patch gdbm-devel openssl-devel sqlite-devel readline-devel zlib-devel bzip2-devel# 这是pyenv在安装python时要用到的包，pyenv是就地编译的，在编译时要用到这些包。# ubuntu19.04需要安装的包:build-essential python-dev python-setuptools python-pip python-smbus libncurses5-dev libgdbm-dev libc6-dev zlib1g-dev libsqlite3-dev tk-dev libssl-dev openssl libffi-devuseradd pythonpasswd pythonsu - python# 要用此用户登录开发# pythonoffline.tar.gz是在线连接的时候出现问题，再解压此包进行配置curl -L https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer | bash# 访问安装pyenv，安装好后会输出三行信息，要加入.bash_profile文件中。使用-L参数，curl就会跳转到新的网址。vim ~/.bash_profile export PATH="/home/python/.pyenv/bin:$PATH" eval "$(pyenv init -)" # 初始化pyenv这个工具，初始化后就可以自动补全了 eval "$(pyenv virtualenv-init -)" # 初始化virtualenv这个插件，因为开发都用虚拟环境# eval会对后面的cmdLine进行两遍扫描，如果在第一遍扫面后cmdLine是一个普通命令，则执行此命令；如果cmdLine中含有变量的间接引用，则保证简介引用的语义。source ~/.bash_profilepython -V# 查看python版本，显示是2.6.6版本。# 注意：不要升级系统本身的python版本，因为有软件依赖，升级会使系统混乱，比如yum可能无法使用。所有工作都应该在pyenv这个多版本工具里进行pyenv# 查看可用到的命令，如install等pyenv install -l# 列出可用的python版本pyenv install 3.5.3 -v# 安装python3.5.3版本，并输出详细信息。但连接非常慢。如果提示"No module named '_ctypes'"，那么需要安装libffi-develcd ~/.pyenvll# 这里是python家目录下的.pyenv目录，里面有上面刚安装过的插件mkdir cache# 在.pyenv目录中创建一个目录，下面准备使用离线安装的方式。cd cache将python-3.5.3.tar.xz、python-3.5.3.tgz两个文件放入cache目录中。这两个文件是在安装过程中可能依赖的包，下载地址：https://www.python.org/ftp/python/3.5.3/cd ..pyenv install 3.5.3 -v# 在cache上一层目录执行安装python -V# 这时显示还是2.6.6版本pyenv version# 查看当前的python版本的位置[python@bogon .pyenv]$ pyenv versions* system (set by /home/python/.pyenv/version) 3.5.3# 查看由pyenv管理的所有python版本，这里有3.5.3版本，但没有*标记* globalpyenv global 3.5.3# 改全局使用的python为3.5.3版本python -V# 查看依然是2.6.6版本pyenv versions# 这时3.5.3前已经有标记了，表示当前使用版本python -V# 查看依然是2.6.6版本pyenv version# 这里显示当前使用版本也是3.5.3再打开一个新的窗口用python用户登录，执行python -V，这时就是3.5.3版本了。如果用root用户这样操作，影响会非常大pyenv global system# 调回2.6.6，再次登录就都调回来了。global会影响当前用户。不建议使用globalpyenv install 3.6.3# 安装一个3.6.3版本# pyenv version是显示当前的python版本；pyenv versions显示所有可用的python版本，和当前版本。pyenv versions* shell只设定当前的会话级别，如果会话变了，版本的调整也就失效了pyenv shell 3.5.3pyenv versionspython -v# 使用shell命令设置后，发现版本都有了变化再打开一个窗口python -V# 这时显示的是2.6.6版本pyenv versions# 这里还是system版本* localmkdir magedu/projects/web# 在python家目录中创建目录cd magedu/projects/webpython -V# 这时显示的是2.6.6版本pyenv local 3.5.3python -V# 这时显示的是3.5.3版本cd ..python -V# 到上一级目录查看版本是2.6.6，也就是版本与目录绑定了，进入特定的目录就会到一个不同的版本中mkdir /home/python/magedu/profects/web/html# 在web中创建html目录cd htmlpython -V# 这里也是3.5.3版本，local的特性是子目录继承的，所以web和html中都会显示3.5.3版本mkdir projects/cmdbcd projects/cmdbpython -V# 这时显示的是2.6.6.版本pyenv local 3.6.3python -V# 显示3.6.3版本# 这里有一个问题，这个版本是大家共用的 虚拟环境123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100cd /home/python/magedu/projects/cmdbpyenv virtualenv 3.5.3 my353# 给3.5.3版本制作一个虚拟版本，叫my353pyenv versions# 这时多了一个my353的版本cd ..mkdir testcd test[python@bogon test]$ pyenv local my353(my353) [python@bogon test]$# 这时提示符有了变化，多了一个(my353)cd ..# 到上一级目录就不会有(my353)cd test# 这时就有了(my353)，使用python -V命令可以看到这里的Python版本是3.5.3了cd# 到家目录cd .pyenvlscd versionsll# 这里有一个my353的软链接cd 3.5.3[python@bogon 3.5.3]$ lsbin envs include lib share# 这里有几个重要的目录，lib目录下有一个python3.5目录，其中有一个site-packages，这个目录有开发中安装的所有的包。如果大家都用3.5.3版本，那么包会全部放到这个目录里cd ../..cd versions/3.5.3/envs# 在3.5.3目录下有一个envs目录，在envs中有my353目录，这是my353的虚拟环境，通过pyenv versions也可以看到这个信息。这个目录中也有一个lib目录，lib目录下有python3.5，再下面也有site-packages目录。如果使用虚拟环境，所有包都会装到这里。cdcd magedu/projects/webpython -V# 是3.5.3版本cd ../test# 进虚拟环境，要安装ipythoncdmkdir .pipcd .piptouch pip.confvim pip.conf [global] index-url=https://mirrors.aliyun.com/pypi/simple/ trusted-host=mirrors.aliyun.com# 这一步主要是为了使用pip的国内镜像# 在使用 pyenv 之后使用 pip 安装的第三方模块会自动安装到当前使用 python 版本下，不会和系# 统模块产生冲突。使用 pip 安装模块之后，如果没有生效，记得使用 pyenv rehash 来更新垫片路径。pip# 提示找不到此命令，因为使用了pyenv管理这个版本，而目前的版本是system，system默认是没有安装pip命令的cdcd magedu/projects/testpip# 现在是3.5.3版本，这里是有pip命令的pip install ipython# 在虚拟环境中用pip安装ipython，只有到虚拟环境中才能使用ipython。pip就是python install packge，也就是安装包的缩写，pip是安装的管理器，与yum相似。ipython是一个与python交互的工具pip install --upgrade pip# 上一步执行完会提示要先升级pip，之后才能安装ipythonipython# 提示没有ipython命令，再登录一下就可以使用了# ubuntu19.04安装时还是会有提示"No module named '_ctypes'"，那么需要安装下列包# sudo apt install build-essential python-dev python-setuptools python-pip python-smbus libncurses5-dev libgdbm-dev libc6-dev zlib1g-dev libsqlite3-dev tk-dev libssl-dev openssl libffi-dev# 这里有一个问题，就是上面这些包要在安装python版本包之前安装，不然就要用pyenv uninstall 3.8.0先卸载安装的版本，再重新安装了。实际是重新编译安装python版本包，不然还会报错pip install jupyter# 这是一个可视化界面cdcd .pyenv/versions/3.5.3/envscd my353/lib/python3.5/site-packages/ll# 包都装在了这里cd .pyenv/versions/3.5.3/lib/python3.5/site-packages/# 这里没有什么东西cdcd magedu/projects/testjupyter notebook --helpjupyter notebook password# 设置密码，如果不设置，会要求输入一长串东西才能使用jupyter notebook# 启动，但因为没有图形接口，所以会有不能运行的提示ss -tln# 这时会监听127.0.0.1:8888端口，但不能使用jupyter notebook --ip=0.0.0.0 --no-browser# 这样启动可以监听所有地址，从外部就可以访问了。--no-browser表示不启动浏览器浏览器访问IP:8888，密码是上面设置的。如果没有设置密码，要输入启动时出现的一长串字符cd magedu/projects/test# 进入相应版本的目录，不然不能使用pippip list# 查看管理的包pip helppip freeze &gt; requirement# 把当前环境中的pip所安装的文件列表以及版本号全部导入reguiremeot， reguiremeot是自定义的名字cat requiremeot# 这就是导出包的过程cd ../webpython -V# 3.5.3版本pip list# 现在包很少pip install -r ../test/requiremeot# 这样可以保证两个环境安装的包是一样的。另外将一个环境中的site-packages中的包复制到另一个环境的相同目录下也可以实现这个效果pip listwindows安装python是要选择"Add Python 3.6 to PATH" 离线安装12345678910git clone https://github.com/pyenv/pyenv.git ~/.pyenvgit clone https://github.com/pyenv/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenvgit clone https://github.com/pyenv/pyenv-update.git ~/.pyenv/plugins/pyenv-updategit clone https://github.com/pyenv/pyenv-which-ext.git ~/.pyenv/plugins/pyenv-which-ext//可以把克隆的目录打包，方便以后离线使用vim ~/.bash_profileexport PATH="/home/python/.pyenv/bin:$PATH"eval "$(pyenv init -)" //初始化pyenv这个工具eval "$(pyenv virtualenv-init -)" //初始化virtualenv这个插件，因为开发都用虚拟环境source ~/.bash_profile windows]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AnsibleTest]]></title>
    <url>%2F2018%2F07%2F16%2FAnsibleTest%2F</url>
    <content type="text"><![CDATA[安装 准备三台主机，主机名与地址分别为：test1:10.5.5.158、test2:10.5.5.159、test3:10.5.5.160 1234567891011121314yum install -y epel-releaseyum install -y ansiblessh-keygen -t rsa -P ''# 生成私钥ssh-copy-id -i ~/.ssh/id_rsa.pub root@10.5.5.159ssh-copy-id -i ~/.ssh/id_rsa.pub root@10.5.5.160# 将公钥传到另外两台主机，这样可以保证使用密钥连接远程主机vim /etc/ansible/hosts [websrvs] 10.5.5.159 10.5.5.160 [localhost] 10.5.5.158# 设置主机分组 ansible配置123456789101112131415161718192021222324252627vim /etc/ansible/hosts [websrvs] www[1:7].ruopu.com# 这样会列出www1.ruopu.com到www7.ruopu.comvim /etc/ansible/hosts [websrvs] 192.168.1.100 ansible_ssh_port=22 ansible_ssh_user=ruopu ansible_ssh_pass=centos# 定义连接目标主机时用的端口，用户名和密码vim /etc/ansible/hosts [websrvs] 192.168.1.100 ansible_ssh_port=22 ansible_ssh_user=ruopu ansible_ssh_pass=centos# 将websrvs中的10.5.5.159改为上面的样子，表示连接目标主机时用的端口，用户名和密码vim /etc/ansible/hosts [websrvs] 172.16.0.67 http_port=8080 172/16.0.68 http_port=8080 [websrvs:vars] http_port=8080# 这是定义组变量，因为上面的http_port的值是一样的，都是8080，所以可以定义这样的组，用中括号括起上面的组名+:vars，下面写上值，这时上面就不用再写http_port=8080了[root@test playbooks]# vim /etc/ansible/ansible.cfgdeprecation_warnings = False# 禁用警告通知 ansible命令模块1234语法：ansible &lt;host-pattern&gt; [-f forks][-m module_name] [-a args] ansible 主机组 -m 模块 -a "值" ping模块12ansible all -m ping -C# 测试是否可以连接到所有主机。ansible &lt;host-pattern&gt; [options];&lt;host-pattern&gt;表示指明要操作的一组主机，options指要执行的任务。-m指定模块，-a向模块发送指令，-f指定几台主机，-C干跳一次，不真正执行；--list-hosts表示查看可以匹配到多少台主机，但命令不会执行 查看组内主机12ansible websrvs --list-hosts # 使用--list-hosts选项，websrvs是组名 group模块，添加、删除组12345678910group模块，gid=group id，name=group name，state=present(创建)/ansent(删除)，system=0(非系统组)/1(系统组)ansible all -m group -a "gid=3000 name=mygrp state=present system=0"# 在目标主机上创建组，组ID是3000，组名是mygrp，present表示创建，如果是absent表示删除，system表示是否为系统组，这里是0表示不是，默认也是0。显示结果中的changed项变为了true，表示变更了tail -1 /etc/group# 到目标主机查看是否添加了组ansible all -m group -a "gid=3000 name=mygrp state=absent"# 删除刚创建的组tail -1 /etc/group# 到目标主机查看是否删除了组 user模块，添加、删除用户1234user模块，uid=用户id，name=用户名，state=创建present/删除absent，groups=附加组，shell=SHELL ansible all -m user -a "uid=5000 name=testuser state=present groups=mygrp shell=/bin/bash"# 创建用户，groups表示附加组，shell表示默认shell copy模块123456789101. 复制文件，src=源目录，dest=目标文件，owner=复制过去的文件属主，group=复制过去的文件属组ansible all -m copy -a "src=/etc/fstab dest=/tmp/fstab.ansible mode=600"# 將本機/etc/fstab文件複製到所有主機的tmp目錄下叫fstab.ansible2. 复制内容，content='内容'，dest=目标文件，owner=复制过去的文件属主，group=复制过去的文件属组 ansible all -m copy -a "content='hi there\n' dest=/tmp/hi.txt owner=testuser group=mygrp"# 将内容hi there写入/tmp目录下的hi.txt文件中，dest指定的文件可以是已經存在的文件3. 复制目录或文件，src=/源目录/，dest=目录路径。如果源目录没有后面的斜线，就复制整个目录过去，如果有斜线，就复制目录下的文件过去 ansible all -m copy -a "src=/etc/pam.d/ dest=/tmp/" fetch模块1234这个模块是从远程主机将内容复制到本地，要先指明远程主机，可以是组或全部主机或单一主机IP，src=远程主机的目录（如果是多台主机，远程主机上要有相同的目录及文件），dest=本地路径。复制后，本地将以IP地址命名远程主机复制过来的内容 ansible all -m fetch -a "src=/tmp/other dest=./"# 因为共有三台主机，所以当前目录下会有三个以IP命名的目录 command模块1234567891. 因为在/etc/ansible/ansible.cfg配置文件中module_name = command指定了默认模块使用command，所以如果是command模块，可以不用-m指定。 ansible all -m command -a "ifconfig"# 在所有主机上执行ifconfig命令2. chdir=到哪个目录执行，mkdir COMMAND。-m command省略了，不建议这样使用。ansible all -a "chdir=/var/tmp mkdir hi.dir"# 到远程主机的/var/tmp目录下创建一个叫hi.dir的目录 shell模块1234用此模块执行shell命令，与command模块类似，但更强大。如果用ansible all -m command -a "echo 123456 | passwd --stdin testuser"命令，是不能将123456这个密码传递给testuser，而会将echo后的全部内容当密码传递给testuser ansible all -m shell -a "echo 123456 | passwd --stdin testuser"# 在所有主机上执行，设置testuser用户密码为123456 file模块1234创建符号链接；src=目标主机的文件，path=目标主机路径，state=link(符号链接模式) ansible all -m file -a "src=/tmp/fstab.ansible path=/var/tmp/fstab.link state=link"# 这里主机应该靠state=link来定义是符号链接 cron模块123创建定时任务；minute=分钟，job＝'任务'，name＝任务名。有任务名方便删除 ansible all -m cron -a "minute=*/3 job='/usr/sbin/ntpdate 192.168.1.64 &amp;&gt; /dev/null' name=None" yum模块1234在目标主机安装软件；name=软件包名，state=installed安装 ansible all -m yum -a "name=nginx state=installed"# 在所有主机上安装nginx service模块123启动、重启、关闭服务；name=程序名，state=started启动、stopped停止、restarted重启、reloaded重新装载 ansible all -m service -a "name=nginx state=started" script模块123远程执行脚本，-a选项后直接指定路径。这只是在远程执行脚本，但脚本不会复制到远程主机 ansible all -m script -a "/tmp/test.sh" setup模块1234获取远程主机上的变量，这会列出远程主机上的所有模块 ansible 192.168.1.100 -m setup# 命令会输出主机的很多属性信息，如内存信息，IP地址等 playbook剧本功能 playbook即剧本，让目标主机按照既定的剧本执行任务。playbook实为目录，在目录中创建相应的子目录，这些子目录就是一个个的角色。剧本中都用YAML格式文件，它是可读性高，用来表达数据序列的格式 playbook的核心元素： Hosts：主机tasks: 任务列表variables: 变量templates: 包含了模板语法的文本文件handlers: 由特定条件触发的任务roles: 角色 playbook的基本组件 Hosts：运行指定任务的目标主机 remoute_user：在远程主机上执行任务的用户 sudo_user tasks：任务列表 模块，模块参数 格式 action module 格式 12345678910&gt; - hosts: all&gt; remote_user: root&gt; # 文件开始都要设置在哪些主机上执行，远程执行者的身份这两行。另外，要以横线空格引导，后面是名字和冒号、空格，这是基本的语法&gt; &gt; tasks&gt; - name&gt; copy: &gt; handlers&gt; # 上面两项是任务和特定条件触发任务。在它们的下面可以用横线空格名字冒号空格来定义一些要执行的内容。注意横线后都是name，说明其下面的内容是做什么的，另外横线与其上面的字母，如与tasks要对齐。横线下面的的字母与name的每一个字母对齐。&gt; 创建剧本12345678910111213141516171819202122232425262728mkdir /root/playbookscd playbooksvim first.yaml - hosts: all# 定义哪台主机执行 remote_user: root# 以谁的身份执行 tasks:# 打算执行的任务。也就是-m选项指定的模块和-a选项指定的任务 - name: install redis# 执行的任务的名字，自取。这是一个描述信息 yum: name=redis state=latest# 安装redis，state=latest最新，latest与present相似，都是安装包的 - name: copy config file copy: src=/root/playbooks/redis.conf dest=/etc/redis.conf owner=redis# 复制配置文件到远程主机的etc目录下 - name: start redis service: name=redis state=started enabled=true# 启动redis，并开机启动复制一个redis.conf配置文件到playbooks目录下ansible-playbook --syntax-check first.yaml# 检查first.yaml文件的语法是否有问题ansible-playbook --list-hosts --list-tasks first.yaml# --list-hosts表示可以在哪些主机上执行，--list-tasks表示都执行哪些任务。ansible-playbook -C first.yaml# 测试执行。按任务分别在每台主机上执行。-C选项是在目标主机上跑一次，但不真正执行ansible-playbook first.yaml# 这是在目标主机真正执行，redis需要使用epel库 条件触发脚本任务123456789101112131415161718192021222324252627282930313233343536373839404142notify: restart redis表示当有变化时通知给name是restart redis的项，这个项是用handlers引导的。notify写在哪里，就是在哪里有变化时通知，如下面就是用notify监控着copy项，如果copy的配置文件有变化就通知给handlers，handlers也就是由特定条件触发的任务vim first.yaml - hosts: all remote_user: root tasks: - name: install redis yum: name=redis state=latest - name: copy config file copy: src=/root/playbooks/redis.conf dest=/etc/redis.conf owner=redis notify: restart redis - name: start redis service: name=redis state=started enabled=true handlers: - name: restart redis service: name=redis state=restartedvim /root/playbooks/redis.conf# 加入一些内容ansible-playbook first.yaml# 执行此命令时，因为配置文件有了变化，所以handlers会收到notify发的通知，并重启redis服务tags标签，定义tags: configfile后可以在ansible-playbook使用中用-t选项指定标签，从而只执行这个有标签的任务。vim first.yaml - hosts: all remote_user: root tasks: - name: install redis yum: name=redis state=latest - name: copy config file copy: src=/root/playbooks/redis.conf dest=/etc/redis.conf owner=redis notify: restart redis tags: configfile - name: start redis service: name=redis state=started enabled=true handlers: - name: restart redis service: name=redis state=restartedvim redis.conf# 再修改一下这个配置文件ansible-playbook -t configfile first.yaml# 用-t选项指定标签名，表示只执行这个有标签的任务。也就是执行copy config file段，因为配置文件有了变化，所以notify会触发下面的handlers重启redis服务。如果没有notify，那么就只会执行copy项。 定义变量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253541. 使用现有变量ansible 10.5.5.159 -m setup# 获取159主机上的变量，setup是变量。下面准备用ansible_env变量vim second.yaml- hosts: 10.5.5.159 remote_user: root tasks: - name: copy file copy: content=&#123;&#123; ansible_env &#125;&#125; dest=/tmp/ansible.env# 调用159主机的ansible_env的值，保存在/tmp/ansible.envansible-playbook second.yaml# 这样ansible_env的变量内容就会写入远程主机的/tmp/ansible.env文件中了2. 自定义变量vim fore.yaml- hosts: all remote_user: root tasks: - name: install package &#123;&#123; pkgname &#125;&#125; yum: name=&#123;&#123; pkgname &#125;&#125; state=latest# yum的y要与name的n对齐，不然也会报语法错误。pkgname是自定义的变量ansible-playbook -e pkgname=memcache fore.yaml# 自定义变量，用-e调用，也就是pkgname，给它一个值，是软件包的名字，这样就能实现安装软件包了3. 三种定义变量的方法vim /etc/ansible/hosts [websrvs] 172.16.0.67 http_port=8080 172/16.0.68 http_port=8080 [websrvs:vars] http_port=8080# 这是定义组变量，因为上面的http_port的值是一样的，都是8080，所以可以定义这样的组，用中括号括起上面的组名+:vars，下面写上值，这时上面就不用再写http_port=8080了vim vars.yaml - hosts: websrvs remote_user: root vars: - pbvar: playbook variable testing# 在这里定义变量名是pbvar，值是playbook variable testing。这是给下面定义的pbvar变量用的 tasks: - name: command line variables copy: content=&#123;&#123; cmdvar &#125;&#125; dest=/tmp/cmd.var# 定义一个变量叫cmdvar，值保存在/tmp/cmd.var上 - name: playbook variables copy: content=&#123;&#123; pbvar &#125;&#125; dest=/tmp/pb.var - name: host iventory variables copy: content=&#123;&#123; http_port &#125;&#125; dest=/tmp/hi.var# 通过三种方式传递变量，pbvar是在yaml文件中定义；http_port是在文件中定义，就是/etc/ansible/hosts文件；还有cmdvar是在命令行中传递ansible-playbook -e cmdvar="command line variable testing" vars.yaml# 上面命令执行后的问题是，在目标主机上出现的cmdvar文件名只能识别到第一个单词，也就是command，不清楚空格后的内容如何能都显示ansible websrvs -a "ls -l /tmp"ansible websrvs -a "cat /tmp/cmd.var /tmp/hi.var /tmp/pb.var"# 有这三个文件， cmd.var中只有command ### 设置登录远程主机的用户名和密码 1234567891011121314151617vim /etc/ansible/hosts [websrvs] 192.168.1.100 ansible_ssh_port=22 ansible_ssh_user=ruopu ansible_ssh_pass=centos# 将websrvs中的10.5.5.159改为上面的样子，表示连接目标主机时用的端口，用户名和密码vim user.yaml- hosts: all remote_user: root tasks: - name: add user user: name=ruopu system=no state=present - name: set password shell: echo centos | passwd --stdin ruopu# 在远程主机上创建用户，并添加密码ansible-playbook user.yaml# 如果改了ansible的hosts目录，上面的剧本在10.5.5.159上是不能执行的，因为ruopu用户没有创建用户的权限。ansible websrvs -m command -a "whoami"# 查看在远程主机下是用哪个用户登录的，一个显示ruopu，一个显示root jinja2模板语法使用ansible变量123456789101112131415161718192021vim redis.conf.j2 bind &#123;&#123; ansible_eno16777736.ipv4.address &#125;&#125;# 内嵌了一个变量，解析ansible 172.16.0.68 -m setup | grep 查找到的IP地址变量，ansible_eno16777736是查到的变量名称，用点来调用ansible查找到的名称。这里主要是两个花括号中的内容，bind是自定义的名字vim template.yaml - hosts: 192.168.1.100 remote_user: root tasks: - name: install config file template: src=/root/playbooks/redis.conf.j2 dest=/tmp/redis.confansible-playbook template.yaml到目标主机查看less /tmp/redis.conf# 这时这里的bind地址变了vim template.yaml - hosts: all remote_user: root tasks: - name: install config file template: src=/root/playbooks/redis.conf.j2 dest=/tmp/redis.confansible-playbook template.yaml# 在所有主机上执行一次，这时在不同主机上执行的结果是不一样的，因为不同主机的IP地址是不一样的。这就是模板的功能。只有那些定义了变量的内容才会变更 使用hosts中的变量12345678910111213141516171819202122vim /etc/ansible/hosts [websrvs] 10.5.5.160 http_port=8080 10.5.5.159 http_port=10080vim mylisten.conf Listen &#123;&#123; http_port &#125;&#125;# 文件名不用.j2结尾也可以，就是定义一个配置文件，在其中调用ansible的变量vim httpd.yaml - hosts: websrvs remote_user: root tasks: - name: install httpd yum: name=httpd state=latest - name: install config file template: src=/root/playbooks/mylisten.conf dest=/etc/httpd/conf.d/mylisten.conf# template模板是调用上面定义的mylisten.conf文件，并会将此文件复制到远程主机的相应目录下 - name: start httpd service: name=httpd state=startedansible-playbook --syntax-check httpd.yamlansible-playbook httpd.yamlansible websrvs -a "ss -tln"# 这时主机监听了除80的端口，一个8080，一个10080.因为在/etc/ansible/hosts文件中定义了http_port 条件判断1234567891011121314151617181920vim os.yaml - hosts: websrvs remote_user: root tasks: - name: install httpd yum: name=httpd state=latest# 将latest改为absent就是卸载软件包 when: ansible_os_family == "RedHat" when: ansible_distribution_major_version == "7"# 设置只有RedHat家族才能用这个模块来安装httpd，并且版本应该是7，如果是CentOS6的话也不会安装httpd - name: start httpd service: name=httpd state=started when: ansible_distribution_major_version == "7"# 如果不加判断条件，CentOS6也会启动httpd服务 - name: install httpd apt: name=apache2 state=latest when: ansible_os_family == "Debian"ansible-playbook -C os.yaml# 显示结果中有skipping表示跳过，用蓝色表示，因为条件不满足ansible-playbook os.yaml 迭代12345678910111213141516vim item.yaml - hosts: websrvs remote_user: root tasks: - name: install &#123;&#123; item &#125;&#125; package yum: name=&#123;&#123; item &#125;&#125; state=latest with_items: - nginx - tomcat - mariadb-server - redis# 用with_items指明变量，用yum中的name调用这些变量并安装。ansible-playbook -C item.yamlansible-playbook item.yamlansible websrvs -a "rpm -q nginx"# 查看刚才的包是否都安装了 测试角色123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778角色创建流程1. 定义配置文件中roles的路径2. 创建角色目录 --&gt; 创建任务（可以通过when设置条件，调用模板，设置标签）3. 创建调用任务的文件4. 创建配置文件模板vim /etc/ansible/ansible.cfg roles_path = /etc/ansible/roles:/usr/share/ansible/roles# 模块要放至的路径。这里定义了两个路径，用冒号相连，用哪个都可以。mkdir -pv /etc/ansible/roles/nginx/&#123;tasks,vars,templates,files,handlers,meta,default&#125;# 在配置文件中定义的roles路径下创建角色，就叫nginx。这些目录中只有tasks是必须有的。tasks定义任务，vars定义变量，templates定义模板，files定义配置文件vim /etc/ansible/roles/nginx/tasks/main.yml - name: install nginx yum: name=nginx state=latest when: ansible_os_family == "RedHat"# 因为就是在tasks目录中，所以在配置文件中不用再写tasks了。所有的角色文件都要叫main.ymlvim nginx.yml - hosts: websrvs remote_user: root roles: # 调用角色，可以调用多个，这里只调用上面定义的nginx角色 - nginxansible-playbook --syntax-check nginx.ymlansible-playbook -C nginx.ymlansible-playbook nginx.ymlvim /etc/ansible/roles/nginx/templates/vhost1.conf.j2 server &#123; listen 80; server_name &#123;&#123; ansible_fqdn &#125;&#125;;# 用ansible的setup获取到的ansible_fqdn变量的名字，这个变量就是主机名。这里的fqdn解析的是目标主机的主机名，但要在目标主机的/etc/hosts中加入对自己的解析，也就是IP到本机主机名的解析。如果不加，显示会有问题，测试中，用ansible 10.5.5.159 -m setup|grep ansible_fqdn查看到的fqdn都是www.master.com，在10.5.5.159的/etc/hosts文件中加入对自己的解析后，前面的命令可以正常显示。 location / &#123; root "/ngxdata/vhost1"; &#125; &#125;# 创建nginx的配置文件模板vim /etc/ansible/roles/nginx/tasks/main.yml - name: install nginx yum: name=nginx state=latest when: ansible_os_family == "RedHat" - name: install conf template: src=vhost1.conf.j2 dest=/etc/nginx/conf.d/vhost1.conf# templates可以自动找到模板文件，不用写父目录，它会去templates目录查找 tags: conf notify: restart nginx # 这个名字要与handlers中的main.yml中的name定义的名字一致；这是当配置文件有变更时重启服务 - name: install site home directory file: path=&#123;&#123; ngxroot &#125;&#125; state=directory# 创建目录，ngxroot变量是在下面的vars子目录中创建的 - name: install index page copy: src=index.html dest=&#123;&#123; ngxroot &#125;&#125;/# index.html文件是在files子目录中创建的，运行时会在目标主机自动创建。运行时ansible会自动到files子目录中查找 - name: start nginx service: name=nginx state=started vim /etc/ansible/roles/nginx/handlers/main.yml - name: restart nginx service: name=nginx state=restarted# handlers中是由特殊条件触发的任务，这里定义的是上面的配置文件如果有变化，会通知这里的restart nginx，在这里定义了会重启nginx服务。vim /etc/ansible/roles/nginx/vars/main.yml ngxroot: /ngxdata/vhost1 # 这里不能用-线，这表示字典模式。定义一个页面的目录路径，在tasks的main.yml中的file中调用vim /etc/ansible/roles/nginx/files/index.html vhosts1ansible-playbook -C nginx.ymlansible-playbook nginx.yml# 完成后，目标主机就会安装上nginx，在nginx的配置目录conf.d中会有一个vhost1.conf的配置文件，在其中定义了内容是vhost1，这时只要将本机的hosts文件配置可以正确解析主机名到IP就可以访问了，如curl test3，会显示vhost1。vim /etc/hosts 10.5.5.160 test3.ccjd.com 10.5.5.159 test2.ccjd.com 10.5.5.158 test1scp /etc/hosts root@10.5.5.159:/etc scp /etc/hosts root@10.5.5.160:/etc# 最后修改hosts文件并复制到所有主机是必不可少的，因为如果不能解析本机的主机名，在ansible的setup模块中的ansible_fqdn就无法正解解析每台主机的主机名或fqdn。 部署测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113准备三台主机，主机信息如下IP : 10.5.5.158 app : nginx、ansible；hostname : test1IP : 10.5.5.159 app : tomcat、tomcat-admin-webapps、tomcat-webapps、tomcat-docs-webapp；hostname : test2.ccjd.comIP : 10.5.5.160 app : tomcat、tomcat-admin-webapps、tomcat-webapps、tomcat-docs-webapp；hostname : test3.ccjd.com效果：nginx反向代理到两台tomcat主机。还可以在tomcat上再部署httpd，nginx反代到httpd，再由httpd反代到tomcat上。* test1** 安装软件包、配置hosts文件yum install -y epel-releaseyum install -y ansiblevim /etc/hosts 10.5.5.160 test3.ccjd.com 10.5.5.159 test2.ccjd.com 10.5.5.158 test1rsync -e ssh -avzr --progress /etc/hosts root@10.5.5.159:/etc/hostsrsync -e ssh -avzr --progress /etc/hosts root@10.5.5.160:/etc/hosts** 生成密钥，实现无密码访问ssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub root@test1ssh-copy-id -i ~/.ssh/id_rsa.pub root@test2.ccjd.comssh-copy-id -i ~/.ssh/id_rsa.pub root@test3.ccjd.com** 配置ansible地址vim /etc/ansible.conf[websrvs] 10.5.5.160 10.5.5.159 test[2:3].ccjd.com# 写成IP或主机名均可，但最好只写一个。这里以主机名为例。[localhost] 10.5.5.158 test1ansible all --list-hostsansible test1 -a "hostname"ansible test2.ccjd.com -a "hostname"ansible test3.ccjd.com -a "hostname"ansible localhost --list-hostsansible websrvs --list-hostsmkdir -pv /etc/ansible/roles/&#123;nginx,tomcat,jdk&#125;/&#123;files,templates,tasks,handlers,vars,meta,default&#125;** 设置ansible剧本cd /etc/ansible/roles/nginxvim tasks/main.yml - name: install nginx yum: name=nginx state=latest when: ansible_os_family == "RedHat"# 当系统是RedHat系列时，安装nginx - name: install conf copy: src=lb.conf dest=/etc/nginx/conf.d/ notify: restart redis# 复制配置文件到目标路径 - name: start nginx service: name=nginx state=started enabled=yes# 启动nginx，并设置开机启动vim handlers/main.yml - name: restart nginx service: name=nginx state=restarted# 当有变更时，可调用此模块重启nginx服务vim files/lb.conf //设置配置文件，以便在tasks中调用 upstream tcsrvs &#123; server test2.ccjd.com:8080; server test3.ccjd.com:8080; &#125;# 配置tomcat的两个地址和端口，之后会反代到这两个地址。 server &#123; listen 80; server_name www.ruopu.com; location / &#123; proxy_pass http://tcsrvs; &#125; &#125;cd /etc/ansible/roles/tomcatvim tasks/main.yml - name: install package yum: name=&#123;&#123; item &#125;&#125; state=latest# 这里调用item函数，在下面设置item的内容 with_items: - tomcat - tomcat-admin-webapps - tomcat-webapps - tomcat-docs-webapp when: ansible_os_family == "RedHat" - name: start tomcat service: name=tomcat state=started enabled=yescd /etc/ansible/roles/jdkvim tasks/main.yml - name: install openjdk yum: name=java-&#123;&#123; version &#125;&#125;-openjdk-devel state=latest# 这里的version函数的内容可以在nginx.yml中定义，也可以在vars模块中定义。 - name: install env file copy: src=java.sh dest=/etc/profile.d/vim files/java.sh export JAVA_HOME=/usrvim vars/main.yml version: 1.8.0 # 字典。这是在vars中定义versionvim balance.yml - hosts: localhost remote_user: root roles: - nginx - hosts: websrvs remote_user: root roles: - jdk# 如果在这个文件中定义version函数，上面要写成"- &#123; role: jdk, version: 1.8.0 &#125;" - tomcatansible-playbook -C /etc/ansible/roles/nginx/balance.ymlansible-playbook /etc/ansible/roles/nginx/balance.yml访问www.ruopu.com，这时显示的是tomcat页面。访问时出现问题，提示502 Bad Gateway，这是nginx反代服务器上的selinux没有关闭的问题在node2和3节点上查看是否安装的是1.8.0版本的javarpm -qa | grep "^java"或java -version zk+kafka部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104准备三台主机，主机信息如下IP : 10.5.5.158 app : zookeeper-3.4.9、kafka_2.12-0.10.2.0；hostname : kafka1IP : 10.5.5.159 app : zookeeper-3.4.9、kafka_2.12-0.10.2.0；hostname : kafka2IP : 10.5.5.160 app : zookeeper-3.4.9、kafka_2.12-0.10.2.0；hostname : kafka3在158主机上安装ansible，实现zk+kafka集群** kafka1hostnamectl set-hostname kafka1yum install -y ansiblevim /etc/hosts 10.5.5.158 kafka1 10.5.5.159 kafka2 10.5.5.160 kafka3rsync -e ssh -arvz --progress /etc/hosts root@kafka2:/etc/hostsrsync -e ssh -arvz --progress /etc/hosts root@kafka3:/etc/hosts# 使用rsync的条件是两端都要安装此包，不然是不能使用的。ssh-keygen -t rsa -P ''ssh-copy-id -i ~/.ssh/id_rsa.pub root@kafka1ssh-copy-id -i ~/.ssh/id_rsa.pub root@kafka2ssh-copy-id -i ~/.ssh/id_rsa.pub root@kafka3vim /etc/ansible/hosts [kafka] kafka[1:3]mkdir -pv /etc/ansible/roles/&#123;kafka,zk,jdk&#125;/&#123;files,templates,handlers,defaults,vars,tasks,meta&#125;cd /etc/ansible/roles/jdkvim tasks/main.yml - name: install openjdk yum: name=java-&#123;&#123; version &#125;&#125;-openjdk-devel state=latest - name: install env file copy: src=java.sh dest=/etc/profile.d/vim files/java.sh export JAVA_HOME=/usrvim vars/main.yml version: 1.8.0cd /etc/ansible/roles/zkvim tasks/main.yml - name: install zookeeper shell: tar xf /root/zookeeper-3.4.9.tar.gz -C /usr/local/ &amp;&amp; ln -sv /usr/local/zookeeper-3.4.9 /usr/local/zookeeper - name: Establish directory shell: mkdir -pv /usr/local/zookeeper/&#123;data,logs&#125; - name: install myid template: src=myid.conf.j2 dest=/usr/local/zookeeper/data/myid - name: install conf copy: src=zoo.cfg dest=/usr/local/zookeeper/conf/ tags: zkconf notify: restart zookeeper - name: start zookeeper shell: /usr/local/zookeeper/bin/zkServer.sh startvim handlers/main.yml - name: restart zookeeper shell: /usr/local/zookeeper/bin/zkServer.sh restartvim files/zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/usr/local/zookeeper/data dataLogDir=/usr/local/zookeeper/logs clientPort=2181 server.1=10.5.5.158:2888:3888 server.2=10.5.5.159:2888:3888 server.3=10.5.5.160:2888:3888vim templates/myid.conf.j2 &#123;&#123; ansible_fqdn &#125;&#125;cd /etc/ansible/roles/kafkavim tasks/main.yml - name: install kafka shell: tar -zxf /root/kafka_2.12-0.10.2.0.tgz -C /usr/local &amp;&amp; ln -sv /usr/local/kafka_2.12-0.10.2.0 /usr/local/kafka - name: install conf template: src=server.properties dest=/usr/local/kafka/config/server.properties tags: kaconf notify: restart kafka - name: start kafka shell: nohup /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties &amp;# 必须让kafka在后台运行，不然在执行剧本时会卡在最后的任务不能正确退出。vim handlers/main.yml - name: restart kafka shell: /usr/local/kafka/bin/kafka-server-stop.sh &amp;&amp; nohup /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties &amp;vim templates/server.properties broker.id=&#123;&#123; ansible_fqdn &#125;&#125; delete.topic.enable=true host.name=&#123;&#123; ansible_default_ipv4[ "address"] &#125;&#125;# 后面是一个引用setup模块输出的子模块的方法，前面要用主模块的名，后面跟[]，在中括号中写上子模块的名字并用引号括起即可。 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 log.dirs=/usr/local/kafka/logs num.partitions=1 num.recovery.threads.per.data.dir=1 log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 zookeeper.connect=10.5.5.158:2181,10.5.5.159:2181,10.5.5.160:2181 zookeeper.connection.timeout.ms=6000vim zk.yml - hosts: kafka remote_user: root roles: - jdk - zk - kafka*** 在执行剧本前，先将kafka_2.12-0.10.2.0.tgz和zookeeper-3.4.9.tar.gz两个包复制到三台主机的root目录。另外，将三台主机的主机名分别改为1、2、3，这是为了在kafka的配置文件server.properties中引用fqdn参数时方便设置broker.id，没有想到其他办法将一个模板配置文件复制到不同主机时可以使用不同的id号，所以使用了此种方法。ansible-playbook /etc/ansible/roles/kafka/zk.yml 普通用户管理ansible12345678910111213141516171819useradd ccjdecho 'centos'|passwd --stdin ccjdvim /etc/sudoers ccjd ALL=(ALL) NOPASSWD:ALL# 每台远程主机都要修改此文件，因为在远程主机上要使用普通用户执行命令并无需输入密码。或可以使用命令完成：“sed -i '$a\ccjd ALL=(ALL) NOPASSWD: ALL' /etc/sudoers”,$a表示在新的一行加入其后面的内容，如果不加$a，那么文件中的所有内容都将被替换。$ 代表的是最后一行，而 a 的动作是新增，\c表示对c转义，如果不转义，c表示取代。su - ccjdssh-keygen -t rsa -P ''# 以普通用户身份生成私钥ssh-copy-id -i ~/.ssh/id_rsa.pub 172.17.172.13# 这要求远程主机上也有ccjd用户。只有这样，才能让自己以ccjd的身份在远程执行sudo命令。vim /etc/ansible/ansible.cfg private_key_file = /home/ccjd/.ssh/id_rsa # remote_user = root# remote一行默认就是注释的chown -R ccjd.ccjd /etc/ansiblechown -R ccjd.ccjd /usr/share/ansible# 第二个文件可能没有ansible 172.17.172.13 -m shell -a "sudo yum install -y java-1.8.0-openjdk-devel"# 执行远程命令时还要加上sudo命令，不然会报错的。 问题 执行中有主机提示“”msg”: “Aborting, target uses selinux but python bindings (libselinux-python) aren’t installed!””。 解决：给主机安装libselinux-python包，如还不能解决，就彻底关闭selinux并重启。]]></content>
      <categories>
        <category>编排工具</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Create VPN]]></title>
    <url>%2F2018%2F06%2F22%2FCreate-VPN%2F</url>
    <content type="text"><![CDATA[查看系统是否支持PPP123cat /dev/ppp cat: /dev/ppp: No such device or address//如果出现以上提示则说明ppp是开启的，可以正常架设pptp服务，若出现Permission denied等其他提示，你需要先去VPS面板里看看有没有enable ppp的功能开关，如果没有则需要发个消息给你的提供商，让他们帮你开通，否则就不必要看下去了，100%无法成功配置PPTP。如果没有此包，可能通过yum安装 设置内核转发123456789* CentOS6echo 1 &gt; /proc/sys/net/ipv4/ip_forwardsed -i 's#net.ipv4.ip_forward = 0#net.ipv4.ip_forward = 1#g' /etc/sysctl.confsysctl -p* CentOS7echo 1 &gt; /proc/sys/net/ipv4/ip_forwardsed -i 's#net.ipv4.ip_forward = 0#net.ipv4.ip_forward = 1#g' /usr/lib/sysctl.d/50-default.conf//CentOS7在/usr/lib/sysctl.d/50-default.conf中设置，/etc/sysctl.conf是没有设置的sysctl -p 安装PPTP12yum install epel-releaseyum -y install pptpd 配置PPTP1234vim /etc/pptpd.conflocalip 10.5.5.70remoteip 192.168.2.200-210# 添加本机公网IP（localip）,这里因为没有公网IP，所以添加的也是内网IP，分配VPN用户的内网网段（remoteip）。 设置用户名和密码1234vim /etc/ppp/chap-secrets # client server secret IP addresses ccjd * CCjd1rj.com *//配置有四段，第二段与第四段为星号 启动pptp服务123systemctl start pptpdnetstat -tlnp//服务监听在TCP的1723端口 端口映射将公网的1723端口映射到内网的1723端口 windows客户端设置创建客户端 故障解决及使用技巧 现象：连接VPN后无法连接外网；解决：查看问题在于网关，网上有建议取消“在远程网络上使用默认网关”。测试此法可行** 查看vpn在线用户 123[root@1 ~]# last|grep still|grep pppccjd ppp1 106.38.36.98 Tue Oct 9 09:53 still logged in ccjd ppp0 106.38.36.98 Tue Oct 9 00:09 still logged in]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>创建PPTP_VPN</tag>
      </tags>
  </entry>
</search>
